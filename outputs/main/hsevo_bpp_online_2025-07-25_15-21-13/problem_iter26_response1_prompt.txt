{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritizes bins by combining normalized fit feasibility, dynamically adjusted sigmoid penalties,\n    and adaptive midpoint based on item and bin characteristics.\n    \"\"\"\n    # Check if the item can fit in the bin\n    can_fit = (bins_remain_cap >= item).astype(float)\n    \n    # Normalize remaining capacity\n    norm_remain_cap = (bins_remain_cap - np.min(bins_remain_cap)) / (np.max(bins_remain_cap) - np.min(bins_remain_cap) + 1e-6)\n    \n    # Calculate adaptive midpoint based on item size relative to bin capacity\n    midpoint = item / (np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 1e-6)\n    \n    # Calculate dynamic penalty factor based on item size\n    penalty_factor = 6.0 + 2 * (item / (np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 1e-6))\n    \n    # Calculate adaptive sigmoid penalty to adjust priority based on remaining capacity and item size\n    sigmoid_penalty = 1 / (1 + np.exp(-penalty_factor * (norm_remain_cap - midpoint)))\n    \n    # Calculate adjusted penalty based on remaining capacity and item size\n    penalty = (bins_remain_cap - item) / (np.max(bins_remain_cap) + 1e-6)\n    \n    # Combine feasibility, sigmoid penalty, and adjusted penalty to calculate priority scores\n    priority_scores = can_fit * sigmoid_penalty / (penalty + 1e-6)\n    \n    return priority_scores\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritizes bins by combining fit feasibility, dynamic sigmoid penalties, and normalized capacity.\n    \"\"\"\n    can_fit = (bins_remain_cap >= item).astype(float)  # Check if item fits in the bin\n    norm_remain_cap = (bins_remain_cap - np.min(bins_remain_cap)) / (np.max(bins_remain_cap) - np.min(bins_remain_cap) + 1e-6)\n    x0 = item / (np.max(bins_remain_cap) + 1e-6)  # Dynamic midpoint based on item size\n    penalty = (bins_remain_cap - item) / (np.max(bins_remain_cap) + 1e-6)  # Adaptive penalty\n    sigmoid_steepness = 10.0  # Tuned sigmoid steepness\n    sigmoid_priority = 1 / (1 + np.exp(-sigmoid_steepness * (norm_remain_cap - x0)))\n    adaptive_influence = sigmoid_priority / (penalty + 1e-6)\n    priority_scores = can_fit * adaptive_influence\n    return priority_scores\n\n### Analyze & experience\n- Comparing (best) vs (worst), we see that the best heuristics utilize detailed calculations for midpoint and penalty factor, ensuring nuanced bin prioritization. The worst heuristics lack variation, reuse similar calculations, and do not adapt well to different item sizes.\n(Second best) vs (second worst) shows that adaptive parameters (penalty factor, midpoint) and sigmoid steepness play a significant role in distinguishing better heuristics.\nComparing (1st) vs (2nd), we see almost identical code with minor differences in constants, indicating the importance of fine-tuning parameters for optimal performance.\n(3rd) vs (4th) further confirms that slight variations in penalty and midpoint calculation do not significantly impact the outcome, suggesting a need for more substantial alterations in heuristic design.\nComparing (second worst) vs (worst), we see that there are no discernible differences in logic or parameters, reinforcing the notion that the core design of the heuristic is crucial.\nOverall:\n- \n- **Keywords**: Adaptive parameters, dynamic adjustments, normalized normalization, unique design, sigmoid functions, flexibility, specificity.\n  \n- **Advice**: \n  - Focus on unique and adaptive design over minor parameter tweaking.\n  - Combine normalization techniques with adaptive sigmoid functions for better accuracy.\n  - Use item and bin characteristics for dynamic parameter adjustment.\n  - Prioritize specificity and simplicity in dynamic penalization.\n\n- **Avoid**: \n  - Fixed methods and static penalties.\n  - Unnecessary complexity and redundant calculations.\n  - Paradoxical adaptive factors.\n\n- **Explanation**: \n  Effective self-reflection highlights the importance of adaptability and specificity in heuristic design, emphasizing that unique approaches and simple yet powerful adjustments lead to better performance. Avoidance of fixed methods and unnecessary complexity ensures that the heuristics remain versatile and efficient, improving their applicability to a wider range of problems.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}