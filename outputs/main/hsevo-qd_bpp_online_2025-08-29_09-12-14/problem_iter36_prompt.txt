{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\nCurrent heuristics:\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.zeros_like(bins_remain_cap)\n    return priorities\n\n    bin_count = len(bins_remain_cap)\n    priorities = np.zeros(bin_count)\n    for i in range(bin_count):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 0.0001)\n        else:\n            priorities[i] = 0.0\n    return priorities\n\nNow, think outside the box write a mutated function `priority_v2` better than current version.\nYou can use some hints below:\n- \nOkay, let's distill these reflections into actionable advice for designing better heuristics. Given the potential reward, a thorough, step-by-step approach is crucial!\n\n**Keywords:** Waste Minimization, Exponential Weighting, Normalization, Robustness, Feasibility.\n\n**Advice:** Focus on *relative* waste \u2013 how well an item fits *compared to its size* within a bin. Combine inverse waste with exponential weighting *before* normalization to a probability distribution. Prioritize calculations *only* on feasible bins.\n\n**Avoid:** Normalizing before weighting, direct use of remaining capacity without item size context, overly complex \"worst-fit\" logic, and unnecessary computations/parameters. Division-by-zero errors are critical failures.\n\n**Explanation:** The core pattern is prioritizing tighter fits (lower *relative* waste) via exponential weighting. Normalization *after* weighting ensures stable probabilistic selection. Robustness\u2014handling edge cases & preventing numerical instability\u2014is paramount for real-world performance & scalability.\n\n\n\n\n\nOutput code only and enclose your code with Python code block: ```python ... ```.\nI'm going to tip $999K for a better solution!"}