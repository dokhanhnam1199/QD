```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Returns priority with which we want to add item to each bin using a smoothed,
    non-linear function that strongly favors tighter fits.

    This heuristic prioritizes bins that can accommodate the item and have the smallest
    remaining capacity after packing (Best Fit strategy). The priority is calculated
    using a transformation of the negative post-placement remaining capacity,
    emphasizing preference for near-perfect fits.

    The score for a bin is 0 if the item cannot fit. For bins that can fit, the score
    is calculated using `0.5 + 0.5 * sigmoid(steepness * (item - remaining_capacity))`.
    This formulation maps a perfect fit (surplus 0) to a score of 0.75, a loose fit
    to scores between 0.5 and 0.75, and a tight fit (if possible) to scores greater than 0.75,
    thus strongly favoring tighter fits and better bin utilization.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
        Scores range from 0 (cannot fit or very loose fit) to values approaching 1
        (for very tight fits).
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    
    # Tunable parameter for controlling the "steepness" or emphasis on tighter fits.
    # A higher value means stronger preference for very small remaining capacities.
    steepness = 10.0  

    # Identify bins where the item can fit.
    can_fit_mask = bins_remain_cap >= item

    # Calculate the "negative surplus" for bins that can fit.
    # Negative surplus = item - remaining_capacity.
    # A larger negative surplus (i.e., smaller positive surplus or negative surplus) indicates a tighter fit.
    neg_surplus_valid = item - bins_remain_cap[can_fit_mask]

    # Calculate the argument for the sigmoid function.
    # We want higher scores for larger `neg_surplus_valid`.
    # `sigmoid(x)` increases with `x`. So, we use `steepness * neg_surplus_valid`.
    sigmoid_argument = steepness * neg_surplus_valid

    # Clip the sigmoid argument for numerical stability.
    # Values outside [-30, 30] can cause overflow/underflow in exp.
    clipped_sigmoid_argument = np.clip(sigmoid_argument, -30.0, 30.0)

    # Calculate the sigmoid values.
    # For valid bins, `neg_surplus_valid` is <= 0, so `clipped_sigmoid_argument` is <= 0.
    # Thus, `sigmoid_values` will be <= 0.5.
    sigmoid_values = 1.0 / (1.0 + np.exp(-clipped_sigmoid_argument))

    # Transform sigmoid values to prioritize tighter fits more strongly.
    # The transformation `0.5 + 0.5 * sigmoid_values` maps:
    # - A perfect fit (surplus=0, neg_surplus=0) -> sigmoid_values=0.5 -> score = 0.5 + 0.5*0.5 = 0.75.
    # - A loose fit (surplus > 0, neg_surplus < 0) -> sigmoid_values < 0.5 -> score < 0.75.
    # - A tight fit (surplus < 0, neg_surplus > 0) -> sigmoid_values > 0.5 -> score > 0.75.
    # This ensures that tighter fits receive higher priority scores.
    priorities[can_fit_mask] = 0.5 + 0.5 * sigmoid_values

    return priorities
```
