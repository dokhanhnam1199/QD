[
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin using Sigmoid Best Fit.\n\n    This heuristic prioritizes bins that can accommodate the item and have the smallest\n    remaining capacity after packing (Best Fit strategy). The priority is calculated\n    using a sigmoid function to provide a smooth ranking, strongly favoring tighter fits.\n\n    The score for a bin is 0 if the item cannot fit. For bins that can fit, the score\n    is calculated as 1 / (1 + exp(steepness * (remaining_capacity - item))).\n    This function is monotonically decreasing with respect to (remaining_capacity - item),\n    meaning smaller non-negative remaining capacities get higher scores.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Scores range from 0 (cannot fit or very loose fit) to 1 (perfect or near-perfect fit).\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    steepness = 5.0  # Tunable parameter: higher values mean stronger preference for tight fits.\n\n    # Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity for bins that can fit the item.\n    # If a bin can fit, the remaining capacity after packing is: bins_remain_cap[i] - item\n    potential_remaining_cap_valid = bins_remain_cap[can_fit_mask] - item\n\n    # Calculate the exponent argument for the sigmoid function.\n    # We want to prioritize smaller `potential_remaining_cap_valid`.\n    # The function `1 / (1 + exp(x))` is decreasing in `x`.\n    # To make it decrease as `potential_remaining_cap_valid` increases, we set `x = steepness * potential_remaining_cap_valid`.\n    # A small `potential_remaining_cap_valid` (tight fit) results in a smaller `x`, thus a higher score.\n    # A large `potential_remaining_cap_valid` (loose fit) results in a larger `x`, thus a lower score.\n    exponent_args = steepness * potential_remaining_cap_valid\n\n    # Clip the exponent arguments to prevent potential overflow/underflow in np.exp.\n    # Values like +/- 700 can cause issues. A range like [-30, 30] is generally safe.\n    # For very negative args, exp -> 0, score -> 1. For very positive args, exp -> inf, score -> 0.\n    clipped_exponent_args = np.clip(exponent_args, -30.0, 30.0)\n\n    # Calculate the priority scores for the valid bins using the sigmoid function.\n    # priorities[can_fit_mask] will be populated with scores between ~0.5 (for perfect fit) and ~0 (for very loose fits).\n    # Scores for bins that cannot fit remain 0.\n    priorities[can_fit_mask] = 1.0 / (1.0 + np.exp(clipped_exponent_args))\n\n    return priorities",
    "response_id": 0,
    "obj": 3.9888312724371757,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response1.txt_stdout.txt",
    "code_path": "problem_iter2_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Exact Fit First then Best Fit.\n\n    The strategy prioritizes bins that can exactly fit the item (Exact Fit).\n    If no bin can exactly fit the item, it prioritizes bins that leave the\n    smallest remaining capacity after placing the item (Best Fit).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit, assign priorities:\n    # 1. Exact Fit: Highest priority.\n    # 2. Best Fit: Remaining capacity is minimized.\n\n    # Identify exact fit bins\n    exact_fit_mask = (bins_remain_cap == item)\n\n    # Assign a very high priority to exact fit bins.\n    # A score like 1.0 can represent the highest tier.\n    priorities[exact_fit_mask] = 1.0\n\n    # For bins that can fit but are not exact fits, assign a secondary priority.\n    # This priority should be less than 1.0 and higher for bins with smaller remaining capacity.\n    # We can use a score derived from the remaining capacity: `1 - (remaining_capacity / MAX_POSSIBLE_REMAINING_CAPACITY)`.\n    # A simpler approach is to directly rank by remaining capacity, ensuring it's lower than exact fit.\n    # We can use `1 - (remaining_capacity / sum_of_all_capacities)` or a similar normalization,\n    # but for simplicity and to maintain hierarchy, we can subtract the remaining capacity from a value just below 1.0.\n\n    # Consider only bins that can fit but are not exact fits.\n    non_exact_can_fit_mask = can_fit_mask & ~exact_fit_mask\n\n    if np.any(non_exact_can_fit_mask):\n        # Calculate the remaining capacity after fitting the item for these bins.\n        remaining_after_fit_values = bins_remain_cap[non_exact_can_fit_mask] - item\n\n        # To prioritize smaller remaining capacities, we can use a score that\n        # decreases as remaining capacity increases.\n        # A common approach is to use `-(remaining_capacity)` or `max_capacity - remaining_capacity`.\n        # To keep scores between 0 and 1 (and lower than exact fit priority of 1.0),\n        # we can normalize the remaining capacity.\n        # Let's create a score that is high for small remaining capacity.\n        # We can achieve this by subtracting the `remaining_after_fit_values` from a value slightly less than 1.0,\n        # and then potentially scaling it.\n        # A simple way to ensure smaller `remaining_after_fit_values` get higher scores (closer to 1.0, but less than 1.0)\n        # is to map the range of `remaining_after_fit_values` to `[0, 0.99]`.\n        # If `remaining_after_fit_values` are all positive (which they are, as we excluded exact fits),\n        # the smallest value will give the highest priority in this tier.\n\n        # To ensure a proper ordering and a value less than 1.0, we can use:\n        # `priority = 0.99 - (remaining_after_fit_values / MAX_EXPECTED_REMAINING)`\n        # Or a simpler approach: just use the negative of the remaining capacity,\n        # and shift it to be positive and less than 1.0.\n        # Example: if remaining capacities are [0.1, 0.5], we want priorities like [0.9, 0.5].\n        # This can be achieved by `0.99 - remaining_after_fit_values`.\n        # This assigns a higher priority to bins with smaller remaining capacity.\n        # The maximum possible remaining capacity for a bin fitting `item` is `max(bins_remain_cap) - item`.\n        # However, a simpler fixed scaling can work.\n\n        # Let's assign priorities in the range [0, 0.99].\n        # We want smaller `remaining_after_fit_values` to have higher priorities.\n        # A simple way is to use `base_score - remaining_capacity`.\n        # Let's set a `base_score = 0.99`.\n        priorities[non_exact_can_fit_mask] = 0.99 - remaining_after_fit_values\n\n    # Bins that cannot fit the item retain their initial priority of 0.\n\n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 10.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score strategy with emphasis on tighter fits.\n\n    This version refines the Sigmoid Fit Score by directly focusing on the\n    \"tightness\" of the fit, which is inversely related to the remaining capacity.\n    A tighter fit (smaller remaining capacity) should yield a higher priority score.\n    The sigmoid function is used to map this tightness to a normalized priority score between 0 and 1.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # For bins that can fit the item, calculate the resulting remaining capacity.\n    # We want to prioritize bins where this resulting remaining capacity is minimized.\n    resulting_remaining_cap = bins_remain_cap[can_fit_mask] - item\n\n    # To prioritize smaller remaining capacities, we can use the inverse of\n    # the resulting remaining capacity as a measure of \"fit tightness\".\n    # A smaller resulting capacity means a larger inverse, hence a tighter fit.\n    # Add a small epsilon to avoid division by zero or extremely large values.\n    epsilon = 1e-9\n    fit_tightness = 1.0 / (resulting_remaining_cap + epsilon)\n\n    # Apply a sigmoid function to normalize the tightness scores and control\n    # the sensitivity to different degrees of tightness.\n    # The sigmoid function `1 / (1 + exp(-x))` maps larger x to values closer to 1.\n    # We scale `fit_tightness` by a factor `k` to control how strongly we\n    # favor tighter fits. A larger `k` means a steeper increase in priority\n    # as the fit becomes tighter.\n    k = 10.0  # Sensitivity parameter: higher k favors tighter fits more strongly.\n    scaled_tightness = k * fit_tightness\n    sigmoid_scores = 1 / (1 + np.exp(-scaled_tightness))\n\n    # Assign the calculated sigmoid scores to the bins that can fit the item.\n    priorities[can_fit_mask] = sigmoid_scores\n\n    return priorities",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response3.txt_stdout.txt",
    "code_path": "problem_iter2_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version implements the \"Best Fit\" heuristic for the online Bin Packing Problem.\n    The priority is higher for bins that have just enough capacity to fit the item,\n    minimizing wasted space. Bins that cannot fit the item are given a priority of 0.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority (i.e., a bin that results in\n        less remaining capacity after packing).\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Find bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the remaining capacity *after* placing the item.\n    # The \"best fit\" heuristic aims to minimize this remaining capacity.\n    # Therefore, a smaller remaining capacity should result in a higher priority score.\n    # We can achieve this by using the negative of the remaining capacity as the priority.\n    # The bin with the smallest `bins_remain_cap[i] - item` will have the largest\n    # negative value, hence the highest priority.\n    priorities[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item)\n\n    return priorities",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response4.txt_stdout.txt",
    "code_path": "problem_iter2_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Best Fit.\n\n    This version implements the \"Best Fit\" heuristic. It prioritizes bins\n    that have the least remaining capacity *after* the item is placed,\n    thereby minimizing wasted space. Bins that cannot fit the item are given\n    a priority of 0 (or a very low score).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Identify bins that have enough capacity for the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity *after* placing the item in the eligible bins\n    # We want to minimize this value for the \"best fit\"\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # To prioritize the minimum remaining capacity, we can assign a score\n    # that is inversely proportional to it, or simply the negative of it.\n    # The smaller the remaining capacity (i.e., the better the fit), the higher the priority.\n    # Using the negative of the remaining capacity achieves this:\n    # -1 is higher priority than -5.\n    # A small epsilon can be added to avoid perfect zero-remaining bins getting arbitrarily high priority\n    # if other heuristics prefer variety, but for pure \"best fit\", negative remaining capacity is direct.\n    # Let's use a slightly adjusted score: higher priority for smaller remaining capacity.\n    # A common strategy is to assign a score based on the *difference* that is maximized.\n    # The difference is `bins_remain_cap - item`. We want to minimize this.\n    # So, we can assign `-(bins_remain_cap - item)` as priority.\n    # This means a smaller positive difference becomes a larger negative number, which we want to select as the maximum.\n\n    # Assign priorities to bins that can fit the item.\n    # Higher priority means smaller remaining capacity after placing the item.\n    priorities[can_fit_mask] = -remaining_after_fit\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined Best Fit strategy for Softmax.\n\n    This priority function aims to prioritize bins that have the least remaining capacity\n    while still being able to fit the item. This is a form of Best Fit.\n    The scores are designed to be used with a softmax-like selection mechanism,\n    where higher scores indicate higher preference. A significant penalty is applied\n    to bins with a large surplus capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to a very low value for bins that cannot fit the item.\n    # Using -inf ensures that after np.exp, these bins will have a priority of 0.\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins that have enough remaining capacity to fit the item.\n    valid_mask = bins_remain_cap >= item\n\n    # For valid bins, calculate a score that reflects the \"goodness\" of the fit.\n    # We want to prioritize bins where the remaining capacity is closest to the item size.\n    # This means minimizing the \"waste\" or \"surplus capacity\": `bins_remain_cap - item`.\n    # A smaller surplus is better.\n    # A score that is inversely proportional to the surplus is desirable.\n    # Let's use `score = 1.0 / (surplus + epsilon)` or `score = -surplus`.\n    # For softmax-like application, `np.exp(score)` is used.\n    # Using `score = -surplus` directly works well:\n    # if surplus is 0, score is 0, exp(0) = 1.\n    # if surplus is 1, score is -1, exp(-1) is ~0.37.\n    # if surplus is 5, score is -5, exp(-5) is ~0.0067.\n    # This naturally penalizes larger surpluses.\n\n    surplus_capacity = bins_remain_cap[valid_mask] - item\n\n    # We want smaller surplus_capacity to yield higher scores.\n    # So, use the negative of the surplus capacity.\n    scores_for_valid_bins = -surplus_capacity\n\n    # Assign these scores to the corresponding positions in the priorities array.\n    priorities[valid_mask] = scores_for_valid_bins\n\n    # The resulting priorities are the exponents for a softmax distribution.\n    # Higher values indicate higher preference.\n    return np.exp(priorities)",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response6.txt_stdout.txt",
    "code_path": "problem_iter2_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Softmax-Based Fit.\n\n    The priority is calculated based on how well an item fits into a bin.\n    A higher priority is given to bins where the remaining capacity is just enough\n    or slightly more than the item size (i.e., minimal surplus). A large surplus capacity is penalized.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to a very low value (negative infinity) for invalid bins.\n    # This ensures that when exp is applied, their priority becomes effectively zero.\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins that can accommodate the item.\n    valid_mask = bins_remain_cap >= item\n\n    # For valid bins, calculate a score that is higher for bins with less surplus capacity.\n    # Surplus capacity is defined as `bins_remain_cap - item`.\n    # We want to maximize the score as surplus capacity decreases.\n    # A simple score function is the negative of the surplus capacity: `-(bins_remain_cap - item)`.\n    # This means a bin with `bins_remain_cap == item` gets a score of 0.\n    # A bin with `bins_remain_cap == item + 1` gets a score of -1.\n    # A bin with `bins_remain_cap == item + 10` gets a score of -10.\n    # When `np.exp()` is applied, these scores are transformed into probabilities.\n    # A score of 0 yields `exp(0) = 1`.\n    # A score of -1 yields `exp(-1) \u2248 0.368`.\n    # A score of -10 yields `exp(-10) \u2248 0.000045`.\n    # This transformation ensures that bins with less surplus capacity have higher priorities.\n\n    surplus_capacity = bins_remain_cap[valid_mask] - item\n    scores_for_valid_bins = -surplus_capacity\n\n    # Assign the calculated scores to the priorities array for valid bins.\n    priorities[valid_mask] = scores_for_valid_bins\n\n    # Apply the exponential function to the scores. This is the core of the Softmax approach.\n    # The resulting values can be interpreted as unnormalized probabilities or weights.\n    # The bin with the highest score will have the highest priority after exponentiation.\n    return np.exp(priorities)",
    "response_id": 6,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response7.txt_stdout.txt",
    "code_path": "problem_iter2_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a heuristic that prioritizes minimal waste.\n\n    This priority function aims to minimize wasted space in bins. It assigns higher\n    priority to bins where the remaining capacity is just enough or slightly more than\n    the item size. Bins that are too small to fit the item are given a priority of zero.\n    The priority is calculated using a function that rewards smaller positive differences\n    between remaining capacity and item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    # Initialize priorities to zero for all bins. Bins that cannot fit the item will retain this zero priority.\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Identify bins that have enough remaining capacity to fit the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate a score based on the \"waste\" (remaining capacity - item size).\n    # We want to reward bins with minimal waste. A smaller waste should result in a higher score.\n    # A function like `1 / (waste + epsilon)` or `exp(-waste / temperature)` can achieve this.\n    # Let's use `1 / (waste + 1e-6)` to give higher scores to smaller positive waste.\n    # Adding a small epsilon (1e-6) to the denominator prevents division by zero if remaining_capacity == item.\n    \n    waste = bins_remain_cap[can_fit_mask] - item\n    \n    # The score is the inverse of the waste. Higher score for lower waste.\n    # We add a small constant to avoid division by zero if item perfectly fits.\n    # A perfectly fitting bin (waste=0) should have the highest priority.\n    # Let's map `waste=0` to a high score and increasing `waste` to decreasing scores.\n    # `1.0 / (waste + 1.0)` maps 0 waste to 1, 1 waste to 0.5, 5 waste to 0.16, etc.\n    # This seems like a good heuristic for minimizing waste.\n\n    scores = 1.0 / (waste + 1.0) # Adding 1.0 to ensure even waste=0 results in a finite score >= 1\n\n    priorities[can_fit_mask] = scores\n\n    return priorities",
    "response_id": 7,
    "obj": 4.198244914240141,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response8.txt_stdout.txt",
    "code_path": "problem_iter2_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined Best Fit strategy.\n\n    This strategy prioritizes bins that have the smallest remaining capacity after packing the item,\n    provided the item fits. Bins that cannot accommodate the item receive a priority of 0.\n    The priority score is designed such that bins with a remaining capacity closer to zero\n    receive higher scores. A sigmoid function is used to provide a smooth ranking.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # For bins that can fit the item, calculate the remaining capacity after packing\n    potential_remaining_cap = bins_remain_cap - item\n    \n    # We want to prioritize bins with the smallest non-negative remaining capacity.\n    # This is a \"Best Fit\" approach. To translate this into a priority score\n    # where higher is better, we can use a function that decreases as\n    # `potential_remaining_cap` increases for `potential_remaining_cap >= 0`.\n    # A sigmoid function of the form `1 / (1 + exp(k * x))` is decreasing if `k > 0`.\n    # Let `x = potential_remaining_cap`.\n    # The larger `potential_remaining_cap` is, the smaller the score will be.\n    # The ideal case is `potential_remaining_cap = 0`, which gives a score of 0.5.\n    # Larger positive remaining capacity gives scores less than 0.5, approaching 0.\n    # This accurately ranks bins by their \"tightness\" of fit among eligible bins.\n    \n    # A steepness parameter controls how quickly the priority drops as remaining capacity increases.\n    # A higher steepness means a stronger preference for tighter fits.\n    steepness = 10.0 # Tunable parameter, higher means more preference for tighter fits\n\n    # Calculate the argument for the sigmoid function for eligible bins.\n    # We use `potential_remaining_cap` directly.\n    exponent_args = steepness * potential_remaining_cap[can_fit_mask]\n    \n    # To avoid numerical overflow/underflow with np.exp, clip the exponent arguments.\n    # Values like exp(700) or exp(-700) can cause issues. A range of [-30, 30] is usually safe.\n    clipped_exponent_args = np.clip(exponent_args, -30.0, 30.0)\n    \n    # Calculate the priority scores using the sigmoid function for eligible bins.\n    # The score will be between (0, 1). Higher scores mean a better fit.\n    priorities[can_fit_mask] = 1.0 / (1.0 + np.exp(clipped_exponent_args))\n    \n    # Bins that cannot fit the item (can_fit_mask is False) retain their initial priority of 0.\n    \n    return priorities",
    "response_id": 8,
    "obj": 4.108496210610296,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response9.txt_stdout.txt",
    "code_path": "problem_iter2_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This heuristic prioritizes exact fits for the item.\n    Among bins that can fit the item but not exactly, it gives higher priority\n    to bins that would have the least remaining capacity after packing the item.\n    Bins that cannot fit the item receive the lowest priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to a low value for bins that cannot fit the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if len(fitting_bins_indices) > 0:\n        # Calculate the remaining capacity if the item is placed in a fitting bin\n        remaining_after_fit = bins_remain_cap[fitting_bins_indices] - item\n\n        # Assign a base priority to all fitting bins.\n        # This base priority should be lower than the bonus for exact fits.\n        # We can use the negative of the remaining capacity to favor smaller remaining capacities.\n        # The smaller (less negative) the value, the higher the priority.\n        # E.g., if remaining capacities are [0.5, 0.1, 0.8], we want higher priority for 0.1.\n        # Using -remaining_capacity: [-0.5, -0.1, -0.8]. Argmax would pick -0.1.\n        priorities[fitting_bins_indices] = -remaining_after_fit\n\n        # Identify exact fits and give them a significantly higher priority.\n        # We can add a large constant to the priority of exact fits.\n        # This constant should be larger than the maximum possible value of -remaining_after_fit.\n        # The minimum value of remaining_after_fit is 0 (for exact fits).\n        # The maximum value of remaining_after_fit could be up to the bin capacity.\n        # If we assign -remaining_after_fit, the range is roughly [-(max_capacity), 0].\n        # Adding a value larger than max_capacity will ensure exact fits are always preferred.\n        exact_fit_mask = (remaining_after_fit == 0)\n        if np.any(exact_fit_mask):\n            # Add a bonus that is greater than any possible non-exact fit priority.\n            # The maximum possible priority from -remaining_after_fit is 0.\n            # Any value > 0 will work as a bonus. Let's use a substantial bonus.\n            bonus = 100.0\n            priorities[fitting_bins_indices[exact_fit_mask]] += bonus\n\n    return priorities",
    "response_id": 9,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 53, in priority_v2\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n12\n3\n"
  },
  {
    "stdout_filepath": "problem_iter3_response0.txt_stdout.txt",
    "code_path": "problem_iter3_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\n...",
    "response_id": 0,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\nImportError: cannot import name 'priority_v2' from 'gpt' (/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py)\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/SLOC.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\nImportError: cannot import name 'priority_v2' from 'gpt' (/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py)\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/cyclomatic_complexity.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\nImportError: cannot import name 'priority_v2' from 'gpt' (/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py)\n"
  },
  {
    "stdout_filepath": "problem_iter3_response1.txt_stdout.txt",
    "code_path": "problem_iter3_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin using an\n    enhanced Sigmoid Best Fit.\n\n    This heuristic prioritizes bins that can accommodate the item.\n    It favors bins that result in a smaller remaining capacity after packing\n    (Best Fit strategy). To achieve this, it uses a sigmoid function applied\n    to the negative of the excess capacity (capacity - item). This means\n    bins with exactly the item's size (zero excess capacity) get the highest\n    priority (close to 1), and bins with a slight excess get progressively\n    lower priorities. Bins that cannot fit the item receive a priority of 0.\n\n    The score for a bin is 0 if the item cannot fit. For bins that can fit,\n    the score is calculated as 1 / (1 + exp(-steepness * (bins_remain_cap - item))).\n    This formulation emphasizes exact fits and penalizes larger remaining\n    capacities more strongly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Scores range from 0 (cannot fit or very loose fit) to 1 (perfect fit).\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    steepness = 5.0  # Tunable parameter: higher values mean stronger preference for tight fits.\n\n    # Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the \"closeness\" score for bins that can fit.\n    # We want to reward bins where (bins_remain_cap - item) is small.\n    # The sigmoid function 1 / (1 + exp(-x)) increases with x.\n    # So, we want x to be large when (bins_remain_cap - item) is small.\n    # Setting x = steepness * (bins_remain_cap - item) doesn't quite do this directly.\n    # Instead, let's consider the \"waste\" or \"excess capacity\" if we fit the item.\n    # If we fit the item into a bin with capacity C, the remaining capacity is C - item.\n    # We want to prioritize smaller values of (C - item).\n    # A good way to do this with sigmoid is to use the negative of the difference\n    # as the argument to exp: `exp(-steepness * (C - item))`.\n    # When (C - item) is 0 (perfect fit), the argument is 0, exp(0)=1, score = 1/(1+1) = 0.5.\n    # Wait, the prior reflection suggested prioritizing exact matches, which should be score 1.\n    # Let's re-evaluate:\n    # Sigmoid: `S(x) = 1 / (1 + exp(-x))`\n    # If we want score 1 for exact fit (remaining_cap - item = 0), then exp(-x) should be 0.\n    # This means -x should be large negative, so x should be large positive.\n    # Let's use `x = steepness * (ideal_capacity - current_capacity)`.\n    # Here, `ideal_capacity` would be the `item` size.\n    # So, `x = steepness * (item - (bins_remain_cap - item))` is not right.\n    # Let's go back to the goal: prioritize bins with smallest `bins_remain_cap - item`.\n    # If `remaining_cap_after_fit = bins_remain_cap - item`, we want to maximize\n    # a function that is high for small `remaining_cap_after_fit`.\n    # Consider `f(x) = 1 / (1 + exp(steepness * x))`. This is decreasing in x.\n    # We want it to be high for small `remaining_cap_after_fit`.\n    # So, let `x = remaining_cap_after_fit`.\n    # `priorities[can_fit_mask] = 1.0 / (1.0 + np.exp(steepness * (bins_remain_cap[can_fit_mask] - item)))`\n    # This matches priority_v1. The reflection mentioned \"prioritize exact matches\" and \"smooth preference curves\".\n    # `priority_v1` does this. For `bins_remain_cap - item = 0`, the score is 1/(1+exp(0)) = 0.5.\n    # For `bins_remain_cap - item < 0` (impossible due to mask), this would be >0.5.\n    # For `bins_remain_cap - item > 0`, the score decreases.\n    # The reflection also says \"penalizing large unused space\". This is achieved by the sigmoid.\n    #\n    # Let's try to interpret the reflection more literally:\n    # \"prioritize exact matches\" -> score 1 for `bins_remain_cap == item`.\n    # \"then bins minimizing remaining capacity\" -> decreasing score as `bins_remain_cap - item` increases.\n    #\n    # How about a function that is 1 at 0 and decreases?\n    # `max(0, 1 - steepness * (bins_remain_cap - item))`? Linear. Not smooth.\n    #\n    # The sigmoid `1 / (1 + exp(-x))` *increases* with x.\n    # If we set `x = steepness * (item - (bins_remain_cap - item))`, this doesn't quite make sense.\n    #\n    # Let's use `bins_remain_cap - item` directly. We want this value to be small.\n    # The function `1 / (1 + exp(k * x))` is a decreasing function of `x`.\n    # If we let `x = bins_remain_cap - item`, we get smaller scores for smaller `x`. This is the opposite.\n    #\n    # Let's redefine the sigmoid for our purpose.\n    # We want a function `f(diff)` where `diff = bins_remain_cap - item`.\n    # `f(0) = 1` (exact match)\n    # `f(positive_small) = high` (close fit)\n    # `f(positive_large) = low` (loose fit)\n    # `f(negative)` = 0 (cannot fit - already handled by mask)\n    #\n    # Consider `1 - (1 / (1 + exp(-steepness * diff))) = exp(-steepness * diff) / (1 + exp(-steepness * diff))`\n    # This is 0 at diff=0. Not what we want.\n    #\n    # Consider `1 / (1 + exp(steepness * diff))`.\n    # At diff=0, this is 0.5.\n    # As diff increases, it goes to 0.\n    # As diff decreases (towards negative), it goes to 1.\n    #\n    # The original `priority_v1` uses `1 / (1 + exp(steepness * (remaining_capacity - item)))`.\n    # This gives 0.5 for perfect fit, and decreases for larger remaining capacities.\n    # This prioritizes bins with smaller remaining capacity *after* packing.\n    #\n    # The prompt reflection: \"prioritize exact matches, then bins minimizing remaining capacity.\"\n    # This implies a higher score for exact matches than for just \"minimizing remaining capacity\".\n    # The current sigmoid approach gives 0.5 for an exact match.\n    #\n    # Let's try a different approach:\n    # If `bins_remain_cap == item`, priority is 1.\n    # Otherwise, for `bins_remain_cap > item`, use a decreasing function.\n    #\n    # How about: `priority = exp(-steepness * (bins_remain_cap - item))` for `bins_remain_cap >= item`.\n    # At `bins_remain_cap == item`, priority is `exp(0) = 1`.\n    # As `bins_remain_cap - item` increases, priority decreases towards 0.\n    # This fits the reflection better.\n    #\n    # Let's adjust the steepness parameter's interpretation.\n    #\n    # The function `exp(-steepness * x)` is a good candidate.\n    # We want smaller `bins_remain_cap - item` to yield higher scores.\n    #\n    # Let's use the formulation `exp(-steepness * diff)` where `diff = bins_remain_cap - item`.\n    # If `bins_remain_cap - item` is 0, exp(0) = 1.\n    # If `bins_remain_cap - item` is small positive, exp is slightly less than 1.\n    # If `bins_remain_cap - item` is large positive, exp is close to 0.\n    # This fits \"prioritize exact matches, then bins minimizing remaining capacity.\"\n\n    # Calculate the 'fit difference' for bins that can accommodate the item.\n    # This is the remaining capacity after packing the item.\n    fit_difference = bins_remain_cap[can_fit_mask] - item\n\n    # Calculate priority using an exponential decay function.\n    # The score is `exp(-steepness * fit_difference)`.\n    # This ensures a score of 1.0 for a perfect fit (fit_difference = 0)\n    # and scores approaching 0 for larger fit_differences (looser fits).\n    # This directly addresses the reflection's requirement to prioritize exact matches.\n\n    # Clip the exponent argument to prevent potential overflow/underflow.\n    # For very large negative `fit_difference` (though not possible with the mask, theoretically),\n    # `steepness * fit_difference` would be large negative, exp -> 0.\n    # For very large positive `fit_difference`, `steepness * fit_difference` would be large positive, exp -> inf.\n    # Let's cap the argument to be safe. A range of [-30, 30] is usually fine for exp.\n    # Since `fit_difference` is always non-negative here, we only need to worry about\n    # `steepness * fit_difference` becoming very large positive.\n    # If `fit_difference` is very large, the priority should be close to 0.\n    # `exp(-steepness * large_positive)` will naturally go to 0.\n    # We might want to avoid `exp(very_large_negative)` if we were using `-fit_difference`.\n    # Here, `exp(-steepness * fit_difference)` is safe.\n    # Let's still consider clipping for robustness, though `fit_difference` is >= 0.\n    # If `fit_difference` is very large, `-steepness * fit_difference` becomes very negative.\n    # `np.exp` handles large negative inputs gracefully by returning 0.\n    # We mainly need to worry about the intermediate `steepness * fit_difference` calculation\n    # if `fit_difference` is enormous, or `steepness` is enormous.\n    # Clipping the result of `steepness * fit_difference` might be sufficient.\n    # `clipped_exponent_arg = np.clip(steepness * fit_difference, -np.inf, 30.0)` ensures `exp` doesn't overflow if `-steepness * fit_difference` is very positive.\n    # But `fit_difference >= 0`, so `steepness * fit_difference >= 0`.\n    # Thus, `-steepness * fit_difference <= 0`.\n    # So, `np.exp` will be between 0 and 1. No overflow risk here.\n    # We can just compute directly.\n\n    scores_for_valid_bins = np.exp(-steepness * fit_difference)\n\n    # Assign the calculated scores to the corresponding bins.\n    priorities[can_fit_mask] = scores_for_valid_bins\n\n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response2.txt_stdout.txt",
    "code_path": "problem_iter3_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin using a refined\n    Best Fit strategy with a weighted approach.\n\n    This heuristic prioritizes bins that can accommodate the item. Among these,\n    it strongly favors bins that result in a near-perfect fit (minimal remaining\n    capacity after packing). It also slightly favors bins with more remaining\n    capacity if the \"tightness\" is similar, providing a smoother transition\n    and preventing premature commitment to very small bins that might be better\n    suited for future smaller items.\n\n    The score for a bin is calculated as:\n    score = (1 / (1 + exp(steepness * (remaining_capacity - item)))) * (1 + bonus_factor * (bins_remain_cap[i] - item))\n    where the first term is the \"tightness score\" and the second term is a \"capacity bonus\".\n    The score is 0 if the item cannot fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Scores range from 0 (cannot fit or very loose fit) to a value greater than 1\n        (ideal fit with high initial capacity).\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    steepness = 5.0  # Tunable parameter: higher values mean stronger preference for tight fits.\n    bonus_factor = 0.1 # Tunable parameter: influences how much more capacity is preferred for similar tightness.\n\n    # Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity for bins that can fit the item.\n    remaining_after_packing = bins_remain_cap[can_fit_mask] - item\n\n    # Calculate the \"tightness score\" using a sigmoid function.\n    # Smaller remaining_after_packing results in a score closer to 1.\n    exponent_args_tightness = steepness * remaining_after_packing\n    clipped_exponent_args_tightness = np.clip(exponent_args_tightness, -30.0, 30.0)\n    tightness_scores = 1.0 / (1.0 + np.exp(clipped_exponent_args_tightness))\n\n    # Calculate the \"capacity bonus\".\n    # This term slightly increases the score for bins that have more remaining capacity\n    # *before* packing, when the tightness is comparable.\n    # We normalize this bonus by the item size to make it less sensitive to absolute bin capacities.\n    # Adding 1 ensures that bins with exactly the same tightness as the item are not penalized.\n    capacity_bonus = 1.0 + bonus_factor * (bins_remain_cap[can_fit_mask] / item) if item > 0 else 1.0\n\n    # Combine the scores. The tightness score is the primary driver,\n    # and the capacity bonus provides a secondary preference.\n    priorities[can_fit_mask] = tightness_scores * capacity_bonus\n\n    return priorities",
    "response_id": 2,
    "obj": 78.32070203430396,
    "SLOC": 12.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response3.txt_stdout.txt",
    "code_path": "problem_iter3_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority with which we want to add item to each bin using Sigmoid Best Fit.\n\n    This heuristic prioritizes bins that can accommodate the item and have the smallest\n    remaining capacity after packing (Best Fit strategy). The priority is calculated\n    using a sigmoid function to provide a smooth ranking, strongly favoring tighter fits.\n\n    The score for a bin is 0 if the item cannot fit. For bins that can fit, the score\n    is calculated as 1 / (1 + exp(steepness * (remaining_capacity - item))).\n    This function is monotonically decreasing with respect to (remaining_capacity - item),\n    meaning smaller non-negative remaining capacities get higher scores.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Scores range from 0 (cannot fit or very loose fit) to 1 (perfect or near-perfect fit).\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    steepness = 5.0  # Tunable parameter: higher values mean stronger preference for tight fits.\n\n    # Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity for bins that can fit the item.\n    # If a bin can fit, the remaining capacity after packing is: bins_remain_cap[i] - item\n    potential_remaining_cap_valid = bins_remain_cap[can_fit_mask] - item\n\n    # Calculate the exponent argument for the sigmoid function.\n    # We want to prioritize smaller `potential_remaining_cap_valid`.\n    # The function `1 / (1 + exp(x))` is decreasing in `x`.\n    # To make it decrease as `potential_remaining_cap_valid` increases, we set `x = steepness * potential_remaining_cap_valid`.\n    # A small `potential_remaining_cap_valid` (tight fit) results in a smaller `x`, thus a higher score.\n    # A large `potential_remaining_cap_valid` (loose fit) results in a larger `x`, thus a lower score.\n    exponent_args = steepness * potential_remaining_cap_valid\n\n    # Clip the exponent arguments to prevent potential overflow/underflow in np.exp.\n    # Values like +/- 700 can cause issues. A range like [-30, 30] is generally safe.\n    # For very negative args, exp -> 0, score -> 1. For very positive args, exp -> inf, score -> 0.\n    clipped_exponent_args = np.clip(exponent_args, -30.0, 30.0)\n\n    # Calculate the priority scores for the valid bins using the sigmoid function.\n    # priorities[can_fit_mask] will be populated with scores between ~0.5 (for perfect fit) and ~0 (for very loose fits).\n    # Scores for bins that cannot fit remain 0.\n    priorities[can_fit_mask] = 1.0 / (1.0 + np.exp(clipped_exponent_args))\n\n    return priorities",
    "response_id": 3,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\nImportError: cannot import name 'priority_v2' from 'gpt' (/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py)\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/SLOC.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\nImportError: cannot import name 'priority_v2' from 'gpt' (/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py)\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/cyclomatic_complexity.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\nImportError: cannot import name 'priority_v2' from 'gpt' (/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py)\n"
  },
  {
    "stdout_filepath": "problem_iter3_response4.txt_stdout.txt",
    "code_path": "problem_iter3_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin using an\n    exponentially decaying Best Fit heuristic.\n\n    This heuristic prioritizes bins that can accommodate the item. It assigns\n    a higher priority to bins with smaller remaining capacity after packing,\n    effectively implementing a \"Best Fit\" strategy. A perfect fit (zero remaining\n    capacity after packing) receives the highest possible score (1.0). The\n    priority decays exponentially as the slack (remaining capacity - item) increases.\n\n    The score for a bin is 0 if the item cannot fit. For bins that can fit,\n    the score is calculated as exp(-steepness * (remaining_capacity - item)).\n    This function ensures that perfect fits have a score of 1, and the score\n    decreases as the slack increases. The 'steepness' parameter controls how\n    rapidly the priority drops with increasing slack.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Scores range from 0 (cannot fit or very loose fit) to 1 (perfect fit).\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    steepness = 10.0  # Tunable parameter: Higher values mean stronger preference for tighter fits.\n\n    # Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the slack (unused capacity) for bins that can fit the item.\n    # slack = remaining_capacity - item. This is always >= 0 for bins in can_fit_mask.\n    slack_valid = bins_remain_cap[can_fit_mask] - item\n\n    # Calculate the priority scores for the valid bins using the exponential function.\n    # score = exp(-steepness * slack).\n    # A slack of 0 (perfect fit) gives exp(0) = 1.\n    # Larger slacks result in scores closer to 0.\n    # We clip the argument to exp to prevent potential overflow/underflow.\n    # Since slack_valid >= 0, the argument `steepness * slack_valid` is also >= 0.\n    # We only need to worry about very large positive arguments, which cause underflow\n    # (score approaching 0). Clipping at -30.0 for the exponent is usually safe.\n    exponent_args = -steepness * slack_valid\n    clipped_exponent_args = np.clip(exponent_args, -30.0, None) # Allow positive values, but limit large negative exp(large_pos)\n\n    priorities[can_fit_mask] = np.exp(clipped_exponent_args)\n\n    return priorities",
    "response_id": 4,
    "obj": 4.108496210610296,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]