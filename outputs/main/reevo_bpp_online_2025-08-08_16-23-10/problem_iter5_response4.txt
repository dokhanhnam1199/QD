```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Returns priority with which we want to add item to each bin using a smoothed
    non-linear function prioritizing minimal post-placement remaining capacity.

    This heuristic prioritizes bins that can accommodate the item and have the smallest
    remaining capacity after packing (Best Fit strategy). The priority is calculated
    using a sigmoid-like function (specifically, 1 / (1 + exp(x))), where 'x' is
    tuned to strongly favor tighter fits.

    The score for a bin is 0 if the item cannot fit. For bins that can fit, the score
    is calculated based on the negative surplus (item - remaining_capacity) which
    we want to minimize. To use a function that rewards smaller values, we transform
    the remaining capacity. A bin with remaining capacity `r` after packing will have
    a score based on `steepness * (r - item)`. Smaller `r` leads to smaller `r-item`,
    which results in a higher priority score.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
        Scores range from 0 (cannot fit or very loose fit) to 1 (perfect or near-perfect fit).
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    steepness = 10.0  # Tunable parameter: higher values mean stronger preference for tight fits.

    # Identify bins where the item can fit.
    can_fit_mask = bins_remain_cap >= item

    # For bins that can fit, calculate the remaining capacity *after* placing the item.
    # We want to prioritize bins where this value is smallest (tightest fit).
    post_placement_remain_cap = bins_remain_cap[can_fit_mask] - item

    # Calculate the exponent argument for the sigmoid function.
    # The function 1 / (1 + exp(x)) is monotonically decreasing in x.
    # To make it favor smaller `post_placement_remain_cap`, we use `steepness * post_placement_remain_cap`.
    # A small `post_placement_remain_cap` (tight fit) results in a smaller argument, thus a higher score.
    # A large `post_placement_remain_cap` (loose fit) results in a larger argument, thus a lower score.
    exponent_args = steepness * post_placement_remain_cap

    # Clip the exponent arguments to prevent potential overflow/underflow in np.exp.
    # Values like +/- 700 can cause issues. A range like [-30, 30] is generally safe.
    # For very negative args, exp -> 0, score -> 1. For very positive args, exp -> inf, score -> 0.
    clipped_exponent_args = np.clip(exponent_args, -30.0, 30.0)

    # Calculate the priority scores for the valid bins.
    # The scores will range from close to 1 (for perfect fits, post_placement_remain_cap=0)
    # down to values close to 0 (for very loose fits).
    priorities[can_fit_mask] = 1.0 / (1.0 + np.exp(clipped_exponent_args))

    return priorities
```
