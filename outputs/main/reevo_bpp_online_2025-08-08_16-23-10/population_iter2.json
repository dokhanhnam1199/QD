[
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin using Sigmoid Best Fit.\n\n    This heuristic prioritizes bins that can accommodate the item and have the smallest\n    remaining capacity after packing (Best Fit strategy). The priority is calculated\n    using a sigmoid function to provide a smooth ranking, strongly favoring tighter fits.\n\n    The score for a bin is 0 if the item cannot fit. For bins that can fit, the score\n    is calculated as 1 / (1 + exp(steepness * (remaining_capacity - item))).\n    This function is monotonically decreasing with respect to (remaining_capacity - item),\n    meaning smaller non-negative remaining capacities get higher scores.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Scores range from 0 (cannot fit or very loose fit) to 1 (perfect or near-perfect fit).\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    steepness = 5.0  # Tunable parameter: higher values mean stronger preference for tight fits.\n\n    # Identify bins where the item can fit.\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity for bins that can fit the item.\n    # If a bin can fit, the remaining capacity after packing is: bins_remain_cap[i] - item\n    potential_remaining_cap_valid = bins_remain_cap[can_fit_mask] - item\n\n    # Calculate the exponent argument for the sigmoid function.\n    # We want to prioritize smaller `potential_remaining_cap_valid`.\n    # The function `1 / (1 + exp(x))` is decreasing in `x`.\n    # To make it decrease as `potential_remaining_cap_valid` increases, we set `x = steepness * potential_remaining_cap_valid`.\n    # A small `potential_remaining_cap_valid` (tight fit) results in a smaller `x`, thus a higher score.\n    # A large `potential_remaining_cap_valid` (loose fit) results in a larger `x`, thus a lower score.\n    exponent_args = steepness * potential_remaining_cap_valid\n\n    # Clip the exponent arguments to prevent potential overflow/underflow in np.exp.\n    # Values like +/- 700 can cause issues. A range like [-30, 30] is generally safe.\n    # For very negative args, exp -> 0, score -> 1. For very positive args, exp -> inf, score -> 0.\n    clipped_exponent_args = np.clip(exponent_args, -30.0, 30.0)\n\n    # Calculate the priority scores for the valid bins using the sigmoid function.\n    # priorities[can_fit_mask] will be populated with scores between ~0.5 (for perfect fit) and ~0 (for very loose fits).\n    # Scores for bins that cannot fit remain 0.\n    priorities[can_fit_mask] = 1.0 / (1.0 + np.exp(clipped_exponent_args))\n\n    return priorities",
    "response_id": 0,
    "obj": 3.9888312724371757,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response1.txt_stdout.txt",
    "code_path": "problem_iter2_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Exact Fit First then Best Fit.\n\n    The strategy prioritizes bins that can exactly fit the item (Exact Fit).\n    If no bin can exactly fit the item, it prioritizes bins that leave the\n    smallest remaining capacity after placing the item (Best Fit).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit, assign priorities:\n    # 1. Exact Fit: Highest priority.\n    # 2. Best Fit: Remaining capacity is minimized.\n\n    # Identify exact fit bins\n    exact_fit_mask = (bins_remain_cap == item)\n\n    # Assign a very high priority to exact fit bins.\n    # A score like 1.0 can represent the highest tier.\n    priorities[exact_fit_mask] = 1.0\n\n    # For bins that can fit but are not exact fits, assign a secondary priority.\n    # This priority should be less than 1.0 and higher for bins with smaller remaining capacity.\n    # We can use a score derived from the remaining capacity: `1 - (remaining_capacity / MAX_POSSIBLE_REMAINING_CAPACITY)`.\n    # A simpler approach is to directly rank by remaining capacity, ensuring it's lower than exact fit.\n    # We can use `1 - (remaining_capacity / sum_of_all_capacities)` or a similar normalization,\n    # but for simplicity and to maintain hierarchy, we can subtract the remaining capacity from a value just below 1.0.\n\n    # Consider only bins that can fit but are not exact fits.\n    non_exact_can_fit_mask = can_fit_mask & ~exact_fit_mask\n\n    if np.any(non_exact_can_fit_mask):\n        # Calculate the remaining capacity after fitting the item for these bins.\n        remaining_after_fit_values = bins_remain_cap[non_exact_can_fit_mask] - item\n\n        # To prioritize smaller remaining capacities, we can use a score that\n        # decreases as remaining capacity increases.\n        # A common approach is to use `-(remaining_capacity)` or `max_capacity - remaining_capacity`.\n        # To keep scores between 0 and 1 (and lower than exact fit priority of 1.0),\n        # we can normalize the remaining capacity.\n        # Let's create a score that is high for small remaining capacity.\n        # We can achieve this by subtracting the `remaining_after_fit_values` from a value slightly less than 1.0,\n        # and then potentially scaling it.\n        # A simple way to ensure smaller `remaining_after_fit_values` get higher scores (closer to 1.0, but less than 1.0)\n        # is to map the range of `remaining_after_fit_values` to `[0, 0.99]`.\n        # If `remaining_after_fit_values` are all positive (which they are, as we excluded exact fits),\n        # the smallest value will give the highest priority in this tier.\n\n        # To ensure a proper ordering and a value less than 1.0, we can use:\n        # `priority = 0.99 - (remaining_after_fit_values / MAX_EXPECTED_REMAINING)`\n        # Or a simpler approach: just use the negative of the remaining capacity,\n        # and shift it to be positive and less than 1.0.\n        # Example: if remaining capacities are [0.1, 0.5], we want priorities like [0.9, 0.5].\n        # This can be achieved by `0.99 - remaining_after_fit_values`.\n        # This assigns a higher priority to bins with smaller remaining capacity.\n        # The maximum possible remaining capacity for a bin fitting `item` is `max(bins_remain_cap) - item`.\n        # However, a simpler fixed scaling can work.\n\n        # Let's assign priorities in the range [0, 0.99].\n        # We want smaller `remaining_after_fit_values` to have higher priorities.\n        # A simple way is to use `base_score - remaining_capacity`.\n        # Let's set a `base_score = 0.99`.\n        priorities[non_exact_can_fit_mask] = 0.99 - remaining_after_fit_values\n\n    # Bins that cannot fit the item retain their initial priority of 0.\n\n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 10.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score strategy with emphasis on tighter fits.\n\n    This version refines the Sigmoid Fit Score by directly focusing on the\n    \"tightness\" of the fit, which is inversely related to the remaining capacity.\n    A tighter fit (smaller remaining capacity) should yield a higher priority score.\n    The sigmoid function is used to map this tightness to a normalized priority score between 0 and 1.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # For bins that can fit the item, calculate the resulting remaining capacity.\n    # We want to prioritize bins where this resulting remaining capacity is minimized.\n    resulting_remaining_cap = bins_remain_cap[can_fit_mask] - item\n\n    # To prioritize smaller remaining capacities, we can use the inverse of\n    # the resulting remaining capacity as a measure of \"fit tightness\".\n    # A smaller resulting capacity means a larger inverse, hence a tighter fit.\n    # Add a small epsilon to avoid division by zero or extremely large values.\n    epsilon = 1e-9\n    fit_tightness = 1.0 / (resulting_remaining_cap + epsilon)\n\n    # Apply a sigmoid function to normalize the tightness scores and control\n    # the sensitivity to different degrees of tightness.\n    # The sigmoid function `1 / (1 + exp(-x))` maps larger x to values closer to 1.\n    # We scale `fit_tightness` by a factor `k` to control how strongly we\n    # favor tighter fits. A larger `k` means a steeper increase in priority\n    # as the fit becomes tighter.\n    k = 10.0  # Sensitivity parameter: higher k favors tighter fits more strongly.\n    scaled_tightness = k * fit_tightness\n    sigmoid_scores = 1 / (1 + np.exp(-scaled_tightness))\n\n    # Assign the calculated sigmoid scores to the bins that can fit the item.\n    priorities[can_fit_mask] = sigmoid_scores\n\n    return priorities",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response3.txt_stdout.txt",
    "code_path": "problem_iter2_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version implements the \"Best Fit\" heuristic for the online Bin Packing Problem.\n    The priority is higher for bins that have just enough capacity to fit the item,\n    minimizing wasted space. Bins that cannot fit the item are given a priority of 0.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        A higher score indicates a higher priority (i.e., a bin that results in\n        less remaining capacity after packing).\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Find bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the remaining capacity *after* placing the item.\n    # The \"best fit\" heuristic aims to minimize this remaining capacity.\n    # Therefore, a smaller remaining capacity should result in a higher priority score.\n    # We can achieve this by using the negative of the remaining capacity as the priority.\n    # The bin with the smallest `bins_remain_cap[i] - item` will have the largest\n    # negative value, hence the highest priority.\n    priorities[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item)\n\n    return priorities",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response4.txt_stdout.txt",
    "code_path": "problem_iter2_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Best Fit.\n\n    This version implements the \"Best Fit\" heuristic. It prioritizes bins\n    that have the least remaining capacity *after* the item is placed,\n    thereby minimizing wasted space. Bins that cannot fit the item are given\n    a priority of 0 (or a very low score).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Identify bins that have enough capacity for the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity *after* placing the item in the eligible bins\n    # We want to minimize this value for the \"best fit\"\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n\n    # To prioritize the minimum remaining capacity, we can assign a score\n    # that is inversely proportional to it, or simply the negative of it.\n    # The smaller the remaining capacity (i.e., the better the fit), the higher the priority.\n    # Using the negative of the remaining capacity achieves this:\n    # -1 is higher priority than -5.\n    # A small epsilon can be added to avoid perfect zero-remaining bins getting arbitrarily high priority\n    # if other heuristics prefer variety, but for pure \"best fit\", negative remaining capacity is direct.\n    # Let's use a slightly adjusted score: higher priority for smaller remaining capacity.\n    # A common strategy is to assign a score based on the *difference* that is maximized.\n    # The difference is `bins_remain_cap - item`. We want to minimize this.\n    # So, we can assign `-(bins_remain_cap - item)` as priority.\n    # This means a smaller positive difference becomes a larger negative number, which we want to select as the maximum.\n\n    # Assign priorities to bins that can fit the item.\n    # Higher priority means smaller remaining capacity after placing the item.\n    priorities[can_fit_mask] = -remaining_after_fit\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined Best Fit strategy for Softmax.\n\n    This priority function aims to prioritize bins that have the least remaining capacity\n    while still being able to fit the item. This is a form of Best Fit.\n    The scores are designed to be used with a softmax-like selection mechanism,\n    where higher scores indicate higher preference. A significant penalty is applied\n    to bins with a large surplus capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to a very low value for bins that cannot fit the item.\n    # Using -inf ensures that after np.exp, these bins will have a priority of 0.\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins that have enough remaining capacity to fit the item.\n    valid_mask = bins_remain_cap >= item\n\n    # For valid bins, calculate a score that reflects the \"goodness\" of the fit.\n    # We want to prioritize bins where the remaining capacity is closest to the item size.\n    # This means minimizing the \"waste\" or \"surplus capacity\": `bins_remain_cap - item`.\n    # A smaller surplus is better.\n    # A score that is inversely proportional to the surplus is desirable.\n    # Let's use `score = 1.0 / (surplus + epsilon)` or `score = -surplus`.\n    # For softmax-like application, `np.exp(score)` is used.\n    # Using `score = -surplus` directly works well:\n    # if surplus is 0, score is 0, exp(0) = 1.\n    # if surplus is 1, score is -1, exp(-1) is ~0.37.\n    # if surplus is 5, score is -5, exp(-5) is ~0.0067.\n    # This naturally penalizes larger surpluses.\n\n    surplus_capacity = bins_remain_cap[valid_mask] - item\n\n    # We want smaller surplus_capacity to yield higher scores.\n    # So, use the negative of the surplus capacity.\n    scores_for_valid_bins = -surplus_capacity\n\n    # Assign these scores to the corresponding positions in the priorities array.\n    priorities[valid_mask] = scores_for_valid_bins\n\n    # The resulting priorities are the exponents for a softmax distribution.\n    # Higher values indicate higher preference.\n    return np.exp(priorities)",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response6.txt_stdout.txt",
    "code_path": "problem_iter2_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Softmax-Based Fit.\n\n    The priority is calculated based on how well an item fits into a bin.\n    A higher priority is given to bins where the remaining capacity is just enough\n    or slightly more than the item size (i.e., minimal surplus). A large surplus capacity is penalized.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to a very low value (negative infinity) for invalid bins.\n    # This ensures that when exp is applied, their priority becomes effectively zero.\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins that can accommodate the item.\n    valid_mask = bins_remain_cap >= item\n\n    # For valid bins, calculate a score that is higher for bins with less surplus capacity.\n    # Surplus capacity is defined as `bins_remain_cap - item`.\n    # We want to maximize the score as surplus capacity decreases.\n    # A simple score function is the negative of the surplus capacity: `-(bins_remain_cap - item)`.\n    # This means a bin with `bins_remain_cap == item` gets a score of 0.\n    # A bin with `bins_remain_cap == item + 1` gets a score of -1.\n    # A bin with `bins_remain_cap == item + 10` gets a score of -10.\n    # When `np.exp()` is applied, these scores are transformed into probabilities.\n    # A score of 0 yields `exp(0) = 1`.\n    # A score of -1 yields `exp(-1) \u2248 0.368`.\n    # A score of -10 yields `exp(-10) \u2248 0.000045`.\n    # This transformation ensures that bins with less surplus capacity have higher priorities.\n\n    surplus_capacity = bins_remain_cap[valid_mask] - item\n    scores_for_valid_bins = -surplus_capacity\n\n    # Assign the calculated scores to the priorities array for valid bins.\n    priorities[valid_mask] = scores_for_valid_bins\n\n    # Apply the exponential function to the scores. This is the core of the Softmax approach.\n    # The resulting values can be interpreted as unnormalized probabilities or weights.\n    # The bin with the highest score will have the highest priority after exponentiation.\n    return np.exp(priorities)",
    "response_id": 6,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response7.txt_stdout.txt",
    "code_path": "problem_iter2_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a heuristic that prioritizes minimal waste.\n\n    This priority function aims to minimize wasted space in bins. It assigns higher\n    priority to bins where the remaining capacity is just enough or slightly more than\n    the item size. Bins that are too small to fit the item are given a priority of zero.\n    The priority is calculated using a function that rewards smaller positive differences\n    between remaining capacity and item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate higher priority.\n    \"\"\"\n    # Initialize priorities to zero for all bins. Bins that cannot fit the item will retain this zero priority.\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Identify bins that have enough remaining capacity to fit the item.\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate a score based on the \"waste\" (remaining capacity - item size).\n    # We want to reward bins with minimal waste. A smaller waste should result in a higher score.\n    # A function like `1 / (waste + epsilon)` or `exp(-waste / temperature)` can achieve this.\n    # Let's use `1 / (waste + 1e-6)` to give higher scores to smaller positive waste.\n    # Adding a small epsilon (1e-6) to the denominator prevents division by zero if remaining_capacity == item.\n    \n    waste = bins_remain_cap[can_fit_mask] - item\n    \n    # The score is the inverse of the waste. Higher score for lower waste.\n    # We add a small constant to avoid division by zero if item perfectly fits.\n    # A perfectly fitting bin (waste=0) should have the highest priority.\n    # Let's map `waste=0` to a high score and increasing `waste` to decreasing scores.\n    # `1.0 / (waste + 1.0)` maps 0 waste to 1, 1 waste to 0.5, 5 waste to 0.16, etc.\n    # This seems like a good heuristic for minimizing waste.\n\n    scores = 1.0 / (waste + 1.0) # Adding 1.0 to ensure even waste=0 results in a finite score >= 1\n\n    priorities[can_fit_mask] = scores\n\n    return priorities",
    "response_id": 7,
    "obj": 4.198244914240141,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response8.txt_stdout.txt",
    "code_path": "problem_iter2_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a refined Best Fit strategy.\n\n    This strategy prioritizes bins that have the smallest remaining capacity after packing the item,\n    provided the item fits. Bins that cannot accommodate the item receive a priority of 0.\n    The priority score is designed such that bins with a remaining capacity closer to zero\n    receive higher scores. A sigmoid function is used to provide a smooth ranking.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # For bins that can fit the item, calculate the remaining capacity after packing\n    potential_remaining_cap = bins_remain_cap - item\n    \n    # We want to prioritize bins with the smallest non-negative remaining capacity.\n    # This is a \"Best Fit\" approach. To translate this into a priority score\n    # where higher is better, we can use a function that decreases as\n    # `potential_remaining_cap` increases for `potential_remaining_cap >= 0`.\n    # A sigmoid function of the form `1 / (1 + exp(k * x))` is decreasing if `k > 0`.\n    # Let `x = potential_remaining_cap`.\n    # The larger `potential_remaining_cap` is, the smaller the score will be.\n    # The ideal case is `potential_remaining_cap = 0`, which gives a score of 0.5.\n    # Larger positive remaining capacity gives scores less than 0.5, approaching 0.\n    # This accurately ranks bins by their \"tightness\" of fit among eligible bins.\n    \n    # A steepness parameter controls how quickly the priority drops as remaining capacity increases.\n    # A higher steepness means a stronger preference for tighter fits.\n    steepness = 10.0 # Tunable parameter, higher means more preference for tighter fits\n\n    # Calculate the argument for the sigmoid function for eligible bins.\n    # We use `potential_remaining_cap` directly.\n    exponent_args = steepness * potential_remaining_cap[can_fit_mask]\n    \n    # To avoid numerical overflow/underflow with np.exp, clip the exponent arguments.\n    # Values like exp(700) or exp(-700) can cause issues. A range of [-30, 30] is usually safe.\n    clipped_exponent_args = np.clip(exponent_args, -30.0, 30.0)\n    \n    # Calculate the priority scores using the sigmoid function for eligible bins.\n    # The score will be between (0, 1). Higher scores mean a better fit.\n    priorities[can_fit_mask] = 1.0 / (1.0 + np.exp(clipped_exponent_args))\n    \n    # Bins that cannot fit the item (can_fit_mask is False) retain their initial priority of 0.\n    \n    return priorities",
    "response_id": 8,
    "obj": 4.108496210610296,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response9.txt_stdout.txt",
    "code_path": "problem_iter2_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This heuristic prioritizes exact fits for the item.\n    Among bins that can fit the item but not exactly, it gives higher priority\n    to bins that would have the least remaining capacity after packing the item.\n    Bins that cannot fit the item receive the lowest priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to a low value for bins that cannot fit the item.\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fitting_bins_indices = np.where(can_fit_mask)[0]\n\n    if len(fitting_bins_indices) > 0:\n        # Calculate the remaining capacity if the item is placed in a fitting bin\n        remaining_after_fit = bins_remain_cap[fitting_bins_indices] - item\n\n        # Assign a base priority to all fitting bins.\n        # This base priority should be lower than the bonus for exact fits.\n        # We can use the negative of the remaining capacity to favor smaller remaining capacities.\n        # The smaller (less negative) the value, the higher the priority.\n        # E.g., if remaining capacities are [0.5, 0.1, 0.8], we want higher priority for 0.1.\n        # Using -remaining_capacity: [-0.5, -0.1, -0.8]. Argmax would pick -0.1.\n        priorities[fitting_bins_indices] = -remaining_after_fit\n\n        # Identify exact fits and give them a significantly higher priority.\n        # We can add a large constant to the priority of exact fits.\n        # This constant should be larger than the maximum possible value of -remaining_after_fit.\n        # The minimum value of remaining_after_fit is 0 (for exact fits).\n        # The maximum value of remaining_after_fit could be up to the bin capacity.\n        # If we assign -remaining_after_fit, the range is roughly [-(max_capacity), 0].\n        # Adding a value larger than max_capacity will ensure exact fits are always preferred.\n        exact_fit_mask = (remaining_after_fit == 0)\n        if np.any(exact_fit_mask):\n            # Add a bonus that is greater than any possible non-exact fit priority.\n            # The maximum possible priority from -remaining_after_fit is 0.\n            # Any value > 0 will work as a bonus. Let's use a substantial bonus.\n            bonus = 100.0\n            priorities[fitting_bins_indices[exact_fit_mask]] += bonus\n\n    return priorities",
    "response_id": 9,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 53, in priority_v2\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n12\n3\n"
  }
]