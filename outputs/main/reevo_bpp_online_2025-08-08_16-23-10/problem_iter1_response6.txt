```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using Sigmoid Fit Score strategy.

    The Sigmoid Fit Score prioritizes bins that leave a smaller remaining capacity
    after the item is placed, aiming to fill bins more efficiently. It uses a
    sigmoid function to map the "tightness" of the fit (inverse of remaining capacity)
    to a priority score.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    # We can only place the item in bins that have enough capacity.
    # For bins with insufficient capacity, the priority is 0.
    valid_bins_mask = bins_remain_cap >= item
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Calculate the remaining capacity if the item were placed in each valid bin.
    remaining_capacities = bins_remain_cap[valid_bins_mask] - item

    # We want to prioritize bins where the remaining capacity is *small*.
    # This means a higher priority for a tighter fit.
    # A simple way to achieve this is to use the inverse of the remaining capacity.
    # To avoid division by zero or very large numbers for near-zero remaining capacities,
    # we can add a small epsilon.
    epsilon = 1e-6
    # The "fit score" is higher for smaller remaining capacities.
    # Let's use the inverse of remaining capacity as a proxy for tightness.
    # Higher inverse means tighter fit.
    fit_scores = 1.0 / (remaining_capacities + epsilon)

    # Now, we apply a sigmoid function. The sigmoid function squashes values
    # between 0 and 1. This can help normalize the scores and make them
    # less sensitive to extreme values.
    # A common sigmoid is 1 / (1 + exp(-x)).
    # If fit_score is large (tight fit), exp(-fit_score) will be close to 0, so sigmoid ~ 1.
    # If fit_score is small (loose fit), exp(-fit_score) will be large, so sigmoid ~ 0.
    # This maps "tightness" (high fit_score) to high priority.
    # We can also scale and shift the fit_score before applying sigmoid to
    # control the steepness of the priority change. For simplicity, we'll
    # directly use the fit_score as input to the sigmoid.

    # Using np.clip to ensure we don't get NaNs or infinities from exp if
    # fit_scores become extremely large or small (though less likely here).
    # For demonstration, a simple sigmoid `1 / (1 + exp(-x))` is applied.
    # To make it sensitive to *small* remaining capacity, we want a high score
    # for small remaining capacity. So, `fit_scores` directly represent this.
    # Applying sigmoid directly to `fit_scores`:
    # A higher `fit_score` (meaning smaller `remaining_capacities`) should yield a higher priority.
    # `sigmoid(x) = 1 / (1 + exp(-x))` where higher x -> higher sigmoid output.
    # We can scale `fit_scores` to influence sensitivity. Let's scale by a factor `k`.
    # `k * fit_scores`. A larger `k` means higher priority for tighter fits.
    k = 1.0 # Scaling factor - adjust this for desired sensitivity
    scaled_fit_scores = k * fit_scores
    sigmoid_priorities = 1 / (1 + np.exp(-scaled_fit_scores))

    # Assign these calculated priorities back to the valid bins
    priorities[valid_bins_mask] = sigmoid_priorities

    return priorities
```
