[
  {
    "stdout_filepath": "problem_iter18_response0.txt_stdout.txt",
    "code_path": "problem_iter18_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_capacity: float) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This function implements a priority function focusing on the remaining capacity after adding the item and introduces controlled randomness.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        bin_capacity: The capacity of each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Bins that cannot hold the item should have the lowest priority\n    valid_bins = bins_remain_cap >= item\n    \n    # For valid bins, use a combination of remaining capacity after addition and the bin utilization as priority\n    remaining_after_addition = bins_remain_cap - item\n    priorities = np.where(valid_bins, - remaining_after_addition / bin_capacity, -np.inf)\n    \n    # Introduce controlled randomness\n    np.random.seed(0)  # For reproducibility\n    noise = np.random.uniform(0, 0.01, size=len(priorities))  \n    priorities += noise * valid_bins  # Only add noise to valid bins\n    \n    return priorities",
    "response_id": 0,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\nTypeError: priority_v2() missing 1 required positional argument: 'bin_capacity'\n12\n1\n245.0\n75.43920331506338\n199\n"
  },
  {
    "stdout_filepath": "problem_iter18_response1.txt_stdout.txt",
    "code_path": "problem_iter18_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    \n    This function implements a priority function focusing on meaningful score differences, \n    scaled noise, and prioritization based on post-addition remaining capacity for online Bin Packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item to each bin\n    remaining_after_addition = bins_remain_cap - item\n    \n    # Bins that cannot hold the item should have the lowest priority\n    valid_bins = remaining_after_addition >= 0\n    \n    # For valid bins, prioritize those with the least remaining capacity after addition\n    priorities = np.where(valid_bins, -remaining_after_addition, -np.inf)\n    \n    # Scale noise relative to the range of priorities for valid bins\n    valid_priorities = priorities[valid_bins]\n    if len(valid_priorities) > 0:\n        min_priority, max_priority = np.min(valid_priorities), np.max(valid_priorities)\n        noise_scale = (max_priority - min_priority) * 0.01  # 1% of the priority range\n    else:\n        noise_scale = 0\n    \n    # Introduce controlled randomness\n    np.random.seed(0)  # For reproducibility\n    noise = np.random.uniform(0, noise_scale, size=len(priorities))\n    priorities += noise * valid_bins  # Only add noise to valid bins\n    \n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 245.0,
    "mi": 75.43920331506338,
    "token_count": 199.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response2.txt_stdout.txt",
    "code_path": "problem_iter18_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, alpha: float = 0.1) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    \n    This function implements a simplified priority function with controlled randomness for exploration.\n    It prioritizes bins that have just enough capacity to hold the item and introduces tunable randomness.\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        alpha: Parameter controlling the level of exploration. Defaults to 0.1.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item to each bin\n    remaining_after_addition = bins_remain_cap - item\n    \n    # Bins that cannot hold the item should have the lowest priority\n    valid_bins = remaining_after_addition >= 0\n    \n    # For valid bins, prioritize those with the least remaining capacity after addition\n    priorities = np.where(valid_bins, -remaining_after_addition, -np.inf)\n    \n    # Introduce controlled randomness for exploration\n    np.random.seed(0)  # For reproducibility\n    noise = np.random.uniform(0, 1, size=len(priorities))  \n    priorities = np.where(valid_bins, priorities + alpha * noise, priorities)\n    \n    return priorities",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 245.0,
    "mi": 75.43920331506338,
    "token_count": 199.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response3.txt_stdout.txt",
    "code_path": "problem_iter18_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_max_cap: float) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    \n    This function implements an improved priority function that considers both the remaining capacity of the bins and the size of the item.\n    It assigns higher priority to bins that have just enough capacity to hold the item, with controlled randomness for exploration.\n    The priorities are normalized and scored relative to the best and worst possible bins.\n    Furthermore, it adjusts the priorities based on the fullness of the bins to encourage packing items tightly.\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        bin_max_cap: Maximum capacity of a bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item to each bin\n    remaining_after_addition = bins_remain_cap - item\n    \n    # Bins that cannot hold the item should have the lowest priority\n    valid_bins = remaining_after_addition >= 0\n    \n    # For valid bins, prioritize those with the least remaining capacity after addition, \n    # adjusted by how full the bin is before adding the item\n    bin_fullness = 1 - (bins_remain_cap / bin_max_cap)  # Measure of how full the bin is\n    priorities = np.where(valid_bins, -remaining_after_addition / (bins_remain_cap + 1e-9) + bin_fullness, -np.inf)\n    \n    # Normalize priorities to [0, 1] range for valid bins using relative scoring\n    min_priority = np.min(priorities[valid_bins])\n    max_priority = np.max(priorities[valid_bins])\n    priorities_valid = (priorities[valid_bins] - min_priority) / (max_priority - min_priority + 1e-9)\n    priorities[valid_bins] = priorities_valid\n    \n    # Apply a sigmoid transformation to enhance discriminability among valid bins\n    priorities[valid_bins] = 1 / (1 + np.exp(-priorities[valid_bins] / (np.max(priorities[valid_bins]) + 1e-9)))\n    priorities[valid_bins] = priorities[valid_bins] / (np.sum(priorities[valid_bins]) + 1e-9)\n    \n    # Introduce controlled randomness\n    np.random.seed(0)  # For reproducibility\n    noise = np.random.uniform(0, 0.01, size=len(priorities))  # Reduced noise for less exploration\n    priorities += noise * valid_bins  # Only add noise to valid bins\n    \n    # Renormalize after adding noise\n    priorities[valid_bins] = priorities[valid_bins] / (np.sum(priorities[valid_bins]) + 1e-9)\n    \n    return priorities",
    "response_id": 3,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\nTypeError: priority_v2() missing 1 required positional argument: 'bin_max_cap'\n12\n1\n245.0\n75.43920331506338\n199\n"
  },
  {
    "stdout_filepath": "problem_iter18_response4.txt_stdout.txt",
    "code_path": "problem_iter18_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    \n    This function implements a priority function that balances fit and exploration for online Bin Packing Problem.\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item to each bin\n    remaining_after_addition = bins_remain_cap - item\n    \n    # Bins that cannot hold the item should have the lowest priority\n    valid_bins = remaining_after_addition >= 0\n    \n    # For valid bins, prioritize those with the least remaining capacity after addition\n    priorities = np.where(valid_bins, -remaining_after_addition / bins_remain_cap, -np.inf)\n    \n    # Introduce scaled randomness for exploration, relative to the bin capacity\n    np.random.seed(0)  # For reproducibility\n    noise = np.random.uniform(0, 1, size=len(priorities))  # Uniform noise between 0 and 1\n    priorities += 5e-3 * noise * valid_bins  # Scaled noise for valid bins\n    \n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 245.0,
    "mi": 75.43920331506338,
    "token_count": 199.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response5.txt_stdout.txt",
    "code_path": "problem_iter18_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    \n    This function implements a priority function that considers both the remaining capacity of the bins and the size of the item.\n    It assigns higher priority to bins that have just enough capacity to hold the item, with controlled randomness for exploration.\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item to each bin\n    remaining_after_addition = bins_remain_cap - item\n    \n    # Bins that cannot hold the item should have the lowest priority\n    valid_bins = remaining_after_addition >= 0\n    \n    # For valid bins, prioritize those with the least remaining capacity after addition\n    priorities = np.where(valid_bins, -remaining_after_addition, -np.inf)\n    \n    # Normalize priorities to [0, 1] range for valid bins\n    valid_priorities = priorities[valid_bins]\n    if len(valid_priorities) > 0:\n        min_priority = np.min(valid_priorities)\n        max_priority = np.max(valid_priorities)\n        priorities[valid_bins] = (valid_priorities - min_priority) / (max_priority - min_priority + 1e-9)\n    \n    # Introduce controlled randomness scaled with the maximum remaining capacity\n    np.random.seed(0)  # For reproducibility\n    max_remain_cap = np.max(bins_remain_cap)\n    noise = np.random.uniform(0, 0.1 * max_remain_cap / (max_remain_cap + 1e-9), size=len(priorities))  \n    priorities += noise * valid_bins  # Only add noise to valid bins\n    \n    return priorities",
    "response_id": 5,
    "obj": 4.2580773833266905,
    "SLOC": 12.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 245.0,
    "mi": 75.43920331506338,
    "token_count": 199.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response6.txt_stdout.txt",
    "code_path": "problem_iter18_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    \n    This function implements a priority function that considers both the remaining capacity of the bins and the size of the item.\n    It assigns higher priority to bins that have just enough capacity to hold the item, with controlled randomness for exploration.\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item to each bin\n    remaining_after_addition = bins_remain_cap - item\n    \n    # Bins that cannot hold the item should have the lowest priority\n    valid_bins = remaining_after_addition >= 0\n    \n    # For valid bins, prioritize those with the least remaining capacity after addition\n    priorities = np.where(valid_bins, -remaining_after_addition / (bins_remain_cap + 1e-9), -np.inf)\n    \n    # Normalize priorities to [0, 1] range for valid bins\n    min_priority = np.min(priorities[valid_bins])\n    max_priority = np.max(priorities[valid_bins])\n    priorities[valid_bins] = (priorities[valid_bins] - min_priority) / (max_priority - min_priority + 1e-9)\n    \n    # Introduce controlled relative randomness\n    np.random.seed(0)  # For reproducibility\n    noise = np.random.uniform(0, 0.1 * np.max(priorities[valid_bins]), size=len(priorities))  # Scaled relative noise for exploration\n    priorities += noise * valid_bins  # Only add noise to valid bins\n    \n    return priorities",
    "response_id": 6,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 245.0,
    "mi": 75.43920331506338,
    "token_count": 199.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response7.txt_stdout.txt",
    "code_path": "problem_iter18_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, alpha: float = 1e-6) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    \n    This function implements a priority function focusing on the remaining capacity after adding the item and scales noise for better balance.\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        alpha: Parameter controlling the level of exploration.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item to each bin\n    remaining_after_addition = bins_remain_cap - item\n    \n    # Bins that cannot hold the item should have the lowest priority\n    valid_bins = remaining_after_addition >= 0\n    \n    # For valid bins, prioritize those with the least remaining capacity after addition\n    priorities = np.where(valid_bins, -remaining_after_addition, -np.inf)\n    \n    # Introduce scaled randomness for exploration\n    np.random.seed(0)  # For reproducibility\n    noise = np.random.uniform(0, 1, size=len(priorities))  \n    priorities = priorities + alpha * noise * valid_bins  \n    \n    return priorities",
    "response_id": 7,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 245.0,
    "mi": 75.43920331506338,
    "token_count": 199.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response8.txt_stdout.txt",
    "code_path": "problem_iter18_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, alpha: float = 0.01) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This function rewards bins that are closest to being full and can fit the item, \n    and adds controlled noise for exploration.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        alpha: Parameter controlling the scale of random noise.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Bins that cannot hold the item should have the lowest priority\n    valid_bins = bins_remain_cap >= item\n    \n    # Reward bins that are closest to being full and can fit the item\n    priorities = np.where(valid_bins, -np.abs(bins_remain_cap - item), -np.inf)\n    \n    # Introduce controlled randomness for exploration\n    noise = np.random.uniform(-alpha, alpha, size=len(bins_remain_cap))\n    noise[~valid_bins] = 0  # No noise for bins that cannot hold the item\n    \n    priorities += noise\n    \n    return priorities",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 245.0,
    "mi": 75.43920331506338,
    "token_count": 199.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response9.txt_stdout.txt",
    "code_path": "problem_iter18_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, alpha: float = 0.1) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n    \n    This function implements a priority function that considers both the remaining capacity of the bins and the size of the item.\n    It assigns higher priority to bins that have just enough capacity to hold the item, with controlled randomness for exploration.\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        alpha: Parameter controlling the level of exploration.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item to each bin\n    remaining_after_addition = bins_remain_cap - item\n    \n    # Bins that cannot hold the item should have the lowest priority\n    valid_bins = remaining_after_addition >= 0\n    \n    # For valid bins, prioritize those with the least remaining capacity after addition\n    priorities = np.where(valid_bins, -remaining_after_addition / (bins_remain_cap + 1e-9), -np.inf)\n    \n    # Normalize priorities to [0, 1] range for valid bins\n    min_priority = np.min(priorities[valid_bins])\n    max_priority = np.max(priorities[valid_bins])\n    priorities[valid_bins] = (priorities[valid_bins] - min_priority) / (max_priority - min_priority + 1e-9)\n    \n    # Introduce controlled and normalized randomness\n    np.random.seed(0)  # For reproducibility\n    noise = np.random.uniform(0, 1, size=len(priorities))  \n    noise = (noise - np.min(noise)) / (np.max(noise) - np.min(noise) + 1e-9)  # Normalize noise\n    priorities += alpha * noise * valid_bins  \n    \n    return priorities",
    "response_id": 9,
    "obj": 4.008775428799367,
    "SLOC": 12.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 245.0,
    "mi": 75.43920331506338,
    "token_count": 199.0,
    "exec_success": true
  }
]