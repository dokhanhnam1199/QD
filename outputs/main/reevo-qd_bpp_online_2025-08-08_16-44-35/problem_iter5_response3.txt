```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a refined
    Almost Full Fit strategy with a sigmoid-like weighting.

    This version refines the Almost Full Fit (AFF) strategy by using a sigmoid-like
    function to give smoother preference to bins that are almost full. It prioritizes
    bins that result in a tighter fit after the item is placed.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Returns:
        Array of same size as bins_remain_cap with priority score of each bin.
        A higher score indicates a higher priority.
    """
    # Initialize priorities to a very low value.
    priorities = np.full_like(bins_remain_cap, -np.inf)

    # Identify bins that can fit the item.
    can_fit_mask = bins_remain_cap >= item

    if not np.any(can_fit_mask):
        return priorities

    # Calculate the remaining capacity after placing the item for bins that can fit it.
    remaining_after_item = bins_remain_cap[can_fit_mask] - item

    # Use a sigmoid-like function to prioritize tighter fits.
    # A simple approach is to use the negative of the remaining capacity,
    # possibly scaled or shifted to emphasize the "almost full" aspect.
    # We want to give higher priority to *smaller* remaining_after_item values.
    # Thus, we can use a function that increases as remaining_after_item decreases.
    #
    # A common transformation for prioritization is to use the negative of the value,
    # or a scaled version of it. For example, -(remaining_after_item).
    # To make it "smoother" or more emphasized towards near-zero remaining capacity,
    # we can consider a transformation like `1 / (1 + remaining_after_item)` if
    # `remaining_after_item` is non-negative, or a function that grows faster as
    # `remaining_after_item` approaches zero.
    #
    # A simple and effective way to prioritize smaller positive differences is to
    # use the negative of the difference. The smaller the positive difference, the
    # larger (less negative) the negative difference becomes.
    #
    # For instance, if remaining_after_item = [3, 1, 5]:
    #   - Bin with remaining_after_item=1: priority = -1 (highest)
    #   - Bin with remaining_after_item=3: priority = -3
    #   - Bin with remaining_after_item=5: priority = -5
    #
    # We can also add a small constant to avoid exactly zero priority if needed,
    # but for maximizing, this is usually not an issue.
    #
    # To further break ties, we can consider the original bin index. Lower indices
    # are generally preferred in tie-breaking scenarios to ensure determinism.
    # We can achieve this by adding a small negative value proportional to the index.
    # A smaller index should result in a less negative contribution, hence higher priority.
    # So, we subtract a small penalty based on the index: `-(bin_index / large_number)`.
    #
    # Let's combine the tightness priority and tie-breaking.
    # The priority for the fitting bins will be:
    # `-(remaining_after_item) - (original_indices[can_fit_mask] / very_large_number)`

    # Get the indices of bins that can fit the item.
    fitting_indices = np.where(can_fit_mask)[0]

    # Calculate the base priority based on tightness.
    # We want to maximize this, so smaller remaining_after_item is better.
    tightness_priority = -remaining_after_item

    # Add a tie-breaking component. Smaller indices should have higher priority.
    # We subtract a small value proportional to the index to ensure that for
    # equal tightness, lower indices are preferred.
    # A large divisor ensures this tie-breaking component is small relative
    # to the tightness priority.
    tie_breaking_penalty = fitting_indices / (len(bins_remain_cap) * 100.0) # Scale to be small

    # Combine tightness and tie-breaking.
    priorities[can_fit_mask] = tightness_priority - tie_breaking_penalty

    return priorities
```
