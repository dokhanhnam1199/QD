[Prior reflection]
Focus on minimizing waste by prioritizing bins with the smallest *positive* remaining capacity. Employ sigmoid functions for smooth preference, ensuring items always fit, and consider tie-breaking with lower bin indices.

[Code]
def priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:

    """Returns priority with which we want to add item to each bin using Almost Full Fit strategy.

    The Almost Full Fit (AFF) strategy prioritizes bins that are almost full.
    It selects the bin with the smallest remaining capacity that can still
    accommodate the item, encouraging fuller bins to be used first, which
    can lead to fewer bins being opened overall.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
        A higher score indicates a higher priority.
    """
    # Initialize priorities to a very low value (effectively -infinity for maximization)
    # This ensures that bins that cannot fit the item receive no priority.
    priorities = np.full_like(bins_remain_cap, -np.inf)

    # Identify bins that can fit the item
    can_fit_mask = bins_remain_cap >= item

    # For bins that can fit the item, assign a priority based on their remaining capacity.
    # The strategy is to prioritize bins that are *almost full*.
    # This means we want to select bins with the smallest positive remaining capacity
    # after placing the item.
    # A higher priority should be given to bins with *less* remaining capacity
    # after the item is placed, but only if they can still accommodate it.
    #
    # The remaining capacity after placing the item is `bins_remain_cap - item`.
    # To give higher priority to smaller remaining capacities, we can use the
    # negative of the remaining capacity.
    #
    # Example:
    # If bin_remain_cap = [5, 3, 7] and item = 2:
    #   - Bin 0: can_fit = True, remaining_after_item = 3. Priority: -3
    #   - Bin 1: can_fit = True, remaining_after_item = 1. Priority: -1 (HIGHER PRIORITY)
    #   - Bin 2: can_fit = True, remaining_after_item = 5. Priority: -5
    #
    # So, the priority is `-(bins_remain_cap - item)`.

    priorities[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item)

    # To further refine AFF, we might want to break ties.
    # A common tie-breaking mechanism for bin packing is to prefer bins that have
    # been used for longer, or simply the first encountered bin.
    # In this implementation, numpy's default behavior will handle ties by
    # returning the indices in the order they appear, which implicitly favors
    # earlier bins in case of identical priority scores.

    return priorities

[Improved code]
```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a refined Almost Full Fit strategy.

    This version prioritizes bins with the smallest *positive* remaining capacity after
    placing the item. It uses a sigmoid-like function for smoother preference, ensuring
    items always fit, and incorporates tie-breaking by favoring lower bin indices.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Returns:
        Array of same size as bins_remain_cap with priority score of each bin.
        A higher score indicates a higher priority.
    """
    # Initialize priorities to a very low value.
    priorities = np.full_like(bins_remain_cap, -np.inf)

    # Identify bins that can fit the item.
    can_fit_mask = bins_remain_cap >= item

    # Calculate remaining capacities for bins that can fit the item.
    remaining_after_item = bins_remain_cap[can_fit_mask] - item

    # Assign priorities based on remaining capacity.
    # We want to prioritize bins with the *smallest positive* remaining capacity.
    # A common way to achieve this is by using the negative of the remaining capacity
    # for smaller values, but we need to be careful to handle the "positive" aspect.
    #
    # A sigmoid-like function can provide a smooth preference.
    # For smallest positive remaining capacity, a higher priority should be given to
    # values closer to zero.
    #
    # Let's consider the values of `remaining_after_item`.
    # If `remaining_after_item` is small and positive (e.g., 0.1, 0.5), these bins are preferred.
    # If `remaining_after_item` is larger (e.g., 2, 5), these bins are less preferred.
    #
    # A transformation like `-remaining_after_item` would rank smaller remaining capacities higher.
    # To make it smoother and emphasize values closer to zero, we can use:
    # `sigmoid(k * (max_remaining - remaining_after_item))` where `k` is a steepness parameter.
    # However, a simpler approach that directly prioritizes smaller positive values is sufficient.
    #
    # We can directly use a transformed version of the remaining capacity.
    # Let's map smaller `remaining_after_item` to higher scores.
    # The smallest possible remaining capacity after fitting an item is 0.
    # The largest possible remaining capacity is `max(bins_remain_cap) - item`.
    #
    # A simple way to prioritize smaller positive values is to use their negative.
    # To ensure a smooth preference and avoid extremely large negative numbers for very small
    # remaining capacities, we can cap the "negative penalty" or use a scaled version.
    #
    # Let's try to prioritize bins where `remaining_after_item` is small and positive.
    # For example, if remaining capacities after fit are [1, 5, 0.1, 3]:
    # We want priority for 0.1 > 1 > 3 > 5.
    #
    # A simple linear transformation: `-(remaining_after_item)`.
    # This gives priorities: [-1, -5, -0.1, -3]. The highest is -0.1. This aligns with the goal.
    #
    # To ensure *positive* smallest remaining capacity is preferred, we already filtered
    # with `can_fit_mask`. So `remaining_after_item` will always be non-negative.
    #
    # To avoid issues with potential very large negative numbers if `remaining_after_item`
    # is very close to zero, we can add a small constant offset or use a scaling factor.
    # However, for direct comparison, `-remaining_after_item` works well for ranking.
    #
    # Let's use a smoothed approach. Consider the reciprocal: `1 / remaining_after_item`.
    # This would heavily favor very small positive values. But it's undefined for 0.
    # We can add a small epsilon or use `1 / (remaining_after_item + epsilon)`.
    #
    # Another approach is to use `np.exp(-remaining_after_item)`.
    # This gives higher values for smaller `remaining_after_item`.
    # `exp(-0.1) approx 0.90`, `exp(-1) approx 0.36`, `exp(-5) approx 0.006`.
    # This seems to capture the "smallest positive remaining capacity" preference well.
    #
    # To break ties, we can add a small value based on the bin index.
    # Lower bin indices should have higher priority in case of ties.
    # We can achieve this by subtracting `bin_index * small_epsilon`.
    # However, since we are calculating priorities for all bins that *can* fit,
    # and then selecting the max, tie-breaking should be handled carefully.
    #
    # Let's refine the priority calculation. We want to prioritize smaller `remaining_after_item`.
    # A smooth function that maps small positive values to high scores and larger values to low scores.
    #
    # Consider the transformation: `sigmoid(A - B * x)` where x is `remaining_after_item`.
    # Let's use `np.exp(-remaining_after_item)`. This gives higher values for smaller `remaining_after_item`.
    #
    # To handle tie-breaking with lower bin indices, we can create a unique score.
    # For example, `np.exp(-remaining_after_item) + (N - bin_index) * epsilon`.
    # Where N is the total number of bins and epsilon is a small value.
    # This way, smaller bin_index will have a larger additive term, increasing its priority.
    #
    # Let `N` be the total number of bins.
    total_bins = len(bins_remain_cap)
    bin_indices = np.arange(total_bins)

    # Calculate a base priority score using the exponential function.
    # A small remaining capacity after packing the item will result in a high score.
    base_priority = np.exp(-remaining_after_item)

    # Create a tie-breaking component.
    # Bins with lower indices should have higher priority in case of ties in base_priority.
    # We want to add a value that increases with decreasing bin index.
    # `(total_bins - bin_indices[can_fit_mask])` will give larger values for smaller indices.
    # We need to scale this to ensure it doesn't overpower the base priority if not needed.
    # A small epsilon multiplied by the index ensures lexicographical ordering.
    # Let's add a term that decreases with index, so `-(index * epsilon)`
    # No, we want *higher* priority for lower index. So `+(large_number - index) * epsilon`.
    # Or, more directly, we can add `1.0 / (bin_indices[can_fit_mask] + 1)` which prioritizes smaller indices.
    #
    # Let's use a small constant added to the score that is inversely proportional to the index.
    # Example: `score = base_priority + constant / (index + 1)`
    # This will give higher scores to smaller indices.
    # The constant needs to be chosen carefully.
    #
    # A simpler tie-breaking mechanism is to ensure that if `base_priority` is the same,
    # the one with the smaller index is preferred.
    # This is usually handled by the sorting algorithm if we provide tuples `(priority, -index)`.
    #
    # Let's refine the priority score itself to incorporate the tie-breaking.
    # We want `f(remaining_capacity, index)`.
    # Higher `f` for smaller `remaining_capacity` and smaller `index`.
    #
    # Consider a scaled approach:
    # priority = exp(-remaining_after_item) * C1 + (total_bins - bin_indices[can_fit_mask]) * C2
    # where C1 and C2 are scaling factors.
    #
    # Let's use a common technique: add a term that is inversely proportional to the index.
    # This way, smaller indices get a boost.
    # `priority = exp(-remaining_after_item) + (1.0 / (bin_indices[can_fit_mask] + 1)) * small_scale`
    #
    # A more direct way to implement lexicographical ordering for maximization:
    # priority = (value_from_remaining, -index)
    # When comparing `(v1, -i1)` and `(v2, -i2)`:
    # If `v1 > v2`, the first is better.
    # If `v1 == v2`, then compare `-i1` and `-i2`. If `-i1 > -i2` (i.e., `i1 < i2`), the first is better.
    #
    # So, we can assign `priority_score = np.exp(-remaining_after_item)` and then use a secondary
    # sort key for the index.
    #
    # Let's create a compound score that naturally sorts correctly.
    # The range of `exp(-remaining_after_item)` can be from `exp(-max_rem)` to `exp(0)=1`.
    # Let's say `max_rem` is around 100. `exp(-100)` is very small.
    # The range is roughly (0, 1].
    # The range of indices is `0` to `total_bins - 1`.
    #
    # We can map the index to a range that complements the priority.
    # For example, `priority = exp(-remaining_after_item) + (total_bins - index) * epsilon`.
    # Let epsilon be small, e.g., 1e-6.
    # `index = 0` gives `total_bins * epsilon`.
    # `index = total_bins-1` gives `1 * epsilon`.
    # This way, smaller indices have larger additive terms.
    #
    # Let's consider the `remaining_after_item` values. If they are all same, say 0.5:
    # `exp(-0.5) = 0.6065` for all.
    # Indices are 0, 1, 2. Total bins = 3.
    # For index 0: `0.6065 + (3-0)*1e-6 = 0.606503`
    # For index 1: `0.6065 + (3-1)*1e-6 = 0.606502`
    # For index 2: `0.6065 + (3-2)*1e-6 = 0.606501`
    # This correctly prioritizes index 0.

    # Scale the index contribution to be less dominant than the remaining capacity score,
    # but significant enough for tie-breaking.
    # The exponential function's values are between 0 and 1 (exclusive of 0).
    # So, `(total_bins - index)` can range from 1 to `total_bins`.
    # If `total_bins = 100`, range is 1 to 100.
    # Multiplying by a small epsilon (e.g., 1e-9) should keep it subordinate.
    epsilon = 1e-9
    tie_breaker = (total_bins - bin_indices[can_fit_mask]) * epsilon

    # Combine the base priority with the tie-breaker.
    # The `can_fit_mask` is applied to `remaining_after_item` and `bin_indices`.
    # We need to assign these computed priorities to the correct positions in the `priorities` array.
    priorities[can_fit_mask] = base_priority + tie_breaker

    return priorities
```
