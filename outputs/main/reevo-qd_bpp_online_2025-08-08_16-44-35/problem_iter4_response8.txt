```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a hybrid approach.

    This heuristic prioritizes bins that offer an "exact fit" (remaining capacity equals item size)
    with a high fixed score. For bins that can fit but don't offer an exact fit, it assigns
    scores based on the remaining capacity after packing. These scores are then passed through
    a softmax function to generate probabilities, ensuring a smooth distribution of priorities
    among the non-exact fits. Bins that cannot fit the item receive a score of 0.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Returns:
        Array of same size as bins_remain_cap with priority score of each bin.
        Higher scores indicate higher priority.
    """
    priorities = np.zeros_like(bins_remain_cap)
    epsilon = 1e-6  # Small constant to avoid division by zero or instability

    # Identify bins that can fit the item
    can_fit_mask = bins_remain_cap >= item
    fit_indices = np.where(can_fit_mask)[0]

    if len(fit_indices) == 0:
        return priorities  # No bins can fit the item

    # Calculate the difference between remaining capacity and item size for fitting bins
    differences = bins_remain_cap[can_fit_mask] - item

    # Exact Fit: Assign a high fixed priority score
    exact_fit_mask = (differences == 0)
    exact_fit_indices = fit_indices[exact_fit_mask]
    if len(exact_fit_indices) > 0:
        priorities[exact_fit_indices] = 10.0  # High fixed priority for exact fits

    # Non-Exact Fit: Use softmax for bins that can fit but not exactly
    non_exact_fit_mask = ~exact_fit_mask
    non_exact_fit_indices_in_fit = np.where(can_fit_mask)[0][non_exact_fit_mask]

    if len(non_exact_fit_indices_in_fit) > 0:
        # For non-exact fits, we want to prioritize bins where `difference` is small.
        # A score inversely proportional to the difference works well.
        # Example: score = 1.0 / (difference + epsilon)
        # This ensures smaller differences get higher scores.
        
        # Calculate the raw scores for non-exact fits
        raw_scores_non_exact = 1.0 / (differences[non_exact_fit_mask] + epsilon)

        # Apply softmax to these raw scores.
        # We shift scores to prevent potential overflow with np.exp and ensure numerical stability.
        # Subtracting the maximum score makes the highest score 0, and others negative.
        max_score = np.max(raw_scores_non_exact)
        shifted_scores = raw_scores_non_exact - max_score
        
        exp_scores = np.exp(shifted_scores)
        sum_exp_scores = np.sum(exp_scores)

        if sum_exp_scores > 0:
            # Normalize to get probabilities (priorities)
            softmax_priorities = exp_scores / sum_exp_scores
            
            # Add these softmax priorities to the existing priorities array.
            # We scale them down slightly so that exact fits (score 10) are distinctly preferred,
            # but non-exact fits still have a meaningful distribution.
            # The scaling factor can be tuned. Here, we'll make them contribute as a secondary preference.
            # Let's add a portion of the softmax priority. A value like 0.5 * softmax_priority
            # or something that maps the range [0, 1] to a smaller range like [0, 1].
            # To avoid overwriting exact fits and ensure they remain dominant, we can add
            # a small value derived from softmax, or simply assign a lower range of values.
            
            # A better approach is to combine the exact fit priority and softmax priority.
            # Exact fits get a high score. Non-exact fits get scores in a lower range,
            # but sorted by tightness.
            
            # Let's re-assign for non-exact fits directly into the priorities array.
            # We want these scores to be less than the exact fit score (10.0).
            # Let's map the softmax probabilities to a range like [0, 5].
            # Maximum softmax probability is 1, so mapping `softmax_priorities * 5.0` could work.
            priorities[non_exact_fit_indices_in_fit] = softmax_priorities * 5.0

    # Ensure that if there were exact fits, they remain with their high priority
    # and non-exact fits have scores that are strictly less than the exact fit score.
    # This is handled by the assignment logic above. If exact fits exist, their score is 10.
    # If only non-exact fits exist, their scores will be in the [0, 5] range.

    return priorities
```
