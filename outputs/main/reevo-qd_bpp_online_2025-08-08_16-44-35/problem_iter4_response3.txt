```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using a Sigmoid Best Fit Score.

    This heuristic prioritizes bins that have a remaining capacity just slightly larger
    than the item's size, aiming for minimal wasted space (Best Fit strategy).
    It uses a sigmoid function to assign higher priority to bins with less slack.
    Bins that cannot accommodate the item receive zero priority.

    The sigmoid function `1 / (1 + exp(k * slack))` maps slack values (where slack = remaining_capacity - item)
    to a priority score between 0 and 1.
    - For slack = 0 (perfect fit), the score is 0.5.
    - For slack > 0, the score is < 0.5, decreasing as slack increases.
    - A higher `sensitivity` (k) amplifies the preference for bins with smaller slack.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Returns:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Identify bins that can accommodate the item
    can_fit_mask = bins_remain_cap >= item

    if np.any(can_fit_mask):
        # For bins that can fit, calculate the "slack" (excess capacity)
        slack = bins_remain_cap[can_fit_mask] - item

        # Use a sigmoid function to score bins based on slack.
        # We want to prioritize bins with minimal slack (close to 0).
        # The function 1 / (1 + exp(k * slack)) achieves this:
        # - If slack is 0 (perfect fit), score is 0.5.
        # - If slack > 0 (excess capacity), score < 0.5, decreasing as slack increases.
        # A higher sensitivity 'k' makes the score drop faster for larger slacks,
        # thus favoring bins closer to the item size more strongly.
        sensitivity = 2.0  # Increased sensitivity for stronger preference for tighter fits

        # Calculate the argument for the sigmoid.
        # To prevent potential overflow in np.exp for very large slack values,
        # we can clip the slack. A reasonable upper bound for slack that still
        # yields a meaningful distinction might be around the bin capacity itself,
        # but for the sigmoid function's argument, we need to consider `sensitivity * slack`.
        # If `sensitivity * slack` exceeds ~700, `np.exp` can result in `inf`.
        # Clipping `slack` to a value where `sensitivity * slack` is manageable is appropriate.
        # For instance, if sensitivity is 2.0, clipping slack to ~300 would be safe.
        # Let's use a moderate clipping value for slack.
        max_slack_for_sigmoid = 100.0  # Slack values larger than this will be treated as equal in penalty
        clipped_slack = np.minimum(slack, max_slack_for_sigmoid)

        exponent_argument = sensitivity * clipped_slack

        # Calculate the sigmoid score: 1 / (1 + exp(-x)) is equivalent to exp(x) / (1 + exp(x))
        # Using 1 / (1 + exp(x)) directly with positive exponent_argument is fine.
        # `np.exp(exponent_argument)` will handle large values by returning `inf`,
        # leading to `1 / (1 + inf)` which evaluates to 0. This is desired for bins
        # with very large slack, as they should have a very low priority.
        priorities[can_fit_mask] = 1.0 / (1.0 + np.exp(exponent_argument))

    return priorities
```
