[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)",
    "response_id": 0,
    "obj": 4.487435181491823,
    "SLOC": 2.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores for bins based on Best Fit heuristic.\n\n    Bins that can fit the item are prioritized by smallest remaining capacity after placement.\n    Infeasible bins receive -inf priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    priority = np.where(can_fit, -(bins_remain_cap - item), -np.inf)\n    return priority",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 4.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores for bins based on minimal leftover space.\n\n    Args:\n        item: Size of the item to be packed.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Higher values indicate better fit.\n    \"\"\"\n    # Prioritize bins that can fit the item with the least leftover space.\n    # Priority is (item - remaining_capacity), which is negative for valid bins,\n    # with higher (less negative) values indicating better fits.\n    return np.where(bins_remain_cap >= item, item - bins_remain_cap, -np.inf)",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response2.txt_stdout.txt",
    "code_path": "problem_iter3_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores combining Best Fit for large and Worst Fit for small items.\n    \n    Uses a dynamic formula based on item size to balance slack minimization and space preservation.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    priority = np.where(\n        can_fit,\n        bins_remain_cap * (1 - 2 * item) + (item ** 2),\n        -np.inf\n    )\n    return priority",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response0.txt_stdout.txt",
    "code_path": "problem_iter4_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on item size using Best Fit for large items and Worst Fit for small ones.\"\"\"\n    can_fit = bins_remain_cap >= item\n    slack = bins_remain_cap - item\n    if item >= 0.5:\n        # Best Fit: prioritize bins with minimal slack (least remaining space after placement)\n        priority = -slack\n    else:\n        # Worst Fit: prioritize bins with maximum remaining capacity\n        priority = bins_remain_cap\n    return np.where(can_fit, priority, -np.inf)",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores for bins balancing best-fit and worst-fit heuristics.\n    \n    Dynamically scores bins based on item size: minimizes residual capacity for large items\n    and preserves space (maximizes residual) for small items. Penalizes infeasible bins (-\u221e).\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    residual = bins_remain_cap - item\n    weight = 1 - 2 * item  # Blends best-fit (negative weight) & worst-fit (positive weight)\n    priority = np.where(can_fit, residual * weight, -np.inf)\n    return priority",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 14.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores blending best-fit and worst-fit with item-size-dependent weights and threshold adjustment.\n    \n    Blends best-fit (residual * negative weight) and worst-fit (residual * positive weight) heuristics with smooth transition at \n    item_size = 0.5, adjusted by epsilon to prioritize best-fit for perfect 0.5-sized items. Additive numerical stability ensures \n    no zero-weight edge cases. Preserves space efficiency for small items and gap avoidance for large items.\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    residual = bins_remain_cap - item\n    \n    # Dynamic weight with smooth transition and edge-case handling\n    weight_bias = 1e-6\n    weight = (1 - 2 * item) - weight_bias  # Best-fit default at item_size threshold\n    \n    priority = np.where(can_fit, residual * weight, -np.inf)\n    return priority",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response0.txt_stdout.txt",
    "code_path": "problem_iter8_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins using adaptive threshold between best-fit and worst-fit heuristics.\n    \n    For items >= 0.5: Best-fit (min residual) to avoid fragmentation.\n    For items < 0.5: Worst-fit (max residual) to preserve larger spaces.\n    Uses numpy's efficient masking for performance.\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    residual = bins_remain_cap - item\n    \n    if item >= 0.5:\n        # Best-fit: Score = -residual for smallest residual space\n        priority = np.where(can_fit, -residual, -np.inf)\n    else:\n        # Worst-fit: Score = residual for largest residual space\n        priority = np.where(can_fit, residual, -np.inf)\n    \n    return priority",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response1.txt_stdout.txt",
    "code_path": "problem_iter9_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores blending Best Fit and Worst Fit heuristics adaptively.\n    \n    For large items, prioritizes tight fits (Best Fit); for small items, prefers spacious bins (Worst Fit).\n    Invalid bins receive -inf. Combines residual space and item size via dynamic weights.\n    \n    Args:\n        item: Size of item to be added.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    residual = bins_remain_cap - item\n    \n    # Adaptive weight based on item size: blends Best Fit (-residual) and Worst Fit (residual)\n    # Weight = item_size \u2192 prioritizes Best Fit more for larger items\n    priority = np.where(can_fit, residual * (1 - 2 * item), -np.inf)\n    return priority",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response0.txt_stdout.txt",
    "code_path": "problem_iter10_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores blending Best Fit and Worst Fit with adaptive weights and tie-breaking.\n    \n    Adaptive blending is achieved via item-size-dependent weights. A small epsilon term breaks ties\n    in favor of tighter fits for edge cases (e.g., item=0.5).\n    \n    Args:\n        item: Size of item to be added.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    residual = bins_remain_cap - item\n    \n    # Main adaptive priority blending Best/Worst Fit (proportional to residual)\n    adaptive_weight = 1.0 - 2.0 * item\n    adaptive_priority = adaptive_weight * residual\n    \n    # Epsilon term biasing toward smaller residuals in tie-breaker cases\n    epsilon_priority = -residual * 1e-6  # Small negative to prefer least residual\n    \n    # Combine priorities while masking invalid bins\n    priority = np.where(can_fit, adaptive_priority + epsilon_priority, -np.inf)\n    return priority",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response0.txt_stdout.txt",
    "code_path": "problem_iter11_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores for bins using a dynamic target residual approach.\n    \n    Priority is determined by how closely a bin's residual after placement matches\n    a target residual of (1 - item_size), blending Best Fit (large items) and\n    Worst Fit (small items) through a size-adjusted quadratic penalty. Feasible bins\n    are scored to balance snug fits for large items and space preservation for\n    small items.\n    \n    Args:\n        item: Size of item to be packed (normalized to bin capacity, assumed to be 1.0).\n        bins_remain_cap: Array of current remaining capacities for each bin.\n        \n    Returns:\n        Array of scores with the same shape as bins_remain_cap.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    residual = bins_remain_cap - item\n    target_residual = 1.0 - item  # Blend target based on item size\n    squared_error = (residual - target_residual) ** 2\n    priority = np.where(can_fit, -squared_error, -np.inf)\n    return priority",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response0.txt_stdout.txt",
    "code_path": "problem_iter12_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores using threshold-based Best Fit for large and Worst Fit for small items.\n    \n    Directly switches between Best Fit (minimizing slack) for items > 0.5 and Worst Fit (preserving flexibility)\n    for items <= 0.5. Eliminates non-linear terms while maintaining adaptive strategy selection.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    if item > 0.5:\n        # Best Fit: prioritize bins with least slack (minimize rem_cap - item)\n        priority = - (bins_remain_cap - item)\n    else:\n        # Worst Fit: prioritize bins with most remaining capacity\n        priority = bins_remain_cap.copy()\n    return np.where(can_fit, priority, -np.inf)",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter13_response3.txt_stdout.txt",
    "code_path": "problem_iter13_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Priority function v2 implementing adaptive bin selection with quadratic penalties.\"\"\"\n    EPSILON = 1e-9\n    if bins_remain_cap.size == 0:\n        return np.array([])  # Handle empty bins case gracefully\n\n    # Infer bin capacity from max remaining capacity\n    C = np.max(bins_remain_cap)\n    \n    # Handle edge cases where all bins are full but item is zero\n    if C < EPSILON and item < EPSILON:\n        return np.zeros_like(bins_remain_cap, dtype=np.float64)\n    if C < EPSILON:\n        C = 1.0  # Fallback normalization value\n    \n    # Adaptive blending weights based on item-capacity ratio\n    item_ratio = item / C\n    weight = item_ratio ** 1.5  # Polynomial expression for adaptive strategy\n    \n    # Feasibility filter and residual computation\n    can_fit = bins_remain_cap >= item\n    residual = bins_remain_cap - item\n    \n    # Best Fit component: quadratic penalty for residual space\n    bf_component = -(residual ** 2)  # Stronger penalty for leftover space\n    \n    # Worst Fit component: slack normalization with epsilon-stabilized weights\n    normalized_slack = residual / (bins_remain_cap + EPSILON)\n    wf_component = normalized_slack * item_ratio  # Size-adjusted slack valuation\n    \n    # Non-linear residual tuning with deviation minimization\n    ideal_residual = C * np.sqrt(item_ratio)  # Math-guided target\n    deviation = residual - ideal_residual\n    deviation_penalty = (deviation ** 2) / (item + EPSILON)\n    \n    # Final priority calculation with adaptive blending and math-optimized terms\n    priority = (weight * bf_component) + ((1 - weight) * wf_component) - deviation_penalty\n    \n    # Epsilon stabilization for smooth transitions\n    priority += EPSILON * np.random.rand(*priority.shape)\n    \n    # Mask infeasible bins and return\n    return np.where(can_fit, priority, -np.inf)",
    "response_id": 3,
    "obj": 9.782608695652188,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter19_response0.txt_stdout.txt",
    "code_path": "problem_iter19_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores blending Best Fit (BF) and Worst Fit (WF) strategies with adaptive weights.\n\n    For large items (> 0.5 + delta), prioritizes BF (minimize slack). For small items (< 0.5 - delta), \n    prioritizes WF (maximize remaining capacity). Linear blend in transition zone (0.4-0.6).\n    \"\"\"\n    THRESHOLD = 0.5\n    DELTA = 0.1  # Transition slope control\n\n    can_fit = bins_remain_cap >= item\n    slack = bins_remain_cap - item\n\n    # Blend weights: linearly interpolate between BF and WF around threshold\n    if item <= THRESHOLD - DELTA:\n        w_bf, w_wf = 0.0, 1.0  # WF dominant for small items\n    elif item >= THRESHOLD + DELTA:\n        w_bf, w_wf = 1.0, 0.0  # BF dominant for large items\n    else:\n        # Linear blend between BF and WF in threshold region\n        t = (item - (THRESHOLD - DELTA)) / (2 * DELTA)\n        w_bf, w_wf = t, 1 - t\n\n    # Component scores\n    bf_component = -slack  # BF: minimize slack\n    wf_component = bins_remain_cap  # WF: maximize remaining capacity\n\n    # Composite priority blend\n    composite = w_bf * bf_component + w_wf * wf_component\n\n    # Mask infeasible bins\n    priority = np.where(can_fit, composite, -np.inf)\n    return priority",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]