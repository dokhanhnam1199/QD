[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    return np.zeros_like(bins_remain_cap)",
    "response_id": 0,
    "obj": 4.487435181491823,
    "SLOC": 2.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores for bins based on Best Fit heuristic.\n\n    Bins that can fit the item are prioritized by smallest remaining capacity after placement.\n    Infeasible bins receive -inf priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    priority = np.where(can_fit, -(bins_remain_cap - item), -np.inf)\n    return priority",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 4.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores for bins based on minimal leftover space.\n\n    Args:\n        item: Size of the item to be packed.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Higher values indicate better fit.\n    \"\"\"\n    # Prioritize bins that can fit the item with the least leftover space.\n    # Priority is (item - remaining_capacity), which is negative for valid bins,\n    # with higher (less negative) values indicating better fits.\n    return np.where(bins_remain_cap >= item, item - bins_remain_cap, -np.inf)",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response2.txt_stdout.txt",
    "code_path": "problem_iter3_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores combining Best Fit for large and Worst Fit for small items.\n    \n    Uses a dynamic formula based on item size to balance slack minimization and space preservation.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    priority = np.where(\n        can_fit,\n        bins_remain_cap * (1 - 2 * item) + (item ** 2),\n        -np.inf\n    )\n    return priority",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response0.txt_stdout.txt",
    "code_path": "problem_iter4_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on item size using Best Fit for large items and Worst Fit for small ones.\"\"\"\n    can_fit = bins_remain_cap >= item\n    slack = bins_remain_cap - item\n    if item >= 0.5:\n        # Best Fit: prioritize bins with minimal slack (least remaining space after placement)\n        priority = -slack\n    else:\n        # Worst Fit: prioritize bins with maximum remaining capacity\n        priority = bins_remain_cap\n    return np.where(can_fit, priority, -np.inf)",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores for bins balancing best-fit and worst-fit heuristics.\n    \n    Dynamically scores bins based on item size: minimizes residual capacity for large items\n    and preserves space (maximizes residual) for small items. Penalizes infeasible bins (-\u221e).\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    residual = bins_remain_cap - item\n    weight = 1 - 2 * item  # Blends best-fit (negative weight) & worst-fit (positive weight)\n    priority = np.where(can_fit, residual * weight, -np.inf)\n    return priority",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 14.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores blending best-fit and worst-fit with item-size-dependent weights and threshold adjustment.\n    \n    Blends best-fit (residual * negative weight) and worst-fit (residual * positive weight) heuristics with smooth transition at \n    item_size = 0.5, adjusted by epsilon to prioritize best-fit for perfect 0.5-sized items. Additive numerical stability ensures \n    no zero-weight edge cases. Preserves space efficiency for small items and gap avoidance for large items.\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    residual = bins_remain_cap - item\n    \n    # Dynamic weight with smooth transition and edge-case handling\n    weight_bias = 1e-6\n    weight = (1 - 2 * item) - weight_bias  # Best-fit default at item_size threshold\n    \n    priority = np.where(can_fit, residual * weight, -np.inf)\n    return priority",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response0.txt_stdout.txt",
    "code_path": "problem_iter8_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins using adaptive threshold between best-fit and worst-fit heuristics.\n    \n    For items >= 0.5: Best-fit (min residual) to avoid fragmentation.\n    For items < 0.5: Worst-fit (max residual) to preserve larger spaces.\n    Uses numpy's efficient masking for performance.\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    residual = bins_remain_cap - item\n    \n    if item >= 0.5:\n        # Best-fit: Score = -residual for smallest residual space\n        priority = np.where(can_fit, -residual, -np.inf)\n    else:\n        # Worst-fit: Score = residual for largest residual space\n        priority = np.where(can_fit, residual, -np.inf)\n    \n    return priority",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 10.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response1.txt_stdout.txt",
    "code_path": "problem_iter9_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores blending Best Fit and Worst Fit heuristics adaptively.\n    \n    For large items, prioritizes tight fits (Best Fit); for small items, prefers spacious bins (Worst Fit).\n    Invalid bins receive -inf. Combines residual space and item size via dynamic weights.\n    \n    Args:\n        item: Size of item to be added.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    residual = bins_remain_cap - item\n    \n    # Adaptive weight based on item size: blends Best Fit (-residual) and Worst Fit (residual)\n    # Weight = item_size \u2192 prioritizes Best Fit more for larger items\n    priority = np.where(can_fit, residual * (1 - 2 * item), -np.inf)\n    return priority",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response0.txt_stdout.txt",
    "code_path": "problem_iter10_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores blending Best Fit and Worst Fit with adaptive weights and tie-breaking.\n    \n    Adaptive blending is achieved via item-size-dependent weights. A small epsilon term breaks ties\n    in favor of tighter fits for edge cases (e.g., item=0.5).\n    \n    Args:\n        item: Size of item to be added.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Returns:\n        Array of priority scores for each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    residual = bins_remain_cap - item\n    \n    # Main adaptive priority blending Best/Worst Fit (proportional to residual)\n    adaptive_weight = 1.0 - 2.0 * item\n    adaptive_priority = adaptive_weight * residual\n    \n    # Epsilon term biasing toward smaller residuals in tie-breaker cases\n    epsilon_priority = -residual * 1e-6  # Small negative to prefer least residual\n    \n    # Combine priorities while masking invalid bins\n    priority = np.where(can_fit, adaptive_priority + epsilon_priority, -np.inf)\n    return priority",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response0.txt_stdout.txt",
    "code_path": "problem_iter11_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores for bins using a dynamic target residual approach.\n    \n    Priority is determined by how closely a bin's residual after placement matches\n    a target residual of (1 - item_size), blending Best Fit (large items) and\n    Worst Fit (small items) through a size-adjusted quadratic penalty. Feasible bins\n    are scored to balance snug fits for large items and space preservation for\n    small items.\n    \n    Args:\n        item: Size of item to be packed (normalized to bin capacity, assumed to be 1.0).\n        bins_remain_cap: Array of current remaining capacities for each bin.\n        \n    Returns:\n        Array of scores with the same shape as bins_remain_cap.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    residual = bins_remain_cap - item\n    target_residual = 1.0 - item  # Blend target based on item size\n    squared_error = (residual - target_residual) ** 2\n    priority = np.where(can_fit, -squared_error, -np.inf)\n    return priority",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 12.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response0.txt_stdout.txt",
    "code_path": "problem_iter12_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores using threshold-based Best Fit for large and Worst Fit for small items.\n    \n    Directly switches between Best Fit (minimizing slack) for items > 0.5 and Worst Fit (preserving flexibility)\n    for items <= 0.5. Eliminates non-linear terms while maintaining adaptive strategy selection.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    if item > 0.5:\n        # Best Fit: prioritize bins with least slack (minimize rem_cap - item)\n        priority = - (bins_remain_cap - item)\n    else:\n        # Worst Fit: prioritize bins with most remaining capacity\n        priority = bins_remain_cap.copy()\n    return np.where(can_fit, priority, -np.inf)",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter29_response1.txt_stdout.txt",
    "code_path": "problem_iter29_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Ranked via size threshold \ud835\uded5: large items (\ud835\udd69 > 0.5) \u2192 BF; small items (\ud835\udd69 \u2264 0.5) \u2192 1.5\u00d7 slack preservation.\n    Tie-breaker (\ud835\udf00\u00b7i) ensures determinism.\n    \n    Args:\n        item: Normalized size (\u22641) of the incoming item.\n        bins_remain_cap: List of normalized remaining capacities (\u22641).\n    \n    Returns:\n        Priorities where higher = better fit. Infeasible bins get -\u221e.\n    \"\"\"\n    # Constants\n    THRESHOLD = 0.5\n    WF_WEIGHT = 1.5  # Increased slack preservation for small items\n    EPSILON = 1e-8   # Tie-breaker to ensure deterministic selection\n\n    # Feasibility mask\n    can_fit = bins_remain_cap >= item\n    \n    # Best Fit for large items: minimize slack\n    bf_slack = bins_remain_cap - item\n    bf_priority = -bf_slack  # Higher = closer to zero slack\n    \n    # Worst Fit variant for small items: maximize slack weighted by positional tie-breaker\n    wf_slack = bins_remain_cap  \n    wf_priority = (wf_slack * WF_WEIGHT) + (EPSILON * np.arange(len(wf_slack)))  # Slack prioritization\n\n    # Select strategy based on item size\n    priority = np.where(\n        can_fit,\n        np.where(\n            item > THRESHOLD,\n            bf_priority,   # High-priority for tight fits (large items)\n            wf_priority    # High-priority for slack preservation (small items)\n        ),\n        -np.inf  # Infeasible bins\n    )\n\n    return priority",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter19_response0.txt_stdout.txt",
    "code_path": "problem_iter19_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores blending Best Fit (BF) and Worst Fit (WF) strategies with adaptive weights.\n\n    For large items (> 0.5 + delta), prioritizes BF (minimize slack). For small items (< 0.5 - delta), \n    prioritizes WF (maximize remaining capacity). Linear blend in transition zone (0.4-0.6).\n    \"\"\"\n    THRESHOLD = 0.5\n    DELTA = 0.1  # Transition slope control\n\n    can_fit = bins_remain_cap >= item\n    slack = bins_remain_cap - item\n\n    # Blend weights: linearly interpolate between BF and WF around threshold\n    if item <= THRESHOLD - DELTA:\n        w_bf, w_wf = 0.0, 1.0  # WF dominant for small items\n    elif item >= THRESHOLD + DELTA:\n        w_bf, w_wf = 1.0, 0.0  # BF dominant for large items\n    else:\n        # Linear blend between BF and WF in threshold region\n        t = (item - (THRESHOLD - DELTA)) / (2 * DELTA)\n        w_bf, w_wf = t, 1 - t\n\n    # Component scores\n    bf_component = -slack  # BF: minimize slack\n    wf_component = bins_remain_cap  # WF: maximize remaining capacity\n\n    # Composite priority blend\n    composite = w_bf * bf_component + w_wf * wf_component\n\n    # Mask infeasible bins\n    priority = np.where(can_fit, composite, -np.inf)\n    return priority",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter22_response1.txt_stdout.txt",
    "code_path": "problem_iter22_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores for bins using Best Fit with tie-breaking.\n\n    Bins that can fit the item are prioritized by smallest leftover space.\n    Tie-breaker prefers bins with larger remaining capacity before placement.\n    Infeasible bins receive -inf priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    # Primary priority: minimize leftover space (-leftover)\n    # Secondary priority: prefer larger remaining capacities (tie-breaker)\n    epsilon = 1e-9  # Small enough to not override primary priority\n    priority = np.where(can_fit, -(bins_remain_cap - item) + epsilon * bins_remain_cap, -np.inf)\n    return priority",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter27_response1.txt_stdout.txt",
    "code_path": "problem_iter27_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority scores for bins by blending Best/Worst Fit heuristics based on item size.\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    can_fit = bins_remain_cap >= item\n    threshold = 0.5\n    residual = bins_remain_cap - item\n    \n    # Calculate blending factor for Best/Worst Fit contribution\n    blend_factor = np.where(item > threshold, 1.0, item / threshold)\n    \n    # Dynamic priority combining Best Fit (minimize residual) and Worst Fit (preserve capacity)\n    # Coefficient (1-2*blend_factor) ensures smooth transition:\n    # - Positive for small items (Worst Fit), increasing residual prioritization\n    # - Negative for large items (Best Fit), minimizing residual\n    priority = (1 - 2 * blend_factor) * residual\n    \n    # Apply -inf to bins that cannot fit the item\n    final_priority = np.where(can_fit, priority, -np.inf)\n    return final_priority",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 13.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter30_response0.txt_stdout.txt",
    "code_path": "problem_iter30_code0.py",
    "code": "import math\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Improved priority for online bin packing via smooth sigmoid-based weight blending best/worst fit.\n    \n    Uses a sigmoid-shaped transition centered at item_size=0.5 for smooth behavior, with numerical bias \n    to ensure stable best-fit selection at thresholds. Weight bias pushes zero-weight edge cases toward best-fit.\n    \n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n    \n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Vectorized filter for valid bins (numerically stable comparison)\n    can_fit = (bins_remain_cap >= item - 1e-9)  # Numerical stability\n    residual = bins_remain_cap - item\n\n    # Smooth, continuous weight function via sigmoidal transition\n    beta = 10  # controls transition sharpness\n    sigmoid_input = beta * (item - 0.5)\n    decay_term = math.exp(-sigmoid_input)  # Forward biased to prevent overflow\n    sigmoid = 1.0 / (1.0 + decay_term)\n    weight = 1.0 - 2.0 * sigmoid  # [small items: +ve (worst), large items: -ve (best)]\n\n    # Bias toward best-fit for numerical stability and threshold robustness\n    weight -= 1e-6  # Ensures best-fit if weight would otherwise be zero\n\n    # Compute final priorities: valid -> residual * weight, invalid -> -infty\n    priority = np.where(can_fit, residual * weight, -np.inf)\n    return priority",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 25.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  }
]