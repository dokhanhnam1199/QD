```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines tightest fit and bin fullness using normalized scores and exponential decay.
    Prioritizes bins that are a good fit and are already relatively full.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    suitable_bins_mask = bins_remain_cap >= item
    
    if np.any(suitable_bins_mask):
        suitable_bins_caps = bins_remain_cap[suitable_bins_mask]
        
        # Metric 1: Tightest fit (proximity)
        # Smaller remaining capacity after packing is better. Add small epsilon to avoid division by zero.
        gaps = suitable_bins_caps - item
        proximity_scores = 1.0 / (gaps + 1e-9)
        
        # Normalize proximity scores to [0, 1]
        min_prox = np.min(proximity_scores)
        max_prox = np.max(proximity_scores)
        if max_prox == min_prox:
            normalized_proximity = np.ones_like(proximity_scores) * 0.5
        else:
            normalized_proximity = (proximity_scores - min_prox) / (max_prox - min_prox)
            
        # Metric 2: Fullness of the bin before packing
        # Higher fullness (lower remaining capacity) is generally better.
        fullness_scores = 1.0 / (suitable_bins_caps + 1e-9)
        
        # Normalize fullness scores to [0, 1]
        min_fullness = np.min(fullness_scores)
        max_fullness = np.max(fullness_scores)
        if max_fullness == min_fullness:
            normalized_fullness = np.ones_like(fullness_scores) * 0.5
        else:
            normalized_fullness = (fullness_scores - min_fullness) / (max_fullness - min_fullness)
            
        # Combine metrics with a preference for tightness, modulated by fullness
        # Use exponential decay on the combined score to create a graded priority
        # A higher combined score (good fit and high fullness) will result in a higher priority
        combined_score = normalized_proximity * 0.7 + normalized_fullness * 0.3
        
        # Apply exponential decay to create graded priorities, similar to Heuristic 12's approach
        # Here, we map the combined score to a priority. A higher combined score should yield a higher priority.
        # Using an exponential function (e.g., exp(x)) naturally produces a graded response.
        # We scale and shift to get a reasonable range, e.g., mapping [0,1] combined_score to a positive range.
        # An exponential function like exp(k * combined_score) where k is a scaling factor.
        # Let's use exp(5 * combined_score) for a steeper curve.
        exponential_priorities = np.exp(5 * combined_score)
        
        # Normalize these exponential priorities to [0, 1]
        min_exp_prio = np.min(exponential_priorities)
        max_exp_prio = np.max(exponential_priorities)
        
        if max_exp_prio == min_exp_prio:
            final_priorities = np.ones_like(exponential_priorities) * 0.5
        else:
            final_priorities = (exponential_priorities - min_exp_prio) / (max_exp_prio - min_exp_prio)
        
        priorities[suitable_bins_mask] = final_priorities
        
    return priorities
```
