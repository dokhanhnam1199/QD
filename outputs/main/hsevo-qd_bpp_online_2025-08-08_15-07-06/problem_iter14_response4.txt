```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Prioritize bins that fit the item snugly, with a penalty for excess capacity.
    Uses exponential scaling on negative differences for graded priorities,
    and includes a term to favor bins that are already more full.
    """
    
    fit_mask = bins_remain_cap >= item
    
    priorities = np.full_like(bins_remain_cap, -np.inf)
    
    if np.any(fit_mask):
        valid_capacities = bins_remain_cap[fit_mask]
        
        # Calculate difference: remaining capacity - item size
        # Smaller difference is better for "best fit"
        differences = valid_capacities - item
        
        # Higher priority for smaller differences (tighter fit)
        # Use exponential scaling for a graded priority, controlled by temperature
        # Lower temperature emphasizes the "best fit" more strongly.
        temperature = 0.5  # Tunable parameter
        
        # Score component 1: Based on tightness of fit (closer to zero difference is better)
        # We want to maximize exp(-difference / temperature)
        fit_score = np.exp(-differences / temperature)
        
        # Score component 2: Favor bins that are already more full.
        # Prioritize bins with smaller remaining capacity among those that fit.
        # Use inverse of remaining capacity, scaled to avoid very large numbers.
        # Adding a small epsilon to avoid division by zero, though fit_mask should prevent zero.
        fullness_score = 1.0 / (valid_capacities + 1e-9)
        
        # Combine scores. A simple multiplication or addition can be used.
        # Multiplication can be more robust for combining relative preferences.
        # Using log-exp for combining could also be considered, but simple multiplication works.
        
        # Adding a small constant to fullness_score to avoid multiplying by zero
        # and to give it some weight even if differences are very small.
        # The relative scale between fit_score and fullness_score is important.
        # Let's normalize them or use a weighting factor if one criterion is more important.
        
        # Let's try adding the scores, after scaling 'fullness_score' to be comparable to 'fit_score'.
        # Or, a multiplicative approach: good fit AND already full bin is best.
        
        # Let's scale the fullness score to avoid it dominating or being negligible.
        # A simple approach is to add the two scores.
        # We want to maximize `fit_score` and `fullness_score`.
        
        # Let's use a weighted sum, or just sum if we assume they are on a comparable scale.
        # The exponential fit_score can range from near 0 to ~1 (if temperature is high or diff is 0).
        # The fullness_score ranges from a small number to 1/item (or 1/min_valid_capacity).
        
        # Let's try to normalize `fullness_score` relative to the minimum possible `fullness_score`.
        # Or, more simply, let's combine them such that a tight fit in a nearly full bin is best.
        
        # A simple approach:
        # `priorities[fit_mask] = fit_score * fullness_score`
        # This penalizes bins that are both not a tight fit and have large remaining capacity.
        
        # Let's reconsider the goal: minimize bins. This means filling bins as much as possible.
        # "Best fit" (minimize difference) is good.
        # "First fit" (use first available) is simple.
        # "Worst fit" (maximize remaining capacity) tends to leave larger gaps.
        
        # The `fit_score` (exponential of negative difference) captures the "best fit" aspect.
        # The `fullness_score` (1/capacity) captures the "already full" aspect.
        
        # Let's try adding them, but perhaps scaling `fullness_score` differently.
        # If `differences` are small, `fit_score` is high. If `valid_capacities` are small, `fullness_score` is high.
        
        # Let's combine them multiplicatively as a starting point.
        # `priorities[fit_mask] = fit_score * fullness_score`
        
        # A more direct approach for "best fit" might be to prioritize the smallest `valid_capacities`.
        # So the priority should be higher for smaller `valid_capacities`.
        # Let's combine the two criteria using a weighted sum, where higher is better.
        
        # Priority = w1 * (1 / (differences + epsilon)) + w2 * (1 / (valid_capacities + epsilon))
        # Or, to emphasize tight fit more, use the exponential as in `fit_score`.
        
        # Let's use the exponential of the negative difference for tightness,
        # and add a term that is inversely proportional to the remaining capacity.
        
        # Final chosen combination: prioritize tight fit using exponential, and secondarily prioritize bins that are already more full.
        # Combine them by adding, where `fullness_score` is scaled.
        # Scale `fullness_score` to be in a similar range as `fit_score`.
        # `fit_score` is typically in (0, 1].
        # `fullness_score` can be large if capacities are small.
        # Let's use `1.0 / (valid_capacities + 1e-9)` as `fullness_score`.
        # To make it additive, let's consider the range.
        
        # Let's stick to the multiplicative combination as it naturally penalizes combinations of poor fit and low fullness.
        # `priorities[fit_mask] = fit_score * fullness_score`
        
        # Let's try adding the scores, as it might be more interpretable as a combined utility.
        # We need to ensure the scales are somewhat aligned.
        # Let's scale `fullness_score` by a factor. Or, better, transform `fullness_score` similar to `fit_score`.
        # `fullness_score_transformed = np.exp(-valid_capacities / another_temperature)`
        # This would prioritize both tight fit and already full bins.
        
        # Let's go with a simple sum of normalized scores or directly use the `fit_score` and `fullness_score` as is.
        # A simpler heuristic inspired by "best fit" but with graded priorities:
        # Directly use `1.0 / (differences + epsilon)` as the primary score.
        # Add a secondary component that favors bins that are already more full.
        
        # Let's use `fit_score` and add a scaled version of `fullness_score`.
        # `priorities[fit_mask] = fit_score + 0.5 * fullness_score` # Example weighting
        
        # Let's try a combined approach using `exp(-difference)` and `exp(-capacity)`
        # This prioritizes small differences and small capacities.
        
        # Revisit heuristic 13/14/16: `exp(-diffs / temperature)`
        # This prioritizes tight fit.
        # Let's add a secondary criterion: prioritize bins that are *more full* (smaller remaining capacity).
        
        # Combined score: `exp(-differences / temp1) + exp(-valid_capacities / temp2)`
        # Where temp1 controls sensitivity to fit tightness, and temp2 to fullness.
        
        temp1 = 0.5 # For fit tightness
        temp2 = 1.0 # For bin fullness
        
        priorities[fit_mask] = np.exp(-differences / temp1) + np.exp(-valid_capacities / temp2)
        
    return priorities
```
