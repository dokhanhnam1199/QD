{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines inverse proximity with a sigmoid for smoother prioritization.\n\n    Favors bins with tight fits, but also provides non-zero priority for\n    less tight fits to encourage exploration.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    if np.any(suitable_bins_mask):\n        suitable_bins_caps = bins_remain_cap[suitable_bins_mask]\n        \n        # Inverse proximity for tight fits (similar to priority_v0)\n        proximity = suitable_bins_caps - item\n        \n        # Use a scaled sigmoid on proximity to create a smoother distribution\n        # Scaling factor `alpha` controls steepness. Higher alpha means steeper curve.\n        alpha = 10.0 \n        # Add a small epsilon to avoid division by zero for perfect fits\n        inverse_proximity_scores = 1.0 / (proximity + 1e-9)\n        \n        # Normalize inverse proximity scores to be between 0 and 1\n        if np.max(inverse_proximity_scores) > 0:\n            normalized_inverse_proximity = inverse_proximity_scores / np.max(inverse_proximity_scores)\n        else:\n            normalized_inverse_proximity = np.zeros_like(inverse_proximity_scores)\n\n        # Sigmoid transformation to map scores to a [0, 1] range, emphasizing tighter fits\n        # Adjusting the sigmoid's center and steepness can tune behavior.\n        # Here, we center it around a value that would correspond to a \"good\" proximity.\n        # For simplicity, we'll use a sigmoid on the normalized inverse proximity.\n        # A higher score from inverse proximity should map to a higher sigmoid output.\n        sigmoid_scores = 1 / (1 + np.exp(-alpha * (normalized_inverse_proximity - 0.5))) # Adjusted sigmoid\n\n        priorities[suitable_bins_mask] = sigmoid_scores\n        \n        # Ensure perfect fits still get a high priority, potentially capped by sigmoid\n        perfect_fit_mask = (proximity == 0)\n        if np.any(perfect_fit_mask):\n            priorities[suitable_bins_mask][perfect_fit_mask] = 1.0 # Assign max priority for perfect fit\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    valid_bins = bins_remain_cap >= item\n    \n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    valid_capacities = bins_remain_cap[valid_bins]\n    \n    # Higher remaining capacity means lower priority (we want to fill bins)\n    # To use Softmax effectively, we want larger values to correspond to higher priority.\n    # So we can use (large_capacity - remaining_capacity) or 1/(remaining_capacity)\n    # Let's try 1/(remaining_capacity) as it penalizes bins that are already very full.\n    \n    inverted_capacities = 1.0 / valid_capacities\n    \n    # To further encourage fitting into bins with *just enough* space, \n    # we can add a term that penalizes bins with very large remaining capacity.\n    # Let's try subtracting the ratio of remaining capacity to total capacity (assuming initial bin capacity is known or can be estimated).\n    # For simplicity here, let's just use the inverse capacity.\n    \n    # Adding a small epsilon to avoid division by zero if a bin has 0 remaining capacity, though valid_bins should prevent this.\n    epsilon = 1e-9\n    scores = 1.0 / (valid_capacities + epsilon)\n    \n    # Softmax is often used to turn scores into probabilities or weights.\n    # A higher score should mean a higher probability of selection.\n    # Let's scale the scores to be positive and somewhat related to \"how well\" it fits.\n    # A common approach in fitting is to maximize the remaining capacity, \n    # but here we want to minimize the number of bins. So we prefer bins that are *almost* full.\n    # Let's try prioritizing bins where item fits snugly.\n    \n    fit_difference = valid_capacities - item\n    # We want to minimize fit_difference. To make it a priority (higher is better), we invert it.\n    # Add a small constant to avoid division by zero if fit_difference is 0.\n    priority_scores = 1.0 / (fit_difference + epsilon)\n    \n    # Apply Softmax to convert scores into probabilities (weights)\n    # We add a small penalty for bins that have much more capacity than needed to discourage very loose fits.\n    # Let's consider the \"waste\" factor. Waste = remaining_capacity - item\n    # We want to minimize waste.\n    \n    # Let's try a heuristic that favors bins that have enough capacity but not excessively more.\n    # We can try a value that increases as remaining_capacity gets closer to item.\n    \n    # Option 1: Prioritize bins that are almost full (minimum remaining capacity that fits item)\n    # We want higher scores for smaller `valid_capacities`. So `1/valid_capacities` or similar.\n    # To be more specific, we want `valid_capacities - item` to be small.\n    # So we can use `1.0 / (valid_capacities - item + epsilon)`\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins] = 1.0 / (valid_capacities - item + epsilon)\n    \n    # Apply Softmax: exp(score) / sum(exp(scores))\n    # For just returning priority scores for selection, we can directly use the calculated scores\n    # or apply a transformation like Softmax.\n    # If we want to select *one* bin based on highest priority, we can just return the scores directly.\n    # If we want to weight bins for some probabilistic selection, Softmax is good.\n    # For this problem, simply returning the scores that indicate preference is sufficient.\n    \n    # Let's refine to prioritize bins where remaining_capacity - item is minimized.\n    # A simple approach for priority is the inverse of the difference.\n    \n    scores = np.zeros_like(bins_remain_cap)\n    scores[valid_bins] = 1.0 / (valid_capacities - item + epsilon)\n\n    # To make it more \"Softmax-like\" in spirit of distribution, \n    # we can use a sigmoid-like transformation or directly use scaled values.\n    # Let's consider a temperature parameter to control the \"sharpness\" of priorities.\n    temperature = 1.0\n    \n    # Let's make values larger for better fits.\n    # A potential issue is if all valid capacities are very large, leading to small inverse values.\n    # We need to ensure scores are somewhat comparable or scaled.\n    \n    # Consider the \"tightness of fit\" as the primary driver.\n    # Tightest fit = smallest (remaining_capacity - item).\n    # So, priority is inversely proportional to (remaining_capacity - item).\n    \n    normalized_scores = np.zeros_like(bins_remain_cap)\n    if np.any(valid_bins):\n        # Calculate scores: higher score for tighter fit\n        # We want to maximize (1 / (remaining_capacity - item))\n        # Or to avoid issues with very small differences, maybe prioritize directly by minimum remaining capacity that fits.\n        \n        # Let's try a direct mapping:\n        # A bin is \"good\" if remaining_capacity is just enough.\n        # So, priority is high when remaining_capacity is close to item.\n        \n        # Let's use `remaining_capacity` itself as a negative factor for priority\n        # and `item` as a positive factor.\n        # How about prioritizing bins with smaller remaining capacity that can still fit the item?\n        # This aligns with the First Fit Decreasing heuristic's goal of filling bins.\n        \n        # Let's map the difference `valid_capacities - item` to a priority.\n        # Smaller difference should yield higher priority.\n        \n        # Example: item = 3, capacities = [5, 7, 10]\n        # Valid capacities = [5, 7, 10]\n        # Differences = [2, 4, 7]\n        # We want to prioritize bins with difference 2, then 4, then 7.\n        # So, 1/2, 1/4, 1/7 would work.\n        \n        diffs = valid_capacities - item\n        priorities = 1.0 / (diffs + epsilon)\n        \n        # Now, to make it more \"Softmax-like\" if we were to select probabilistically,\n        # we can exponentiate and normalize. But for direct priority score, this is fine.\n        # Let's add a small value to all priorities to avoid negative exponents in a Softmax if we were to use it.\n        # And let's scale them to prevent numerical underflow or overflow with Softmax.\n        \n        # For a direct priority score where higher means better, \n        # this inverse difference works well for \"best fit\" aspect.\n        \n        # Consider what happens if multiple bins have the exact same \"best fit\" difference.\n        # The current approach would give them equal priority.\n        \n        # To incorporate the \"Softmax-Based Fit\" idea, let's interpret it as:\n        # transform the \"fitness\" of a bin (how well it fits the item) into a priority.\n        # The fitness can be related to how close `remaining_capacity` is to `item`.\n        \n        # Let's define fitness as: -(remaining_capacity - item)^2. Higher fitness for smaller squared difference.\n        # Or, more simply, as we did: 1.0 / (remaining_capacity - item + epsilon)\n        \n        # Softmax transformation of these scores to get a distribution if needed.\n        # For now, we just need the scores themselves.\n        \n        # Let's try to directly use the remaining capacity for scaling, \n        # encouraging smaller capacities that fit.\n        \n        # Prioritize bins with the smallest remaining capacity that can fit the item.\n        # So, the priority score should be higher for smaller `valid_capacities`.\n        # Let's try `1.0 / valid_capacities`.\n        \n        # Consider a case: item = 2, bins_remain_cap = [3, 5, 10]\n        # Valid bins = [3, 5, 10]\n        # Option A (inverse diff): 1/(3-2)=1, 1/(5-2)=0.33, 1/(10-2)=0.125. Prioritizes bin with 3. (Best Fit)\n        # Option B (inverse capacity): 1/3=0.33, 1/5=0.2, 1/10=0.1. Prioritizes bin with 3.\n        \n        # If the goal is \"smallest number of bins\", then fitting into a nearly full bin is good.\n        # \"Best Fit\" heuristic is good for this.\n        \n        # Let's combine the \"fit\" (difference) with the \"emptiness\" (remaining capacity).\n        # Maybe penalize very large remaining capacities, even if they fit.\n        \n        # Let's use the difference again, as it directly measures \"how much space is left after fitting\".\n        # Smaller difference is better.\n        \n        diffs = valid_capacities - item\n        \n        # Scale diffs to be more in line with Softmax inputs (e.g., range -inf to +inf for exp)\n        # A common pattern is to use `exp(value)` where larger `value` is better.\n        # We want to maximize `-(diffs)`. So `exp(-diffs)`? No, we want to maximize score for smaller diffs.\n        # Let's use `exp(-diffs)` with `temperature`.\n        \n        temperature = 0.5 # Lower temperature means stronger preference for best fit\n        scaled_diffs = -diffs / temperature\n        \n        # Apply Softmax concept: exp(score) / sum(exp(scores))\n        # We can simply return exp(scaled_diffs) as the priority, which is proportional to softmax output.\n        \n        priorities = np.exp(scaled_diffs)\n        \n    \n    final_priorities = np.zeros_like(bins_remain_cap)\n    final_priorities[valid_bins] = priorities\n    \n    return final_priorities\n\n### Analyze & experience\n- *   **Heuristic 1 vs. Heuristic 13/16:** Heuristic 1 uses a loop for calculation, while 13 and 16 achieve the same result using vectorized NumPy operations (`1 / (cap - item + 1e-9)` applied element-wise). Vectorization is generally more efficient in Python with NumPy. Heuristic 12 and 15 are similar to 13/16 but add comments and slightly different variable names. Heuristic 8 takes absolute difference which is not ideal for prioritizing tighter fits (a bin with -1 difference is worse than a bin with +1 difference, but `abs` makes them equal). Heuristic 8 also applies the `can_fit_mask` *after* calculating inverse absolute difference, which is less clean than filtering first.\n*   **Heuristic 2/6/10 vs. Heuristic 4/14/17:** Heuristics 2, 6, and 10 are identical. They use a sigmoid function applied to normalized inverse proximity scores. Heuristic 4, 14, and 17 are also identical and very similar to 2/6/10, also using sigmoid and normalization. The difference lies in how normalization is performed. 4/14/17 normalize based on `(inverse_proximity - min) / (max - min)`, aiming to center around 0.5 for the sigmoid. 2/6/10 normalize by dividing by the max inverse proximity, effectively scaling to [0, 1] where 1 is the tightest fit. The explicit handling of perfect fits (priority = 1.0) in 2/6/10/4/14/17 is a good addition for ensuring these are always prioritized. The logic in 2/6/10/4/14/17 seems more robust and nuanced than simpler inverse proximity.\n*   **Heuristic 7 vs. Heuristic 11/17:** Heuristic 7 uses a Softmax on negative differences (`-(eligible_capacities - item)`), which effectively prioritizes bins with small remaining capacity after fitting the item. This is a strong approach. Heuristics 11 and 17 are identical and also use a `temperature` parameter with `exp(-diffs / temperature)`. This is conceptually similar to Softmax but returns raw scores proportional to the softmax probabilities, which is often sufficient for selection. Heuristic 17 also includes `1.0 / valid_capacities` logic which is then commented out or seemingly superseded by the `exp(-diffs / temperature)` part. The `temperature` parameter offers a tunable knob.\n*   **Heuristic 3 vs. Heuristic 9:** Heuristic 3 uses `item - bins_remain_cap` for fitting bins, resulting in negative priorities. Higher values (closer to 0) are better fits. Heuristic 9 aims to combine tight fit (`item - bins_that_fit_cap`) with fullness (`1.0 / (bins_that_fit_cap - item + epsilon)`). This combination is more complex and potentially captures more desired behavior by rewarding both tight fits and already full bins (which might imply less residual capacity for future items). Heuristic 3 is simpler but might not exploit the \"already full\" aspect as well.\n*   **Heuristic 5 vs. Others:** Heuristic 5 uses a simple \"best fit\" approach by identifying the minimum difference and assigning a priority of 1.0 only to bins with that minimum difference, and 0.0 otherwise. This is a greedy, non-smooth approach, unlike the graded priorities offered by inverse proximity or sigmoid functions in other heuristics. It doesn't differentiate between multiple \"best fit\" bins, nor does it provide a soft preference for slightly less optimal fits.\n*   **Heuristic 18/19/20 vs. Others:** These are identical and use a sigmoid on normalized gaps. The normalization is `gaps / np.max(remaining_capacities_of_suitable_bins)`. This differs from heuristics 2/6/10/4/14/17 by normalizing based on the *maximum remaining capacity* among suitable bins, rather than the inverse proximity scores. This could lead to different shaping of the priority distribution. The fallback to `0.5` when all priorities are zero is a good fallback for uniform preference in such edge cases.\n*   **Overall Comparison:** Heuristics like 2, 4, 6, 7, 10, 11, 14, 17, 18, 19, 20 offer more sophisticated ways to generate graded priorities, often using sigmoid or exponential functions on derived scores (like inverse proximity or differences). These provide smoother exploration and can balance multiple objectives (tight fit, bin fullness). Simple inverse proximity (1, 12, 13, 15, 16) is a solid baseline. Heuristics like 3 and 9 attempt to combine factors but might be less standard. Heuristic 5 is too simplistic and binary. Heuristics 18/19/20's normalization approach is a variation worth noting. The use of `np.any` and vectorized operations is generally preferred over explicit loops.\n- \nHere's a redefined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Granular scoring, multi-criteria fusion, adaptive parameterization, empirical validation.\n*   **Advice:** Focus on creating finely-grained, multi-dimensional scoring mechanisms that integrate diverse criteria (e.g., fit, fullness, strategic placement) through weighted sums or more complex fusion methods.\n*   **Avoid:** Binary or overly simplistic preference assignments. Avoid introducing complex mathematical transformations without a clear, demonstrable benefit to heuristic performance on the specific problem.\n*   **Explanation:** By moving beyond single metrics and embracing nuanced, combined scoring, heuristics can capture a richer understanding of the problem space, leading to more intelligent and adaptive decision-making, especially when validated against real-world or simulated problem instances.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}