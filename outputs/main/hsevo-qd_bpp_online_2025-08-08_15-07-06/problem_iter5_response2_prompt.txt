{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    This is a heuristic for the online bin packing problem.\n    We want to prioritize bins that are \"almost full\" but can still fit the item.\n    This strategy aims to fill bins as much as possible before opening new ones.\n\n    The priority is calculated as follows:\n    1. For bins that can fit the item:\n       - Calculate how much \"space\" is left after fitting the item.\n       - We want to *minimize* this leftover space, but we also don't want to penalize bins that are already very full.\n       - A good measure might be `(bin_capacity - item) / bin_capacity` if we're talking about proportions,\n         but we have remaining capacities. So, `remaining_capacity - item`.\n       - To get a \"priority\" where higher is better, we can take the negative of this difference: `item - remaining_capacity`.\n         This means a bin with `remaining_capacity = 0.9` and `item = 0.8` gives `-0.7` (higher is better than -0.2 for a bin with `remaining_capacity = 0.3`).\n       - To avoid very large negative numbers for bins that are too small, we can set the priority to a very low number (or zero) if the item doesn't fit.\n\n    2. For bins that cannot fit the item:\n       - Assign a very low priority (e.g., 0 or negative infinity effectively, but we'll use 0).\n\n    Let's refine this:\n    We want to put the item into a bin where the remaining capacity is *just enough* or slightly more than the item.\n    If remaining_capacity >= item:\n        Priority = some_function(remaining_capacity - item)\n    Else:\n        Priority = -infinity (effectively 0 for practical purposes if others are positive)\n\n    Consider the difference: `bins_remain_cap - item`.\n    If this difference is negative, the item doesn't fit. We'll assign a very low priority.\n    If this difference is non-negative, we want to prioritize bins where this difference is *smallest* (closest to zero).\n    So, we want to maximize `-(bins_remain_cap - item) = item - bins_remain_cap`.\n    This means if a bin has `rem_cap = 1.0` and `item = 0.5`, priority is `-0.5`.\n    If a bin has `rem_cap = 0.6` and `item = 0.5`, priority is `-0.1`. The latter is higher priority.\n\n    Let's make it simpler. We want the bin where `bins_remain_cap` is *closest to `item`*, but greater than or equal to `item`.\n    This is like finding the minimum of `bins_remain_cap - item` for all `bins_remain_cap >= item`.\n    To turn this into a \"priority\" (higher is better), we can use `-abs(bins_remain_cap - item)` or `item - bins_remain_cap`.\n    Let's stick with `item - bins_remain_cap`.\n\n    Priorities will be negative. Higher values mean a better fit.\n    We need to handle the case where `bins_remain_cap < item`.\n    \"\"\"\n    \n    fit_mask = bins_remain_cap >= item\n    \n    \n    priorities = np.full_like(bins_remain_cap, -np.inf)\n    \n    \n    priorities[fit_mask] = item - bins_remain_cap[fit_mask]\n    \n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            priorities[i] = 1 / (cap - item + 1e-9)\n    return priorities\n\n### Analyze & experience\n- *   **Heuristic 1 vs. Heuristic 13/16:** Heuristic 1 uses a loop for calculation, while 13 and 16 achieve the same result using vectorized NumPy operations (`1 / (cap - item + 1e-9)` applied element-wise). Vectorization is generally more efficient in Python with NumPy. Heuristic 12 and 15 are similar to 13/16 but add comments and slightly different variable names. Heuristic 8 takes absolute difference which is not ideal for prioritizing tighter fits (a bin with -1 difference is worse than a bin with +1 difference, but `abs` makes them equal). Heuristic 8 also applies the `can_fit_mask` *after* calculating inverse absolute difference, which is less clean than filtering first.\n*   **Heuristic 2/6/10 vs. Heuristic 4/14/17:** Heuristics 2, 6, and 10 are identical. They use a sigmoid function applied to normalized inverse proximity scores. Heuristic 4, 14, and 17 are also identical and very similar to 2/6/10, also using sigmoid and normalization. The difference lies in how normalization is performed. 4/14/17 normalize based on `(inverse_proximity - min) / (max - min)`, aiming to center around 0.5 for the sigmoid. 2/6/10 normalize by dividing by the max inverse proximity, effectively scaling to [0, 1] where 1 is the tightest fit. The explicit handling of perfect fits (priority = 1.0) in 2/6/10/4/14/17 is a good addition for ensuring these are always prioritized. The logic in 2/6/10/4/14/17 seems more robust and nuanced than simpler inverse proximity.\n*   **Heuristic 7 vs. Heuristic 11/17:** Heuristic 7 uses a Softmax on negative differences (`-(eligible_capacities - item)`), which effectively prioritizes bins with small remaining capacity after fitting the item. This is a strong approach. Heuristics 11 and 17 are identical and also use a `temperature` parameter with `exp(-diffs / temperature)`. This is conceptually similar to Softmax but returns raw scores proportional to the softmax probabilities, which is often sufficient for selection. Heuristic 17 also includes `1.0 / valid_capacities` logic which is then commented out or seemingly superseded by the `exp(-diffs / temperature)` part. The `temperature` parameter offers a tunable knob.\n*   **Heuristic 3 vs. Heuristic 9:** Heuristic 3 uses `item - bins_remain_cap` for fitting bins, resulting in negative priorities. Higher values (closer to 0) are better fits. Heuristic 9 aims to combine tight fit (`item - bins_that_fit_cap`) with fullness (`1.0 / (bins_that_fit_cap - item + epsilon)`). This combination is more complex and potentially captures more desired behavior by rewarding both tight fits and already full bins (which might imply less residual capacity for future items). Heuristic 3 is simpler but might not exploit the \"already full\" aspect as well.\n*   **Heuristic 5 vs. Others:** Heuristic 5 uses a simple \"best fit\" approach by identifying the minimum difference and assigning a priority of 1.0 only to bins with that minimum difference, and 0.0 otherwise. This is a greedy, non-smooth approach, unlike the graded priorities offered by inverse proximity or sigmoid functions in other heuristics. It doesn't differentiate between multiple \"best fit\" bins, nor does it provide a soft preference for slightly less optimal fits.\n*   **Heuristic 18/19/20 vs. Others:** These are identical and use a sigmoid on normalized gaps. The normalization is `gaps / np.max(remaining_capacities_of_suitable_bins)`. This differs from heuristics 2/6/10/4/14/17 by normalizing based on the *maximum remaining capacity* among suitable bins, rather than the inverse proximity scores. This could lead to different shaping of the priority distribution. The fallback to `0.5` when all priorities are zero is a good fallback for uniform preference in such edge cases.\n*   **Overall Comparison:** Heuristics like 2, 4, 6, 7, 10, 11, 14, 17, 18, 19, 20 offer more sophisticated ways to generate graded priorities, often using sigmoid or exponential functions on derived scores (like inverse proximity or differences). These provide smoother exploration and can balance multiple objectives (tight fit, bin fullness). Simple inverse proximity (1, 12, 13, 15, 16) is a solid baseline. Heuristics like 3 and 9 attempt to combine factors but might be less standard. Heuristic 5 is too simplistic and binary. Heuristics 18/19/20's normalization approach is a variation worth noting. The use of `np.any` and vectorized operations is generally preferred over explicit loops.\n- \nHere's a redefined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Granular scoring, multi-criteria fusion, adaptive parameterization, empirical validation.\n*   **Advice:** Focus on creating finely-grained, multi-dimensional scoring mechanisms that integrate diverse criteria (e.g., fit, fullness, strategic placement) through weighted sums or more complex fusion methods.\n*   **Avoid:** Binary or overly simplistic preference assignments. Avoid introducing complex mathematical transformations without a clear, demonstrable benefit to heuristic performance on the specific problem.\n*   **Explanation:** By moving beyond single metrics and embracing nuanced, combined scoring, heuristics can capture a richer understanding of the problem space, leading to more intelligent and adaptive decision-making, especially when validated against real-world or simulated problem instances.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}