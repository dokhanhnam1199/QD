{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            priorities[i] = 1 / (cap - item + 1e-9)\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.zeros_like(bins_remain_cap)\n    fitting_bins_mask = bins_remain_cap >= item\n    fitting_bins = bins_remain_cap[fitting_bins_mask]\n    if fitting_bins.size > 0:\n        differences = fitting_bins - item\n        best_fit_indices = np.where(bins_remain_cap == np.min(differences))[0]\n        priorities[best_fit_indices] = 1.0\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1 and Heuristic 4 (which are identical): They use a Softmax-based approach, prioritizing tighter fits. This is a sophisticated method that balances preferences well.\n\nComparing Heuristic 2 and Heuristic 8 (which are identical): These use an inverse proximity (1/proximity) strategy. This is a good heuristic that directly favors bins with less remaining space after fitting. The handling of `proximity == 0` with `float('inf')` is a strong indicator of a good fit.\n\nComparing Heuristic 3 and Heuristic 11, 14, 16 (which are similar): These use an inverse difference `1.0 / (np.abs(diffs) + 1e-9)`. This is similar to the inverse proximity, but the `np.abs()` is not strictly necessary if we filter for `bins_remain_cap >= item` first. The explicit masking to zero for ineligible bins is good.\n\nComparing Heuristic 5 and Heuristic 12, 13, 15 (which are very similar): Heuristic 5 uses `-differences + 1.0` for priority. This also favors tighter fits. The use of `-1.0` for ineligible bins is a clear indicator. The more complex versions (12, 13, 15) attempt to incorporate Softmax-like behavior or scaling with temperature, which can be beneficial but also adds complexity.\n\nComparing Heuristic 6 and Heuristic 7 (identical): These implement a \"best fit\" strategy by assigning a priority of 1.0 only to bins that achieve the minimum difference. This is a greedy approach that focuses on a single best option.\n\nComparing Heuristic 9 and Heuristic 10 (identical): These use an Epsilon-Greedy strategy. They exploit the best fit most of the time but explore randomly with a small probability. This can help escape local optima but adds a stochastic element.\n\nComparing Heuristic 19 and Heuristic 20 (identical): These use a sigmoid function based on normalized gaps. This is an interesting approach that attempts to create a smooth priority distribution but might be overly complex for a simple priority score.\n\nOverall: Heuristics 1 and 4 (Softmax) and 2 and 8 (Inverse Proximity with infinity for perfect fit) appear to be the most robust and well-designed. Heuristics 3, 11, 14, 16 are good inverse difference strategies. Heuristic 5 is a clear and simple \"best fit\" variant. The Epsilon-Greedy (9, 10) offers exploration. The sigmoid-based ones (19, 20) and the strict \"best fit\" ones (6, 7, 17, 18) are less versatile or potentially over-engineered for a simple priority function. The complexity in 12, 13, 15 without clear justification for temperature scaling makes them less preferable than simpler inverse methods.\n- \nHere's a redefined approach to self-reflection for heuristic design:\n\n*   **Keywords:** Simplicity, Transparency, Empirical Validation, Targeted Exploration.\n*   **Advice:** Focus on constructing heuristics with easily understandable mechanics and clear justifications for their components. Prioritize simple rules that can be incrementally enhanced.\n*   **Avoid:** Overly complex, opaque mathematical functions without demonstrable performance gains. Avoid \"black box\" heuristic components.\n*   **Explanation:** The goal is to build heuristics that are debuggable and adaptable. Understanding *why* a heuristic makes a choice is crucial for identifying limitations and designing targeted improvements, rather than relying on blind experimentation with complex mechanisms.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}