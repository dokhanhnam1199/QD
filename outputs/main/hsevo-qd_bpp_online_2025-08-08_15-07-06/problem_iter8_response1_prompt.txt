{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Best Fit and inverse proximity for Bin Packing priority.\n    Prioritizes bins that are closer fits, with a strong preference for the absolute best fit.\n    \"\"\"\n    eligible_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(eligible_bins_mask):\n        eligible_capacities = bins_remain_cap[eligible_bins_mask]\n        differences = eligible_capacities - item\n\n        # Strategy 1: Inverse proximity (favoring smaller remaining capacities)\n        # Add epsilon for numerical stability and to avoid division by zero.\n        inverse_proximity_scores = 1.0 / (differences + 1e-9)\n\n        # Strategy 2: Identify the absolute best fit(s)\n        min_diff = np.min(differences)\n        best_fit_mask_local = (differences == min_diff)\n\n        # Combine strategies: Give a significantly higher priority to the absolute best fit(s)\n        # and use inverse proximity for others.\n        # We scale the best fit scores to be clearly dominant.\n        combined_scores = np.zeros_like(eligible_capacities)\n        combined_scores[best_fit_mask_local] = 100.0  # High priority for best fit\n        combined_scores[~best_fit_mask_local] = inverse_proximity_scores[~best_fit_mask_local]\n\n        # Normalize scores to be in a reasonable range, though not strictly probabilities here.\n        # Using Softmax-like scaling for non-best-fit items to maintain relative preference.\n        non_best_fit_scores = inverse_proximity_scores[~best_fit_mask_local]\n        if non_best_fit_scores.size > 0:\n            exp_scores = np.exp(non_best_fit_scores - np.max(non_best_fit_scores))\n            normalized_non_best_fit = exp_scores / np.sum(exp_scores)\n            combined_scores[~best_fit_mask_local] = normalized_non_best_fit\n\n        # Assign combined scores back to the original array structure\n        priorities[eligible_bins_mask] = combined_scores\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            priorities[i] = 1 / (cap - item + 1e-9)\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1st (multi-criteria: tightness and fullness) with Heuristic 13th (similar multi-criteria but with Softmax scaling concept), we see that Heuristic 1st uses a simpler weighted sum `-(gap**2) + lambda_param * fitting_bins_remain_cap` which directly optimizes for small gaps and fuller bins. Heuristic 13th attempts to incorporate Softmax principles with `np.exp(-diffs / temperature)`, aiming for a more distributed priority if multiple bins are considered. Heuristic 1st seems more direct and interpretable for this problem.\n\nComparing Heuristic 4th and 7th (sigmoid on normalized inverse proximity) with Heuristic 8th, 9th, 12th (inverse proximity with infinite priority for perfect fits), we observe a trade-off. Heuristics 4th/7th use a sigmoid for smooth, distributed preferences, while 8th/9th/12th strongly favor exact fits by assigning `inf`. This strong preference might be desirable for consolidation but could ignore slightly less perfect but still good fits.\n\nComparing Heuristic 6th and 10th (binary: 1.0 for best fit, 0.0 otherwise) with Heuristic 14th and 16th (simple inverse proximity `1 / (cap - item + 1e-9)`), the simple inverse proximity (14th/16th) offers a more granular preference than the binary approach (6th/10th). The binary approach only distinguishes the absolute best fit, ignoring nuances between other suitable bins.\n\nComparing Heuristic 13th and 15th (Softmax-like exponential scaling of inverse difference) with Heuristic 17th (similar exponential scaling of inverse difference but with adjusted temperature and normalization), we see subtle differences in implementation. Heuristic 13th/15th use `np.exp(-diffs / temperature)` directly as priority, while 17th also calculates `1.0 / (valid_capacities - item + epsilon)` and then proceeds with the exponential scaling. The direct application of `exp(-diffs/temperature)` seems more straightforward for generating graded priorities.\n\nOverall, heuristics that use a direct measure of \"fit\" (like inverse difference or squared difference) and scale it appropriately (like inverse proximity or exponential scaling) seem to offer better granularity and control than simple binary choices or less direct metrics. The inclusion of a secondary criterion, like overall bin fullness, as seen in Heuristic 1st, adds another dimension to consider.\n- \nHere's a refined approach to self-reflection for designing better heuristics, avoiding the pitfalls of ineffective reflection:\n\n*   **Keywords:** Granular scoring, weighted combinations, smooth transitions, vectorized operations, tunable parameters, empirical validation.\n*   **Advice:** Focus on building heuristics that provide graded preferences rather than strict binary choices. Combine multiple relevant criteria using weighted sums or similar functions, adjusting weights based on empirical performance. Utilize smooth mapping functions (like scaled inverse or sigmoid) to translate raw metrics into nuanced scores.\n*   **Avoid:** Over-reliance on single, direct metrics without considering secondary factors. Complex, unjustified transformations or overly complicated meta-heuristics without empirical backing. Ignoring bin eligibility.\n*   **Explanation:** This approach emphasizes creating heuristics that capture the \"degree\" of fitness and preference, leading to more adaptive and robust solutions. Smooth transitions prevent abrupt changes in heuristic behavior, and empirically validating parameter choices ensures effectiveness.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}