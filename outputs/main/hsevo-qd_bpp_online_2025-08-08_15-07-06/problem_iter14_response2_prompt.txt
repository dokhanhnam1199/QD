{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Calculates priority for bins to pack an item.\n    Prioritizes bins with minimal remaining capacity that can fit the item,\n    using an exponential scaling for graded preferences.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(suitable_bins_mask):\n        return priorities\n    \n    suitable_bins_caps = bins_remain_cap[suitable_bins_mask]\n    \n    differences = suitable_bins_caps - item\n    \n    if suitable_bins_caps.size > 0:\n        min_diff = np.min(differences)\n        \n        \n        scaled_diffs = differences - min_diff\n        \n        \n        temperature = 0.1\n        exp_scores = np.exp(-scaled_diffs / temperature)\n        \n        \n        normalized_exp_scores = exp_scores / np.max(exp_scores)\n        \n        priorities[suitable_bins_mask] = normalized_exp_scores\n        \n        \n        if np.all(priorities == 0):\n            priorities[suitable_bins_mask] = 0.5\n            \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    valid_bins = bins_remain_cap >= item\n    \n    if not np.any(valid_bins):\n        return np.zeros_like(bins_remain_cap)\n\n    valid_capacities = bins_remain_cap[valid_bins]\n    \n    # Higher remaining capacity means lower priority (we want to fill bins)\n    # To use Softmax effectively, we want larger values to correspond to higher priority.\n    # So we can use (large_capacity - remaining_capacity) or 1/(remaining_capacity)\n    # Let's try 1/(remaining_capacity) as it penalizes bins that are already very full.\n    \n    inverted_capacities = 1.0 / valid_capacities\n    \n    # To further encourage fitting into bins with *just enough* space, \n    # we can add a term that penalizes bins with very large remaining capacity.\n    # Let's try subtracting the ratio of remaining capacity to total capacity (assuming initial bin capacity is known or can be estimated).\n    # For simplicity here, let's just use the inverse capacity.\n    \n    # Adding a small epsilon to avoid division by zero if a bin has 0 remaining capacity, though valid_bins should prevent this.\n    epsilon = 1e-9\n    scores = 1.0 / (valid_capacities + epsilon)\n    \n    # Softmax is often used to turn scores into probabilities or weights.\n    # A higher score should mean a higher probability of selection.\n    # Let's scale the scores to be positive and somewhat related to \"how well\" it fits.\n    # A common approach in fitting is to maximize the remaining capacity, \n    # but here we want to minimize the number of bins. So we prefer bins that are *almost* full.\n    # Let's try prioritizing bins where item fits snugly.\n    \n    fit_difference = valid_capacities - item\n    # We want to minimize fit_difference. To make it a priority (higher is better), we invert it.\n    # Add a small constant to avoid division by zero if fit_difference is 0.\n    priority_scores = 1.0 / (fit_difference + epsilon)\n    \n    # Apply Softmax to convert scores into probabilities (weights)\n    # We add a small penalty for bins that have much more capacity than needed to discourage very loose fits.\n    # Let's consider the \"waste\" factor. Waste = remaining_capacity - item\n    # We want to minimize waste.\n    \n    # Let's try a heuristic that favors bins that have enough capacity but not excessively more.\n    # We can try a value that increases as remaining_capacity gets closer to item.\n    \n    # Option 1: Prioritize bins that are almost full (minimum remaining capacity that fits item)\n    # We want higher scores for smaller `valid_capacities`. So `1/valid_capacities` or similar.\n    # To be more specific, we want `valid_capacities - item` to be small.\n    # So we can use `1.0 / (valid_capacities - item + epsilon)`\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins] = 1.0 / (valid_capacities - item + epsilon)\n    \n    # Apply Softmax: exp(score) / sum(exp(scores))\n    # For just returning priority scores for selection, we can directly use the calculated scores\n    # or apply a transformation like Softmax.\n    # If we want to select *one* bin based on highest priority, we can just return the scores directly.\n    # If we want to weight bins for some probabilistic selection, Softmax is good.\n    # For this problem, simply returning the scores that indicate preference is sufficient.\n    \n    # Let's refine to prioritize bins where remaining_capacity - item is minimized.\n    # A simple approach for priority is the inverse of the difference.\n    \n    scores = np.zeros_like(bins_remain_cap)\n    scores[valid_bins] = 1.0 / (valid_capacities - item + epsilon)\n\n    # To make it more \"Softmax-like\" in spirit of distribution, \n    # we can use a sigmoid-like transformation or directly use scaled values.\n    # Let's consider a temperature parameter to control the \"sharpness\" of priorities.\n    temperature = 1.0\n    \n    # Let's make values larger for better fits.\n    # A potential issue is if all valid capacities are very large, leading to small inverse values.\n    # We need to ensure scores are somewhat comparable or scaled.\n    \n    # Consider the \"tightness of fit\" as the primary driver.\n    # Tightest fit = smallest (remaining_capacity - item).\n    # So, priority is inversely proportional to (remaining_capacity - item).\n    \n    normalized_scores = np.zeros_like(bins_remain_cap)\n    if np.any(valid_bins):\n        # Calculate scores: higher score for tighter fit\n        # We want to maximize (1 / (remaining_capacity - item))\n        # Or to avoid issues with very small differences, maybe prioritize directly by minimum remaining capacity that fits.\n        \n        # Let's try a direct mapping:\n        # A bin is \"good\" if remaining_capacity is just enough.\n        # So, priority is high when remaining_capacity is close to item.\n        \n        # Let's use `remaining_capacity` itself as a negative factor for priority\n        # and `item` as a positive factor.\n        # How about prioritizing bins with smaller remaining capacity that can still fit the item?\n        # This aligns with the First Fit Decreasing heuristic's goal of filling bins.\n        \n        # Let's map the difference `valid_capacities - item` to a priority.\n        # Smaller difference should yield higher priority.\n        \n        # Example: item = 3, capacities = [5, 7, 10]\n        # Valid capacities = [5, 7, 10]\n        # Differences = [2, 4, 7]\n        # We want to prioritize bins with difference 2, then 4, then 7.\n        # So, 1/2, 1/4, 1/7 would work.\n        \n        diffs = valid_capacities - item\n        priorities = 1.0 / (diffs + epsilon)\n        \n        # Now, to make it more \"Softmax-like\" if we were to select probabilistically,\n        # we can exponentiate and normalize. But for direct priority score, this is fine.\n        # Let's add a small value to all priorities to avoid negative exponents in a Softmax if we were to use it.\n        # And let's scale them to prevent numerical underflow or overflow with Softmax.\n        \n        # For a direct priority score where higher means better, \n        # this inverse difference works well for \"best fit\" aspect.\n        \n        # Consider what happens if multiple bins have the exact same \"best fit\" difference.\n        # The current approach would give them equal priority.\n        \n        # To incorporate the \"Softmax-Based Fit\" idea, let's interpret it as:\n        # transform the \"fitness\" of a bin (how well it fits the item) into a priority.\n        # The fitness can be related to how close `remaining_capacity` is to `item`.\n        \n        # Let's define fitness as: -(remaining_capacity - item)^2. Higher fitness for smaller squared difference.\n        # Or, more simply, as we did: 1.0 / (remaining_capacity - item + epsilon)\n        \n        # Softmax transformation of these scores to get a distribution if needed.\n        # For now, we just need the scores themselves.\n        \n        # Let's try to directly use the remaining capacity for scaling, \n        # encouraging smaller capacities that fit.\n        \n        # Prioritize bins with the smallest remaining capacity that can fit the item.\n        # So, the priority score should be higher for smaller `valid_capacities`.\n        # Let's try `1.0 / valid_capacities`.\n        \n        # Consider a case: item = 2, bins_remain_cap = [3, 5, 10]\n        # Valid bins = [3, 5, 10]\n        # Option A (inverse diff): 1/(3-2)=1, 1/(5-2)=0.33, 1/(10-2)=0.125. Prioritizes bin with 3. (Best Fit)\n        # Option B (inverse capacity): 1/3=0.33, 1/5=0.2, 1/10=0.1. Prioritizes bin with 3.\n        \n        # If the goal is \"smallest number of bins\", then fitting into a nearly full bin is good.\n        # \"Best Fit\" heuristic is good for this.\n        \n        # Let's combine the \"fit\" (difference) with the \"emptiness\" (remaining capacity).\n        # Maybe penalize very large remaining capacities, even if they fit.\n        \n        # Let's use the difference again, as it directly measures \"how much space is left after fitting\".\n        # Smaller difference is better.\n        \n        diffs = valid_capacities - item\n        \n        # Scale diffs to be more in line with Softmax inputs (e.g., range -inf to +inf for exp)\n        # A common pattern is to use `exp(value)` where larger `value` is better.\n        # We want to maximize `-(diffs)`. So `exp(-diffs)`? No, we want to maximize score for smaller diffs.\n        # Let's use `exp(-diffs)` with `temperature`.\n        \n        temperature = 0.5 # Lower temperature means stronger preference for best fit\n        scaled_diffs = -diffs / temperature\n        \n        # Apply Softmax concept: exp(score) / sum(exp(scores))\n        # We can simply return exp(scaled_diffs) as the priority, which is proportional to softmax output.\n        \n        priorities = np.exp(scaled_diffs)\n        \n    \n    final_priorities = np.zeros_like(bins_remain_cap)\n    final_priorities[valid_bins] = priorities\n    \n    return final_priorities\n\n### Analyze & experience\n- *   **Comparing (1st) vs (2nd):** Heuristic 1st introduces a quadratic penalty `-(gap**2)` and a linear term `lambda_param * fitting_bins_remain_cap`, aiming for a more nuanced score that balances tight fit with overall bin fullness. Heuristic 2nd also aims for multi-criteria but its explanation is more exploratory and less concrete in its final scoring logic within the docstring. The implementation of 1st seems to better reflect a specific, refined scoring strategy.\n\n*   **Comparing (3rd) vs (4th):** Heuristic 3rd implements a simple binary \"best fit\" logic (1.0 for minimum difference, 0.0 otherwise), failing to provide graded priorities or consider overall bin fullness. Heuristic 4th attempts a multi-criteria approach with normalization and sigmoid activation, aiming for smoother, graded priorities, but its normalization and weighting logic can be complex and might not always yield the most intuitive results.\n\n*   **Comparing (5th) vs (6th):** Heuristic 5th uses an exponential score based on the difference from the minimum difference, with a temperature parameter. Heuristic 6th uses Softmax on the negative differences, creating a probability distribution, which is a more standard approach for graded priorities in similar contexts. Heuristic 6th's Softmax implementation is generally more robust for generating graded priorities.\n\n*   **Comparing (7th) vs (8th):** Heuristic 7th uses a simple `item - bins_remain_cap` score, which is a direct representation of tightest fit but can lead to large negative values. Heuristic 8th uses `1.0 / (differences + 1e-9)` and explicitly assigns `inf` to perfect fits, offering a clearer \"best fit\" prioritization.\n\n*   **Comparing (9th) vs (10th):** Heuristic 9th uses a simple `1.0 / proximity` for fitting bins, prioritizing the tightest fit. Heuristic 10th attempts to combine this with a quadratic penalty `-(differences**2)`, aiming to penalize larger gaps more heavily while still favoring tight fits. Heuristic 10th's multi-faceted scoring is more sophisticated.\n\n*   **Comparing (11th) vs (12th):** Heuristic 11th is identical to Heuristic 10th. Heuristic 12th is identical to Heuristic 6th.\n\n*   **Comparing (13th) vs (14th):** Heuristic 13th and 14th are identical. They use `exp(-diffs / temperature)` which is a Softmax-like approach focused on the tightest fit, controlled by temperature.\n\n*   **Comparing (15th) vs (16th):** Heuristic 15th, 17th, 18th, 19th, 20th are all identical implementations of a simple \"best fit\" heuristic (`1 / (cap - item + 1e-9)`). Heuristic 16th (and its identical counterparts 13th/14th) uses a temperature-controlled exponential function on negative differences, which provides a smoother, graded priority distribution compared to the simple inverse of the difference.\n\n*   **Overall:** Heuristics 1st, 10th/11th, and 13th/14th/16th/17th/18th/19th/20th show a progression. Heuristic 1st offers a good balance of tight fit and bin fullness. Heuristics 10th/11th attempt to penalize gaps quadratically. Heuristics 13th/14th/16th/etc. use a Softmax-like approach for graded priorities based on tightness. The simplest (and thus arguably worst for nuanced optimization) are the basic \"best fit\" heuristics (15th onwards). Heuristic 4th tries complex normalization and sigmoid, which might be overly complicated. Heuristic 3rd is too simplistic.\n- \nHere's a redefined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Multi-criteria, graded scoring, tunable parameters, nuanced penalties, vectorized operations.\n*   **Advice:** Focus on composite scoring functions that blend multiple criteria (fit, fullness, etc.) using smooth, non-linear mappings (e.g., exponentials, sigmoid). Tune parameters to adapt to problem characteristics. Leverage vectorized operations for performance.\n*   **Avoid:** Overtly simple binary or linear scoring. Unjustified complex transformations without empirical evidence. Ignoring edge cases or bin eligibility.\n*   **Explanation:** Nuanced scoring and tunable parameters allow heuristics to capture subtle trade-offs and adapt to diverse problem instances, leading to more effective and robust solutions than blunt, oversimplified approaches.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}