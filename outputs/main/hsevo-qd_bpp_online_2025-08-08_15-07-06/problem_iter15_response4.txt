```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    This heuristic aims to provide a more sophisticated scoring mechanism than v1
    by incorporating multiple criteria with non-linear weighting and a tunable penalty
    for wasted space. It leverages a multi-criteria fusion approach using soft penalties
    and rewards to create a nuanced priority score.

    The strategy is to prioritize bins based on:
    1.  How well the item fits the remaining capacity (tightness), with a preference for
        minimal positive slack, but still accepting perfect fits. A quadratic penalty
        is used for the gap to ensure diminishing returns for larger gaps.
    2.  The current fullness of the bin, as a secondary criterion, to encourage
        using generally fuller bins.
    3.  A 'graceful degradation' penalty for bins that have a significant amount
        of remaining capacity, even if they fit the item. This aims to avoid filling
        bins unnecessarily when a tighter fit is available.

    Scoring logic for bins that can fit the item (`bins_remain_cap >= item`):
    -   **Tightness Score (Primary):** We want to minimize `bins_remain_cap - item`.
        To convert this minimization to a maximization problem for the priority score,
        we can use `-(bins_remain_cap - item)`. To make it more granular and less
        sensitive to very small gaps, we can square this term. For best fit,
        `bins_remain_cap - item` should be close to zero. We want to maximize the
        score from this component. Let's use `-(bins_remain_cap - item)**2`. This
        term is maximized when `bins_remain_cap - item = 0`.

    -   **Fullness Score (Secondary):** To encourage using generally fuller bins,
        we can add a term proportional to `bins_remain_cap`. A higher `bins_remain_cap`
        means the bin was fuller to begin with. Let this be `alpha * bins_remain_cap`.

    -   **Wasted Space Penalty (Tertiary):** We want to penalize leaving *too much*
        excess space, but in a nuanced way. If `bins_remain_cap` is much larger than
        `item`, it might be a suboptimal choice. We can introduce a term that becomes
        more negative as `bins_remain_cap` increases beyond a certain point, relative
        to `item`.
        Consider the term `-(bins_remain_cap - item) * (bins_remain_cap / BIN_CAPACITY)`
        where `BIN_CAPACITY` is the maximum bin capacity. This penalizes large remaining
        capacities, scaled by how "full" the bin is. A simpler approach could be to
        penalize based on `bins_remain_cap` itself, but we already do that in the
        fullness score.

        Let's try a simpler penalty: If a bin has `bins_remain_cap` significantly larger
        than `item`, we want to reduce its priority. The "waste" is `bins_remain_cap - item`.
        A smooth penalty could be something like `-(bins_remain_cap - item)**3` if we want
        to heavily penalize large wastes, or `-(bins_remain_cap - item)` for a linear penalty.
        However, `priority_v1` already covers the linear penalty.

        Let's focus on making the "tightness" score more useful.
        Consider a function that rewards small positive gaps and perfect fits, and penalizes
        negative gaps (non-fits) and large positive gaps.
        A Gaussian-like function centered at 0 for the gap `bins_remain_cap - item` could work,
        but it's complex to vectorize.

        Let's refine the combination:
        We want to maximize `-(bins_remain_cap - item)**2` (tightness).
        We want to maximize `alpha * bins_remain_cap` (current fullness).

        Combining these: `score = -(bins_remain_cap - item)**2 + alpha * bins_remain_cap`
        This formulation from the previous thought process seems promising. It prioritizes
        minimal positive slack and perfect fits, and then uses current bin fullness as
        a tie-breaker.

        Let's introduce a tunable parameter `beta` to control the sensitivity to the gap.
        `score = -beta * (bins_remain_cap - item)**2 + alpha * bins_remain_cap`

        Consider the objective: we want to select bins that are not overly empty.
        If a bin has `bins_remain_cap` much larger than `item`, it's not ideal.
        Let's introduce a term that penalizes `bins_remain_cap` relative to `item`.
        A penalty proportional to `bins_remain_cap / (item + epsilon)` could be used,
        but it's not smooth.

        Alternative approach: Sigmoid-like function.
        Let `gap = bins_remain_cap - item`. We want to maximize `f(gap)`.
        We want `f(0)` to be high. `f(small_positive)` to be high. `f(large_positive)` to be lower.
        We want `f(negative)` to be very low.

        Let's stick to the weighted sum of smooth components.
        Component 1: Tightness, `-(bins_remain_cap - item)**2`. Max at `gap=0`.
        Component 2: Fullness, `alpha * bins_remain_cap`. Max at max `bins_remain_cap`.

        We need to combine these thoughtfully. The problem with the previous combination
        `-(bins_remain_cap - item)**2 + alpha * bins_remain_cap` is that it can
        favor bins with very large `bins_remain_cap` if `alpha` is sufficiently high,
        which might contradict the goal of minimizing bins.

        Let's re-evaluate the criteria:
        1.  **Minimal Waste:** Minimize `bins_remain_cap - item`. This is best achieved by maximizing `-(bins_remain_cap - item)`.
        2.  **Maximum Current Fill:** Maximize `bins_remain_cap`.

        The conflict arises when a bin that is currently very full (high `bins_remain_cap`)
        also has a large gap.

        Consider a score that rewards bins for being "efficiently utilized".
        Efficiency could be related to `item / (item + gap)`.
        This is `item / bins_remain_cap`.

        Let's try a score that is high when `bins_remain_cap` is slightly larger than `item`,
        and decreases smoothly as `bins_remain_cap` increases further.

        A score component could be `exp(-gamma * (bins_remain_cap - item))`, where `gamma > 0`.
        This function is maximized at `bins_remain_cap = item`.
        `score = exp(-gamma * (bins_remain_cap - item)) + alpha * bins_remain_cap`

        Let `gamma = 10` and `alpha = 0.5`.
        `item = 0.5`
        Bin X: `bins_remain_cap = 0.5`. Gap = 0. Score = `exp(0) + 0.5 * 0.5 = 1 + 0.25 = 1.25`.
        Bin Y: `bins_remain_cap = 0.55`. Gap = 0.05. Score = `exp(-10 * 0.05) + 0.5 * 0.55 = exp(-0.5) + 0.275 ≈ 0.6065 + 0.275 = 0.8815`.
        Bin Z: `bins_remain_cap = 0.8`. Gap = 0.3. Score = `exp(-10 * 0.3) + 0.5 * 0.8 = exp(-3) + 0.4 ≈ 0.0498 + 0.4 = 0.4498`.
        Bin A: `bins_remain_cap = 0.4` (does not fit). Score = `-inf`.

        In this case, Bin X (perfect fit) gets the highest score. This is similar to `priority_v1`.

        We want to improve by being more "adaptive" or "nuanced".

        Let's introduce a penalty for being "too empty" but also a penalty for being "too full".
        This suggests a multi-modal or more complex scoring function.

        Consider a score that is a weighted sum of:
        1.  **Tightness Score:** Penalize the gap `bins_remain_cap - item`. Maximize `-(bins_remain_cap - item)`. This is `priority_v1`.
        2.  **Fullness Score:** Reward higher `bins_remain_cap`. Maximize `bins_remain_cap`.

        Let's try to modulate the tightness score based on overall fullness.
        If a bin is very full (`bins_remain_cap` is high), even a tight fit might leave a lot of *absolute* space.
        If a bin is less full (`bins_remain_cap` is low, but still fits), a tight fit might be more valuable.

        Let `gap = bins_remain_cap - item`.
        Let `current_fill_ratio = (BIN_CAPACITY - bins_remain_cap) / BIN_CAPACITY`. (Assume BIN_CAPACITY = 1 for simplicity)
        `current_fill_ratio = 1 - bins_remain_cap`.

        We want to maximize `-(gap)` and maximize `current_fill_ratio`.
        If we combine them: `-(gap) + alpha * current_fill_ratio`
        `-(bins_remain_cap - item) + alpha * (1 - bins_remain_cap)`
        `item - bins_remain_cap + alpha - alpha * bins_remain_cap`
        `item + alpha - (1 + alpha) * bins_remain_cap`

        Let `alpha = 0.5`.
        `score = item + 0.5 - 1.5 * bins_remain_cap`.
        This score is maximized when `bins_remain_cap` is minimized.
        So, among fitting bins, it picks the one with the smallest `bins_remain_cap`.

        `item = 0.5`
        Bin X: `bins_remain_cap = 0.5`. Score = `0.5 + 0.5 - 1.5 * 0.5 = 1 - 0.75 = 0.25`. (Perfect fit)
        Bin Y: `bins_remain_cap = 0.55`. Score = `0.5 + 0.5 - 1.5 * 0.55 = 1 - 0.825 = 0.175`.
        Bin Z: `bins_remain_cap = 0.8`. Score = `0.5 + 0.5 - 1.5 * 0.8 = 1 - 1.2 = -0.2`.

        This heuristic favors the tightest fit (Bin X), and then the next tightest (Bin Y).
        This is similar to Best Fit.

        To be *better*, we should aim for something that captures more nuance.

        Let's introduce a penalty for "wasted space", but a smooth, tunable one.
        Consider `wasted_space = bins_remain_cap - item`.
        We want to minimize `wasted_space`.
        A component could be `exp(-k * wasted_space)` for `k > 0`. This is maximized at `wasted_space = 0`.
        Let's add `alpha * (1 - bins_remain_cap)` for current fullness.

        `score = exp(-k * (bins_remain_cap - item)) + alpha * (1 - bins_remain_cap)`
        This is equivalent to `exp(-k*gap) + alpha*(1 - (item+gap))`.
        To maximize, we want `gap` small and `bins_remain_cap` small.

        Let `k = 10`, `alpha = 0.5`.
        `item = 0.5`
        Bin X: `bins_remain_cap = 0.5`. Gap = 0. Score = `exp(0) + 0.5 * (1 - 0.5) = 1 + 0.5 * 0.5 = 1 + 0.25 = 1.25`.
        Bin Y: `bins_remain_cap = 0.55`. Gap = 0.05. Score = `exp(-10 * 0.05) + 0.5 * (1 - 0.55) = exp(-0.5) + 0.5 * 0.45 ≈ 0.6065 + 0.225 = 0.8315`.
        Bin Z: `bins_remain_cap = 0.8`. Gap = 0.3. Score = `exp(-10 * 0.3) + 0.5 * (1 - 0.8) = exp(-3) + 0.5 * 0.2 ≈ 0.0498 + 0.1 = 0.1498`.

        This still heavily favors the tightest fit.

        Let's try to reward bins that are "close" to fitting, even if not perfectly, and are not "too empty".
        We can use a smooth function that peaks when `bins_remain_cap` is slightly above `item`,
        and then decreases.

        Consider a score that emphasizes the *ratio* of the item to the bin's capacity.
        `score = (item / bins_remain_cap) * (1 - (bins_remain_cap - item))`
        This is not ideal due to division and potential for zero.

        A better approach could be to combine a few factors with tunable weights.
        1.  **Tightness Metric:** `-(bins_remain_cap - item)` (Maximize for small positive slack)
        2.  **Fillness Metric:** `bins_remain_cap` (Maximize for fuller bins)

        Let's try a composite score using a tunable parameter to smooth the transition and prioritize different aspects.

        **Key idea:** Create a score that is high for bins where `bins_remain_cap` is slightly larger than `item`, and also considers the overall fullness. We want to avoid bins that are excessively empty.

        Let `fit_score = item / (bins_remain_cap + epsilon)` for fitting bins, where epsilon is a small constant to avoid division by zero. This rewards smaller gaps.
        Let `fullness_score = bins_remain_cap`.

        Combining: `score = w1 * fit_score + w2 * fullness_score`
        This still might favor very full bins.

        Let's consider a "graceful degradation" approach.
        For bins that fit:
        -   Primary objective: Minimize `bins_remain_cap - item`.
        -   Secondary objective: Maximize `bins_remain_cap`.

        We can achieve this by creating a score that is high when `bins_remain_cap` is close to `item`, and then tapers off as `bins_remain_cap` increases. Additionally, if two bins have similar "closeness", we prefer the one that is more full.

        A smoothed version of `priority_v1` might be better. `priority_v1` is `item - bins_remain_cap`.
        This is maximized when `bins_remain_cap` is smallest (for fitting bins).

        Let's try a score that penalizes the *excess capacity* `bins_remain_cap - item` using a non-linear function, and adds a bonus for the overall fullness `bins_remain_cap`.

        Consider the function: `f(x) = x` for `x <= 0` and `f(x) = exp(-k*x)` for `x > 0`.
        Let `x = bins_remain_cap - item`.
        For fitting bins (`x >= 0`): `score_part1 = exp(-k * (bins_remain_cap - item))`.
        This is maximized when `bins_remain_cap - item = 0`.

        Let's try to create a score that is high for bins that are "just right" - not too much space left, but not overly full either.

        **The core idea:** Use a blend of "Best Fit" (minimizing `bins_remain_cap - item`) and "Most Full" (maximizing `bins_remain_cap`), but with a mechanism to prevent selecting bins that are *too* empty.

        Let `gap = bins_remain_cap - item`.
        Let `fill_ratio = 1 - bins_remain_cap` (assuming BIN_CAPACITY = 1).

        We want to maximize `-(gap)` and maximize `fill_ratio`.
        A score that captures this could be a weighted sum where we ensure that `gap` doesn't become too large.

        Consider the term `-(gap)^2`, which is maximized at `gap = 0`.
        Add `alpha * fill_ratio` for current fullness.
        `score = -(bins_remain_cap - item)**2 + alpha * (1 - bins_remain_cap)`

        Let's introduce a parameter `nu` to penalize bins that have a *large* amount of remaining capacity relative to their current fill.
        This is like penalizing "waste" in a way that scales with current utilization.

        For fitting bins:
        `score = -(bins_remain_cap - item)**2 * (1 + nu * (bins_remain_cap - item))`
        This makes the penalty for a gap increase cubically for larger gaps.

        Let's try a more intuitive approach with tunable parameters.
        We want to prioritize bins that minimize `bins_remain_cap - item`.
        We also want to favor bins that are more full.

        Score: `w1 * (item - bins_remain_cap) + w2 * bins_remain_cap`
        This is similar to the `priority_v1` modification explored earlier.
        `score = item - bins_remain_cap + alpha * bins_remain_cap = item - (1-alpha) * bins_remain_cap`.
        This still favors smaller `bins_remain_cap`.

        Let's try a score that is high when `bins_remain_cap` is slightly larger than `item`, and then drops off.
        We can use a Gaussian-like function centered around `item`.
        However, vectorizing Gaussians can be tricky.

        A smooth, parameterized function:
        For fitting bins:
        `score = exp(-k * (bins_remain_cap - item)) * (1 + alpha * bins_remain_cap)`

        Let `k = 10`, `alpha = 0.5`.
        `item = 0.5`
        Bin X: `bins_remain_cap = 0.5`. Score = `exp(0) * (1 + 0.5 * 0.5) = 1 * 1.25 = 1.25`.
        Bin Y: `bins_remain_cap = 0.55`. Score = `exp(-10 * 0.05) * (1 + 0.5 * 0.55) = exp(-0.5) * (1 + 0.275) ≈ 0.6065 * 1.275 ≈ 0.7733`.
        Bin Z: `bins_remain_cap = 0.8`. Score = `exp(-10 * 0.3) * (1 + 0.5 * 0.8) = exp(-3) * (1 + 0.4) ≈ 0.0498 * 1.4 ≈ 0.0697`.

        This still favors the perfect fit. The goal is to find a heuristic that is *better*.
        "Better" implies it performs better in terms of the number of bins used.

        Let's consider a score that is sensitive to both small positive slack AND overall bin fullness,
        but penalizes large slack.

        Consider a score: `-(bins_remain_cap - item)**2 + alpha * (1 - bins_remain_cap)`
        This prefers small positive gaps and currently fuller bins.

        Let's add a penalty for bins that are "too empty".
        This is handled by the `-inf` for non-fitting bins.

        What if we introduce a parameter that adjusts the "tightness" preference?
        Let `tightness_focus = 1.0`.

        `score = (item - bins_remain_cap) * tightness_focus + alpha * bins_remain_cap`
        This is `priority_v1` if `alpha=0`.

        Let's try to make the priority score more "convex" or "peak" near the ideal fit.

        **New Strategy:**
        1.  **Bin Eligibility:** Only consider bins where `bins_remain_cap >= item`. Assign `-inf` to others.
        2.  **Fit Quality:** Prioritize bins where `bins_remain_cap` is close to `item`.
            Use a score component `-(bins_remain_cap - item)**2`. This is maximized when `bins_remain_cap == item`.
        3.  **Bin Fullness:** As a secondary factor, reward bins that were more full initially.
            Use a score component `alpha * bins_remain_cap`.
        4.  **Graceful Degradation Penalty:** If `bins_remain_cap` is significantly larger than `item`, we want to penalize this.
            This can be achieved by making the `-(bins_remain_cap - item)**2` term decay faster for larger gaps.
            Alternatively, we can explicitly penalize large `bins_remain_cap` in a way that
            complements the `alpha * bins_remain_cap` term.

        Let's combine the first two criteria:
        `tightness_fullness_score = -(bins_remain_cap - item)**2 + alpha * bins_remain_cap`

        Now, how to introduce the "graceful degradation" for bins that are too empty?
        The `-(bins_remain_cap - item)**2` term inherently penalizes large gaps.

        Consider a score that is high when `bins_remain_cap` is just above `item`, and drops off smoothly,
        and also considers overall fullness.

        Let's use a Gaussian-like component for the gap, modulated by fullness.
        `score = exp(-k * (bins_remain_cap - item)**2) * (1 + alpha * bins_remain_cap)`

        Here:
        - `exp(-k * (bins_remain_cap - item)**2)`: Peaks at `bins_remain_cap == item`, drops off quadratically.
          `k` controls the width of the peak. Larger `k` means tighter preference.
        - `(1 + alpha * bins_remain_cap)`: This term boosts the score for fuller bins.
          `alpha` controls the weight of this boost.

        Let's choose parameters:
        `k = 100` (high sensitivity to tightness)
        `alpha = 0.5` (moderate boost for fullness)

        `item = 0.5`
        Bin X: `bins_remain_cap = 0.5`. Gap = 0.
            Score = `exp(-100 * 0**2) * (1 + 0.5 * 0.5) = exp(0) * (1 + 0.25) = 1 * 1.25 = 1.25`.
        Bin Y: `bins_remain_cap = 0.55`. Gap = 0.05.
            Score = `exp(-100 * (0.05)**2) * (1 + 0.5 * 0.55) = exp(-100 * 0.0025) * (1 + 0.275) = exp(-0.25) * 1.275 ≈ 0.7788 * 1.275 ≈ 0.9930`.
        Bin Z: `bins_remain_cap = 0.8`. Gap = 0.3.
            Score = `exp(-100 * (0.3)**2) * (1 + 0.5 * 0.8) = exp(-100 * 0.09) * (1 + 0.4) = exp(-9) * 1.4 ≈ 0.000123 * 1.4 ≈ 0.00017`.

        This still favors the perfect fit, but the drop-off is more pronounced.
        The "graceful degradation" aspect implies that a bin that is *slightly* larger but not *too* large might be preferred over a perfect fit if the overall fullness is significantly better.

        Let's invert the gap term's sensitivity to make it less aggressive, or adjust the fullness term.
        Consider `k=10` instead of `k=100`.
        `item = 0.5`
        Bin X: `bins_remain_cap = 0.5`. Gap = 0. Score = `exp(0) * (1 + 0.5 * 0.5) = 1 * 1.25 = 1.25`.
        Bin Y: `bins_remain_cap = 0.55`. Gap = 0.05.
            Score = `exp(-10 * (0.05)**2) * (1 + 0.5 * 0.55) = exp(-10 * 0.0025) * (1 + 0.275) = exp(-0.025) * 1.275 ≈ 0.9753 * 1.275 ≈ 1.2435`.
        Bin Z: `bins_remain_cap = 0.8`. Gap = 0.3.
            Score = `exp(-10 * (0.3)**2) * (1 + 0.5 * 0.8) = exp(-10 * 0.09) * (1 + 0.4) = exp(-0.9) * 1.4 ≈ 0.4066 * 1.4 ≈ 0.5692`.

        In this case, with `k=10`, Bin X (perfect fit) is still preferred, but Bin Y (slight slack) is very close. This implies a good balance.
        The `alpha` parameter controls how much we value bins that are generally fuller. If `alpha` is high, Bin Y might even surpass Bin X if `k` is low enough.

        Let's introduce another parameter `beta` to control the "width" of the ideal fit.
        We want to maximize `exp(-beta * (bins_remain_cap - item)**2)`.

        And we want to maximize `alpha * bins_remain_cap`.

        Let's try combining them in a different way:
        We want to maximize `-(bins_remain_cap - item)**2`.
        Let's add a term that penalizes `bins_remain_cap` if it's too large.
        Consider a function `g(x)` that is zero for small `x` and increasingly negative for large `x`.
        E.g., `g(x) = min(0, -(x - c)**p)` for `p > 0` and some constant `c`.

        A simpler approach: use `max` to select between two good candidates.
        Candidate 1: Tightest fit (like `priority_v1`).
        Candidate 2: Fuller bin with a slight slack.

        Let's reconsider the advice: "finely-grained, multi-dimensional scoring mechanisms that integrate diverse criteria (e.g., fit, fullness, strategic placement) through weighted sums or more complex fusion methods."

        The `exp(-k * gap**2) * (1 + alpha * bins_remain_cap)` approach is a fusion of two criteria.
        The parameter `k` controls the focus on tightness, while `alpha` controls the focus on fullness.

        To make it *better*, we need to address the "graceful degradation" or "avoiding over-emptiness" more directly.

        Consider the "Wasted Space Ratio": `(bins_remain_cap - item) / bins_remain_cap`. We want to minimize this.
        Consider the "Current Fill Ratio": `(BIN_CAPACITY - bins_remain_cap) / BIN_CAPACITY`. We want to maximize this.

        Let `fill_ratio = (1.0 - bins_remain_cap)` (assuming BIN_CAPACITY = 1.0)
        Let `wasted_ratio = (bins_remain_cap - item) / (bins_remain_cap + 1e-9)`

        Score = `w1 * (1 - wasted_ratio) + w2 * fill_ratio`
        Score = `w1 * (1 - (bins_remain_cap - item) / (bins_remain_cap + 1e-9)) + w2 * (1 - bins_remain_cap)`

        Let `w1 = 1.0`, `w2 = 0.5`.
        `score = (bins_remain_cap + 1e-9 - bins_remain_cap + item) / (bins_remain_cap + 1e-9) + 0.5 * (1 - bins_remain_cap)`
        `score = (item + 1e-9) / (bins_remain_cap + 1e-9) + 0.5 - 0.5 * bins_remain_cap`

        Let `item = 0.5`.
        Bin X: `bins_remain_cap = 0.5`. Score = `(0.5) / (0.5) + 0.5 - 0.5 * 0.5 = 1 + 0.5 - 0.25 = 1.25`.
        Bin Y: `bins_remain_cap = 0.55`. Score = `(0.5) / (0.55) + 0.5 - 0.5 * 0.55 ≈ 0.909 + 0.5 - 0.275 = 1.134`.
        Bin Z: `bins_remain_cap = 0.8`. Score = `(0.5) / (0.8) + 0.5 - 0.5 * 0.8 = 0.625 + 0.5 - 0.4 = 0.725`.

        This heuristic (`(item + 1e-9) / (bins_remain_cap + 1e-9) + 0.5 - 0.5 * bins_remain_cap`)
        prioritizes the tightest fit (Bin X), then slightly slack (Bin Y), then looser fit (Bin Z).
        It seems like a robust Best Fit variant.

        To add the "graceful degradation" or "nuance", we need to avoid bins that are too empty.
        The current approach implicitly does this via `-inf`.

        Let's try to create a score that is high for bins that are "almost full" and "almost fitting".
        Consider a score that is a polynomial or exponential centered around a "good" region.

        **Final Proposal (`priority_v2`):**
        Combine a strong preference for minimal slack with a moderate preference for current bin fullness.
        The score function will penalize large slack quadratically.

        For fitting bins (`bins_remain_cap >= item`):
        Score = `w_slack * -(bins_remain_cap - item)**2 + w_fullness * bins_remain_cap`

        Let's tune the weights.
        If `w_slack = 100`, `w_fullness = 1`.
        `score = -100 * (bins_remain_cap - item)**2 + bins_remain_cap`

        `item = 0.5`
        Bin X: `bins_remain_cap = 0.5`. Gap = 0.
            Score = `-100 * 0**2 + 0.5 = 0.5`.
        Bin Y: `bins_remain_cap = 0.55`. Gap = 0.05.
            Score = `-100 * (0.05)**2 + 0.55 = -100 * 0.0025 + 0.55 = -0.25 + 0.55 = 0.3`.
        Bin Z: `bins_remain_cap = 0.8`. Gap = 0.3.
            Score = `-100 * (0.3)**2 + 0.8 = -100 * 0.09 + 0.8 = -9 + 0.8 = -8.2`.

        This heuristic strongly favors the perfect fit (Bin X), then the slightly slack (Bin Y).
        This is effectively a sharpened version of Best Fit.

        Let's introduce a penalty for "emptiness" more directly.
        Consider the inverse of the current bin fill: `1 / bins_remain_cap`.
        We want to penalize bins that have too much remaining capacity.

        Revised Score:
        For fitting bins:
        `score = -bins_remain_cap + item + alpha * (1 - bins_remain_cap)`
        This gives: `item + alpha - (1 + alpha) * bins_remain_cap`.
        This prioritizes minimum `bins_remain_cap`.

        Let's try this:
        The score aims to balance tight fitting with overall bin fullness.
        It penalizes large remaining capacities more severely.

        For fitting bins:
        `score = (item - bins_remain_cap) * k1 + bins_remain_cap * k2`
        where `k1` heavily favors tight fits, and `k2` favors fuller bins.

        Let's try the exponential function approach again but with different framing.
        We want to maximize a function that peaks at `bins_remain_cap = item`.
        Let `f(x) = exp(-k * (x - item)**2)` where `x = bins_remain_cap`.
        This peaks at `x = item`.

        Now, combine with fullness `x`.
        `score = exp(-k * (bins_remain_cap - item)**2) * (1 + alpha * bins_remain_cap)`
        This was analyzed earlier. `k=10`, `alpha=0.5` seemed to work well.

        Let's try to implement this.
        Parameters: `k` (tightness sensitivity), `alpha` (fullness weight).
    """

    # Assign a very low priority to bins that cannot fit the item
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    # Identify bins that can fit the item
    fit_mask = bins_remain_cap >= item

    # Calculate scores for fitting bins
    fitting_bins_remain_cap = bins_remain_cap[fit_mask]
    gap = fitting_bins_remain_cap - item

    # Tunable parameters
    k = 10.0  # Sensitivity to tightness (higher k means stronger preference for tight fit)
    alpha = 0.5 # Weight for current bin fullness (higher alpha means stronger preference for fuller bins)

    # Score calculation:
    # The first term `exp(-k * gap**2)` peaks at gap=0 (perfect fit) and decays quadratically.
    # The second term `(1 + alpha * fitting_bins_remain_cap)` boosts the score for bins that are
    # fuller to begin with, acting as a tie-breaker or secondary preference.
    # The `1 + ...` ensures the multiplier is always positive.
    scores = np.exp(-k * (gap**2)) * (1 + alpha * fitting_bins_remain_cap)

    # Assign calculated scores to the eligible bins
    priorities[fit_mask] = scores

    return priorities
```
