```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines 'best fit' proximity with a preference for fuller bins using exponential scaling.
    Favors bins with minimal remaining capacity after packing, smoothed by an exponential function.
    """
    eligible_bins_mask = bins_remain_cap >= item
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    if np.any(eligible_bins_mask):
        eligible_capacities = bins_remain_cap[eligible_bins_mask]
        
        # Prioritize bins with minimum remaining capacity that fits the item.
        # This aligns with "best fit" and also the intuition to fill bins more.
        # Use inverse of remaining capacity as a base score.
        # Add a small epsilon to avoid division by zero.
        epsilon = 1e-9
        base_scores = 1.0 / (eligible_capacities + epsilon)

        # Combine with tightness: we want to minimize (eligible_capacities - item)
        # So, a good heuristic score would be inversely proportional to this difference.
        # Using 1 / (difference + epsilon) captures this "tightness".
        # A higher value indicates a tighter fit.
        fit_scores = 1.0 / (eligible_capacities - item + epsilon)
        
        # To combine, we can multiply or add scaled versions.
        # Let's use an approach inspired by exponential scaling (like softmax input)
        # to create a smooth distribution where better fits get higher scores.
        # We want to prioritize smaller `eligible_capacities - item`.
        # Let's use `exp(-scaled_difference)`. A smaller difference leads to a larger exponent value.
        
        # Use a temperature parameter to control the sharpness of the priority distribution.
        # Lower temperature means stronger preference for the best fits.
        temperature = 0.5 
        
        # Calculate scores based on tightness: smaller difference -> higher score.
        # We invert the difference and scale it for the exponent.
        # Negative difference / temperature makes better fits have larger positive inputs to exp.
        diffs = eligible_capacities - item
        scaled_scores = -diffs / temperature
        
        # Apply exponential transformation to create graded priorities.
        # This is similar to the input to a softmax function.
        graded_priorities = np.exp(scaled_scores)

        # We can also integrate the preference for fuller bins by multiplying with base_scores.
        # However, `scaled_scores` already implicitly favors smaller capacities because `diffs` will be smaller.
        # Let's stick to the "best fit" (tightest fit) as the primary driver, transformed exponentially.
        
        priorities[eligible_bins_mask] = graded_priorities

    return priorities
```
