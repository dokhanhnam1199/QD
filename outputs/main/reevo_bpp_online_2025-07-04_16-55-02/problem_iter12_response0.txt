```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    bin_size = bins_remain_cap.max()

    # 1. Feasibility: Only consider bins where the item fits.
    feasible_bins = bins_remain_cap >= item

    # 2. Waste Minimization: Primary objective is to minimize waste.
    post_fill_levels = bins_remain_cap - item
    priorities[feasible_bins] = -post_fill_levels[feasible_bins] / bin_size  # Directly use negative normalized waste

    # 3. Infeasibility Penalty: Strong penalty for infeasible bins.
    priorities[~feasible_bins] = -np.inf

    # 4. Tight Fit Bonus: Significant bonus for bins that become nearly full.
    near_full_threshold = 0.05  # Even tighter fit
    near_full_bonus = 3.0  # Increased bonus

    near_full_bins = feasible_bins & (post_fill_levels >= 0) & (post_fill_levels <= (bin_size * near_full_threshold))
    
    # Dynamic tight fit bonus based on how tight fit is
    tight_fit_scale = 1 - (post_fill_levels[near_full_bins] / (bin_size * near_full_threshold))
    priorities[near_full_bins] += near_full_bonus * tight_fit_scale

    # 5. Consolidate Items: Penalize bins with very small remaining capacity.
    too_little_threshold = 0.15
    too_little_penalty = -2.0  # Stronger penalty

    too_little_bins = feasible_bins & (post_fill_levels > 0) & (post_fill_levels <= (bin_size * too_little_threshold))
    
    # Dynamic adjustment of consolidation penalty based on item size
    consolidation_penalty_scale = item / bin_size
    priorities[too_little_bins] += too_little_penalty * consolidation_penalty_scale

    # 6. Large Item Strategy: Fill nearly empty bins if the item is large.
    large_item_threshold = 0.7
    nearly_empty_threshold = 0.95
    nearly_empty_bonus = 2.5

    if item > bin_size * large_item_threshold:
        nearly_empty_bins = feasible_bins & (bins_remain_cap >= bin_size * nearly_empty_threshold)
        priorities[nearly_empty_bins] += nearly_empty_bonus

    # 7. Slightly prefer bins that are already relatively full
    already_full_threshold = 0.85
    already_full_bonus = 0.5

    already_full_bins = feasible_bins & (bins_remain_cap <= bin_size * (1 - already_full_threshold))
    priorities[already_full_bins] += already_full_bonus

    # 8. Item size based waste minimization adjustment:
    # Bigger items should prioritize bins closer to their size
    waste = post_fill_levels[feasible_bins]
    item_size_proximity_bonus = np.exp(-np.abs(waste - (bin_size - item)) / bin_size)  # Gaussian-like bonus
    priorities[feasible_bins] += item_size_proximity_bonus * 0.2 #Scaling this proximity bonus

    # 9. Handle No Feasible Bins: Ensure a bin is always chosen.
    if not np.any(feasible_bins):
        # Find the bin with minimum waste if item were placed (even if it overflows)
        waste = item - bins_remain_cap
        min_waste_bin = np.argmin(waste)
        priorities[min_waste_bin] = 0.01  # Very small positive priority
        priorities[waste > 0] = -np.inf  # Still prefer to only overflow the least
    
    return priorities
```
