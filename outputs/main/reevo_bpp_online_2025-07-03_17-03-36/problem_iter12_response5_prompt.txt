{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_capacity = np.max(bins_remain_cap)\n    normalized_item = item / bin_capacity\n\n    # 1. Feasibility: Infeasible bins get a very large negative priority.\n    feasible_bins = bins_remain_cap >= item\n    priorities[~feasible_bins] = -1e9\n\n    # 2. Normalized Remaining Capacity (Best Fit, but scaled):\n    remaining_after_fit = bins_remain_cap - item\n    remaining_after_fit[~feasible_bins] = bin_capacity * 2\n    normalized_remaining = remaining_after_fit / bin_capacity\n    best_fit_priority = -normalized_remaining  # Smaller remaining is better.\n    priorities += best_fit_priority\n\n    # 3. Moderate Fill Avoidance: Encourage filling bins somewhat, but not completely.\n    fill_threshold_low = 0.1\n    fill_threshold_high = 0.95\n    fill_avoidance_penalty = 0.05\n    fill_avoidance_mask = feasible_bins & (normalized_remaining > fill_threshold_low) & (normalized_remaining < fill_threshold_high)\n    priorities[fill_avoidance_mask] -= fill_avoidance_penalty * normalized_item # Penalize more for larger items\n\n\n    # 4. Bin Balancing: Encourage bins with fill levels closest to the mean.\n    bin_fill_levels = (bin_capacity - bins_remain_cap) / bin_capacity\n    mean_fill_level = np.mean(bin_fill_levels)\n    bin_balancing_bonus = -np.abs(bin_fill_levels - mean_fill_level) * 0.02 # Small bonus, normalized\n    priorities += bin_balancing_bonus\n\n    # 5. Fragmentation Penalty: Discourage creating small fragments, scaled to item size.\n    fragment_threshold = 0.1\n    fragment_penalty = 0.4\n    fragment_mask = feasible_bins & (normalized_remaining > 0) & (normalized_remaining <= fragment_threshold)\n    priorities[fragment_mask] -= fragment_penalty * normalized_item # Penalize more if item is large\n\n    # 6. Near-Perfect Fit Reward: Strong reward for near-perfect fits.\n    near_perfect_threshold = 0.05\n    near_perfect_bonus = 0.5\n    near_perfect_mask = feasible_bins & (normalized_remaining > 0) & (normalized_remaining <= near_perfect_threshold)\n    priorities[near_perfect_mask] += near_perfect_bonus\n\n    # 7. Item-Size Dependent Bonus: Slightly prefer bins closer in size to the item.\n    size_difference = np.abs(bins_remain_cap - item) / bin_capacity\n    size_similarity_bonus = -size_difference * 0.03\n    priorities += size_similarity_bonus\n\n    # 8. Exploration Bonus : Encourage exploration of empty or nearly empty bins.\n    exploration_threshold = 0.95\n    exploration_bonus = 0.01\n    exploration_mask = feasible_bins & (bins_remain_cap / bin_capacity > exploration_threshold)\n    priorities[exploration_mask] += exploration_bonus\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_capacity = np.max(bins_remain_cap)\n\n    # 1. Feasibility: Infeasible bins get a very large negative priority.\n    feasible_bins = bins_remain_cap >= item\n    priorities[~feasible_bins] = -1e9\n\n    # 2. Best Fit: Prefer bins where the remaining capacity after placement is minimal\n    remaining_after_fit = bins_remain_cap - item\n    remaining_after_fit[~feasible_bins] = bin_capacity * 2  # Set to large value for infeasible bins\n    best_fit_priority = -remaining_after_fit / bin_capacity  # Normalize & invert: smaller remaining is better\n    priorities += best_fit_priority\n\n    # 3. Moderate Fill: Penalize bins that are nearly full or nearly empty *before* item placement.\n    nearly_full_threshold = 0.9\n    nearly_empty_threshold = 0.1\n    moderate_fill_penalty = 0.3\n\n    nearly_full_bins = (bins_remain_cap / bin_capacity) > nearly_full_threshold\n    nearly_empty_bins = (bins_remain_cap / bin_capacity) < nearly_empty_threshold\n\n    priorities[feasible_bins & nearly_full_bins] -= moderate_fill_penalty\n    priorities[feasible_bins & nearly_empty_bins] -= moderate_fill_penalty\n\n    # 4. Fragmentation Penalty: Heavily penalize bins that will create a very small fragment.\n    fragment_threshold = 0.15\n    fragment_penalty = 0.8\n    fragment_mask = feasible_bins & (remaining_after_fit > 0) & (remaining_after_fit / bin_capacity <= fragment_threshold)\n    priorities[fragment_mask] -= fragment_penalty\n\n    # 5. Reward Near-Perfect Fit: Significant bonus for near perfect fits\n    near_perfect_fit_threshold = 0.05\n    near_perfect_fit_bonus = 0.7\n    near_perfect_mask = feasible_bins & (remaining_after_fit > 0) & (remaining_after_fit / bin_capacity <= near_perfect_fit_threshold)\n    priorities[near_perfect_mask] += near_perfect_fit_bonus\n\n    # 6. Small Item Penalty: Slightly discourage placing very small items into partially filled bins.  Also, give a slight preference to placing small items in empty bins.\n    small_item_threshold = 0.1\n    small_item_penalty = 0.1\n    small_item = item / bin_capacity < small_item_threshold\n    if small_item:\n        partially_filled_bins = feasible_bins & (bins_remain_cap < bin_capacity) & (bins_remain_cap > 0)\n        empty_bins = bins_remain_cap == bin_capacity\n        priorities[partially_filled_bins] -= small_item_penalty\n        priorities[empty_bins] += small_item_penalty / 2  # Slight preference for empty bins\n\n    # 7. Bin balancing: Try to balance the fill levels of the bins\n    bin_fill_levels = (bin_capacity - bins_remain_cap) / bin_capacity\n    mean_fill_level = np.mean(bin_fill_levels)\n    bin_balancing_penalty = 0.05 * np.abs(bin_fill_levels - mean_fill_level)\n    priorities -= bin_balancing_penalty\n\n    return priorities\n\n[Reflection]\nFocus on stronger penalties/rewards, clear thresholds, and item-size awareness for fragmentation and small items.\n\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}