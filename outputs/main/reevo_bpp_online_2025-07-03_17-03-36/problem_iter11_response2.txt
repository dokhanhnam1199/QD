```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    bin_capacity = np.max(bins_remain_cap)
    normalized_item = item / bin_capacity

    # 1. Feasibility: Infeasible bins get a very large negative priority.
    feasible_bins = bins_remain_cap >= item
    priorities[~feasible_bins] = -1e9

    # 2. Normalized Remaining Capacity (Best Fit, but scaled):
    remaining_after_fit = bins_remain_cap - item
    remaining_after_fit[~feasible_bins] = bin_capacity * 2
    normalized_remaining = remaining_after_fit / bin_capacity
    best_fit_priority = -normalized_remaining  # Smaller remaining is better.
    priorities += best_fit_priority

    # 3. Moderate Fill Avoidance: Encourage filling bins somewhat, but not completely.
    fill_threshold_low = 0.1
    fill_threshold_high = 0.95
    fill_avoidance_penalty = 0.05
    fill_avoidance_mask = feasible_bins & (normalized_remaining > fill_threshold_low) & (normalized_remaining < fill_threshold_high)
    priorities[fill_avoidance_mask] -= fill_avoidance_penalty * normalized_item # Penalize more for larger items


    # 4. Bin Balancing: Encourage bins with fill levels closest to the mean.
    bin_fill_levels = (bin_capacity - bins_remain_cap) / bin_capacity
    mean_fill_level = np.mean(bin_fill_levels)
    bin_balancing_bonus = -np.abs(bin_fill_levels - mean_fill_level) * 0.02 # Small bonus, normalized
    priorities += bin_balancing_bonus

    # 5. Fragmentation Penalty: Discourage creating small fragments, scaled to item size.
    fragment_threshold = 0.1
    fragment_penalty = 0.4
    fragment_mask = feasible_bins & (normalized_remaining > 0) & (normalized_remaining <= fragment_threshold)
    priorities[fragment_mask] -= fragment_penalty * normalized_item # Penalize more if item is large

    # 6. Near-Perfect Fit Reward: Strong reward for near-perfect fits.
    near_perfect_threshold = 0.05
    near_perfect_bonus = 0.5
    near_perfect_mask = feasible_bins & (normalized_remaining > 0) & (normalized_remaining <= near_perfect_threshold)
    priorities[near_perfect_mask] += near_perfect_bonus

    # 7. Item-Size Dependent Bonus: Slightly prefer bins closer in size to the item.
    size_difference = np.abs(bins_remain_cap - item) / bin_capacity
    size_similarity_bonus = -size_difference * 0.03
    priorities += size_similarity_bonus

    # 8. Exploration Bonus : Encourage exploration of empty or nearly empty bins.
    exploration_threshold = 0.95
    exploration_bonus = 0.01
    exploration_mask = feasible_bins & (bins_remain_cap / bin_capacity > exploration_threshold)
    priorities[exploration_mask] += exploration_bonus

    return priorities
```
