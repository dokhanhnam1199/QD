{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Improves upon the basic 1/distance_matrix heuristic for TSP.\n\n    This heuristic combines several factors to estimate the desirability\n    of including an edge:\n\n    1.  Inverse distance: Shorter edges are generally better.\n    2.  Node degree penalty: Avoids high-degree nodes early on to encourage\n        a more balanced tour.  Calculated from average distances. Edges\n        connecting nodes that are, on average, further away from others are preferred.\n    3.  Global distance context: Considers the overall distance distribution.  Encourages\n        inclusion of edges that are significantly shorter than the average.\n\n    Args:\n        distance_matrix: A numpy array representing the distance matrix.\n\n    Returns:\n        A numpy array of the same shape as distance_matrix, where each element\n        represents the desirability of including the corresponding edge in the TSP tour.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Calculate average distance for each node\n    avg_distances = np.mean(distance_matrix, axis=0)\n\n    # Global average distance\n    global_avg_distance = np.mean(distance_matrix)\n\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                # Inverse distance\n                distance_component = 1 / distance_matrix[i, j]\n\n                # Node degree penalty/preference (using average distances as proxy for centrality)\n                degree_component = avg_distances[i] + avg_distances[j]  # Prefer edges connecting \"peripheral\" nodes\n\n                #Global distance context:\n                global_context_component = np.exp(-(distance_matrix[i, j] / global_avg_distance)) #exp(-x) decays as x grows. Shorter edges get higher weights.\n\n\n                heuristic_matrix[i, j] = distance_component * (1 / (degree_component)) * global_context_component\n            else:\n                heuristic_matrix[i, j] = 0  # Avoid self-loops\n\n    return heuristic_matrix\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A more sophisticated heuristic for the Traveling Salesman Problem.\n    This version combines distance, a \"gravity\" effect, and randomness.\n\n    The heuristic favors shorter distances but also encourages exploration\n    of less-visited edges.  A stochastic element is introduced to avoid\n    getting stuck in local optima.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix where distance_matrix[i][j]\n                                       represents the distance between node i and node j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each element\n                    represents a heuristic value indicating the desirability of\n                    including the corresponding edge in the TSP tour.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance component (shorter distances are better)\n    inverse_distance = 1.0 / (distance_matrix + 1e-6)  # Add a small constant to avoid division by zero\n\n    # \"Gravity\" component: Encourage connections to nodes that are far from the \"center of gravity\".\n    # This promotes exploration and avoids clustering in one region.\n    total_distances = np.sum(distance_matrix, axis=0)  # Sum of distances from each node to all other nodes\n    gravity_potential = total_distances / np.mean(total_distances)  # Normalize to a reasonable scale\n\n\n    # Combine the components\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_matrix[i, j] = inverse_distance[i, j] * (gravity_potential[i] + gravity_potential[j]) # Both nodes have gravity effects\n\n            else:\n                heuristic_matrix[i, j] = 0  # No self-loops\n    # Add a stochastic element to encourage exploration\n\n    random_noise = np.random.rand(n, n) * 0.1  # Small random values\n    heuristic_matrix = heuristic_matrix + random_noise\n\n\n    return heuristic_matrix\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Improved heuristics for the Traveling Salesman Problem based on distance and neighborhood.\n    Prioritizes shorter distances and edges connecting to nodes with longer average distances to other nodes.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix representing the distances between nodes.\n                                       distance_matrix[i][j] is the distance between node i and node j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each element\n                      indicates the desirability of including the corresponding edge in the TSP tour.\n    \"\"\"\n    n = distance_matrix.shape[0]\n\n    # 1. Inverse distance heuristic: shorter distances are more desirable\n    inverse_distance = 1 / (distance_matrix + 1e-9)  # Adding a small value to avoid division by zero\n\n    # 2. Node Importance Heuristic: Give higher weight to edges connecting nodes with overall larger distances\n    #    to others. This encourages exploring less-connected parts of the graph early on,\n    #    potentially preventing premature convergence to local optima.\n    node_importance = np.sum(distance_matrix, axis=1)  # Sum of distances for each node\n    node_importance_matrix = np.tile(node_importance, (n, 1)) # Replicate node importance for matrix operations\n    node_importance_heuristic = node_importance_matrix + node_importance_matrix.T\n    #3. combine heuristics\n    heuristic_matrix = inverse_distance * (node_importance_heuristic/np.max(node_importance_heuristic))\n\n    # Set diagonal elements to zero to avoid self-loops.  The inverse_distance also handles this, but added for extra safety.\n    np.fill_diagonal(heuristic_matrix, 0)\n\n    return heuristic_matrix\n\n[Heuristics 4th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Heuristics for the Traveling Salesman Problem (TSP) based on distance.\n\n    This version incorporates several ideas:\n\n    1.  Inverse Distance:  As in v1, shorter distances are initially preferred.\n    2.  Greedy Start Bias: To encourage better starting edges for local search, prefer edges that link to locations\n        that have smaller summed distances to all others.\n    3.  Global connection boost: Edges that bridge regions of high density, represented\n        by distant neighbors are somewhat preferred.  It tries to help 'stitch together'\n        separated clusters.\n    4. Prevent Self-Loops: Explicitly sets the heuristic value of self-loops (distance of 0) to 0.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance (primary heuristic)\n    heuristics = 1.0 / (distance_matrix + 1e-9)  # Avoid division by zero\n\n    # Calculate node 'importance' (sum of distances to all other nodes)\n    node_importance = np.sum(distance_matrix, axis=1)\n\n    # Node bias. Preferentially links two \"important\" nodes.\n    for i in range(n):\n        for j in range(n):\n           heuristics[i,j] = heuristics[i, j] * ((1/(node_importance[i]+ 1e-9)) + (1/(node_importance[j] + 1e-9)))\n\n    #Global Connection Boost: Penalize edges to locations already closeby\n    for i in range(n):\n        for j in range(n):\n\n            avg_dist_to_neighbors_i = np.mean(distance_matrix[i,:])\n            avg_dist_to_neighbors_j = np.mean(distance_matrix[j,:])\n            heuristics[i,j] = heuristics[i,j] * (avg_dist_to_neighbors_i + avg_dist_to_neighbors_j)\n\n    # Zero out self-loops (distance of 0)\n    for i in range(n):\n        heuristics[i, i] = 0.0\n\n    return heuristics\n\n[Heuristics 5th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Einstein's heuristics for TSP using stochastic solution sampling,\n    considering both distance and potential cluster structures.\n\n    Args:\n        distance_matrix: A numpy array representing the distances between cities.\n\n    Returns:\n        A numpy array of the same shape as distance_matrix, representing the\n        prior indicators of how promising it is to include each edge in a solution.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n\n    # 1. Inverse distance: Shorter distances are generally more promising.\n    heuristic_matrix = 1 / (distance_matrix + 1e-9)  # Adding a small constant to avoid division by zero\n\n    # 2. Node degree centrality adjustment: Nodes with fewer close neighbors might be more critical.\n    degree_centrality = np.sum(heuristic_matrix, axis=0)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_matrix[i, j] /= (degree_centrality[i] * degree_centrality[j])**0.25 # Adjust centrality influence with exponent\n    \n    # 3. Adjust for Triangle Inequality violations (proxy for \"shortcuts\"):\n    #    If going from i to k to j is significantly shorter than i to j, it hints\n    #    that i to j may be a useful long-range connection in some cases.\n    #    We *decrease* its heuristic value, penalizing direct connections where shortcuts exist\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                shortcut_factor = 0.0\n                for k in range(n):\n                    if i != k and j != k:\n                         potential_shortcut = distance_matrix[i, k] + distance_matrix[k, j]\n                         shortcut_factor += np.maximum(0, (distance_matrix[i, j] - potential_shortcut) / distance_matrix[i,j])\n                heuristic_matrix[i, j] /= (1 + shortcut_factor/ n ) # Average, normalized impact of shortcuts\n\n    # 4. Symmetry correction:  Ensure the matrix is symmetric (if it wasn't already)\n    heuristic_matrix = (heuristic_matrix + heuristic_matrix.T) / 2\n\n    return heuristic_matrix\n\n[Heuristics 6th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Improved heuristics for the Traveling Salesman Problem based on distance and node connectivity.\n\n    This heuristic considers both the distance between nodes and an estimate of the connectivity\n    of each node within the graph represented by the distance matrix.  Shorter distances are\n    generally favored, and nodes that appear to be more centrally located or highly connected\n    are given a boost in their edge desirability.  This helps guide the search towards solutions\n    that balance short hops with good overall tour structure.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix where distance_matrix[i, j] represents the distance\n                                     between node i and node j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, containing heuristic values\n                     indicating the desirability of including each edge in the TSP solution.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n\n    # 1. Inverse Distance (Basic desirability)\n    heuristic_matrix = 1 / (distance_matrix + 1e-9)  # Add a small constant to avoid division by zero\n\n    # 2. Node Connectivity Estimate (Sum of inverse distances to other nodes)\n    node_connectivity = np.sum(heuristic_matrix, axis=1)\n\n    # 3. Combine Distance and Connectivity\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_matrix[i, j] *= (node_connectivity[i] + node_connectivity[j]) / 2.0 # Averaging connectivity of both nodes\n            else:\n                heuristic_matrix[i, j] = 0  # No self-loops allowed\n\n    # 4. Normalize heuristics (optional, but can improve stability)\n    heuristic_matrix = heuristic_matrix / np.max(heuristic_matrix)\n\n    return heuristic_matrix\n\n[Heuristics 7th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Heuristics for Traveling Salesman Problem (TSP) based on distance and node degree.\n\n    This function calculates a heuristic score for each edge in the distance matrix,\n    indicating how promising it is to include that edge in the final TSP solution.\n    The heuristic combines the inverse of distance with a node degree penalty.  Edges\n    connected to nodes with fewer connections are preferred.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix representing the distances\n            between all pairs of nodes.  distance_matrix[i, j] is the distance\n            from node i to node j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each\n            element represents the heuristic score for the corresponding edge.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix)\n\n    # Calculate node degree desirability: nodes with lower degree should be prioritized.\n    # This helps prevent premature closure of sub-tours.\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_matrix[i, j] = 1 / (distance_matrix[i, j] + 1e-9) # avoid division by zero\n            else:\n                heuristic_matrix[i, j] = 0  # No self-loops\n\n    # Normalize to ensure values between 0 and 1, enhancing exploration\n    heuristic_matrix = (heuristic_matrix - np.min(heuristic_matrix)) / (np.max(heuristic_matrix) - np.min(heuristic_matrix) + 1e-9)\n\n\n    #Calculate node degree \"attractiveness\".\n    node_degree = np.sum(heuristic_matrix > 0, axis=0)  # Approximate current node degrees.\n\n    # Modify the heuristic by penalizing higher degree nodes. Favor connecting to low degree nodes.\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n\n                degree_penalty = 1 / (node_degree[i] + node_degree[j] + 1e-9) # Favor low degree connections.\n\n                heuristic_matrix[i,j] = heuristic_matrix[i, j] * degree_penalty #Combines distance and node desirability\n\n\n    #Re-normalize\n    heuristic_matrix = (heuristic_matrix - np.min(heuristic_matrix)) / (np.max(heuristic_matrix) - np.min(heuristic_matrix) + 1e-9)\n\n    return heuristic_matrix\n\n[Heuristics 8th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Heuristics for the Traveling Salesman Problem (TSP) using concepts inspired by\n    black holes and gravitational lensing. The core idea is to bias the search towards\n    edges that are shorter (stronger gravitational pull) and connect to nodes with fewer\n    nearby nodes (less obscured).\n\n    This heuristic attempts to mimic the way light bends around a black hole, where shorter paths\n    are preferred, and areas of lower node density are more \"visible\" (less obscured).\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix representing the distances between nodes.\n                                         distance_matrix[i, j] is the distance between node i and node j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each element\n                      indicates the desirability of including the corresponding edge in the solution.\n                      Higher values represent more desirable edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse of distance, analogous to gravitational pull (shorter distances are preferred)\n    inverse_distance = 1.0 / (distance_matrix + 1e-9)  # Add small constant to avoid division by zero\n\n    # Node degree heuristic: Favors nodes with fewer nearby neighbors\n    # Mimics the idea that nodes in less dense regions are more accessible.\n\n    for i in range(n):\n        # Calculate a \"node visibility\" score for each node i.\n        # Lower degree (fewer neighbors within a certain radius) implies higher visibility.\n\n        # Option 1: Simple inverse degree\n        node_degree = np.sum(distance_matrix[i, :] < np.mean(distance_matrix[i,:])) # count how many nodes nearby\n\n        node_visibility = 1.0 / (node_degree + 1)  # Avoid division by zero\n\n        # Option 2: More complex \"gravitational potential\" based on inverse distance.\n        # potential = np.sum(inverse_distance[i, :])\n        # node_visibility = 1.0 / (potential + 1e-9)\n\n        for j in range(n):\n            # Combine inverse distance (attraction) and node visibility.\n            heuristics_matrix[i, j] = inverse_distance[i, j] * (node_visibility+ 1e-9)  #Adjust to encourage visibility\n\n\n\n    # Additional edge weighting - prioritize shorter edges, but also consider\n    # how well they connect to the overall graph structure. A small adjustment\n    # ensures symmetry and avoids zero division\n    for i in range(n):\n        for j in range(n):\n                heuristics_matrix[i, j] +=  np.mean([heuristics_matrix[i, k] + heuristics_matrix[k,j] for k in range(n)])/(n+1e-9) # give higher score if intermediate hop would also be useful\n\n\n    # Normalize to avoid extreme values (improve numerical stability).\n    max_val = np.max(heuristics_matrix)\n    if max_val > 0:\n      heuristics_matrix /= max_val\n\n    return heuristics_matrix\n\n[Heuristics 9th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Improved heuristic for TSP based on a combination of distance,\n    reciprocal rank, and adaptive weighting based on local density.\n    Higher values indicate a more promising edge.\n\n    Args:\n        distance_matrix: A NumPy array representing the distance matrix.\n                         distance_matrix[i, j] is the distance between node i and node j.\n\n    Returns:\n        A NumPy array of the same shape as distance_matrix,\n        representing the heuristic scores for each edge.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Avoid division by zero and self-loops\n    distance_matrix = np.where(distance_matrix == 0, np.inf, distance_matrix)\n    np.fill_diagonal(distance_matrix, np.inf) # ensure we don't choose self-loops\n\n    # 1. Inverse Distance: Shorter distances are generally more desirable\n    inverse_distance = 1 / distance_matrix\n\n    # 2. Reciprocal Rank: Reward edges that are short relative to others from the same node.\n    reciprocal_rank = np.zeros_like(distance_matrix, dtype=float)\n    for i in range(n):\n        # Get distances from node i to all other nodes\n        distances = distance_matrix[i, :]\n        # Get the rank of each distance from node i (lower distance = lower rank)\n        ranks = np.argsort(distances)  # Indices sorted by distance\n        ranked_distances = np.argsort(ranks) + 1  # Rank starts from 1\n        reciprocal_rank[i, :] = 1 / ranked_distances\n\n    # 3. Adaptive weighting: Account for local node density. Denser areas mean even short edges must be handled with caution\n    #   - We calculate node density using a simple averaging of neighboring inverse distances.  High inverse distance == high node density nearby\n    #   - Low local density gives greater weight to reciprocal rank to aggressively explore shorter paths, preventing traps\n    #   - High local density deemphasizes reciprocal rank, and instead focuses on pure distance.\n    node_densities = np.zeros(n)\n    for i in range(n):\n        node_densities[i] = np.mean(inverse_distance[i, :])\n\n    # Weight scaling factor based on density. Higher local density, reduces exploration.\n    density_scaling = 1.0 / (1.0 + node_densities) # Scale densities so they become penalty coefficients.\n    density_scaling = np.tile(density_scaling, (n,1))\n    density_scaling = np.minimum(density_scaling, density_scaling.T) #take lower density factor between connected nodes\n\n\n    # Combine heuristics: inverse distance contributes heavily to base utility, exploration reciprocal rank to boost better ones\n    heuristic_matrix = inverse_distance + density_scaling * reciprocal_rank # density acts as a weighting penalty on exploration.\n\n    # Normalize heuristic matrix so stochastic sampling isn't overly sensitive to scale.\n    heuristic_matrix = (heuristic_matrix - np.min(heuristic_matrix)) / (np.max(heuristic_matrix) - np.min(heuristic_matrix) + 1e-9) # scaled [0,1]\n\n    return heuristic_matrix\n\n[Heuristics 10th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Improved heuristic for TSP based on a combination of distance,\n    reciprocal rank, and adaptive weighting based on local density.\n    Higher values indicate a more promising edge.\n\n    Args:\n        distance_matrix: A NumPy array representing the distance matrix.\n                         distance_matrix[i, j] is the distance between node i and node j.\n\n    Returns:\n        A NumPy array of the same shape as distance_matrix,\n        representing the heuristic scores for each edge.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Avoid division by zero and self-loops\n    distance_matrix = np.where(distance_matrix == 0, np.inf, distance_matrix)\n    np.fill_diagonal(distance_matrix, np.inf) # ensure we don't choose self-loops\n\n    # 1. Inverse Distance: Shorter distances are generally more desirable\n    inverse_distance = 1 / distance_matrix\n\n    # 2. Reciprocal Rank: Reward edges that are short relative to others from the same node.\n    reciprocal_rank = np.zeros_like(distance_matrix, dtype=float)\n    for i in range(n):\n        # Get distances from node i to all other nodes\n        distances = distance_matrix[i, :]\n        # Get the rank of each distance from node i (lower distance = lower rank)\n        ranks = np.argsort(distances)  # Indices sorted by distance\n        ranked_distances = np.argsort(ranks) + 1  # Rank starts from 1\n        reciprocal_rank[i, :] = 1 / ranked_distances\n\n    # 3. Adaptive weighting: Account for local node density. Denser areas mean even short edges must be handled with caution\n    #   - We calculate node density using a simple averaging of neighboring inverse distances.  High inverse distance == high node density nearby\n    #   - Low local density gives greater weight to reciprocal rank to aggressively explore shorter paths, preventing traps\n    #   - High local density deemphasizes reciprocal rank, and instead focuses on pure distance.\n    node_densities = np.zeros(n)\n    for i in range(n):\n        node_densities[i] = np.mean(inverse_distance[i, :])\n\n    # Weight scaling factor based on density. Higher local density, reduces exploration.\n    density_scaling = 1.0 / (1.0 + node_densities) # Scale densities so they become penalty coefficients.\n    density_scaling = np.tile(density_scaling, (n,1))\n    density_scaling = np.minimum(density_scaling, density_scaling.T) #take lower density factor between connected nodes\n\n\n    # Combine heuristics: inverse distance contributes heavily to base utility, exploration reciprocal rank to boost better ones\n    heuristic_matrix = inverse_distance + density_scaling * reciprocal_rank # density acts as a weighting penalty on exploration.\n\n    # Normalize heuristic matrix so stochastic sampling isn't overly sensitive to scale.\n    heuristic_matrix = (heuristic_matrix - np.min(heuristic_matrix)) / (np.max(heuristic_matrix) - np.min(heuristic_matrix) + 1e-9) # scaled [0,1]\n\n    return heuristic_matrix\n\n[Heuristics 11th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Improves upon v1 by incorporating a \"gravity\" towards the center of the nodes\n    and penalizing edges that cross far from the center, potentially leading to\n    more compact and efficient routes. It also combines information about minimal outgoing edges,\n    avoiding premature convergence and promoting exploration.\n\n    Args:\n        distance_matrix: A numpy ndarray representing the distance matrix.\n\n    Returns:\n        A numpy ndarray of the same shape as distance_matrix, representing the\n        heuristic values for each edge.\n    \"\"\"\n    n = distance_matrix.shape[0]\n\n    # 1. Inverse distance (basic heuristic)\n    heuristic_matrix = 1 / (distance_matrix + 1e-9)  # Adding a small value to avoid division by zero\n\n    # 2. Center of the nodes (proxy for geographical center)\n    center_x = np.mean(np.arange(n))\n    center_y = np.mean(np.arange(n))\n\n    # 3. Calculate distances from each node to the center\n    center_distances = np.sqrt((np.arange(n) - center_x)**2 + (np.arange(n) - center_y)**2)\n\n    # 4. Heuristic factor based on proximity to the center\n    center_proximity_factor = np.zeros((n, n))\n    for i in range(n):\n        for j in range(n):\n             center_proximity_factor[i,j] = 1.0 - (abs(center_distances[i] - center_distances[j]) / (np.max(center_distances)+1e-9))\n\n    # 5. Minimal outgoing edge bonus: Helps explore different paths by\n    #   identifying for each node edges that have small distances.\n    min_outgoing_indices = np.argmin(distance_matrix, axis=1)\n    min_outgoing_bonus = np.zeros((n, n))\n    for i in range(n):\n        min_outgoing_bonus[i, min_outgoing_indices[i]] = 1.0 # encourage to take edges that lead to the closest cities, at least once.\n\n    # 6. Combine all factors (weighted)\n\n    heuristic_matrix = (0.6 * heuristic_matrix +\n                           0.3 * center_proximity_factor +\n                           0.1 * min_outgoing_bonus) # emphasize distance, but consider geographical proximity.\n\n    return heuristic_matrix\n\n[Heuristics 12th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Heuristics for TSP using a combination of inverse distance and node centrality.\n\n    The idea here is to favor edges that are short and connect to nodes that are centrally located in the graph.\n    This aims to prevent solutions that branch out to distant nodes early on.\n\n    Args:\n        distance_matrix: A NumPy ndarray representing the distance matrix for the TSP.\n\n    Returns:\n        A NumPy ndarray of the same shape as the input distance matrix,\n        where each element represents the \"promise\" of including the corresponding edge in a solution.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n\n    # Inverse distance heuristic\n    inverse_distance = 1 / (distance_matrix + np.eye(n)) # Add identity to avoid division by zero for self-loops.  Self-loops aren't part of TSP, but numerical stability matters\n\n    # Node centrality heuristic (degree centrality based on inverse distances)\n    node_centrality = np.sum(inverse_distance, axis=1) # Sum of inverse distances for each node, giving how well a node connected to the rest.\n\n    # Edge-wise centrality (product of the centrality of the two nodes connected by an edge)\n    edge_centrality = np.zeros_like(distance_matrix)\n    for i in range(n):\n        for j in range(n):\n            edge_centrality[i, j] = node_centrality[i] * node_centrality[j]\n\n    # Combine the heuristics\n    # Adding small constance for numerical stability,\n    # scaling the distance with node centrality information\n    heuristic_matrix = inverse_distance * (edge_centrality**0.5 + 1e-9)\n\n    return heuristic_matrix\n\n[Heuristics 13th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Heuristics for the Traveling Salesman Problem (TSP) based on stochastic solution sampling,\n    inspired by black hole principles.\n\n    This version combines inverse distance with a stochastic element, weighted by\n    the distance to the farthest node.  The stochasticity allows for escaping local\n    optima, mimicking Hawking radiation.  The weighting emphasizes potentially longer,\n    but globally more efficient, \"quantum tunneling\" paths.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix where distance_matrix[i, j]\n                                     represents the distance between city i and city j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, containing heuristic values.\n                    Higher values indicate more promising edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    max_distance = np.max(distance_matrix[np.isfinite(distance_matrix)])  # Avoid infs when computing stochasticity\n\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                # Inverse distance (shorter distances are preferred)\n                inverse_distance = 1 / distance_matrix[i, j] if distance_matrix[i,j] !=0 else np.inf # prevent division by zero. If 0 then inf will automatically prevent algorithm to visit this route\n\n                # Stochastic element (Hawking radiation): favor exploration based on \"black hole event horizon\"\n                stochasticity = np.random.rand() * (distance_matrix[i,j] / max_distance) # Normalize by the \"event horizon\" (max distance)\n\n                # Combine inverse distance and stochasticity. Weights promote potential quantum tunneling\n                heuristic_matrix[i, j] = inverse_distance + stochasticity\n\n            else:\n                heuristic_matrix[i, j] = 0  # No self-loops\n\n    return heuristic_matrix\n\n[Heuristics 14th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Heuristics for the Traveling Salesman Problem (TSP) using a combination of inverse distance,\n    savings heuristic, and a touch of randomness to encourage exploration.\n\n    Args:\n        distance_matrix: A NumPy ndarray representing the distance matrix between cities.\n\n    Returns:\n        A NumPy ndarray of the same shape as distance_matrix, representing the prior\n        indicator of how promising each edge is. Higher values indicate more promising edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n\n    # 1. Inverse distance (basic heuristic)\n    inverse_distance = 1 / (distance_matrix + np.eye(n))  # Add identity to avoid division by zero on the diagonal\n    heuristics += inverse_distance\n\n    # 2. Savings Heuristic:  Measure the \"savings\" from directly linking two cities rather than going back to a depot (city 0).  Normalize savings by distance.\n\n    depot = 0  # Arbitrarily choose city 0 as the depot/starting point. This can be randomized as well.\n    savings = np.zeros_like(distance_matrix)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j: # Avoid savings between same city\n                savings[i, j] = distance_matrix[depot, i] + distance_matrix[depot, j] - distance_matrix[i, j]\n    #scale savings by overall distances involved.\n    heuristics += savings / (distance_matrix + np.eye(n))\n    # 3. Randomness (Encourage exploration)\n    randomness = np.random.rand(n, n) * 0.1  # Small random values\n\n    heuristics += randomness\n\n    # 4. Make sure diagnal is small/zero\n\n    heuristics[np.diag_indices_from(heuristics)] = -1\n    # 5. Normalize the heuristics\n    heuristics = (heuristics - np.min(heuristics)) / (np.max(heuristics) - np.min(heuristics))  # Scale to [0, 1]\n\n\n    return heuristics\n\n[Heuristics 15th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Heuristics for the Traveling Salesman Problem (TSP) using a combination of inverse distance,\n    savings heuristic, and a touch of randomness to encourage exploration.\n\n    Args:\n        distance_matrix: A NumPy ndarray representing the distance matrix between cities.\n\n    Returns:\n        A NumPy ndarray of the same shape as distance_matrix, representing the prior\n        indicator of how promising each edge is. Higher values indicate more promising edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n\n    # 1. Inverse distance (basic heuristic)\n    inverse_distance = 1 / (distance_matrix + np.eye(n))  # Add identity to avoid division by zero on the diagonal\n    heuristics += inverse_distance\n\n    # 2. Savings Heuristic:  Measure the \"savings\" from directly linking two cities rather than going back to a depot (city 0).  Normalize savings by distance.\n\n    depot = 0  # Arbitrarily choose city 0 as the depot/starting point. This can be randomized as well.\n    savings = np.zeros_like(distance_matrix)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j: # Avoid savings between same city\n                savings[i, j] = distance_matrix[depot, i] + distance_matrix[depot, j] - distance_matrix[i, j]\n    #scale savings by overall distances involved.\n    heuristics += savings / (distance_matrix + np.eye(n))\n    # 3. Randomness (Encourage exploration)\n    randomness = np.random.rand(n, n) * 0.1  # Small random values\n\n    heuristics += randomness\n\n    # 4. Make sure diagnal is small/zero\n\n    heuristics[np.diag_indices_from(heuristics)] = -1\n    # 5. Normalize the heuristics\n    heuristics = (heuristics - np.min(heuristics)) / (np.max(heuristics) - np.min(heuristics))  # Scale to [0, 1]\n\n\n    return heuristics\n\n[Heuristics 16th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Heuristics for the Traveling Salesman Problem (TSP) using a combination of inverse distance,\n    savings heuristic, and a touch of randomness to encourage exploration.\n\n    Args:\n        distance_matrix: A NumPy ndarray representing the distance matrix between cities.\n\n    Returns:\n        A NumPy ndarray of the same shape as distance_matrix, representing the prior\n        indicator of how promising each edge is. Higher values indicate more promising edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix)\n\n    # 1. Inverse distance (basic heuristic)\n    inverse_distance = 1 / (distance_matrix + np.eye(n))  # Add identity to avoid division by zero on the diagonal\n    heuristics += inverse_distance\n\n    # 2. Savings Heuristic:  Measure the \"savings\" from directly linking two cities rather than going back to a depot (city 0).  Normalize savings by distance.\n\n    depot = 0  # Arbitrarily choose city 0 as the depot/starting point. This can be randomized as well.\n    savings = np.zeros_like(distance_matrix)\n\n    for i in range(n):\n        for j in range(n):\n            if i != j: # Avoid savings between same city\n                savings[i, j] = distance_matrix[depot, i] + distance_matrix[depot, j] - distance_matrix[i, j]\n    #scale savings by overall distances involved.\n    heuristics += savings / (distance_matrix + np.eye(n))\n    # 3. Randomness (Encourage exploration)\n    randomness = np.random.rand(n, n) * 0.1  # Small random values\n\n    heuristics += randomness\n\n    # 4. Make sure diagnal is small/zero\n\n    heuristics[np.diag_indices_from(heuristics)] = -1\n    # 5. Normalize the heuristics\n    heuristics = (heuristics - np.min(heuristics)) / (np.max(heuristics) - np.min(heuristics))  # Scale to [0, 1]\n\n\n    return heuristics\n\n[Heuristics 17th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Heuristics for the Traveling Salesman Problem (TSP) based on a combination of\n    inverse distance, savings heuristic, and random perturbations, inspired\n    by quantum mechanics principles (stochastic sampling with \"path integrals\").\n\n    Args:\n        distance_matrix: A numpy ndarray representing the distance matrix between cities.\n\n    Returns:\n        A numpy ndarray of the same shape as distance_matrix, representing the\n        prior probability of including each edge in a solution.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance (short distances are preferred)\n    inverse_distance = 1.0 / (distance_matrix + 1e-9)  # Adding a small value to avoid division by zero\n\n    # Savings heuristic (inspired by Clarke-Wright algorithm)\n    #  Higher savings indicate a higher likelihood of inclusion.\n    savings = np.zeros_like(distance_matrix, dtype=float)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                # Savings from merging i and j into a route\n                savings[i, j] = distance_matrix[i, 0] + distance_matrix[0, j] - distance_matrix[i, j] # assuming start node is 0\n                savings[j, i] = distance_matrix[j, 0] + distance_matrix[0, i] - distance_matrix[j, i]\n\n    # Combine inverse distance and savings\n    heuristics = inverse_distance + savings # maybe add scaling factors\n\n    # Add a stochastic element -  \"quantum fluctuations\"\n    # This introduces some randomness to allow for exploration of different paths\n    # even if some edges seem less promising initially.\n    random_perturbation = np.random.normal(0, 0.1, size=(n, n)) # scaled random noise\n    heuristics += random_perturbation\n\n    # Ensure the diagonal is zero and all values are non-negative.\n\n    for i in range(n):\n        heuristics[i, i] = 0\n\n    heuristics = np.maximum(heuristics, 0) # Ensure probabilities are non-negative\n\n\n    # Normalize the heuristics\n    total_sum = np.sum(heuristics)\n    if total_sum > 0:\n        heuristics /= total_sum  # Convert to probabilities (optional, but useful)\n    else:\n        heuristics = np.ones_like(distance_matrix) / (n * (n -1))\n\n    return heuristics\n\n[Heuristics 18th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A heuristic function for the Traveling Salesman Problem based on Newton's laws and physical intuition.\n    This function incorporates a combination of inverse distance (gravity),\n    a temperature-based exploration factor, and a path coherence term.\n\n    Args:\n        distance_matrix (np.ndarray): A matrix where distance_matrix[i, j] is the distance between city i and city j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, containing heuristic values for each edge.\n                     Higher values indicate more promising edges.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse Distance (Gravitational Analogy): Closer cities are more attractive.\n    inverse_distance = 1 / (distance_matrix + 1e-9)  # Add a small constant to avoid division by zero.\n\n    # 2. Temperature-based Exploration: Encourage exploration initially, focusing as the search progresses.\n    temperature = 1.0  # Initial temperature (can be tuned). It decreases over time implicitly\n    exploration_factor = np.exp(-distance_matrix / temperature)\n\n    # 3. Path Coherence: Encourages edges that connect to nodes that are \"well-connected\" in general,\n    #    considering all edge connections in the graph to create a smooth and promising initial path\n    path_coherence = np.zeros_like(distance_matrix, dtype=float)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                # Compute the sum of inverse distances from i and j to all other nodes\n                attraction_i = np.sum(inverse_distance[i, :])\n                attraction_j = np.sum(inverse_distance[j, :])\n                path_coherence[i, j] = (attraction_i + attraction_j)\n    \n    # 4. Combine the factors, weighting each appropriately. These weightings can be optimized through trials.\n    alpha = 0.6  # Weight for inverse distance\n    beta = 0.2   # Weight for exploration factor\n    gamma = 0.2   # Weight for path coherence\n\n    heuristics = alpha * inverse_distance + beta * exploration_factor + gamma * path_coherence\n\n    # Set diagonal elements (distance to self) to zero, avoiding self-loops.\n    np.fill_diagonal(heuristics, 0)\n\n    return heuristics\n\n[Heuristics 19th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    A heuristic function for the Traveling Salesman Problem based on Newton's laws and physical intuition.\n    This function incorporates a combination of inverse distance (gravity),\n    a temperature-based exploration factor, and a path coherence term.\n\n    Args:\n        distance_matrix (np.ndarray): A matrix where distance_matrix[i, j] is the distance between city i and city j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, containing heuristic values for each edge.\n                     Higher values indicate more promising edges.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse Distance (Gravitational Analogy): Closer cities are more attractive.\n    inverse_distance = 1 / (distance_matrix + 1e-9)  # Add a small constant to avoid division by zero.\n\n    # 2. Temperature-based Exploration: Encourage exploration initially, focusing as the search progresses.\n    temperature = 1.0  # Initial temperature (can be tuned). It decreases over time implicitly\n    exploration_factor = np.exp(-distance_matrix / temperature)\n\n    # 3. Path Coherence: Encourages edges that connect to nodes that are \"well-connected\" in general,\n    #    considering all edge connections in the graph to create a smooth and promising initial path\n    path_coherence = np.zeros_like(distance_matrix, dtype=float)\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                # Compute the sum of inverse distances from i and j to all other nodes\n                attraction_i = np.sum(inverse_distance[i, :])\n                attraction_j = np.sum(inverse_distance[j, :])\n                path_coherence[i, j] = (attraction_i + attraction_j)\n    \n    # 4. Combine the factors, weighting each appropriately. These weightings can be optimized through trials.\n    alpha = 0.6  # Weight for inverse distance\n    beta = 0.2   # Weight for exploration factor\n    gamma = 0.2   # Weight for path coherence\n\n    heuristics = alpha * inverse_distance + beta * exploration_factor + gamma * path_coherence\n\n    # Set diagonal elements (distance to self) to zero, avoiding self-loops.\n    np.fill_diagonal(heuristics, 0)\n\n    return heuristics\n\n[Heuristics 20th]\nimport numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Heuristics for Traveling Salesman Problem (TSP) based on:\n    1. Inverse distance (shorter distances are preferred).\n    2. Node degree preference:  Nodes connected to more other nodes tend to be connected earlier.\n    3. Avoidance of long edges connected to nodes already having short edges.\n\n    Args:\n        distance_matrix: A numpy ndarray representing the distance matrix.\n\n    Returns:\n        A numpy ndarray of the same shape as distance_matrix,\n        representing the heuristic value for each edge. Higher values\n        indicate more promising edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros_like(distance_matrix, dtype=float)\n\n    # 1. Inverse distance heuristic\n    inverse_distance = 1.0 / (distance_matrix + 1e-9)  # Add a small value to avoid division by zero\n\n    # 2. Node degree preference: encourage exploration of nodes\n    node_degree = np.sum(inverse_distance, axis=0)  # Sum of inverse distances for each node\n    node_degree_matrix = np.outer(node_degree, node_degree)\n\n    # 3. Penalize long edges for nodes that already have short edges\n    min_dist_to_node = np.min(distance_matrix + np.diag([np.inf]*n), axis=0) # smallest distance to all nodes\n\n    node_min_dist_matrix = np.outer(min_dist_to_node,min_dist_to_node)\n    penalization_matrix = distance_matrix * (node_min_dist_matrix )\n\n    heuristics = inverse_distance +  0.1*node_degree_matrix - 0.0001 * penalization_matrix\n\n    return heuristics\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}