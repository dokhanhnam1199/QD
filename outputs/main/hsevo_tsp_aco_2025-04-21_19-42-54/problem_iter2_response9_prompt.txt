{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    A more sophisticated heuristic for the Traveling Salesman Problem.\n    This version combines distance, a \"gravity\" effect, and randomness.\n\n    The heuristic favors shorter distances but also encourages exploration\n    of less-visited edges.  A stochastic element is introduced to avoid\n    getting stuck in local optima.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix where distance_matrix[i][j]\n                                       represents the distance between node i and node j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each element\n                    represents a heuristic value indicating the desirability of\n                    including the corresponding edge in the TSP tour.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse distance component (shorter distances are better)\n    inverse_distance = 1.0 / (distance_matrix + 1e-6)  # Add a small constant to avoid division by zero\n\n    # \"Gravity\" component: Encourage connections to nodes that are far from the \"center of gravity\".\n    # This promotes exploration and avoids clustering in one region.\n    total_distances = np.sum(distance_matrix, axis=0)  # Sum of distances from each node to all other nodes\n    gravity_potential = total_distances / np.mean(total_distances)  # Normalize to a reasonable scale\n\n\n    # Combine the components\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_matrix[i, j] = inverse_distance[i, j] * (gravity_potential[i] + gravity_potential[j]) # Both nodes have gravity effects\n\n            else:\n                heuristic_matrix[i, j] = 0  # No self-loops\n    # Add a stochastic element to encourage exploration\n\n    random_noise = np.random.rand(n, n) * 0.1  # Small random values\n    heuristic_matrix = heuristic_matrix + random_noise\n\n\n    return heuristic_matrix\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristics for Traveling Salesman Problem (TSP) based on distance and node degree.\n\n    This function calculates a heuristic score for each edge in the distance matrix,\n    indicating how promising it is to include that edge in the final TSP solution.\n    The heuristic combines the inverse of distance with a node degree penalty.  Edges\n    connected to nodes with fewer connections are preferred.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix representing the distances\n            between all pairs of nodes.  distance_matrix[i, j] is the distance\n            from node i to node j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each\n            element represents the heuristic score for the corresponding edge.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix)\n\n    # Calculate node degree desirability: nodes with lower degree should be prioritized.\n    # This helps prevent premature closure of sub-tours.\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_matrix[i, j] = 1 / (distance_matrix[i, j] + 1e-9) # avoid division by zero\n            else:\n                heuristic_matrix[i, j] = 0  # No self-loops\n\n    # Normalize to ensure values between 0 and 1, enhancing exploration\n    heuristic_matrix = (heuristic_matrix - np.min(heuristic_matrix)) / (np.max(heuristic_matrix) - np.min(heuristic_matrix) + 1e-9)\n\n\n    #Calculate node degree \"attractiveness\".\n    node_degree = np.sum(heuristic_matrix > 0, axis=0)  # Approximate current node degrees.\n\n    # Modify the heuristic by penalizing higher degree nodes. Favor connecting to low degree nodes.\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n\n                degree_penalty = 1 / (node_degree[i] + node_degree[j] + 1e-9) # Favor low degree connections.\n\n                heuristic_matrix[i,j] = heuristic_matrix[i, j] * degree_penalty #Combines distance and node desirability\n\n\n    #Re-normalize\n    heuristic_matrix = (heuristic_matrix - np.min(heuristic_matrix)) / (np.max(heuristic_matrix) - np.min(heuristic_matrix) + 1e-9)\n\n    return heuristic_matrix\n\n### Analyze & experience\n- *   Comparing (1st) vs (20th), we see that the best heuristic incorporates inverse distance, node degree preference, and global distance context, penalizing long edges connected to nodes already having short edges, while the worst focuses on inverse distance, node degree, and penalizing long edges connected to nodes already having short edges. The key difference lies in the inclusion of the global context component in the best heuristic, along with degree component implemented by average distance, making it superior.\n*   Comparing (2nd) vs (19th), we observe that the second-best heuristic combines inverse distance with a \"gravity\" effect encouraging exploration of less-visited edges and randomness to escape local optima. The 19th heuristic uses inverse distance, a temperature-based exploration factor, and path coherence. The added randomness and gravity component makes the 2nd better than 19th.\n*   Comparing (1st) vs (2nd), the first prioritizes a more balanced tour with global distance awareness using average distances, while the second opts for exploration through a gravity effect and stochastic noise. The focus on a balanced tour appears to be more effective.\n*   Comparing (3rd) vs (4th), the 3rd heuristic prioritizes shorter distances and edges connecting to nodes with longer average distances, while the 4th incorporates inverse distance, a greedy start bias based on summed distances, and a global connection boost. The node importance heuristic seems better than greedy start bias.\n*   Comparing (2nd worst) vs (worst), the 19th relies on temperature-controlled exploration and path coherence, while the 20th uses node degree preference and avoidance of long edges connected to nodes with short edges. The path coherence mechanism appears less robust than degree-based exploration.\n*   Overall: Effective heuristics incorporate a balance between exploitation (favoring shorter distances) and exploration (avoiding local optima). They often factor in node connectivity, either through degree penalties/preferences or gravity-like effects. The weighting of different components and the specific implementation of exploration mechanisms (randomness, temperature, savings heuristic) plays a significant role in performance. Global context awareness is also crucial for achieving superior results.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, here's a redefinition of \"Current self-reflection\" focused on designing better heuristics, avoiding common pitfalls, and a roadmap for improvement:\n\n*   **Keywords:** Heuristic design, exploitation-exploration balance, global context, premature convergence, adaptive strategies, performance metrics.\n\n*   **Advice:** Design heuristics that dynamically adapt their exploration/exploitation ratio based on search progress and problem characteristics. Incorporate global information strategically, using it to guide, not dictate, the search. Rigorously test and benchmark heuristics against diverse problem instances.\n\n*   **Avoid:** Over-reliance on any single strategy (e.g., pure exploitation), neglecting global problem context, ignoring performance metrics and feedback loops.\n\n*   **Explanation:** Effective heuristic design requires a nuanced understanding of the problem landscape. Balance short-term gains with broader exploration guided by global awareness and adapt your strategy based on real-world performance data.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}