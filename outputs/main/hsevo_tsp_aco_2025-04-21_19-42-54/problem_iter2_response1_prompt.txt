{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Traveling Salesman Problem (TSP) via stochastic solution sampling following \"heuristics\". TSP requires finding the shortest path that visits all given nodes and returns to the starting node.\nThe `heuristics` function takes as input a distance matrix, and returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the input.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Improved heuristics for the Traveling Salesman Problem based on distance and node connectivity.\n\n    This heuristic considers both the distance between nodes and an estimate of the connectivity\n    of each node within the graph represented by the distance matrix.  Shorter distances are\n    generally favored, and nodes that appear to be more centrally located or highly connected\n    are given a boost in their edge desirability.  This helps guide the search towards solutions\n    that balance short hops with good overall tour structure.\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix where distance_matrix[i, j] represents the distance\n                                     between node i and node j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, containing heuristic values\n                     indicating the desirability of including each edge in the TSP solution.\n    \"\"\"\n\n    n = distance_matrix.shape[0]\n\n    # 1. Inverse Distance (Basic desirability)\n    heuristic_matrix = 1 / (distance_matrix + 1e-9)  # Add a small constant to avoid division by zero\n\n    # 2. Node Connectivity Estimate (Sum of inverse distances to other nodes)\n    node_connectivity = np.sum(heuristic_matrix, axis=1)\n\n    # 3. Combine Distance and Connectivity\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_matrix[i, j] *= (node_connectivity[i] + node_connectivity[j]) / 2.0 # Averaging connectivity of both nodes\n            else:\n                heuristic_matrix[i, j] = 0  # No self-loops allowed\n\n    # 4. Normalize heuristics (optional, but can improve stability)\n    heuristic_matrix = heuristic_matrix / np.max(heuristic_matrix)\n\n    return heuristic_matrix\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Heuristics for the Traveling Salesman Problem (TSP) using concepts inspired by\n    black holes and gravitational lensing. The core idea is to bias the search towards\n    edges that are shorter (stronger gravitational pull) and connect to nodes with fewer\n    nearby nodes (less obscured).\n\n    This heuristic attempts to mimic the way light bends around a black hole, where shorter paths\n    are preferred, and areas of lower node density are more \"visible\" (less obscured).\n\n    Args:\n        distance_matrix (np.ndarray): A square matrix representing the distances between nodes.\n                                         distance_matrix[i, j] is the distance between node i and node j.\n\n    Returns:\n        np.ndarray: A matrix of the same shape as distance_matrix, where each element\n                      indicates the desirability of including the corresponding edge in the solution.\n                      Higher values represent more desirable edges.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    # Inverse of distance, analogous to gravitational pull (shorter distances are preferred)\n    inverse_distance = 1.0 / (distance_matrix + 1e-9)  # Add small constant to avoid division by zero\n\n    # Node degree heuristic: Favors nodes with fewer nearby neighbors\n    # Mimics the idea that nodes in less dense regions are more accessible.\n\n    for i in range(n):\n        # Calculate a \"node visibility\" score for each node i.\n        # Lower degree (fewer neighbors within a certain radius) implies higher visibility.\n\n        # Option 1: Simple inverse degree\n        node_degree = np.sum(distance_matrix[i, :] < np.mean(distance_matrix[i,:])) # count how many nodes nearby\n\n        node_visibility = 1.0 / (node_degree + 1)  # Avoid division by zero\n\n        # Option 2: More complex \"gravitational potential\" based on inverse distance.\n        # potential = np.sum(inverse_distance[i, :])\n        # node_visibility = 1.0 / (potential + 1e-9)\n\n        for j in range(n):\n            # Combine inverse distance (attraction) and node visibility.\n            heuristics_matrix[i, j] = inverse_distance[i, j] * (node_visibility+ 1e-9)  #Adjust to encourage visibility\n\n\n\n    # Additional edge weighting - prioritize shorter edges, but also consider\n    # how well they connect to the overall graph structure. A small adjustment\n    # ensures symmetry and avoids zero division\n    for i in range(n):\n        for j in range(n):\n                heuristics_matrix[i, j] +=  np.mean([heuristics_matrix[i, k] + heuristics_matrix[k,j] for k in range(n)])/(n+1e-9) # give higher score if intermediate hop would also be useful\n\n\n    # Normalize to avoid extreme values (improve numerical stability).\n    max_val = np.max(heuristics_matrix)\n    if max_val > 0:\n      heuristics_matrix /= max_val\n\n    return heuristics_matrix\n\n### Analyze & experience\n- *   Comparing (1st) vs (20th), we see that the best heuristic incorporates inverse distance, node degree preference, and global distance context, penalizing long edges connected to nodes already having short edges, while the worst focuses on inverse distance, node degree, and penalizing long edges connected to nodes already having short edges. The key difference lies in the inclusion of the global context component in the best heuristic, along with degree component implemented by average distance, making it superior.\n*   Comparing (2nd) vs (19th), we observe that the second-best heuristic combines inverse distance with a \"gravity\" effect encouraging exploration of less-visited edges and randomness to escape local optima. The 19th heuristic uses inverse distance, a temperature-based exploration factor, and path coherence. The added randomness and gravity component makes the 2nd better than 19th.\n*   Comparing (1st) vs (2nd), the first prioritizes a more balanced tour with global distance awareness using average distances, while the second opts for exploration through a gravity effect and stochastic noise. The focus on a balanced tour appears to be more effective.\n*   Comparing (3rd) vs (4th), the 3rd heuristic prioritizes shorter distances and edges connecting to nodes with longer average distances, while the 4th incorporates inverse distance, a greedy start bias based on summed distances, and a global connection boost. The node importance heuristic seems better than greedy start bias.\n*   Comparing (2nd worst) vs (worst), the 19th relies on temperature-controlled exploration and path coherence, while the 20th uses node degree preference and avoidance of long edges connected to nodes with short edges. The path coherence mechanism appears less robust than degree-based exploration.\n*   Overall: Effective heuristics incorporate a balance between exploitation (favoring shorter distances) and exploration (avoiding local optima). They often factor in node connectivity, either through degree penalties/preferences or gravity-like effects. The weighting of different components and the specific implementation of exploration mechanisms (randomness, temperature, savings heuristic) plays a significant role in performance. Global context awareness is also crucial for achieving superior results.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, here's a redefinition of \"Current self-reflection\" focused on designing better heuristics, avoiding common pitfalls, and a roadmap for improvement:\n\n*   **Keywords:** Heuristic design, exploitation-exploration balance, global context, premature convergence, adaptive strategies, performance metrics.\n\n*   **Advice:** Design heuristics that dynamically adapt their exploration/exploitation ratio based on search progress and problem characteristics. Incorporate global information strategically, using it to guide, not dictate, the search. Rigorously test and benchmark heuristics against diverse problem instances.\n\n*   **Avoid:** Over-reliance on any single strategy (e.g., pure exploitation), neglecting global problem context, ignoring performance metrics and feedback loops.\n\n*   **Explanation:** Effective heuristic design requires a nuanced understanding of the problem landscape. Balance short-term gains with broader exploration guided by global awareness and adapt your strategy based on real-world performance data.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}