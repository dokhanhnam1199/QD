{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Almost Full Fit priority function.\n\n    This strategy prioritizes bins that will be \"almost full\" after placing the item.\n    A bin is considered \"almost full\" if its remaining capacity after placing the item\n    is small. We want to select the bin that leaves the minimum remaining capacity,\n    provided it can accommodate the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        remaining_capacities_if_fit = bins_remain_cap[can_fit_mask] - item\n        \n        # We want to prioritize bins where the remaining capacity is *minimal* after fitting.\n        # So, a smaller remaining capacity should yield a higher priority.\n        # We can invert the remaining capacity values and then scale them or just use\n        # a value inversely proportional to the remaining capacity.\n        # Here, we'll use 1 / (remaining_capacity + epsilon) to avoid division by zero\n        # and to ensure smaller remaining capacities get higher scores.\n        # A simple approach is to subtract from a large number or use a negative linear function.\n        # Let's use a value that is inversely proportional to remaining capacity.\n        # However, to keep it simpler and still capture the \"almost full\" idea,\n        # we can assign a higher priority to bins that leave a smaller remainder.\n        # A very direct interpretation of \"almost full\" is to prioritize the bin\n        # that, after placing the item, has the smallest *positive* remaining capacity.\n        # This can be achieved by minimizing `bins_remain_cap - item`.\n        # So, we want to *maximize* the negative of `bins_remain_cap - item`.\n        \n        priorities[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item)\n        \n        # Alternative: Use a small epsilon to make it robust\n        # epsilon = 1e-9\n        # priorities[can_fit_mask] = 1.0 / (remaining_capacities_if_fit + epsilon)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Differentiated and Scaled Fit priority function.\n\n    This strategy aims to provide more differentiated priority scores by considering\n    both how \"full\" a bin becomes and how well the item \"fits\" relative to the bin's\n    current remaining capacity. It also scales the contribution of these factors.\n\n    The priority is calculated based on two components:\n    1.  **Slack Minimization:** Similar to \"Almost Full Fit\", we want to minimize\n        the remaining capacity after placing the item. This is captured by\n        `bins_remain_cap - item`. A smaller value here is better.\n    2.  **Fit Ratio:** We also consider how \"tight\" the fit is relative to the\n        bin's current remaining capacity. A bin with much more capacity might\n        be less preferable even if it leaves a small absolute remainder,\n        if another bin with less capacity can also accommodate the item snugly.\n        This is captured by `item / bins_remain_cap`. A smaller value here is better.\n\n    These two components are combined with scaling factors to create a single priority score.\n    The function prioritizes bins that can fit the item (remaining capacity >= item).\n    Bins that cannot fit receive a priority of -1.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        available_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # Component 1: Minimize remaining capacity after placing the item (Slack)\n        # We want to maximize the negative of slack, so smaller slack -> higher priority.\n        slack = available_bins_remain_cap - item\n        slack_priority = -slack\n        \n        # Component 2: Minimize the ratio of item size to bin remaining capacity (Fit Ratio)\n        # This penalizes using a large bin for a small item if a tighter fit is available.\n        # We want to maximize the negative of the ratio.\n        # Add a small epsilon to avoid division by zero if an item perfectly fills a bin\n        # that had 0 remaining capacity (though this case is handled by can_fit_mask,\n        # it's good practice for robustness if logic were to change).\n        epsilon = 1e-9\n        fit_ratio = item / (available_bins_remain_cap + epsilon)\n        fit_ratio_priority = -fit_ratio\n        \n        # Combine components with scaling.\n        # We can assign weights based on desired behavior.\n        # For example, give more weight to minimizing slack (e.g., 0.7) and less to fit ratio (e.g., 0.3).\n        # The specific weights can be tuned based on empirical performance.\n        weight_slack = 0.7\n        weight_fit_ratio = 0.3\n        \n        # A simple linear combination. Normalize the priorities if their scales differ significantly\n        # or if we want to ensure they contribute to a bounded range.\n        # For now, we combine them directly.\n        combined_priority = (weight_slack * slack_priority) + (weight_fit_ratio * fit_ratio_priority)\n        \n        # Assign the calculated priorities to the bins that can fit the item.\n        priorities[can_fit_mask] = combined_priority\n        \n    return priorities\n\n### Analyze & experience\n- Comparing Heuristics 1, 5, 6, 12, 15 (Exact Fit + Normalized Slack variants) with Heuristics 2, 4, 7 (Almost Full Fit variants) and Heuristic 3 (Hybrid V1), we see that prioritizing exact fits offers a clear, high-priority strategy. Normalized slack provides a good way to differentiate non-exact fits based on relative space utilization. The \"Almost Full Fit\" heuristics (like V1, which is essentially maximizing -slack) are simpler but lack the explicit handling of exact fits or the nuanced scaling of normalized slack. Heuristic 3 attempts a hybrid but its implementation is less clear than the dedicated strategies.\n\nComparing Heuristics 1, 5, 6, 12, 15:\n- Heuristics 1, 5, 15 are very similar, prioritizing exact fits (score 1.0) and then using a scaled version of `1.0 - normalized_slack` for non-exact fits, mapping them to a range like [0.5, 0.99]. This provides a clear hierarchy and differentiated scores.\n- Heuristic 6 is very similar to 1, 5, 15 but uses slightly different scaling (0.5 to 0.99).\n- Heuristic 12 uses `1.0` for exact fits and `0.5 + 0.49 * (1.0 - normalized_slack)` for non-exact fits, which is functionally identical to 1, 5, 15.\n- Heuristic 13 attempts to combine exact fit priority with a Best Fit strategy (minimizing normalized residual) and a tie-breaker based on initial slack. The scoring mechanism (lexicographical preference via scaling) is more complex but aims for a multi-objective optimization.\n- Heuristic 14 also prioritizes exact fits and then uses a normalized remaining capacity (mapped to [0.5, 0.95]) for non-exact fits, similar to 1, 5, 6, 12, 15.\n\nComparing \"Almost Full Fit\" variants (2, 4, 7) with others:\n- Heuristics 2, 4, 7 are consistent in using `-slack` (maximizing negative slack) as the primary scoring mechanism. This prioritizes bins that become most full. They assign -1 to bins that cannot fit. This is a simple and effective \"Best Fit\" approach but doesn't explicitly handle exact fits as a special case.\n\nComparing Heuristics 8, 9, 10, 11, 16, 17, 20:\n- Heuristic 8 attempts to use `-log(slack + epsilon)` for differentiation, which is a novel approach for small slack values.\n- Heuristics 9, 10, 11 combine slack minimization with fit ratio `item / bins_remain_cap`, weighted. This adds a second dimension to the scoring.\n- Heuristic 16 tries to balance tightness with avoiding extreme fills, using `-slack` as a base and adding a penalty for very tight fits (when `slack` is below a threshold relative to `item`). This is a more sophisticated attempt to balance competing goals.\n- Heuristic 17 is identical to 16.\n- Heuristic 20 prioritizes exact fits with a very high score (1e6), then uses a scaled `-remaining_after_fit` (Best Fit) and a penalty based on negative initial remaining capacity as a tie-breaker. This is a strong multi-objective approach.\n\nHeuristics 18 and 19 are incomplete code snippets.\n\nOverall, heuristics that combine a clear, high priority for exact fits with a well-defined scoring for non-exact fits (like normalized slack or scaled best-fit) tend to perform better. Heuristics that attempt multi-objective optimization (e.g., balancing tightness with avoiding fragmentation or using tie-breakers) show promise but can become complex. The \"Almost Full Fit\" (-slack) is a solid baseline but can be improved by explicit exact-fit handling or more nuanced differentiation.\n- \nHere's a redefined self-reflection for designing better heuristics, focusing on robust differentiation and avoiding pitfalls:\n\n*   **Keywords:** Objective clarity, Score differentiation, Robustness, Scalability.\n*   **Advice:** Design scores that clearly distinguish between excellent fits and good-enough options. Use a hierarchical approach, prioritizing exact matches, then finely tuned slack minimization (normalized or scaled), and finally, stable secondary metrics.\n*   **Avoid:** Over-reliance on absolute slack, direct division by capacities prone to instability, and complex, unexplainable scoring interactions.\n*   **Explanation:** The goal is to create heuristics that make decisive, understandable choices. Clear scoring ensures that the algorithm consistently favors better solutions without getting lost in minor, unstable numerical variations, promoting robustness across different problem scales.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}