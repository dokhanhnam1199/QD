[
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Best Fit and a scaled inverse for robust prioritization.\n\n    Prioritizes bins that result in the smallest remaining capacity after packing (Best Fit),\n    and for other bins, uses an inverse of the remaining capacity scaled by a small constant\n    to avoid extreme values and provide smoother ranking.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    available_bins_mask = bins_remain_cap >= item\n    available_bins_caps = bins_remain_cap[available_bins_mask]\n\n    if available_bins_caps.size > 0:\n        remaining_after_fit = available_bins_caps - item\n        \n        # Prioritize exact fits (remaining capacity is 0) with a high score\n        exact_fit_mask = remaining_after_fit == 0\n        priorities[available_bins_mask][exact_fit_mask] = 1.0\n\n        # For non-exact fits, use a scaled inverse to prioritize bins with less remaining space\n        non_exact_fit_mask = ~exact_fit_mask\n        non_exact_bins_remaining = remaining_after_fit[non_exact_fit_mask]\n        \n        if non_exact_bins_remaining.size > 0:\n            # Add a small constant to avoid division by zero and to smooth priorities\n            # Scale by a factor to differentiate non-exact fits without overpowering exact fits\n            scaled_inverse = 0.1 / (non_exact_bins_remaining + 1.0) \n            priorities[available_bins_mask][non_exact_fit_mask] = scaled_inverse\n            \n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 3.0,
    "halstead": 95.90827503317318,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response1.txt_stdout.txt",
    "code_path": "problem_iter2_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Best Fit and a scaled inverse for robust prioritization.\n\n    Prioritizes bins with minimal remaining capacity after packing (Best Fit)\n    and uses a scaled inverse for other eligible bins to differentiate.\n    \"\"\"\n    eligible_bins_mask = bins_remain_cap >= item\n\n    if not np.any(eligible_bins_mask):\n        return np.zeros_like(bins_remain_cap)\n\n    eligible_bins_remain_cap = bins_remain_cap[eligible_bins_mask]\n\n    differences = eligible_bins_remain_cap - item\n\n    # Best Fit component: Prioritize bins with smallest remaining capacity\n    min_diff = np.min(differences)\n    best_fit_scores = -differences \n\n    # Scaled inverse component: For other bins, use scaled inverse to differentiate\n    # Avoid division by zero or very small numbers by adding a small constant\n    # Normalize by a factor related to the maximum difference to keep scores in a reasonable range.\n    # Adding 1.0 to the denominator makes it less sensitive to small differences.\n    if np.max(differences) > 1e-9:\n        scaled_inverse_scores = 1.0 / (differences + 1.0 + 1e-9)\n    else:\n        scaled_inverse_scores = np.ones_like(differences)\n\n\n    # Combine scores: Give higher priority to best-fit bins, then use scaled inverse.\n    # A simple way to combine is to prioritize exact fits with a bonus,\n    # or use a weighted sum. Here we'll slightly favor best-fit bins.\n    # A simple approach: add a bonus to best-fit candidates.\n    # We can also use a threshold: if it's a \"very good\" fit, give it a high score.\n    \n    # Let's try to boost the best-fit bins slightly more.\n    # We can achieve this by using the best_fit_scores for the minimum difference bins,\n    # and scaled_inverse_scores for others.\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Assign best_fit_scores to all eligible bins initially\n    priorities[eligible_bins_mask] = best_fit_scores\n    \n    # For bins that are not the absolute best fit, use scaled_inverse_scores\n    # This requires identifying bins that are NOT the best fit.\n    non_best_fit_mask = eligible_bins_mask.copy()\n    if len(differences) > 0:\n        min_diff_indices_in_eligible = np.where(differences == min_diff)[0]\n        # Convert indices back to original array indices\n        indices_to_exclude = np.where(eligible_bins_mask)[0][min_diff_indices_in_eligible]\n        non_best_fit_mask[indices_to_exclude] = False\n        \n        # Apply scaled inverse to non-best-fit eligible bins\n        priorities[non_best_fit_mask] = scaled_inverse_scores[np.where(non_best_fit_mask[eligible_bins_mask])[0]]\n\n    # Ensure that the bins that were originally the best fit still have their higher scores.\n    # If scaled_inverse_scores is higher than best_fit_scores for the best-fit bins,\n    # we might want to reconsider the combination strategy.\n    # A simpler combination: use the scaled_inverse_scores for all, but boost best-fit.\n    \n    # Let's simplify the combination logic:\n    # Use scaled inverse for all eligible bins, and add a bonus to the best fit bins.\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    \n    if np.max(differences) > 1e-9:\n        scaled_inverse_scores = 1.0 / (differences + 1.0 + 1e-9)\n    else:\n        scaled_inverse_scores = np.ones_like(differences)\n\n    priorities[eligible_bins_mask] = scaled_inverse_scores\n    \n    # Add a bonus to the best-fit bins to ensure they are strongly preferred.\n    # The bonus should be large enough to dominate the scaled inverse score.\n    bonus = 10.0 # Arbitrary bonus value\n    if len(differences) > 0:\n        min_diff_indices_in_eligible = np.where(differences == min_diff)[0]\n        indices_to_boost = np.where(eligible_bins_mask)[0][min_diff_indices_in_eligible]\n        priorities[indices_to_boost] += bonus\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 82, in priority_v2\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n6\n232.98948760601\n"
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins using a hybrid approach: favoring exact fits and then\n    best fits by inverting the remaining capacity, while ensuring stability.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate remaining capacity after placing the item for fitting bins\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n    \n    # Calculate priority: higher for bins that will be more full (less remaining capacity)\n    # Adding 1.0 to the denominator to avoid division by zero and to ensure\n    # that bins with zero remaining capacity get a high but finite priority.\n    # This is a stable inversion that prioritizes bins that result in less slack.\n    priorities[can_fit_mask] = 1.0 / (remaining_after_fit + 1.0)\n    \n    # Bins that cannot fit the item receive zero priority, meaning they are not considered.\n    \n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 39.863137138648355,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response3.txt_stdout.txt",
    "code_path": "problem_iter2_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Exact Fit First with a normalized Best Fit strategy.\n    Prioritizes exact fits, then best fits using a scaled inverse of residual capacity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # 1. Exact Fit: Highest priority (1.0)\n    exact_fit_indices = np.where(bins_remain_cap == item)[0]\n    priorities[exact_fit_indices] = 1.0\n\n    # 2. Best Fit: Prioritize bins with minimal positive remaining capacity\n    # Only consider bins that can fit the item and are not exact fits\n    can_fit_mask = (bins_remain_cap >= item) & (bins_remain_cap != item)\n    fit_indices = np.where(can_fit_mask)[0]\n\n    if len(fit_indices) > 0:\n        residual_capacities = bins_remain_cap[fit_indices] - item\n        \n        # Normalize residuals to be between 0 and 1, where smaller residual is better.\n        # A common way is 1 - (residual / max_residual).\n        # To avoid division by zero if all residuals are the same and positive, add a small epsilon.\n        max_residual = np.max(residual_capacities)\n        normalized_residuals = residual_capacities / (max_residual + 1e-9)\n        \n        # Assign priorities that are higher for smaller residuals.\n        # Scale between 0.5 (for worst fit among feasible) and 1.0 (for exact fit).\n        # We use 1 - normalized_residuals so that smaller residuals get higher values.\n        # The base priority for exact fit is 1.0. Best fit will be less than 1.0.\n        # Let's map best fit to a range like [0.5, 0.99] to clearly distinguish from exact fit.\n        # So, a smaller residual should yield a higher score in this range.\n        # The term (1 - normalized_residuals) gives values from ~0 (max residual) to ~1 (min residual).\n        # We can scale this to [0.5, 0.99].\n        # desired_range = 0.99 - 0.5\n        # scaled_best_fit_priorities = 0.5 + (1 - normalized_residuals) * desired_range\n        \n        # A simpler approach that still prioritizes better fits:\n        # Assign a priority that decreases as residual increases.\n        # A score like 0.5 + (0.5 * (1 - normalized_residuals)) maps to [0.5, 1.0]\n        # Let's try to map it such that the best fit gets a high score, but less than 1.0.\n        # We can use a fraction of the maximum possible priority (1.0)\n        # For example, priority = 0.8 * (1 - normalized_residuals) + 0.1\n        # This maps best fit (min residual) to ~0.9 and worst fit (max residual) to ~0.1\n        # Let's use a slightly simpler scheme: give higher priority to smaller residuals.\n        # Use a value that decreases with residual capacity.\n        # Example: 0.75 * (1 - normalized_residuals) + 0.25\n        # This maps best fit to 1.0 and worst fit to 0.25.\n        # To ensure it's less than 1.0, we can use a scaling factor.\n        # Let's use a direct inverse scaling but ensure it's lower than exact fit.\n        \n        # Use a value inversely proportional to the residual, scaled down.\n        # Ensure it's less than 1.0.\n        # Use a score like `1.0 - (residual / (max_residual + item + 1e-9))`\n        # This makes smaller residuals higher priority.\n        best_fit_scores = 1.0 - (residual_capacities / (max_residual + item + 1e-9))\n        \n        # Scale these scores to a range below 1.0, e.g., [0.5, 0.9].\n        # The range of best_fit_scores is approximately [0, 1].\n        # Map [0, 1] to [0.5, 0.9]: scale = 0.4, offset = 0.5\n        final_best_fit_priorities = 0.5 + best_fit_scores * 0.4\n        \n        priorities[fit_indices] = final_best_fit_priorities\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 2.0,
    "halstead": 201.90890672641936,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response4.txt_stdout.txt",
    "code_path": "problem_iter2_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins that are closest to fitting the item (best fit),\n    while also giving a strong preference to exact fits.\n    It uses inverse of slack for non-exact fits, with a bonus for exact matches.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Mask for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate slack for bins that can fit\n    slack = bins_remain_cap[can_fit_mask] - item\n    \n    # Exact fit bonus: prioritize bins with zero slack\n    exact_fit_mask_local = slack == 0\n    if np.any(exact_fit_mask_local):\n        # Assign a high priority to exact fits\n        priorities[can_fit_mask][exact_fit_mask_local] = 1.0\n    \n    # Non-exact fits: prioritize those with smaller slack (closer to fitting)\n    non_exact_fit_mask_local = slack > 0\n    if np.any(non_exact_fit_mask_local):\n        # Use inverse of slack + 1 to avoid division by zero and give higher priority to smaller slack\n        # Add a small epsilon for numerical stability, though slack > 0 should handle it.\n        priorities[can_fit_mask][non_exact_fit_mask_local] = 1.0 / (slack[non_exact_fit_mask_local] + 1e-9)\n        \n    # Normalize priorities to ensure a consistent scale, giving a slight boost to exact fits\n    # This is inspired by prioritizing exact fits with a score of 1.0 and scaled inverse for others\n    # We can scale non-exact fits relative to the best non-exact fit to make them more distinguishable\n    if np.any(priorities[can_fit_mask][non_exact_fit_mask_local]):\n        max_non_exact_priority = np.max(priorities[can_fit_mask][non_exact_fit_mask_local])\n        if max_non_exact_priority > 0: # Avoid division by zero if only exact fits exist\n            priorities[can_fit_mask][non_exact_fit_mask_local] /= max_non_exact_priority\n            priorities[can_fit_mask][non_exact_fit_mask_local] *= 0.9 # Scale down non-exact fits\n            \n    # Ensure exact fits (priority 1.0) still stand out\n    if np.any(priorities[can_fit_mask][exact_fit_mask_local]):\n         priorities[can_fit_mask][exact_fit_mask_local] = 1.0\n            \n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 6.0,
    "halstead": 116.69205856195879,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit and Sigmoid Fit Score.\n    Prioritizes bins that are closest to fitting the item (Best Fit)\n    and uses a sigmoid to smooth prioritization among them.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n        \n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    # Best Fit component: Calculate difference for bins that can fit\n    differences = fitting_bins_remain_cap - item\n    \n    # Sigmoid scaling for smoother prioritization among fitting bins\n    # Normalize differences to a [0, 1] range for sigmoid input\n    # Avoid division by zero if all fitting bins have the same remaining capacity\n    max_diff = np.max(differences)\n    min_diff = np.min(differences)\n    \n    if max_diff == min_diff:\n        scaled_diffs = np.zeros_like(differences) # All fitting bins are equally \"best\"\n    else:\n        scaled_diffs = (differences - min_diff) / (max_diff - min_diff)\n        \n    # Sigmoid function to transform scaled differences into priorities\n    # Steepness parameter (e.g., 5) can be tuned\n    sigmoid_scores = 1 / (1 + np.exp(-5 * (1 - scaled_diffs))) # Invert so smaller diffs get higher scores\n    \n    priorities[can_fit_mask] = sigmoid_scores\n    \n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 3.0,
    "halstead": 155.88872502451935,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response6.txt_stdout.txt",
    "code_path": "problem_iter2_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins by favoring exact fits and then best fits using a scaled inverse.\n    Combines the exact fit preference of Best Fit with the scaled inverse approach of Softmax-Based Fit.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    eligible_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(eligible_bins_mask):\n        return priorities\n\n    eligible_bins_remain_cap = bins_remain_cap[eligible_bins_mask]\n    \n    # Prioritize exact fits with a high score\n    exact_fit_mask = np.isclose(eligible_bins_remain_cap, item)\n    priorities[eligible_bins_mask][exact_fit_mask] = 1.0\n    \n    # For non-exact fits, use a scaled inverse of the remaining capacity\n    non_exact_fit_mask = ~exact_fit_mask\n    if np.any(non_exact_fit_mask):\n        non_exact_eligible_bins_remain_cap = eligible_bins_remain_cap[non_exact_fit_mask]\n        \n        # Scale differences to be between 0 and 1 for the inverse calculation\n        # Add 1 to the difference to avoid division by zero and to penalize\n        # bins that are slightly larger than needed.\n        differences = non_exact_eligible_bins_remain_cap - item\n        \n        # Use a robust scaling similar to the softmax approach, but without exponentiation\n        # to avoid potential overflow and maintain a more linear preference for smaller remaining capacities.\n        # Adding 1e-9 for numerical stability.\n        scaled_inverse = 1.0 / (differences + 1.0 + 1e-9)\n        \n        # Normalize these scaled inverse priorities so the highest is 1,\n        # making them comparable to the exact fit score of 1.0.\n        if np.max(scaled_inverse) > 1e-9: # Avoid division by zero if all scaled_inverse are near zero\n            normalized_scaled_inverse = scaled_inverse / np.max(scaled_inverse)\n        else:\n            normalized_scaled_inverse = scaled_inverse # Or handle as a special case if needed\n            \n        priorities[eligible_bins_mask][non_exact_fit_mask] = normalized_scaled_inverse\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 4.0,
    "halstead": 108.04820237218406,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response7.txt_stdout.txt",
    "code_path": "problem_iter2_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins that offer the tightest fit using a combination of inverse scaling and offset for numerical stability.\n\n    This heuristic aims to give higher priority to bins where the remaining capacity is just enough to fit the item,\n    using an inverse relationship with the difference between bin capacity and item size. A small offset is added\n    to the denominator to prevent division by zero and to ensure bins that exactly fit receive a very high priority.\n    \"\"\"\n    suitable_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n\n    if suitable_bins_remain_cap.size > 0:\n        # Calculate the difference between remaining capacity and item size for suitable bins.\n        differences = suitable_bins_remain_cap - item\n        # Assign priorities: inverse of (difference + 1.0 + epsilon).\n        # Adding 1.0 to the difference ensures that bins with zero difference (exact fits)\n        # get a high priority (1/1). Adding a small epsilon (1e-9) handles potential\n        # floating-point issues and ensures non-zero denominators.\n        priorities[suitable_bins_mask] = 1.0 / (differences + 1.0 + 1e-9)\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 70.32403072095333,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response8.txt_stdout.txt",
    "code_path": "problem_iter2_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit and a scaled inverse for prioritized bin selection.\n\n    Prioritizes bins that perfectly fit the item (exact fit). For bins\n    that can fit but not perfectly, it assigns a priority inversely\n    proportional to the remaining capacity after packing, scaled by a\n    small constant to avoid extreme values and ensure numerical stability.\n    Bins that cannot fit receive a priority of -1.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        suitable_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        exact_fit_mask = suitable_bins_remain_cap == item\n        \n        # Prioritize exact fits with a high score (e.g., 1.0)\n        priorities[can_fit_mask][exact_fit_mask] = 1.0\n        \n        # For bins that can fit but not exactly, use an inverse of remaining capacity\n        # scaled to avoid numerical issues and give a smooth priority ranking.\n        # Adding 1 to the remaining capacity before inversion helps to avoid division by zero\n        # and slightly de-emphasizes very small remainders compared to a direct 1/x.\n        # A small epsilon is also added for robustness.\n        non_exact_fit_mask = ~exact_fit_mask\n        \n        if np.any(non_exact_fit_mask):\n            remaining_after_fit = suitable_bins_remain_cap[non_exact_fit_mask] - item\n            # Using 1.0 / (remaining_capacity + constant) to prioritize smaller remainders\n            # The constant (e.g., 1.0) makes the priority less extreme for small remainders.\n            # Adding a small epsilon for numerical stability.\n            priorities[can_fit_mask][non_exact_fit_mask] = 1.0 / (remaining_after_fit + 1.0 + 1e-9)\n            \n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 3.0,
    "halstead": 89.92418250750748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response9.txt_stdout.txt",
    "code_path": "problem_iter2_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Best Fit (exact fit prioritization) with a scaled Worst Fit approach for remaining bins.\"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    fitting_bins_caps = bins_remain_cap[can_fit_mask]\n    \n    if fitting_bins_caps.size > 0:\n        exact_fit_diff = fitting_bins_caps - item\n        \n        # Prioritize exact fits first by assigning a high positive score\n        exact_fit_mask = (exact_fit_diff == 0)\n        priorities[can_fit_mask][exact_fit_mask] = 1.0 \n        \n        # For bins that don't offer an exact fit, use the inverse of the remaining capacity \n        # (closer to exact fit is better) to prioritize them.\n        # This is similar to Best Fit, but we are not strictly enforcing exact fit as the *only* option.\n        non_exact_fit_mask = ~exact_fit_mask\n        non_exact_fit_caps = fitting_bins_caps[non_exact_fit_mask]\n        \n        # If there are non-exact fits, assign priorities based on how much space is left.\n        # A smaller remaining capacity after fitting (i.e., closer to exact fit) gets a higher priority.\n        # We use a scaled inverse to avoid extreme values and ensure a good distribution.\n        if non_exact_fit_caps.size > 0:\n            # We want to prioritize bins with less remaining capacity after fitting\n            # Using 1 / (remaining_capacity_after_fit + 1e-9) means smaller remaining capacity is better\n            priorities[can_fit_mask][non_exact_fit_mask] = 1.0 / (non_exact_fit_caps - item + 1e-9)\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 3.0,
    "halstead": 122.9848878378053,
    "exec_success": true
  }
]