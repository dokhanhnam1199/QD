```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines Exact Fit First with a normalized Best Fit strategy.
    Prioritizes exact fits, then best fits using a scaled inverse of residual capacity.
    """
    priorities = np.zeros_like(bins_remain_cap)

    # 1. Exact Fit: Highest priority (1.0)
    exact_fit_indices = np.where(bins_remain_cap == item)[0]
    priorities[exact_fit_indices] = 1.0

    # 2. Best Fit: Prioritize bins with minimal positive remaining capacity
    # Only consider bins that can fit the item and are not exact fits
    can_fit_mask = (bins_remain_cap >= item) & (bins_remain_cap != item)
    fit_indices = np.where(can_fit_mask)[0]

    if len(fit_indices) > 0:
        residual_capacities = bins_remain_cap[fit_indices] - item
        
        # Normalize residuals to be between 0 and 1, where smaller residual is better.
        # A common way is 1 - (residual / max_residual).
        # To avoid division by zero if all residuals are the same and positive, add a small epsilon.
        max_residual = np.max(residual_capacities)
        normalized_residuals = residual_capacities / (max_residual + 1e-9)
        
        # Assign priorities that are higher for smaller residuals.
        # Scale between 0.5 (for worst fit among feasible) and 1.0 (for exact fit).
        # We use 1 - normalized_residuals so that smaller residuals get higher values.
        # The base priority for exact fit is 1.0. Best fit will be less than 1.0.
        # Let's map best fit to a range like [0.5, 0.99] to clearly distinguish from exact fit.
        # So, a smaller residual should yield a higher score in this range.
        # The term (1 - normalized_residuals) gives values from ~0 (max residual) to ~1 (min residual).
        # We can scale this to [0.5, 0.99].
        # desired_range = 0.99 - 0.5
        # scaled_best_fit_priorities = 0.5 + (1 - normalized_residuals) * desired_range
        
        # A simpler approach that still prioritizes better fits:
        # Assign a priority that decreases as residual increases.
        # A score like 0.5 + (0.5 * (1 - normalized_residuals)) maps to [0.5, 1.0]
        # Let's try to map it such that the best fit gets a high score, but less than 1.0.
        # We can use a fraction of the maximum possible priority (1.0)
        # For example, priority = 0.8 * (1 - normalized_residuals) + 0.1
        # This maps best fit (min residual) to ~0.9 and worst fit (max residual) to ~0.1
        # Let's use a slightly simpler scheme: give higher priority to smaller residuals.
        # Use a value that decreases with residual capacity.
        # Example: 0.75 * (1 - normalized_residuals) + 0.25
        # This maps best fit to 1.0 and worst fit to 0.25.
        # To ensure it's less than 1.0, we can use a scaling factor.
        # Let's use a direct inverse scaling but ensure it's lower than exact fit.
        
        # Use a value inversely proportional to the residual, scaled down.
        # Ensure it's less than 1.0.
        # Use a score like `1.0 - (residual / (max_residual + item + 1e-9))`
        # This makes smaller residuals higher priority.
        best_fit_scores = 1.0 - (residual_capacities / (max_residual + item + 1e-9))
        
        # Scale these scores to a range below 1.0, e.g., [0.5, 0.9].
        # The range of best_fit_scores is approximately [0, 1].
        # Map [0, 1] to [0.5, 0.9]: scale = 0.4, offset = 0.5
        final_best_fit_priorities = 0.5 + best_fit_scores * 0.4
        
        priorities[fit_indices] = final_best_fit_priorities

    return priorities
```
