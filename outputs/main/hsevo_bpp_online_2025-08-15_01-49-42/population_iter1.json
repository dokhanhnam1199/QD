[
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    available_bins_mask = bins_remain_cap >= item\n    priorities[available_bins_mask] = bins_remain_cap[available_bins_mask] - item\n    priorities[priorities < 0] = 0\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 149.30195452732352,
    "cyclomatic_complexity": 1.0,
    "halstead": 27.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Best Fit strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    possible_bins = bins_remain_cap >= item\n    priorities[possible_bins] = bins_remain_cap[possible_bins] - item\n    priorities[~possible_bins] = -np.inf\n    min_residual = np.min(priorities[priorities != -np.inf])\n    priorities[priorities != -np.inf] = priorities[priorities != -np.inf] - min_residual\n    priorities[priorities < 0] = 0\n    priorities = -priorities\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 16, in priority_v2\n    priorities[~can_fit_mask] = -np.inf\nOverflowError: cannot convert float infinity to integer\n1\n137.6075250475963\n"
  },
  {
    "stdout_filepath": "problem_iter1_response2.txt_stdout.txt",
    "code_path": "problem_iter1_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Worst Fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n    priorities[can_fit_mask] = bins_remain_cap[can_fit_mask] - item\n    priorities[~can_fit_mask] = -np.inf\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 149.30195452732352,
    "cyclomatic_complexity": 1.0,
    "halstead": 31.699250014423125,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response3.txt_stdout.txt",
    "code_path": "problem_iter1_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Almost Full Fit priority function.\n\n    This strategy prioritizes bins that will be \"almost full\" after placing the item.\n    A bin is considered \"almost full\" if its remaining capacity after placing the item\n    is small. We want to select the bin that leaves the minimum remaining capacity,\n    provided it can accommodate the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        remaining_capacities_if_fit = bins_remain_cap[can_fit_mask] - item\n        \n        # We want to prioritize bins where the remaining capacity is *minimal* after fitting.\n        # So, a smaller remaining capacity should yield a higher priority.\n        # We can invert the remaining capacity values and then scale them or just use\n        # a value inversely proportional to the remaining capacity.\n        # Here, we'll use 1 / (remaining_capacity + epsilon) to avoid division by zero\n        # and to ensure smaller remaining capacities get higher scores.\n        # A simple approach is to subtract from a large number or use a negative linear function.\n        # Let's use a value that is inversely proportional to remaining capacity.\n        # However, to keep it simpler and still capture the \"almost full\" idea,\n        # we can assign a higher priority to bins that leave a smaller remainder.\n        # A very direct interpretation of \"almost full\" is to prioritize the bin\n        # that, after placing the item, has the smallest *positive* remaining capacity.\n        # This can be achieved by minimizing `bins_remain_cap - item`.\n        # So, we want to *maximize* the negative of `bins_remain_cap - item`.\n        \n        priorities[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item)\n        \n        # Alternative: Use a small epsilon to make it robust\n        # epsilon = 1e-9\n        # priorities[can_fit_mask] = 1.0 / (remaining_capacities_if_fit + epsilon)\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 41.20902501875006,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Exact Fit First heuristic priority function.\n    Prioritizes bins that can exactly fit the item.\n    Among those that can exactly fit, it prioritizes the one that leaves the least remaining capacity.\n    If no bin can exactly fit, it prioritizes the bin that leaves the least positive remaining capacity after placing the item (Best Fit).\n    If no bin can fit the item, all priorities will be zero.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Identify bins that can exactly fit the item\n    exact_fit_indices = np.where(bins_remain_cap == item)[0]\n\n    if len(exact_fit_indices) > 0:\n        # Among exact fits, pick the one that leaves least residual capacity (which is 0 in this case)\n        # This is an arbitrary choice as all exact fits result in 0 residual.\n        # We'll just give them the highest priority.\n        priorities[exact_fit_indices] = 1.0\n    else:\n        # If no exact fit, use a Best Fit approach\n        # Find bins where the item can fit\n        fit_indices = np.where(bins_remain_cap >= item)[0]\n\n        if len(fit_indices) > 0:\n            # Calculate remaining capacity for bins that can fit the item\n            residual_capacities = bins_remain_cap[fit_indices] - item\n\n            # Assign priorities based on smallest residual capacity (Best Fit)\n            # We want to prioritize smaller residuals, so we can invert them or subtract from a max value\n            # A simple way is to assign a higher score to smaller residuals.\n            # Let's use a scale that makes smaller residuals higher priority.\n            # Max possible residual is related to bin capacity, but we don't know that.\n            # Let's use inverse of residual + a small epsilon to avoid division by zero if residual is 0.\n            # However, since we handled exact fit, residual will be > 0 here.\n            # Let's assign priority such that smaller positive residual gets higher priority.\n            # A linear mapping could work: priority = MaxPossibleResidual - Residual.\n            # Since we don't know MaxPossibleResidual, let's try a large number minus the residual.\n            # Or simply, we can assign priorities inversely proportional to residual capacity.\n            # To make it a \"priority score\" that's higher for better fits:\n            # Consider a value inversely proportional to the *excess* capacity above the item.\n            # Let's use a score such that 1 / (residual + epsilon) or similar.\n            # A simpler approach for 'best fit' in a priority system:\n            # Maximize -(residual capacity)\n            # So, we want the bin where residual_capacity is minimized.\n            # We can map this to a positive priority score.\n            # For example, map the minimum residual to the highest score.\n\n            # Let's define a scaling factor or a base priority for fitting.\n            # Give a base priority for fitting, then enhance it for better fit.\n            base_priority = 0.5\n            fit_priorities = base_priority + (1 - base_priority) * (1 - residual_capacities / np.max(residual_capacities + 1e-9))\n            # Adding 1e-9 to denominator to avoid division by zero if all residuals are identical and maximal.\n            # The term (1 - residual_capacities / np.max(residual_capacities + 1e-9))\n            # will range from 0 (for max residual) to near 1 (for min residual).\n            # So, fit_priorities will range from 0.5 to 1.0.\n\n            priorities[fit_indices] = fit_priorities\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 3.0,
    "halstead": 147.1612434150308,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response5.txt_stdout.txt",
    "code_path": "problem_iter1_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    suitable_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n    \n    if suitable_bins_remain_cap.size > 0:\n        # Inverse distance (proximity fit): prioritize bins that are closer to fitting the item\n        # A smaller remaining capacity (but still fitting) is better\n        # We want to invert this, so larger values mean higher priority\n        # Using (1 / (remaining_capacity - item + epsilon)) to avoid division by zero and heavily favor bins with minimal leftover space.\n        # Adding a small constant to remaining capacity before inversion to push smaller leftover spaces to higher priorities\n        \n        # Option 1: Simple inverse of remaining capacity, emphasizing tighter fits\n        # priorities[suitable_bins_mask] = 1.0 / (suitable_bins_remain_cap + 1e-9)\n        \n        # Option 2: Prioritize bins that leave minimal waste, which means remaining_capacity is closest to item size\n        # Difference from item size: (remaining_capacity - item)\n        # Smaller difference is better, so we want to invert it for higher priority.\n        # Add a small constant to avoid division by zero and to ensure that bins that exactly fit get a high priority.\n        differences = suitable_bins_remain_cap - item\n        priorities[suitable_bins_mask] = 1.0 / (differences + 1.0 + 1e-9) \n\n        # Option 3: Weighted inverse distance - could consider how \"full\" the bin is relative to its initial capacity if that info was available.\n        # For now, sticking to relative to item size.\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 70.32403072095333,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response6.txt_stdout.txt",
    "code_path": "problem_iter1_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    feasible_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n\n    if not np.any(feasible_bins_mask):\n        return priorities\n\n    feasible_bins_remain_cap = bins_remain_cap[feasible_bins_mask]\n    \n    diffs = feasible_bins_remain_cap - item\n    \n    scaled_diffs = diffs / np.max(feasible_bins_remain_cap) if np.max(feasible_bins_remain_cap) > 0 else np.zeros_like(diffs)\n    \n    sigmoid_scores = 1 / (1 + np.exp(-5 * (scaled_diffs - 0.5)))\n    \n    priorities[feasible_bins_mask] = sigmoid_scores\n    \n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 3.0,
    "halstead": 128.3789500201924,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = bins_remain_cap[i] - item\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.9999653629493 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response8.txt_stdout.txt",
    "code_path": "problem_iter1_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculates priority scores for placing an item into bins using an Epsilon-Greedy approach\n    biased towards bins with the least remaining capacity that can still fit the item.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A NumPy array representing the remaining capacity of each bin.\n\n    Returns:\n        A NumPy array of the same size as bins_remain_cap, where each element is the\n        priority score for placing the item in the corresponding bin.\n    \"\"\"\n    epsilon = 0.2  # Exploration probability\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins)\n\n    # Identify bins that can fit the item\n    possible_bins_indices = np.where(bins_remain_cap >= item)[0]\n\n    if len(possible_bins_indices) == 0:\n        return priorities  # No bin can fit the item\n\n    # Greedy part: prioritize bins with least remaining capacity that can fit the item\n    # We want to find the bins that have the smallest remaining capacity BUT can still fit the item.\n    # This is equivalent to maximizing (bins_remain_cap - item) for bins that can fit.\n    # Or, minimizing (bins_remain_cap - item) which is the \"waste\" if we put the item there.\n    # A smaller waste means a tighter fit, which is generally preferred in BPP to save larger spaces.\n    if len(possible_bins_indices) > 0:\n        valid_capacities = bins_remain_cap[possible_bins_indices]\n        # Calculate a \"tightness\" score: smaller is better (tighter fit)\n        # We add a small epsilon to avoid division by zero if capacity is exactly item size\n        tightness_scores = valid_capacities - item\n\n        # Normalize tightness scores to be between 0 and 1 (smaller waste -> higher normalized score for greedy choice)\n        # To do this, we can use a reverse normalization:\n        # Higher values in (max_waste - waste) means smaller waste.\n        if len(tightness_scores) > 0:\n            min_waste = np.min(tightness_scores)\n            max_waste = np.max(tightness_scores)\n            if max_waste - min_waste > 0:\n                normalized_greedy_scores = (max_waste - tightness_scores) / (max_waste - min_waste)\n            else:\n                normalized_greedy_scores = np.ones_like(tightness_scores) * 0.5 # All are equally good/bad\n\n            # Assign these greedy scores to the corresponding possible bins\n            priorities[possible_bins_indices] = normalized_greedy_scores\n\n    # Epsilon-Greedy exploration: introduce randomness\n    # With probability epsilon, pick a random bin that can fit the item\n    if np.random.rand() < epsilon and len(possible_bins_indices) > 0:\n        random_bin_index = np.random.choice(possible_bins_indices)\n        # Give a high, uniform score to the randomly chosen bin to ensure it's considered\n        priorities = np.zeros_like(priorities) # Reset priorities\n        priorities[random_bin_index] = 1.0 # Assign a high priority to this random choice\n\n    # If no greedy choice was made due to epsilon or no bins fit initially,\n    # ensure all possible bins have at least some minimal priority to be considered.\n    # This can also happen if all bins have same remaining capacity.\n    if np.sum(priorities) == 0 and len(possible_bins_indices) > 0:\n        priorities[possible_bins_indices] = 0.5 # Assign a neutral priority if no greedy selection happened\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.3777423214998095,
    "cyclomatic_complexity": 9.0,
    "halstead": 255.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response9.txt_stdout.txt",
    "code_path": "problem_iter1_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Softmax-Based Fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    valid_bins_mask = bins_remain_cap >= item\n    valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n\n    if valid_bins_remain_cap.size == 0:\n        return np.zeros_like(bins_remain_cap)",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 2.0,
    "halstead": 15.509775004326936,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements a priority function based on the First Fit strategy for the online Bin Packing Problem.\n    This heuristic prioritizes bins that can accommodate the item and have the least remaining capacity\n    after fitting the item (i.e., bins that will be \"most full\" after packing).\n    It returns a priority score for each bin.\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A NumPy array representing the remaining capacity of each bin.\n\n    Returns:\n        A NumPy array of the same size as bins_remain_cap, where each element is the priority score\n        for the corresponding bin. Bins that cannot fit the item are given a priority of 0.\n        Among the bins that can fit the item, a higher priority is given to bins that will have\n        less remaining capacity after the item is placed.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    for i, capacity in enumerate(bins_remain_cap):\n        if capacity >= item:\n            \n            remaining_after_fit = capacity - item\n            \n            \n            priorities[i] = 1.0 / (remaining_after_fit + 1e-9)  \n            \n    return priorities",
    "response_id": 10,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 39.863137138648355,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response11.txt_stdout.txt",
    "code_path": "problem_iter1_code11.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n    priorities[suitable_bins_mask] = 1 / (bins_remain_cap[suitable_bins_mask] - item + 1e-9)\n    return priorities",
    "response_id": 11,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 1.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response12.txt_stdout.txt",
    "code_path": "problem_iter1_code12.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Worst Fit strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    fitting_bins_capacities = bins_remain_cap[can_fit_mask]\n    \n    if fitting_bins_capacities.size > 0:\n        \n        priorities[can_fit_mask] = fitting_bins_capacities - item\n        \n    return priorities",
    "response_id": 12,
    "tryHS": false,
    "obj": 149.30195452732352,
    "cyclomatic_complexity": 2.0,
    "halstead": 36.541209043760986,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response13.txt_stdout.txt",
    "code_path": "problem_iter1_code13.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Almost Full Fit strategy for online Bin Packing Problem.\n    Prioritizes bins that are almost full but can still accommodate the item.\n    A small capacity difference is preferred over a large one,\n    while ensuring the item fits.\n    \"\"\"\n    # Find bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n\n    # Calculate the remaining capacity after placing the item\n    remaining_capacities_if_placed = bins_remain_cap[suitable_bins_mask] - item\n\n    # Calculate the \"tightness\" of the fit. Smaller is better.\n    # Add a small epsilon to avoid division by zero if remaining capacity is exactly 0\n    tightness = remaining_capacities_if_placed / (bins_remain_cap[suitable_bins_mask] + 1e-9)\n\n    # Higher priority for bins that are tighter fits (closer to 1 after fitting)\n    # We want bins that are almost full but can still take the item.\n    # A good heuristic is to give priority based on how little is left over.\n    # A bin with remaining_capacity = 0.1 for an item of size 0.9 (original bin 1.0) is\n    # a better fit than a bin with remaining_capacity = 0.5 for an item of size 0.5 (original bin 1.0)\n    # We can invert the remaining capacity or use 1 - tightness.\n    # A higher value indicates a better fit.\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # We use 1 - tightness as the priority score. A smaller remaining space after fitting\n    # means a higher priority.\n    # Let's try to prioritize bins where the remaining capacity after placing the item\n    # is as small as possible.\n    # So, a bin where `bins_remain_cap - item` is small gets a high score.\n    # We can use `1 / (bins_remain_cap - item + epsilon)` but this might favor bins with very small capacities.\n    # A better approach for \"Almost Full Fit\" is to give priority to bins where the remaining capacity\n    # *after* placing the item is minimized, but not negative.\n    \n    # Let's calculate a score that is higher for bins that are \"more full\" after the item is placed.\n    # This means `bins_remain_cap - item` should be small.\n    # We can use the negative of the remaining capacity as a simple measure.\n    # More negative means smaller remaining capacity, thus higher priority.\n    \n    priorities[suitable_bins_mask] = -(remaining_capacities_if_placed)\n    \n    # To make sure we prioritize bins that are *almost* full, we can penalize bins\n    # that have a lot of space left.\n    # Consider the difference between the original capacity and the remaining capacity *after* placement.\n    # We want this difference to be close to the bin's original capacity.\n    \n    # Let's reconsider. The goal is to place the item in a bin such that the remaining space\n    # in that bin is minimized. This means `bins_remain_cap - item` should be minimal (but non-negative).\n    # So, the priority should be proportional to `-(bins_remain_cap - item)`.\n    \n    # Let's define priority as a value that we want to maximize.\n    # If a bin has very little space left *after* placing the item, it's a good fit.\n    # So, priority is inversely related to `bins_remain_cap - item`.\n    # A simple way: `1.0 / (bins_remain_cap - item + epsilon)`.\n    # However, this could be problematic if the original capacities vary widely.\n    \n    # The \"Almost Full Fit\" implies we want to find a bin that is *just* large enough,\n    # or as close to full as possible after the item is placed.\n    # So, `bins_remain_cap - item` should be small.\n    # Let's try priority = 1 / (1 + (bins_remain_cap - item))\n    # This gives a higher score to smaller (bins_remain_cap - item).\n    \n    # Re-calculating the priority for suitable bins\n    priorities[suitable_bins_mask] = 1.0 / (1.0 + (bins_remain_cap[suitable_bins_mask] - item))\n    \n    # To ensure \"Almost Full Fit\" specifically, we might want to emphasize bins that are already quite full.\n    # This can be achieved by multiplying the score by how full the bin already is (before placing the item).\n    # However, \"Almost Full Fit\" typically focuses on the *remaining capacity after placement*.\n    \n    # Let's use a strategy that favors bins with the smallest remaining capacity *after* the item is placed.\n    # This means we want to minimize `bins_remain_cap - item`.\n    # So, the priority score should be high when `bins_remain_cap - item` is low.\n    # We can use `-(bins_remain_cap - item)` as a proxy for higher priority for lower remaining capacity.\n    \n    priorities[suitable_bins_mask] = -(bins_remain_cap[suitable_bins_mask] - item)\n\n    return priorities",
    "response_id": 13,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Exact Fit First.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    for i, remaining_cap in enumerate(bins_remain_cap):\n        if remaining_cap >= item:\n            exact_fit_diff = remaining_cap - item\n            priorities[i] = -exact_fit_diff  # Prioritize bins with minimal remaining space after fitting\n    \n    # Among bins that can fit the item, we want to prioritize the one\n    # that leaves the least amount of remaining space (exact fit).\n    # Negative value for priority implies that smaller remaining capacity is better.\n    # If multiple bins offer the exact same smallest remaining capacity,\n    # the one that appears first in the array will be chosen due to the loop's nature.\n    \n    return priorities",
    "response_id": 14,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 20.67970000576925,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    available_bins_mask = bins_remain_cap >= item\n    valid_bins_capacities = bins_remain_cap[available_bins_mask]\n    if valid_bins_capacities.size > 0:\n        inverse_distances = 1.0 / (valid_bins_capacities - item + 1e-9)\n        priorities[available_bins_mask] = inverse_distances\n    return priorities",
    "response_id": 15,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 57.110323830864054,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Sigmoid-like function: emphasizes bins with capacities close to item size\n    # but also considers those with a bit more remaining space to avoid fragmentation.\n    # High values for bins that can fit the item, lower values for those that cannot.\n    # We want to penalize bins that are too large as they might leave too much wasted space,\n    # and also penalize bins that are too small (cannot fit).\n    \n    # Capacities where the item fits\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate \"fit score\" for bins that can fit the item\n    # We want to prioritize bins that have just enough space, or slightly more.\n    # A simple approach is to use a function that peaks around the item's size.\n    # Consider a scaled version of the item size, e.g., item * 1.1 (a little buffer).\n    # The sigmoid function takes values from -inf to +inf and maps them to 0 to 1.\n    # We'll shift and scale the argument to center it around a desired capacity.\n    \n    # Let's define a \"target\" capacity slightly larger than the item for a good fit.\n    # A small epsilon can be added to prevent division by zero in case of zero remaining capacity.\n    epsilon = 1e-9\n    target_capacity = item * 1.1 \n    \n    # Calculate the difference from the target capacity for bins that can fit.\n    # A smaller positive difference is better.\n    difference_from_target = bins_remain_cap[can_fit_mask] - target_capacity\n    \n    # Apply a sigmoid-like function. We want higher scores for smaller positive differences.\n    # A steep sigmoid will prioritize very tightly fitting bins.\n    # Let's scale the difference to control the steepness. A larger 'k' means steeper.\n    k = 10.0  # Steepness parameter\n    \n    # Sigmoid: 1 / (1 + exp(-k * x)) maps (-inf, inf) to (0, 1).\n    # We want to maximize this, so smaller positive difference (closer to 0) is better.\n    # If difference_from_target is negative, it means bins_remain_cap < target_capacity\n    # but still >= item. We want to give these high scores.\n    # If difference_from_target is positive and small, it's good.\n    # If difference_from_target is positive and large, it's worse.\n    \n    # Let's invert the sigmoid behavior or adjust the input to sigmoid.\n    # Option 1: Use -sigmoid(-k * difference) which maps to (0,1) and peaks at negative differences.\n    # Option 2: Use 1 - sigmoid(k * difference) which maps to (0,1) and peaks at negative differences.\n    # Option 3: Use 1 / (1 + exp(k * difference)). This maps (-inf, inf) to (0, 1) and peaks at negative differences.\n    \n    # Using option 3: 1 / (1 + exp(k * difference))\n    # A large negative difference means the bin is much smaller than the target but still fits. Good.\n    # A difference close to zero means it's close to the target. Good.\n    # A large positive difference means it's much larger than the target. Worse.\n    \n    # Add epsilon to the denominator to avoid division by zero if exp overflows.\n    fit_scores_for_fitting_bins = 1.0 / (1.0 + np.exp(k * difference_from_target))\n    \n    # Initialize priorities with a low value for bins that cannot fit the item.\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Assign the calculated fit scores to the bins that can fit the item.\n    priorities[can_fit_mask] = fit_scores_for_fitting_bins\n    \n    # To ensure that bins with slightly more space are still considered,\n    # we can add a small bonus for bins that are larger, but not excessively larger.\n    # Or, simply ensure the sigmoid naturally handles this.\n    # The current sigmoid peaks when difference_from_target is negative and approaches 0 as difference_from_target increases positively.\n    # This means bins that are slightly too small for the target (but still fit the item) will have highest scores.\n    # Then bins that match the target will have moderate scores, and bins much larger will have lower scores.\n    \n    # If we want to prioritize bins that have *enough* space, but not *too much*,\n    # we can think of the ideal space as 'item'.\n    # Let's re-evaluate the sigmoid input.\n    # We want to maximize `f(x)` where `x` is the remaining capacity.\n    # `f(item) = 1`\n    # `f(x < item) = 0`\n    # `f(x > item) = 0`, but decrease as `x` increases.\n    \n    # A Gaussian-like function centered at 'item' could work.\n    # `exp(-beta * (bins_remain_cap - item)^2)`\n    # This peaks at 'item'. Bins smaller than item will have lower values (and 0 if they don't fit).\n    # Bins larger than item will also have lower values.\n    \n    beta = 0.1 # Controls the width of the Gaussian. Smaller beta means wider.\n    \n    # Initialize scores to zero.\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # For bins that can fit the item:\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate scores for fitting bins.\n    # Use a Gaussian-like function centered around `item`.\n    # Values further from `item` get lower scores.\n    # Bins that are too large will have low scores. Bins that are \"just right\" will have high scores.\n    # Bins that are smaller than item get 0.\n    \n    # Let's use the difference `bins_remain_cap - item`.\n    # We want values close to 0 to have high scores.\n    \n    # Calculate the squared difference from the item size.\n    # We only care about bins that can fit.\n    diff_sq = (bins_remain_cap[can_fit_mask] - item)**2\n    \n    # Gaussian function: exp(-beta * diff_sq)\n    # High values for small differences (close to 'item').\n    # Lower values for larger differences (much larger than 'item').\n    scores_for_fitting = np.exp(-beta * diff_sq)\n    \n    # Assign these scores to the appropriate bins.\n    priorities[can_fit_mask] = scores_for_fitting\n    \n    return priorities",
    "response_id": 16,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 144.75398259382442,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response17.txt_stdout.txt",
    "code_path": "problem_iter1_code17.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    available_bins = bins_remain_cap >= item\n    priorities[available_bins] = bins_remain_cap[available_bins] - item\n    priorities[priorities < 0] = 0\n    return priorities",
    "response_id": 17,
    "tryHS": false,
    "obj": 149.30195452732352,
    "cyclomatic_complexity": 1.0,
    "halstead": 27.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response18.txt_stdout.txt",
    "code_path": "problem_iter1_code18.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using an epsilon-greedy approach favoring bins with less remaining capacity.\"\"\"\n    epsilon = 0.1\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins)\n\n    available_bins_mask = bins_remain_cap >= item\n    available_bins_indices = np.where(available_bins_mask)[0]\n\n    if len(available_bins_indices) == 0:\n        return np.zeros(num_bins)\n\n    if np.random.rand() < epsilon:\n        chosen_bin_index = np.random.choice(available_bins_indices)\n        priorities[chosen_bin_index] = 1.0\n    else:\n        remaining_capacities_for_available_bins = bins_remain_cap[available_bins_mask]\n        \n        # Calculate priorities: favor bins with less remaining capacity\n        # Inverting the remaining capacity to make smaller capacities have higher priority\n        # Add a small epsilon to avoid division by zero if any remaining capacity is zero\n        inverted_capacities = 1.0 / (remaining_capacities_for_available_bins - item + 1e-9)\n        \n        # Normalize priorities to sum to 1, so it can be interpreted as a probability distribution\n        normalized_priorities = inverted_capacities / np.sum(inverted_capacities)\n        \n        # Assign these normalized priorities to the original bins\n        priorities[available_bins_mask] = normalized_priorities\n        \n        # Select the bin with the highest priority (largest inverted capacity)\n        best_bin_original_index = available_bins_indices[np.argmax(normalized_priorities)]\n        priorities = np.zeros(num_bins) # Reset priorities to ensure only the best bin gets high priority\n        priorities[best_bin_original_index] = 1.0 # Set the best bin to have the highest priority\n\n    return priorities",
    "response_id": 18,
    "tryHS": false,
    "obj": 4.248105305145606,
    "cyclomatic_complexity": 3.0,
    "halstead": 89.20647778231529,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Softmax-Based Fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    eligible_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(eligible_bins_mask):\n        return np.zeros_like(bins_remain_cap)\n        \n    eligible_bins_remain_cap = bins_remain_cap[eligible_bins_mask]\n    \n    \n    differences = eligible_bins_remain_cap - item\n    \n    \n    scaled_differences = differences / np.max(eligible_bins_remain_cap)\n    \n    \n    exponentiated_priorities = np.exp(scaled_differences)\n    \n    \n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[eligible_bins_mask] = exponentiated_priorities\n    \n    return priorities",
    "response_id": 19,
    "tryHS": false,
    "obj": 12.654567211806949,
    "cyclomatic_complexity": 2.0,
    "halstead": 36.541209043760986,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response20.txt_stdout.txt",
    "code_path": "problem_iter1_code20.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements the First Fit Decreasing heuristic for the online Bin Packing Problem.\n    This version prioritizes bins that can fit the item with the least remaining capacity\n    after the item is placed, encouraging tighter packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            remaining_capacity = bins_remain_cap[i] - item\n            \n            if remaining_capacity == 0:\n                priorities[i] = float('inf') # Highest priority for exact fit\n            else:\n                # Prioritize bins that result in smaller remaining capacity\n                # The idea is to try and \"fill up\" bins as much as possible\n                # A smaller remaining capacity after placing the item is preferred\n                # We use the inverse of remaining capacity to get a higher score for smaller remaining capacities.\n                # Adding 1 to the denominator to avoid division by zero and to ensure positive scores.\n                priorities[i] = 1.0 / (remaining_capacity + 1e-6) \n        else:\n            priorities[i] = -1.0 # Assign a low priority if the item doesn't fit\n\n    # Normalize priorities to be between 0 and 1 for potentially smoother behavior in other algorithms\n    # However, for First Fit strategy, direct comparison is sufficient.\n    # If no bin can fit the item, all priorities will be -1.0.\n    # In a real implementation, a new bin would be opened in such a case.\n    # This function only provides priorities for existing bins.\n    \n    return priorities",
    "response_id": 20,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 4.0,
    "halstead": 64.72503367497926,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    suitable_bins_mask = bins_remain_cap >= item\n    suitable_bins = bins_remain_cap[suitable_bins_mask]\n    if suitable_bins.size > 0:\n        differences = suitable_bins - item\n        min_diff = np.min(differences)\n        priorities[suitable_bins_mask] = 1.0 / (differences - min_diff + 1e-9)\n    return priorities",
    "response_id": 21,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 72.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response22.txt_stdout.txt",
    "code_path": "problem_iter1_code22.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = bins_remain_cap[i] - item\n    return priorities",
    "response_id": 22,
    "tryHS": false,
    "obj": 149.30195452732352,
    "cyclomatic_complexity": 3.0,
    "halstead": 13.931568569324174,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response23.txt_stdout.txt",
    "code_path": "problem_iter1_code23.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1 / (bins_remain_cap[i] - item + 1e-9)\n    return priorities",
    "response_id": 23,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 3.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response24.txt_stdout.txt",
    "code_path": "problem_iter1_code24.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, bin_cap in enumerate(bins_remain_cap):\n        if bin_cap >= item:\n            priorities[i] = 1.0 / (bin_cap - item + 1e-9)\n    return priorities",
    "response_id": 24,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 3.0,
    "halstead": 39.863137138648355,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response25.txt_stdout.txt",
    "code_path": "problem_iter1_code25.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Inverse Distance (Proximity Fit).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1 / (bins_remain_cap[i] - item + 1e-9)\n    return priorities",
    "response_id": 25,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 3.0,
    "halstead": 41.51317942364757,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response26.txt_stdout.txt",
    "code_path": "problem_iter1_code26.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    fitting_ratios = np.clip(item / bins_remain_cap, 0.001, 0.999)\n    priorities = 1 / (1 + np.exp(-(fitting_ratios - 0.5) * 10))\n    return priorities",
    "response_id": 26,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 66.41714012534482,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response27.txt_stdout.txt",
    "code_path": "problem_iter1_code27.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    available_bins_mask = bins_remain_cap >= item\n    available_bins_caps = bins_remain_cap[available_bins_mask]\n    if available_bins_caps.size > 0:\n        priorities[available_bins_mask] = 1.0 / (available_bins_caps - item + 1e-9)\n    return priorities",
    "response_id": 27,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 2.0,
    "halstead": 57.110323830864054,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response28.txt_stdout.txt",
    "code_path": "problem_iter1_code28.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap, dtype=np.float64)\n    epsilon = 0.1\n    available_bins_mask = bins_remain_cap >= item\n    valid_bins_remain_cap = bins_remain_cap[available_bins_mask]\n    \n    if np.any(available_bins_mask):\n        greedy_scores = -valid_bins_remain_cap\n        \n        min_cap_idx = np.argmin(valid_bins_remain_cap)\n        max_cap_idx = np.argmax(valid_bins_remain_cap)\n        \n        greedy_scores[min_cap_idx] += 1.0 * (1 - epsilon) \n        greedy_scores[max_cap_idx] -= 1.0 * (1 - epsilon)\n        \n        \n        random_indices = np.random.choice(len(valid_bins_remain_cap), size=int(epsilon * len(valid_bins_remain_cap)), replace=False)\n        greedy_scores[random_indices] += np.random.randn(len(random_indices)) * 0.5\n\n        \n        priorities[available_bins_mask] = greedy_scores\n        \n        \n        if not np.any(priorities[available_bins_mask]):\n            priorities[available_bins_mask] = np.random.rand(np.sum(available_bins_mask))\n\n    return priorities",
    "response_id": 28,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 23, in priority_v2\n    return priorities\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n3\n153.80110650593844\n"
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    valid_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(valid_bins_mask):\n        valid_bins_remain_cap = bins_remain_cap[valid_bins_mask]\n        \n        \n        score_diff = valid_bins_remain_cap - item\n        \n        \n        exp_scores = np.exp(score_diff)\n        \n        \n        priorities[valid_bins_mask] = exp_scores\n        \n        \n        normalized_priorities = priorities / np.sum(priorities)\n        return normalized_priorities\n    else:\n        return priorities",
    "response_id": 29,
    "tryHS": false,
    "obj": 149.30195452732352,
    "cyclomatic_complexity": 2.0,
    "halstead": 27.0,
    "exec_success": true
  }
]