{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Almost Full Fit priority function.\n\n    This strategy prioritizes bins that will be \"almost full\" after placing the item.\n    A bin is considered \"almost full\" if its remaining capacity after placing the item\n    is small. We want to select the bin that leaves the minimum remaining capacity,\n    provided it can accommodate the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        remaining_capacities_if_fit = bins_remain_cap[can_fit_mask] - item\n        \n        # We want to prioritize bins where the remaining capacity is *minimal* after fitting.\n        # So, a smaller remaining capacity should yield a higher priority.\n        # We can invert the remaining capacity values and then scale them or just use\n        # a value inversely proportional to the remaining capacity.\n        # Here, we'll use 1 / (remaining_capacity + epsilon) to avoid division by zero\n        # and to ensure smaller remaining capacities get higher scores.\n        # A simple approach is to subtract from a large number or use a negative linear function.\n        # Let's use a value that is inversely proportional to remaining capacity.\n        # However, to keep it simpler and still capture the \"almost full\" idea,\n        # we can assign a higher priority to bins that leave a smaller remainder.\n        # A very direct interpretation of \"almost full\" is to prioritize the bin\n        # that, after placing the item, has the smallest *positive* remaining capacity.\n        # This can be achieved by minimizing `bins_remain_cap - item`.\n        # So, we want to *maximize* the negative of `bins_remain_cap - item`.\n        \n        priorities[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item)\n        \n        # Alternative: Use a small epsilon to make it robust\n        # epsilon = 1e-9\n        # priorities[can_fit_mask] = 1.0 / (remaining_capacities_if_fit + epsilon)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritizes exact fits, then bins with minimal normalized slack.\n\n    This heuristic combines the \"exact fit\" strategy with a \"best fit\"\n    approach normalized by remaining capacity, ensuring clear ranking.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    exact_fit_mask = bins_remain_cap == item\n    non_exact_fit_mask = bins_remain_cap > item\n    \n    # Prioritize exact fits with a score of 1.0\n    priorities[exact_fit_mask] = 1.0\n    \n    # For non-exact fits, calculate priority based on normalized slack\n    if np.any(non_exact_fit_mask):\n        eligible_bins_remain_cap = bins_remain_cap[non_exact_fit_mask]\n        \n        # Calculate remaining capacity after placing the item\n        remaining_capacities_if_fit = eligible_bins_remain_cap - item\n        \n        # Calculate normalized slack: remaining capacity / current bin capacity\n        # Add epsilon for numerical stability for bins that might have 0 capacity (though unlikely in BPP)\n        epsilon = 1e-9\n        normalized_slack = remaining_capacities_if_fit / (eligible_bins_remain_cap + epsilon)\n        \n        # Priority is 1 - normalized_slack: smaller slack means higher priority (closer to 1.0)\n        # This maps the best fit (smallest normalized slack) to a score close to 1.0,\n        # and progressively lower scores for bins with larger normalized slack.\n        # This also ensures scores are positive and distinct from exact fits (1.0).\n        priorities[non_exact_fit_mask] = 1.0 - normalized_slack\n\n    # If there are exact fits, they are already set to 1.0.\n    # For non-exact fits, scores will be in the range [0, 1).\n    # We can shift non-exact fit scores slightly lower if we want exact fits to be strictly dominant.\n    # For example, subtract a small value from non-exact fit scores if any exact fits exist.\n    # However, the current scheme where exact fits are 1.0 and others are < 1.0 naturally handles this.\n    \n    return priorities\n\n### Analyze & experience\n- *   **Heuristics 1 vs 2:** Heuristic 1 prioritizes exact fits (score 1.0) and then uses an inverse of remaining capacity for others. Heuristic 2 implements a BFD-inspired approach, maximizing negative remaining capacity and using negative initial slack as a tie-breaker, scaled by a large factor. Heuristic 1's scoring for non-exact fits (1/(remaining+1)) is simpler but might not distinguish as well as Heuristic 2's combined score. Heuristic 2's explicit tie-breaking and scaling seem more robust for BFD.\n\n*   **Heuristics 2 vs 5:** Heuristic 2 uses a scaled combination of minimizing remaining capacity and minimizing initial slack. Heuristic 5 focuses solely on minimizing remaining capacity (equivalent to maximizing negative remaining capacity). Heuristic 2's tie-breaking mechanism (considering initial slack) adds a refinement that Heuristic 5 lacks, potentially leading to better packing in cases of identical minimum remainders.\n\n*   **Heuristics 5 vs 7:** These heuristics appear to be identical in their core logic: prioritizing bins that leave the minimum remaining capacity after fitting an item. Both assign a score as the negative of the remaining capacity after fit.\n\n*   **Heuristics 1 vs 9:** Heuristic 1 rewards exact fits with 1.0 and uses inverse remaining capacity for others. Heuristic 9 prioritizes exact fits with 1.0 and then uses a normalized slack (remaining / current capacity) for non-exact fits, scaled to be between 0.5 and 0.99. Heuristic 9's normalization and scaling for non-exact fits offer a more nuanced approach than Heuristic 1's simple inverse.\n\n*   **Heuristics 9 vs 10:** Heuristics 9 and 10 are identical. They both prioritize exact fits with 1.0 and then use a scaled normalized slack (1 - normalized_slack) for non-exact fits, mapping to [0.5, 0.99].\n\n*   **Heuristics 10 vs 14:** Heuristic 10 prioritizes exact fits with 1.0 and then uses a scaled normalized slack (1 - normalized_slack) for non-exact fits, mapping to [0.5, 0.99]. Heuristic 14 also prioritizes exact fits with 1.0 and uses (1 - normalized slack) for non-exact fits, but these scores are not explicitly scaled to a range like [0.5, 0.99], implying they could be [0, 1). Both use normalized slack, but Heuristic 10's explicit scaling might offer more control.\n\n*   **Heuristics 14 vs 16:** Heuristic 14 prioritizes exact fits with 1.0 and uses `1.0 - normalized_slack` for non-exact fits. Heuristic 16 prioritizes exact fits with 1.0 and uses `0.5 * (1.0 - normalized_slack)` for non-exact fits. Heuristic 16's scaling factor of 0.5 ensures non-exact fits are always distinctly lower than exact fits, potentially offering clearer separation.\n\n*   **Heuristics 16 vs 17:** Heuristic 16 prioritizes exact fits with 1.0 and uses `0.5 * (1.0 - normalized_slack)` for non-exact fits. Heuristic 17 prioritizes exact fits with 1.0 and then uses `1.0 + (1.0 / (normalized_slack + 1e-9))` for non-exact fits. Heuristic 17's scoring for non-exact fits is much higher and seems to invert the normalized slack, making smaller slack yield larger scores. This approach might overvalue non-exact fits.\n\n*   **Heuristics 17 vs 15:** Heuristic 17 prioritizes exact fits with 1.0 and uses `1.0 + (1.0 / (normalized_slack + 1e-9))` for non-exact fits. Heuristic 15 prioritizes exact fits with 1.0 and uses `1.0 + (1.0 / (normalized_slack + 1e-9))` for non-exact fits. These appear identical.\n\n*   **Heuristics 15 vs 18:** Heuristic 15 prioritizes exact fits with 1.0 and uses `1.0 + (1.0 / (normalized_slack + 1e-9))` for non-exact fits. Heuristic 18 prioritizes exact fits with a very high score (1e6) and then uses `-normalized_slack * 1e5` for non-exact fits. Heuristic 18's high score for exact fits and negative scaling for non-exact fits is a different approach. The negative scaling for non-exact fits is unusual for \"higher score = higher priority.\"\n\n*   **Heuristics 18 vs 20:** Heuristics 18 and 20 are identical. They prioritize exact fits with a very high score (1e6) and then use `-normalized_slack * 1e5` for non-exact fits, which appears to have the intention of maximizing the negative normalized slack (minimizing slack).\n\n*   **Heuristics 19 vs 20:** Heuristic 19 is incomplete but aims for exact fits with a specific score and inverse slack. Heuristic 20 prioritizes exact fits with a very high score (1e6) and then uses `-normalized_slack * 1e5` for non-exact fits. Heuristic 20's explicit high score for exact fits and the negative scaling for non-exact fits are concrete implementations.\n\n*   **Overall:** Heuristics 2 and 10/9/14/16 offer robust BFD-like strategies by combining primary (minimizing residual/slack) and secondary (initial slack) objectives or by using normalized slack. Heuristics 18/20 have a clear hierarchy with a very high score for exact fits and negative scaled slack for others, but the negative scaling for priority is counter-intuitive. Heuristics 15/17 use an unusual inversion for non-exact fits. Heuristics 1/5/7 focus on simple inverse remaining capacity.\n- \nHere's a redefined approach to self-reflection for heuristic design:\n\n*   **Keywords:** Differentiated Scores, Scaled Objective Integration, Robustness, Contextual Prioritization.\n*   **Advice:** Design self-reflection to create *distinct, contextually relevant scores* for candidate solutions. Integrate multiple objectives (e.g., fit quality, resource utilization) using scaling or weighted sums that reflect their relative importance.\n*   **Avoid:** Overly simplistic scoring (e.g., direct inverse slack), manual prioritization that's not data-driven, and brittle numerical operations.\n*   **Explanation:** This focuses on creating nuanced, comparable scores that guide the heuristic towards robust, well-reasoned choices by considering the interplay of various factors and ensuring numerical stability.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}