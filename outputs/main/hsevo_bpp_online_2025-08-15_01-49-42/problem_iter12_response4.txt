```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Hybrid "Best Fit" and "Worst Fit" with capacity normalization priority function.

    This strategy aims to improve upon simple "almost full" by considering two aspects:
    1.  Prioritizing bins that are "tight" fits (leaving minimal remaining capacity),
        similar to Best Fit, but without being overly sensitive to small differences.
    2.  As a secondary consideration, and to avoid clustering items into only the smallest
        remaining capacity bins (which might lead to fragmentation later), it also
        slightly favors bins that have more remaining capacity, up to a certain point,
        acting as a "soft" worst fit to spread items better.
    3.  It normalizes remaining capacities to handle varying bin sizes or item scales more robustly.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Returns:
        Array of priority scores for each bin. Bins that cannot accommodate the item
        receive a priority of -1. Higher scores indicate higher priority.
    """
    priorities = np.full_like(bins_remain_cap, -1.0)

    can_fit_mask = bins_remain_cap >= item

    if np.any(can_fit_mask):
        eligible_capacities = bins_remain_cap[can_fit_mask]
        remaining_capacities_if_fit = eligible_capacities - item

        # Primary score component: Prioritize bins that leave minimal remaining capacity.
        # We use a score that is inversely related to the remaining capacity.
        # Adding epsilon to denominator for numerical stability and to avoid zero division.
        # Small remaining capacity -> large positive score.
        epsilon = 1e-9
        tight_fit_score = 1.0 / (remaining_capacities_if_fit + epsilon)

        # Secondary score component: Introduce a slight preference for bins with more capacity,
        # acting as a "soft" worst fit to prevent premature clustering.
        # This component is scaled to be less dominant than the tight fit.
        # Larger remaining capacity -> larger score.
        # We can normalize the remaining capacities relative to the *maximum* possible remaining capacity
        # among eligible bins to make this component more stable.
        # If all eligible bins have the same remaining capacity, this score will be uniform.
        if np.max(eligible_capacities) > 0:
             normalized_slack = eligible_capacities / np.max(eligible_capacities)
        else:
             normalized_slack = np.zeros_like(eligible_capacities) # Handle case where max capacity is 0

        # Combine scores: Prioritize tight fits, then spread items.
        # The weight (0.3) balances tight fitting vs. spreading. Adjust as needed.
        combined_score = tight_fit_score * 0.7 + normalized_slack * 0.3

        priorities[can_fit_mask] = combined_score

    return priorities
```
