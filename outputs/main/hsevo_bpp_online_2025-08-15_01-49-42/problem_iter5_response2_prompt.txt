{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines Exact Fit First with a normalized Best Fit strategy.\n    Prioritizes exact fits, then best fits using a scaled inverse of residual capacity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # 1. Exact Fit: Highest priority (1.0)\n    exact_fit_indices = np.where(bins_remain_cap == item)[0]\n    priorities[exact_fit_indices] = 1.0\n\n    # 2. Best Fit: Prioritize bins with minimal positive remaining capacity\n    # Only consider bins that can fit the item and are not exact fits\n    can_fit_mask = (bins_remain_cap >= item) & (bins_remain_cap != item)\n    fit_indices = np.where(can_fit_mask)[0]\n\n    if len(fit_indices) > 0:\n        residual_capacities = bins_remain_cap[fit_indices] - item\n        \n        # Normalize residuals to be between 0 and 1, where smaller residual is better.\n        # A common way is 1 - (residual / max_residual).\n        # To avoid division by zero if all residuals are the same and positive, add a small epsilon.\n        max_residual = np.max(residual_capacities)\n        normalized_residuals = residual_capacities / (max_residual + 1e-9)\n        \n        # Assign priorities that are higher for smaller residuals.\n        # Scale between 0.5 (for worst fit among feasible) and 1.0 (for exact fit).\n        # We use 1 - normalized_residuals so that smaller residuals get higher values.\n        # The base priority for exact fit is 1.0. Best fit will be less than 1.0.\n        # Let's map best fit to a range like [0.5, 0.99] to clearly distinguish from exact fit.\n        # So, a smaller residual should yield a higher score in this range.\n        # The term (1 - normalized_residuals) gives values from ~0 (max residual) to ~1 (min residual).\n        # We can scale this to [0.5, 0.99].\n        # desired_range = 0.99 - 0.5\n        # scaled_best_fit_priorities = 0.5 + (1 - normalized_residuals) * desired_range\n        \n        # A simpler approach that still prioritizes better fits:\n        # Assign a priority that decreases as residual increases.\n        # A score like 0.5 + (0.5 * (1 - normalized_residuals)) maps to [0.5, 1.0]\n        # Let's try to map it such that the best fit gets a high score, but less than 1.0.\n        # We can use a fraction of the maximum possible priority (1.0)\n        # For example, priority = 0.8 * (1 - normalized_residuals) + 0.1\n        # This maps best fit (min residual) to ~0.9 and worst fit (max residual) to ~0.1\n        # Let's use a slightly simpler scheme: give higher priority to smaller residuals.\n        # Use a value that decreases with residual capacity.\n        # Example: 0.75 * (1 - normalized_residuals) + 0.25\n        # This maps best fit to 1.0 and worst fit to 0.25.\n        # To ensure it's less than 1.0, we can use a scaling factor.\n        # Let's use a direct inverse scaling but ensure it's lower than exact fit.\n        \n        # Use a value inversely proportional to the residual, scaled down.\n        # Ensure it's less than 1.0.\n        # Use a score like `1.0 - (residual / (max_residual + item + 1e-9))`\n        # This makes smaller residuals higher priority.\n        best_fit_scores = 1.0 - (residual_capacities / (max_residual + item + 1e-9))\n        \n        # Scale these scores to a range below 1.0, e.g., [0.5, 0.9].\n        # The range of best_fit_scores is approximately [0, 1].\n        # Map [0, 1] to [0.5, 0.9]: scale = 0.4, offset = 0.5\n        final_best_fit_priorities = 0.5 + best_fit_scores * 0.4\n        \n        priorities[fit_indices] = final_best_fit_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Adaptive Best Fit Decreasing-like priority function with capacity normalization.\n\n    This strategy prioritizes bins that are a \"good fit\" for the item,\n    aiming to minimize wasted space. It considers bins that can fit the item\n    and assigns higher priority to those where the remaining capacity after\n    placement is relatively small compared to the bin's original capacity.\n    This aims to utilize bins more efficiently and potentially leave larger\n    remaining spaces in other bins for future larger items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # Calculate remaining capacity after placing the item\n        remaining_if_fit = fitting_bins_remain_cap - item\n\n        # Normalize remaining capacity by the bin's *original* capacity (approximated by current remaining capacity)\n        # to get a relative measure of wasted space.\n        # A lower relative remaining capacity (less waste) gets a higher score.\n        # We use bins_remain_cap which is the capacity *before* fitting.\n        # To avoid division by zero if a bin is exactly full (though this shouldn't happen if item > 0),\n        # we add a small epsilon.\n        epsilon = 1e-9\n        \n        # Higher priority for bins that leave *less* relative slack.\n        # The slack is (bin_capacity - item). We want to minimize this slack relative to bin_capacity.\n        # So we maximize -(slack / bin_capacity).\n        # We use fitting_bins_remain_cap as an approximation of bin_capacity if it's not empty.\n        # If a bin has 0 remaining capacity, it means it's full. If an item fits, the remaining capacity is 0.\n        # The relative slack is 0 / bin_capacity = 0.\n        \n        # Calculate the \"goodness of fit\" by minimizing the remaining capacity relative to the bin's capacity.\n        # A smaller `remaining_if_fit / fitting_bins_remain_cap` indicates a better fit.\n        # We want to maximize the negative of this value to get higher priorities for better fits.\n        relative_slack = remaining_if_fit / (fitting_bins_remain_cap + epsilon)\n        priorities[can_fit_mask] = -relative_slack\n\n        # An alternative that might be more direct about minimizing wasted space:\n        # Prioritize bins that are \"almost full\" after fitting, but consider the original capacity.\n        # We want to maximize `1 - (remaining_if_fit / fitting_bins_remain_cap)` which is `(fitting_bins_remain_cap - remaining_if_fit) / fitting_bins_remain_cap`.\n        # This is equivalent to maximizing `item / fitting_bins_remain_cap`, which prioritizes bins\n        # where the item takes up a larger proportion of the *available* capacity.\n        # priorities[can_fit_mask] = item / (fitting_bins_remain_cap + epsilon)\n        \n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1 ([Heuristics 1st]) and Heuristic 7 ([Heuristics 7th]), they are functionally identical, both using `1.0 / (remaining_after_fit + epsilon)` with `epsilon=1.0` in Heuristic 1 and `epsilon=0.8954438612151145` in Heuristic 7. The choice of `epsilon` is a hyperparameter.\n\nComparing Heuristic 2 ([Heuristics 2nd]) and Heuristic 6 ([Heuristics 6th]), they are identical implementations using `1.0 / (differences + 1.0 + 1e-9)`.\n\nComparing Heuristic 3 ([Heuristics 3rd]) and Heuristic 11 ([Heuristics 11th]), both aim to minimize normalized slack `remaining_capacities_if_fit / current_bin_capacities`. Heuristic 3 uses `-(remaining_capacities_if_fit) - epsilon * eligible_bins_remain_cap` while Heuristic 11 uses `1.0 - normalized_slack`. Heuristic 11's `1.0 - normalized_slack` is a clearer objective function for minimizing slack. Heuristic 3's approach of penalizing already fuller bins might be an interesting secondary objective but adds complexity.\n\nComparing Heuristic 9 ([Heuristics 9th]) and Heuristic 11 ([Heuristics 11th]), they are identical, both implementing `1.0 - normalized_slack` where `normalized_slack` is `remaining_capacities_if_fit / (current_bin_capacities + epsilon)`.\n\nComparing Heuristic 10 ([Heuristics 10th]) and Heuristic 12 ([Heuristics 12th]), they are identical, implementing an exact fit priority of 1.0 and then scaling best fit priorities to a range like [0.5, 0.9].\n\nComparing Heuristic 13 ([Heuristics 13th]) and Heuristic 19 ([Heuristics 19th]), they are identical. They prioritize exact fits with 1.0 and then normalize other scaled inverse priorities so the highest is 1.0.\n\nComparing Heuristic 14 ([Heuristics 14th]) and Heuristic 17 ([Heuristics 17th]) and Heuristic 20 ([Heuristics 20th]), they are identical. They prioritize exact fits with 1.0 and then apply `0.1 / (non_exact_bins_remaining + 1.0)` for non-exact fits.\n\nComparing Heuristic 5 ([Heuristics 5th]) and Heuristic 16 ([Heuristics 16th]): Heuristic 5 directly uses `-(bins_remain_cap[can_fit_mask] - item)` which is equivalent to maximizing the negative slack. Heuristic 16 uses a sigmoid function on normalized differences, which is a more complex approach to prioritize smaller differences.\n\nOverall, heuristics that directly prioritize minimizing slack (like `1.0 - normalized_slack` or negative slack) or exact fits with a clear scoring are generally better. The use of `epsilon` or other constants for stability and scaling is important. Combinations of exact fit with best fit are common and effective.\n- \nHere's a redefinition of \"Current self-reflection\" to inform heuristic design, avoiding the pitfalls of \"Ineffective self-reflection\":\n\n*   **Keywords:** Exact fit, slack minimization, normalized slack, stable scoring, distinct ranking.\n*   **Advice:** Design scoring functions that explicitly reward exact fits, and for imperfect fits, prioritize minimizing normalized slack (slack / bin capacity) to robustly compare options across different bin sizes.\n*   **Avoid:** Direct comparisons of raw slack, numerical instability from division by zero or very small capacities, and overly complex scaling that obscures underlying trade-offs.\n*   **Explanation:** Clear, stable scoring ensures the heuristic reliably identifies the best available bin without getting bogged down by numerical quirks or losing interpretability, crucial for effective optimization.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}