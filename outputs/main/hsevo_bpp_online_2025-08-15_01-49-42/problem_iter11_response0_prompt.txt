{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritizes exact fits, then bins with minimal normalized slack using a scaled approach.\n    Combines the exact fit priority of v0/v9/v10 with the normalized slack approach of v9/v10.\n    The scoring ensures a clear hierarchy: exact fits > best fits (min normalized slack).\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Exact Fit: Highest priority (1.0)\n    exact_fit_mask = np.isclose(bins_remain_cap, item)\n    priorities[exact_fit_mask] = 1.0\n\n    # Best Fit: Prioritize bins with minimal positive remaining capacity after fitting.\n    # Consider bins that can fit the item and are not exact fits.\n    can_fit_mask = (bins_remain_cap >= item) & ~exact_fit_mask\n    fit_indices = np.where(can_fit_mask)[0]\n\n    if len(fit_indices) > 0:\n        remaining_after_fit = bins_remain_cap[fit_indices] - item\n        current_capacities = bins_remain_cap[fit_indices]\n\n        # Calculate normalized slack: (remaining_capacity_after_fit) / (current_bin_capacity)\n        # Smaller normalized slack is better. Add epsilon for numerical stability.\n        normalized_slack = remaining_after_fit / (current_capacities + 1e-9)\n\n        # Assign priorities that are higher for smaller normalized slack.\n        # We use 1.0 - normalized_slack to map smaller slack to higher scores.\n        # Scale these scores to be clearly less than 1.0, e.g., into the range [0.5, 0.99].\n        # This mirrors the effective scoring of v9/v10.\n        best_fit_scores = 1.0 - normalized_slack\n        scaled_best_fit_priorities = 0.5 + best_fit_scores * 0.49\n\n        priorities[fit_indices] = scaled_best_fit_priorities\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines exact fit preference with scaled inverse normalized slack for non-exact fits.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n### Analyze & experience\n- Comparing Heuristics 1, 5, 6, 12, 15 (Exact Fit + Normalized Slack variants) with Heuristics 2, 4, 7 (Almost Full Fit variants) and Heuristic 3 (Hybrid V1), we see that prioritizing exact fits offers a clear, high-priority strategy. Normalized slack provides a good way to differentiate non-exact fits based on relative space utilization. The \"Almost Full Fit\" heuristics (like V1, which is essentially maximizing -slack) are simpler but lack the explicit handling of exact fits or the nuanced scaling of normalized slack. Heuristic 3 attempts a hybrid but its implementation is less clear than the dedicated strategies.\n\nComparing Heuristics 1, 5, 6, 12, 15:\n- Heuristics 1, 5, 15 are very similar, prioritizing exact fits (score 1.0) and then using a scaled version of `1.0 - normalized_slack` for non-exact fits, mapping them to a range like [0.5, 0.99]. This provides a clear hierarchy and differentiated scores.\n- Heuristic 6 is very similar to 1, 5, 15 but uses slightly different scaling (0.5 to 0.99).\n- Heuristic 12 uses `1.0` for exact fits and `0.5 + 0.49 * (1.0 - normalized_slack)` for non-exact fits, which is functionally identical to 1, 5, 15.\n- Heuristic 13 attempts to combine exact fit priority with a Best Fit strategy (minimizing normalized residual) and a tie-breaker based on initial slack. The scoring mechanism (lexicographical preference via scaling) is more complex but aims for a multi-objective optimization.\n- Heuristic 14 also prioritizes exact fits and then uses a normalized remaining capacity (mapped to [0.5, 0.95]) for non-exact fits, similar to 1, 5, 6, 12, 15.\n\nComparing \"Almost Full Fit\" variants (2, 4, 7) with others:\n- Heuristics 2, 4, 7 are consistent in using `-slack` (maximizing negative slack) as the primary scoring mechanism. This prioritizes bins that become most full. They assign -1 to bins that cannot fit. This is a simple and effective \"Best Fit\" approach but doesn't explicitly handle exact fits as a special case.\n\nComparing Heuristics 8, 9, 10, 11, 16, 17, 20:\n- Heuristic 8 attempts to use `-log(slack + epsilon)` for differentiation, which is a novel approach for small slack values.\n- Heuristics 9, 10, 11 combine slack minimization with fit ratio `item / bins_remain_cap`, weighted. This adds a second dimension to the scoring.\n- Heuristic 16 tries to balance tightness with avoiding extreme fills, using `-slack` as a base and adding a penalty for very tight fits (when `slack` is below a threshold relative to `item`). This is a more sophisticated attempt to balance competing goals.\n- Heuristic 17 is identical to 16.\n- Heuristic 20 prioritizes exact fits with a very high score (1e6), then uses a scaled `-remaining_after_fit` (Best Fit) and a penalty based on negative initial remaining capacity as a tie-breaker. This is a strong multi-objective approach.\n\nHeuristics 18 and 19 are incomplete code snippets.\n\nOverall, heuristics that combine a clear, high priority for exact fits with a well-defined scoring for non-exact fits (like normalized slack or scaled best-fit) tend to perform better. Heuristics that attempt multi-objective optimization (e.g., balancing tightness with avoiding fragmentation or using tie-breakers) show promise but can become complex. The \"Almost Full Fit\" (-slack) is a solid baseline but can be improved by explicit exact-fit handling or more nuanced differentiation.\n- \nHere's a redefined self-reflection for designing better heuristics, focusing on robust differentiation and avoiding pitfalls:\n\n*   **Keywords:** Objective clarity, Score differentiation, Robustness, Scalability.\n*   **Advice:** Design scores that clearly distinguish between excellent fits and good-enough options. Use a hierarchical approach, prioritizing exact matches, then finely tuned slack minimization (normalized or scaled), and finally, stable secondary metrics.\n*   **Avoid:** Over-reliance on absolute slack, direct division by capacities prone to instability, and complex, unexplainable scoring interactions.\n*   **Explanation:** The goal is to create heuristics that make decisive, understandable choices. Clear scoring ensures that the algorithm consistently favors better solutions without getting lost in minor, unstable numerical variations, promoting robustness across different problem scales.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}