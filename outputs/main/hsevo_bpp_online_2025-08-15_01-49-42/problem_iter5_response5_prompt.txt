{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Adaptive Best Fit priority function with capacity normalization.\n\n    This strategy aims to find the bin that minimizes the wasted space (slack)\n    after placing the item, normalized by the bin's original capacity.\n    This normalization helps in comparing bins of different sizes more effectively.\n    It prioritizes bins that are \"best fit\" in a relative sense.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # Calculate remaining capacity after placing the item for eligible bins\n        remaining_capacities_if_fit = eligible_bins_remain_cap - item\n        \n        # To prioritize the \"best fit\" (minimum remaining capacity), we want to maximize\n        # a value that is inversely related to the remaining capacity.\n        # A simple approach is to maximize the negative of the remaining capacity.\n        # To normalize, we can consider the slack relative to the bin's capacity *before* fitting.\n        # However, we only have remaining capacity. A proxy for \"how full\" the bin is\n        # would be related to how much capacity it *had* before this item, which is\n        # `bins_remain_cap[can_fit_mask]`.\n        # We want to prioritize bins that leave minimal slack, and among those,\n        # perhaps those that were already closer to full (i.e., had smaller remaining_cap).\n        \n        # A robust metric is to minimize the *relative* slack.\n        # Relative slack can be defined as (remaining_capacity_after_fit) / (original_capacity_before_fit).\n        # Since we don't have original capacity, we can use the current remaining capacity as a proxy for\n        # how \"full\" the bin is. Bins that are already very full (small bins_remain_cap)\n        # are more sensitive to new items.\n        \n        # Let's define priority as the negative of the remaining capacity after fitting,\n        # but then consider which bins were \"more full\" to begin with.\n        # A good heuristic is to prioritize bins that leave the smallest *absolute* remaining capacity.\n        # If there's a tie in absolute remaining capacity, consider the bin that was closer to full.\n        \n        # Maximize the negative of remaining capacity: higher value for smaller remaining capacity.\n        # This is similar to v1 but we can refine the scoring.\n        \n        # Let's try to maximize `-(remaining_capacity_if_fit)`.\n        # To introduce a preference for bins that were already somewhat full,\n        # we can add a term related to the original remaining capacity.\n        # For instance, we want to minimize `remaining_capacity_if_fit`, and among those,\n        # minimize `bins_remain_cap[can_fit_mask]`.\n        # So, we want to maximize `-(remaining_capacity_if_fit)` and then `-(bins_remain_cap[can_fit_mask])`.\n        \n        # Combine these: prioritize bins with small `remaining_capacities_if_fit`\n        # and among those, prioritize bins with small `bins_remain_cap[can_fit_mask]`.\n        # This can be achieved by maximizing a lexicographical comparison or a weighted sum.\n        \n        # A simple approach that captures \"best fit\" and prefers already fuller bins:\n        # Maximize `-(remaining_capacity_if_fit)`.\n        # To add the \"already fuller\" aspect, let's use a scoring function like:\n        # `-(remaining_capacity_if_fit) - epsilon * bins_remain_cap[can_fit_mask]`\n        # where epsilon is a small positive value. This ensures that if two bins\n        # have the same `remaining_capacity_if_fit`, the one that started with\n        # less remaining capacity (i.e., was fuller) gets a higher score.\n        \n        epsilon = 1e-6 # A small constant to break ties and favor fuller bins\n        \n        # Calculate scores: Higher scores for bins that leave less remaining capacity,\n        # and among those, for bins that were already more full.\n        scores = -(remaining_capacities_if_fit) - epsilon * eligible_bins_remain_cap\n        \n        priorities[can_fit_mask] = scores\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Adaptive Almost Full Fit with Normalized Slack priority function.\n\n    This strategy prioritizes bins that will be \"almost full\" after placing the item,\n    but it adapts to the item's size relative to the bin's capacity and normalizes\n    the slack to avoid issues with vastly different bin capacities.\n\n    The priority is calculated based on the *normalized slack* after placing the item.\n    A smaller normalized slack (meaning the bin is closer to being full relative\n    to its remaining capacity before the item) indicates higher priority.\n    We also incorporate a slight penalty for bins that are too large relative to the item\n    to encourage tighter packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        current_bin_capacities = bins_remain_cap[can_fit_mask]\n        \n        # Calculate remaining capacity after placing the item\n        remaining_capacities_if_fit = current_bin_capacities - item\n        \n        # Calculate a measure of \"how full\" the bin will be relative to its original capacity\n        # We use the capacity *before* placing the item for normalization.\n        # If a bin has capacity C, and we place item I, it leaves C-I remaining.\n        # The \"fullness\" is related to (C-I)/C. We want to minimize this ratio.\n        # To avoid division by zero if original capacity was 0 (shouldn't happen in BPP but for robustness),\n        # we can use the capacity *before* placing the item for normalization.\n        # A smaller remaining capacity relative to the original bin capacity is better.\n        # We are prioritizing bins that will be \"almost full\" after placement.\n        # This means the remaining capacity (current_bin_capacities - item) should be small.\n        \n        # Normalize the remaining capacity by the capacity *before* placing the item.\n        # This gives a measure of slack relative to the bin's size.\n        # We use the capacity of the bin *before* the item is placed for normalization.\n        # A smaller normalized remaining capacity (slack) is better.\n        \n        # Using `current_bin_capacities` for normalization:\n        # slack_ratio = remaining_capacities_if_fit / current_bin_capacities\n        \n        # A more robust normalization would be to use the capacity *of the bin*.\n        # However, since we only have remaining capacities, we can proxy this by\n        # `current_bin_capacities + item` (the capacity the bin *had* before this item).\n        # But a simpler and often effective approach for \"almost full\" is to focus on\n        # minimizing `remaining_capacities_if_fit`.\n        \n        # Let's define priority as inversely proportional to remaining capacity,\n        # but also consider how large the remaining capacity is relative to the item.\n        # A common heuristic is to prioritize the bin with the smallest *positive* remainder.\n        # This means maximizing -(remaining_capacities_if_fit).\n        \n        # To make it \"better\" and \"adaptive\":\n        # We want to penalize bins that are excessively large for the item.\n        # Consider a bin with capacity 100 and item 1. Remaining is 99.\n        # Consider a bin with capacity 10 and item 1. Remaining is 9.\n        # The second bin is relatively fuller.\n        \n        # Let's use the ratio of (item size / bin capacity before placing item)\n        # Higher ratio means the item takes up more of the bin's original capacity.\n        # Then, subtract this ratio from 1 to get a measure of how much capacity is *left* relative to item size.\n        # Or, simply prioritize bins that minimize (remaining_capacity_if_fit).\n\n        # Refined approach: Prioritize bins that minimize remaining capacity.\n        # To make it adaptive, let's use the ratio of the *remaining capacity after fit*\n        # to the *capacity of the bin before the item*.\n        # We want to *minimize* this ratio.\n        # So, priority will be `-(remaining_capacities_if_fit / current_bin_capacities)`.\n        # This normalizes the remaining capacity by the bin's available space.\n        \n        # Add a small epsilon to the denominator to avoid division by zero for bins with zero capacity.\n        epsilon = 1e-9\n        \n        # Calculate normalized slack: remaining capacity after fitting / current bin capacity.\n        # A smaller normalized slack is preferred.\n        normalized_slack = remaining_capacities_if_fit / (current_bin_capacities + epsilon)\n        \n        # The priority should be higher for smaller normalized_slack.\n        # So, we can use -normalized_slack.\n        # To ensure positive scores for fitting bins and to differentiate them clearly from non-fitting bins,\n        # we can add a base score.\n        # Let's aim for higher scores for better fits.\n        # We want to maximize `1 - normalized_slack`. This means minimizing `normalized_slack`.\n        # So, `priority = 1.0 - normalized_slack`.\n        \n        # Consider the case where `current_bin_capacities` is very large compared to `item`.\n        # `normalized_slack` will be close to 1.0, and `1 - normalized_slack` will be close to 0.\n        # If `current_bin_capacities` is just slightly larger than `item`,\n        # `remaining_capacities_if_fit` is small, `normalized_slack` is small,\n        # and `1 - normalized_slack` is close to 1.0. This is good.\n        \n        priorities[can_fit_mask] = 1.0 - normalized_slack\n\n        # Alternative: Prioritize the bin with the minimum remaining capacity directly.\n        # This is the core of \"almost full fit\".\n        # To make it adaptive, we can scale this minimum remaining capacity.\n        # However, the normalized slack approach is generally more robust across different bin scales.\n        \n        # Let's refine the score to ensure it's always positive and higher for better fits,\n        # and clearly distinguishable from non-fitting bins.\n        # We want to maximize the \"fitness\", where fitness is inversely related to slack.\n        # Fitness = 1 / (normalized_slack + epsilon)\n        # However, this can lead to very large numbers if normalized_slack is tiny.\n        \n        # A simpler, robust approach:\n        # Maximize -(remaining_capacities_if_fit). This favors bins that become most full.\n        # To make it adaptive, normalize this difference by the original capacity.\n        # Priority = -(remaining_capacities_if_fit / (current_bin_capacities + epsilon))\n        # This is essentially `normalized_slack` but negated. Higher values are better.\n        \n        priorities[can_fit_mask] = -normalized_slack\n        \n        # To ensure positive scores and to distinguish from the \"-1\" for non-fitting bins,\n        # and to make the \"best fit\" have the highest score, we can transform this.\n        # For example, map the range of potential `-normalized_slack` values to a positive range.\n        # The range of `normalized_slack` is [0, 1]. So, `-normalized_slack` is [-1, 0].\n        # We want to map this to a positive score, where 0 maps to the highest score.\n        # So, we can use `1 + normalized_slack` (range [0, 1]) or `1 - normalized_slack` (range [0, 1]).\n        # `1 - normalized_slack` means smaller normalized slack -> higher priority. This is aligned.\n        \n        priorities[can_fit_mask] = 1.0 - normalized_slack\n        \n        # Let's consider the heuristic advice: \"Focus on precisely defining objective functions (e.g., exact fit satisfaction, minimizing slack), and consistently normalize or scale capacities to create a common comparison basis.\"\n        # Minimizing slack is key. `remaining_capacities_if_fit` is the slack.\n        # Normalizing it by `current_bin_capacities` gives `normalized_slack`.\n        # We want to minimize `normalized_slack`.\n        # Therefore, we want to maximize `1 - normalized_slack`.\n        # This seems to be a good implementation of the advice.\n\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1 ([Heuristics 1st]) and Heuristic 7 ([Heuristics 7th]), they are functionally identical, both using `1.0 / (remaining_after_fit + epsilon)` with `epsilon=1.0` in Heuristic 1 and `epsilon=0.8954438612151145` in Heuristic 7. The choice of `epsilon` is a hyperparameter.\n\nComparing Heuristic 2 ([Heuristics 2nd]) and Heuristic 6 ([Heuristics 6th]), they are identical implementations using `1.0 / (differences + 1.0 + 1e-9)`.\n\nComparing Heuristic 3 ([Heuristics 3rd]) and Heuristic 11 ([Heuristics 11th]), both aim to minimize normalized slack `remaining_capacities_if_fit / current_bin_capacities`. Heuristic 3 uses `-(remaining_capacities_if_fit) - epsilon * eligible_bins_remain_cap` while Heuristic 11 uses `1.0 - normalized_slack`. Heuristic 11's `1.0 - normalized_slack` is a clearer objective function for minimizing slack. Heuristic 3's approach of penalizing already fuller bins might be an interesting secondary objective but adds complexity.\n\nComparing Heuristic 9 ([Heuristics 9th]) and Heuristic 11 ([Heuristics 11th]), they are identical, both implementing `1.0 - normalized_slack` where `normalized_slack` is `remaining_capacities_if_fit / (current_bin_capacities + epsilon)`.\n\nComparing Heuristic 10 ([Heuristics 10th]) and Heuristic 12 ([Heuristics 12th]), they are identical, implementing an exact fit priority of 1.0 and then scaling best fit priorities to a range like [0.5, 0.9].\n\nComparing Heuristic 13 ([Heuristics 13th]) and Heuristic 19 ([Heuristics 19th]), they are identical. They prioritize exact fits with 1.0 and then normalize other scaled inverse priorities so the highest is 1.0.\n\nComparing Heuristic 14 ([Heuristics 14th]) and Heuristic 17 ([Heuristics 17th]) and Heuristic 20 ([Heuristics 20th]), they are identical. They prioritize exact fits with 1.0 and then apply `0.1 / (non_exact_bins_remaining + 1.0)` for non-exact fits.\n\nComparing Heuristic 5 ([Heuristics 5th]) and Heuristic 16 ([Heuristics 16th]): Heuristic 5 directly uses `-(bins_remain_cap[can_fit_mask] - item)` which is equivalent to maximizing the negative slack. Heuristic 16 uses a sigmoid function on normalized differences, which is a more complex approach to prioritize smaller differences.\n\nOverall, heuristics that directly prioritize minimizing slack (like `1.0 - normalized_slack` or negative slack) or exact fits with a clear scoring are generally better. The use of `epsilon` or other constants for stability and scaling is important. Combinations of exact fit with best fit are common and effective.\n- \nHere's a redefinition of \"Current self-reflection\" to inform heuristic design, avoiding the pitfalls of \"Ineffective self-reflection\":\n\n*   **Keywords:** Exact fit, slack minimization, normalized slack, stable scoring, distinct ranking.\n*   **Advice:** Design scoring functions that explicitly reward exact fits, and for imperfect fits, prioritize minimizing normalized slack (slack / bin capacity) to robustly compare options across different bin sizes.\n*   **Avoid:** Direct comparisons of raw slack, numerical instability from division by zero or very small capacities, and overly complex scaling that obscures underlying trade-offs.\n*   **Explanation:** Clear, stable scoring ensures the heuristic reliably identifies the best available bin without getting bogged down by numerical quirks or losing interpretability, crucial for effective optimization.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}