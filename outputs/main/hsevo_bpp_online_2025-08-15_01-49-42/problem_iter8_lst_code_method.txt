{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes exact fits and then applies a scaled inverse slack for remaining bins.\n\n    This heuristic rewards bins that perfectly accommodate the item with a score of 1.0.\n    For other bins, it calculates a priority based on the inverse of the remaining\n    capacity after fitting, ensuring numerical stability and favoring tighter fits.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    suitable_bins_indices = np.where(can_fit_mask)[0]\n\n    # Prioritize exact fits with a score of 1.0\n    exact_fit_mask = suitable_bins_remain_cap == item\n    priorities[suitable_bins_indices[exact_fit_mask]] = 1.0\n\n    # For non-exact fits, use a scaled inverse of the remaining capacity after fitting\n    non_exact_fit_mask = ~exact_fit_mask\n    if np.any(non_exact_fit_mask):\n        non_exact_bins_remain_cap = suitable_bins_remain_cap[non_exact_fit_mask]\n        # Calculate the remaining capacity after fitting the item\n        remaining_after_fit = non_exact_bins_remain_cap - item\n        # Assign priorities: inverse of (remaining_after_fit + 1.0 + epsilon)\n        # Adding 1.0 ensures bins that exactly fit (remaining_after_fit=0) get a high priority (1/1).\n        # A small epsilon (1e-9) prevents division by zero and handles floating-point issues.\n        priorities[suitable_bins_indices[non_exact_fit_mask]] = 1.0 / (remaining_after_fit + 1.0 + 1e-9)\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Best Fit Decreasing (BFD) inspired priority for Online Bin Packing.\n\n    This strategy aims to find a bin that can accommodate the item and, among those,\n    selects the one that leaves the minimum remaining capacity (Best Fit principle).\n    To enhance robustness and handle cases where multiple bins might leave the same\n    minimal remaining capacity, a tie-breaking mechanism is introduced by prioritizing\n    bins with less initial slack (i.e., those that were already closer to being full).\n    This encourages packing larger items into bins that can better accommodate them\n    without wasting much space, aligning with the spirit of BFD for improved packing density.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # Calculate remaining capacity after placing the item\n        remaining_after_fit = fitting_bins_remain_cap - item\n        \n        # Priority 1: Minimize remaining capacity after fitting (Best Fit).\n        # We want to maximize the negative of remaining_after_fit.\n        # A large negative number means a small positive remaining capacity.\n        priority_score_bf = -remaining_after_fit\n        \n        # Priority 2: Tie-breaking - prioritize bins that were closer to full *before* fitting.\n        # This means prioritizing bins with smaller *original* remaining capacity\n        # among those that can fit the item and result in the same minimum 'remaining_after_fit'.\n        # To achieve this, we can penalize bins that have a larger original remaining capacity.\n        # We'll subtract the original remaining capacity from a large number, or simply\n        # use its negative value. Using the negative of the original remaining capacity\n        # means smaller original remaining capacities get higher (less negative) scores.\n        priority_score_tiebreaker = -fitting_bins_remain_cap\n\n        # Combine priorities: Primarily Best Fit, secondarily prefer bins with less initial slack.\n        # A simple way to combine is to use a weighted sum or lexicographical ordering.\n        # Lexicographical ordering is often preferred: sort by the primary criterion first,\n        # then by the secondary criterion for ties.\n        # To implement this with a single score, we can use a scaled value.\n        # For example, score = primary_value * large_constant + secondary_value\n        # Here, we want to maximize `priority_score_bf` and then `priority_score_tiebreaker`.\n        # We can achieve this by: score = priority_score_bf + (priority_score_tiebreaker / scale)\n        # where scale is chosen such that priority_score_bf always dominates priority_score_tiebreaker.\n        # A simpler way if we want to assign higher score:\n        # Let's assign a large multiplier to the primary goal (minimizing remaining capacity).\n        # The secondary goal (less initial slack) will be added.\n        # The primary goal is maximizing -(remaining_after_fit).\n        # The secondary goal is maximizing -(fitting_bins_remain_cap).\n\n        # We want to maximize the \"goodness\".\n        # Goodness is primarily determined by minimizing remaining_after_fit.\n        # So, a higher value of -remaining_after_fit is better.\n        # Secondarily, among bins with the same remaining_after_fit, we want to pick\n        # the one with smaller original fitting_bins_remain_cap. This means a higher\n        # value of -fitting_bins_remain_cap is better.\n\n        # To combine these, we can use a scoring system where the primary factor has\n        # a much larger weight.\n        # Let's scale the tie-breaking score to be much smaller than the primary score.\n        # The range of `remaining_after_fit` could be up to the bin capacity.\n        # The range of `fitting_bins_remain_cap` could also be up to the bin capacity.\n        # If we simply add them, they might interfere.\n        # A common technique is to use a large number for scaling.\n        # Let's assume max bin capacity is M.\n        # A score like: `-(remaining_after_fit) * (M + 1) + -(fitting_bins_remain_cap)`\n        # This ensures that minimizing `remaining_after_fit` is the dominant factor.\n        # The tie-breaker `-(fitting_bins_remain_cap)` ensures that among bins with\n        # the same `remaining_after_fit`, we pick the one with the smallest original capacity.\n\n        # To avoid hardcoding M, we can use a relative scaling.\n        # The maximum possible value for `remaining_after_fit` is bounded by the\n        # maximum possible bin capacity. Let's use a sufficiently large constant,\n        # or estimate a maximum possible capacity if known, or use a very large number.\n        # A safe bet is a number larger than any expected `fitting_bins_remain_cap`.\n        # Let's assume a large constant for scaling.\n        # A very large multiplier ensures that the primary objective (minimizing remaining space)\n        # completely dominates the secondary objective (minimizing initial slack).\n        scale_factor = 1e6 # Sufficiently large to dominate any difference in initial capacities\n\n        combined_priorities = priority_score_bf * scale_factor + priority_score_tiebreaker\n        \n        priorities[can_fit_mask] = combined_priorities\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Best Fit Decreasing (BFD) inspired priority for Online Bin Packing.\n\n    This strategy aims to find a bin that can accommodate the item and, among those,\n    selects the one that leaves the minimum remaining capacity (Best Fit principle).\n    To enhance robustness and handle cases where multiple bins might leave the same\n    minimal remaining capacity, a tie-breaking mechanism is introduced by prioritizing\n    bins with less initial slack (i.e., those that were already closer to being full).\n    This encourages packing larger items into bins that can better accommodate them\n    without wasting much space, aligning with the spirit of BFD for improved packing density.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # Calculate remaining capacity after placing the item\n        remaining_after_fit = fitting_bins_remain_cap - item\n        \n        # Priority 1: Minimize remaining capacity after fitting (Best Fit).\n        # We want to maximize the negative of remaining_after_fit.\n        # A large negative number means a small positive remaining capacity.\n        priority_score_bf = -remaining_after_fit\n        \n        # Priority 2: Tie-breaking - prioritize bins that were closer to full *before* fitting.\n        # This means prioritizing bins with smaller *original* remaining capacity\n        # among those that can fit the item and result in the same minimum 'remaining_after_fit'.\n        # To achieve this, we can penalize bins that have a larger original remaining capacity.\n        # We'll subtract the original remaining capacity from a large number, or simply\n        # use its negative value. Using the negative of the original remaining capacity\n        # means smaller original remaining capacities get higher (less negative) scores.\n        priority_score_tiebreaker = -fitting_bins_remain_cap\n\n        # Combine priorities: Primarily Best Fit, secondarily prefer bins with less initial slack.\n        # A simple way to combine is to use a weighted sum or lexicographical ordering.\n        # Lexicographical ordering is often preferred: sort by the primary criterion first,\n        # then by the secondary criterion for ties.\n        # To implement this with a single score, we can use a scaled value.\n        # For example, score = primary_value * large_constant + secondary_value\n        # Here, we want to maximize `priority_score_bf` and then `priority_score_tiebreaker`.\n        # We can achieve this by: score = priority_score_bf + (priority_score_tiebreaker / scale)\n        # where scale is chosen such that priority_score_bf always dominates priority_score_tiebreaker.\n        # A simpler way if we want to assign higher score:\n        # Let's assign a large multiplier to the primary goal (minimizing remaining capacity).\n        # The secondary goal (less initial slack) will be added.\n        # The primary goal is maximizing -(remaining_after_fit).\n        # The secondary goal is maximizing -(fitting_bins_remain_cap).\n\n        # We want to maximize the \"goodness\".\n        # Goodness is primarily determined by minimizing remaining_after_fit.\n        # So, a higher value of -remaining_after_fit is better.\n        # Secondarily, among bins with the same remaining_after_fit, we want to pick\n        # the one with smaller original fitting_bins_remain_cap. This means a higher\n        # value of -fitting_bins_remain_cap is better.\n\n        # To combine these, we can use a scoring system where the primary factor has\n        # a much larger weight.\n        # Let's scale the tie-breaking score to be much smaller than the primary score.\n        # The range of `remaining_after_fit` could be up to the bin capacity.\n        # The range of `fitting_bins_remain_cap` could also be up to the bin capacity.\n        # If we simply add them, they might interfere.\n        # A common technique is to use a large number for scaling.\n        # Let's assume max bin capacity is M.\n        # A score like: `-(remaining_after_fit) * (M + 1) + -(fitting_bins_remain_cap)`\n        # This ensures that minimizing `remaining_after_fit` is the dominant factor.\n        # The tie-breaker `-(fitting_bins_remain_cap)` ensures that among bins with\n        # the same `remaining_after_fit`, we pick the one with the smallest original capacity.\n\n        # To avoid hardcoding M, we can use a relative scaling.\n        # The maximum possible value for `remaining_after_fit` is bounded by the\n        # maximum possible bin capacity. Let's use a sufficiently large constant,\n        # or estimate a maximum possible capacity if known, or use a very large number.\n        # A safe bet is a number larger than any expected `fitting_bins_remain_cap`.\n        # Let's assume a large constant for scaling.\n        # A very large multiplier ensures that the primary objective (minimizing remaining space)\n        # completely dominates the secondary objective (minimizing initial slack).\n        scale_factor = 1e6 # Sufficiently large to dominate any difference in initial capacities\n\n        combined_priorities = priority_score_bf * scale_factor + priority_score_tiebreaker\n        \n        priorities[can_fit_mask] = combined_priorities\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes exact fits and then applies a scaled inverse slack for remaining bins.\n\n    This heuristic rewards bins that perfectly accommodate the item with a score of 1.0.\n    For other bins, it calculates a priority based on the inverse of the remaining\n    capacity after fitting, ensuring numerical stability and favoring tighter fits.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    suitable_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    suitable_bins_indices = np.where(can_fit_mask)[0]\n\n    # Prioritize exact fits with a score of 1.0\n    exact_fit_mask = suitable_bins_remain_cap == item\n    priorities[suitable_bins_indices[exact_fit_mask]] = 1.0\n\n    # For non-exact fits, use a scaled inverse of the remaining capacity after fitting\n    non_exact_fit_mask = ~exact_fit_mask\n    if np.any(non_exact_fit_mask):\n        non_exact_bins_remain_cap = suitable_bins_remain_cap[non_exact_fit_mask]\n        # Calculate the remaining capacity after fitting the item\n        remaining_after_fit = non_exact_bins_remain_cap - item\n        # Assign priorities: inverse of (remaining_after_fit + 1.0 + epsilon)\n        # Adding 1.0 ensures bins that exactly fit (remaining_after_fit=0) get a high priority (1/1).\n        # A small epsilon (1e-9) prevents division by zero and handles floating-point issues.\n        priorities[suitable_bins_indices[non_exact_fit_mask]] = 1.0 / (remaining_after_fit + 1.0 + 1e-9)\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Almost Full Fit priority function.\n\n    This strategy prioritizes bins that will be \"almost full\" after placing the item.\n    A bin is considered \"almost full\" if its remaining capacity after placing the item\n    is small. We want to select the bin that leaves the minimum remaining capacity,\n    provided it can accommodate the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        remaining_capacities_if_fit = bins_remain_cap[can_fit_mask] - item\n        \n        # We want to prioritize bins where the remaining capacity is *minimal* after fitting.\n        # So, a smaller remaining capacity should yield a higher priority.\n        # We can invert the remaining capacity values and then scale them or just use\n        # a value inversely proportional to the remaining capacity.\n        # Here, we'll use 1 / (remaining_capacity + epsilon) to avoid division by zero\n        # and to ensure smaller remaining capacities get higher scores.\n        # A simple approach is to subtract from a large number or use a negative linear function.\n        # Let's use a value that is inversely proportional to remaining capacity.\n        # However, to keep it simpler and still capture the \"almost full\" idea,\n        # we can assign a higher priority to bins that leave a smaller remainder.\n        # A very direct interpretation of \"almost full\" is to prioritize the bin\n        # that, after placing the item, has the smallest *positive* remaining capacity.\n        # This can be achieved by minimizing `bins_remain_cap - item`.\n        # So, we want to *maximize* the negative of `bins_remain_cap - item`.\n        \n        priorities[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item)\n        \n        # Alternative: Use a small epsilon to make it robust\n        # epsilon = 1e-9\n        # priorities[can_fit_mask] = 1.0 / (remaining_capacities_if_fit + epsilon)\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Exact Fit with Normalized Slack Minimization priority function.\n\n    This strategy prioritizes bins that provide an exact fit for the item.\n    If no exact fit is available, it prioritizes bins that minimize the\n    \"normalized slack\" after placing the item. Normalized slack is defined\n    as (remaining_capacity - item) / original_bin_capacity. This helps\n    to favor bins that have a smaller relative waste, regardless of their\n    absolute remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        bin_capacities: Array of original capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n        Exact fits receive the highest possible score (e.g., a large positive number).\n        Other fits are ranked by the negative of their normalized slack (to maximize).\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    # Assume bin_capacities are available or can be inferred/passed.\n    # For this example, let's assume a constant bin capacity of 1.0 if not provided.\n    # In a real scenario, bin_capacities would likely be an input or stored with bins.\n    # We'll use a placeholder if bin_capacities is not passed implicitly.\n    # A more robust implementation would pass bin_capacities explicitly.\n    \n    # Placeholder for original bin capacities. In a real application, this would be known.\n    # Let's assume for demonstration purposes that all bins have a capacity of 1.0\n    # or that this information is accessible. If not, this heuristic needs adaptation.\n    # A practical approach would be to pass `bin_capacities` as an argument.\n    # For this problem, we'll simulate it assuming a fixed capacity for all bins\n    # to make the \"normalized slack\" concept work. A better design would pass it.\n    \n    # If `bins_remain_cap` were derived from `original_capacity - current_fill`,\n    # then `original_capacity` would be available. For a standalone function,\n    # we'll use a proxy: assume original capacity is related to current fill + remaining.\n    # A common simplification is to assume a standard bin capacity if not explicitly given.\n    # Let's assume a nominal bin capacity for the normalization.\n    # A safer approach is to actually pass the original bin capacities.\n    # For this exercise, we'll make a simplifying assumption:\n    # If item <= 1.0, and bins_remain_cap are used, it implies bins of capacity >= 1.0.\n    # Let's assume all bins have an implicit capacity of 1.0 for normalization purposes.\n    # If the actual bin capacities vary and are not provided, this normalization is problematic.\n    # Assuming a fixed conceptual bin capacity for normalization.\n    \n    # Let's try to infer a capacity if possible or use a default.\n    # A more robust way is to pass `original_bin_capacities` to the function.\n    # For the purpose of this example, we will assume a common bin capacity\n    # if bin_capacities is not an explicit parameter.\n    # If we can't assume a fixed capacity, the normalization needs careful handling.\n\n    # A common pattern in BPP is that items are a fraction of bin capacity,\n    # so if item sizes are like 0.5, 0.2, etc., bin capacity is often 1.0.\n    # Let's use 1.0 as the *reference* capacity for normalization if no better info.\n    # This is a critical assumption.\n    reference_capacity = 1.0 # This should ideally be passed as an argument\n\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        # Prioritize exact fits with a high score\n        exact_fit_mask = (bins_remain_cap == item) & can_fit_mask\n        priorities[exact_fit_mask] = 1e9  # High priority for exact fits\n\n        # For bins that can fit but are not exact fits\n        non_exact_fit_mask = can_fit_mask & ~exact_fit_mask\n        \n        if np.any(non_exact_fit_mask):\n            remaining_after_fit = bins_remain_cap[non_exact_fit_mask] - item\n            \n            # Calculate normalized slack: (remaining_capacity - item) / reference_capacity\n            # We want to MINIMIZE normalized slack, so we maximize its negative.\n            # Add a small epsilon to the denominator to avoid division by zero if reference_capacity is 0\n            # or if we were normalizing by `bins_remain_cap[non_exact_fit_mask]` itself.\n            # Using a fixed reference capacity avoids issues with bins that are already very full.\n            \n            # Normalized slack = (bins_remain_cap[non_exact_fit_mask] - item) / reference_capacity\n            # We want to maximize -(normalized slack)\n            \n            # Using a simple inversion strategy for non-exact fits, prioritizing smaller remainders.\n            # The key is to make it stable and distinct from exact fits.\n            # We can scale the negative remainder.\n            # Maximizing the negative of the slack.\n            \n            # A common way to implement \"minimize slack\" is to use `-(slack)` where slack is positive.\n            # So, for `bins_remain_cap[non_exact_fit_mask] - item`, we want to maximize this value if it's negative,\n            # or minimize it if it's positive.\n            # The \"slack\" is `bins_remain_cap[non_exact_fit_mask] - item`.\n            # We want to minimize this slack. Thus, we maximize `- (slack)`.\n            \n            # Let's prioritize bins that leave smaller positive remaining capacity.\n            # If we want to prioritize MINIMIZING the slack `(bins_remain_cap[non_exact_fit_mask] - item)`\n            # we maximize `-(bins_remain_cap[non_exact_fit_mask] - item)`.\n            \n            # To incorporate \"normalized slack\" and avoid issues with very small bins,\n            # we normalize the slack by a reference capacity.\n            # slack = bins_remain_cap[non_exact_fit_mask] - item\n            # normalized_slack = slack / reference_capacity\n            # priority = -normalized_slack\n            \n            normalized_slack = (bins_remain_cap[non_exact_fit_mask] - item) / reference_capacity\n            priorities[non_exact_fit_mask] = -normalized_slack\n            \n            # A small adjustment to ensure non-exact fits are always less than exact fits,\n            # and to make scores more distinct if needed.\n            # Adding a large offset to the non-exact fit scores ensures they are distinct\n            # from the exact fit scores, but still ordered by their slack.\n            # However, -normalized_slack already achieves ordering.\n            # The key is that `1e9` is significantly larger than any possible `-normalized_slack`.\n            \n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Almost Full Fit priority function.\n\n    This strategy prioritizes bins that will be \"almost full\" after placing the item.\n    A bin is considered \"almost full\" if its remaining capacity after placing the item\n    is small. We want to select the bin that leaves the minimum remaining capacity,\n    provided it can accommodate the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        remaining_capacities_if_fit = bins_remain_cap[can_fit_mask] - item\n        \n        # We want to prioritize bins where the remaining capacity is *minimal* after fitting.\n        # So, a smaller remaining capacity should yield a higher priority.\n        # We can invert the remaining capacity values and then scale them or just use\n        # a value inversely proportional to the remaining capacity.\n        # Here, we'll use 1 / (remaining_capacity + epsilon) to avoid division by zero\n        # and to ensure smaller remaining capacities get higher scores.\n        # A simple approach is to subtract from a large number or use a negative linear function.\n        # Let's use a value that is inversely proportional to remaining capacity.\n        # However, to keep it simpler and still capture the \"almost full\" idea,\n        # we can assign a higher priority to bins that leave a smaller remainder.\n        # A very direct interpretation of \"almost full\" is to prioritize the bin\n        # that, after placing the item, has the smallest *positive* remaining capacity.\n        # This can be achieved by minimizing `bins_remain_cap - item`.\n        # So, we want to *maximize* the negative of `bins_remain_cap - item`.\n        \n        priorities[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item)\n        \n        # Alternative: Use a small epsilon to make it robust\n        # epsilon = 1e-9\n        # priorities[can_fit_mask] = 1.0 / (remaining_capacities_if_fit + epsilon)\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid heuristic: exact fit first, then best-fit by minimizing normalized slack.\n    Prioritizes exact fits with a score of 1.0, then bins that minimize\n    (remaining_capacity - item) / original_bin_capacity.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    # Mask for bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        eligible_indices = np.where(can_fit_mask)[0]\n\n        # Exact fit: highest priority\n        exact_fit_mask = (eligible_bins_remain_cap == item)\n        if np.any(exact_fit_mask):\n            priorities[eligible_indices[exact_fit_mask]] = 1.0\n        \n        # Best fit for non-exact fits: minimize normalized slack\n        # Slack = remaining_capacity - item\n        # Normalized slack = slack / current_bin_capacity\n        # We want to MINIMIZE normalized slack, so HIGHER priority for smaller normalized slack.\n        non_exact_fit_mask = (eligible_bins_remain_cap > item)\n        \n        if np.any(non_exact_fit_mask):\n            non_exact_indices = eligible_indices[non_exact_fit_mask]\n            non_exact_remain_caps = eligible_bins_remain_cap[non_exact_fit_mask]\n            \n            # To get original bin capacities, we'd need to know them.\n            # Assuming the provided 'bins_remain_cap' are from a full set of bins,\n            # and we don't have the original capacities here.\n            # A practical proxy: use the current remaining capacity if it's not too small,\n            # or a fixed large number for normalization if capacity is not available.\n            # However, the prompt implies 'bins_remain_cap' IS the state.\n            # Let's redefine based on common best-fit: minimize remaining capacity after packing.\n            # This is a common \"best-fit\" interpretation.\n            \n            # If we strictly want \"normalized slack\" (slack / original_capacity),\n            # we'd need original capacities. Without it, we fall back to minimizing slack.\n            # The \"Better code\" example used negative slack. Let's refine that.\n            \n            # Strategy: Prioritize bins that leave the LEAST remaining capacity.\n            # This is equivalent to maximizing -(remaining_capacity - item).\n            # To avoid large negative numbers and ensure stable ranking, we can normalize.\n            # Let's use the \"Better code\" logic as it's clean for Best Fit: minimize residual.\n            \n            # Let's take the 'priority_v0' approach of minimizing remaining capacity after fit\n            # but ensure it's distinct from exact fit.\n            \n            # For non-exact fits, score based on how much capacity is left after fitting.\n            # Lower remaining capacity after fitting = higher priority.\n            remaining_after_fit = non_exact_remain_caps - item\n            \n            # To make scores distinct and avoid issues with very small residuals,\n            # we can use a scaled inverse. A common approach is to subtract from a constant\n            # or use a decreasing function.\n            # Let's use a score that is inversely proportional to the residual capacity,\n            # but scaled to be less than 1.0.\n            # Example: 0.5 + 0.4 * (1 - normalized_residual)\n            # Where normalized_residual = residual / max_residual\n            \n            if len(remaining_after_fit) > 0:\n                max_remaining_after_fit = np.max(remaining_after_fit)\n                # Normalize residuals to [0, 1], where 0 is best (min residual)\n                # Add epsilon for stability if all residuals are same\n                normalized_remaining = remaining_after_fit / (max_remaining_after_fit + 1e-9)\n                \n                # Scale to a range below 1.0, e.g., [0.5, 0.95].\n                # This maps best-fit (normalized_remaining near 0) to ~0.95\n                # and worst-fit (normalized_remaining near 1) to ~0.5.\n                best_fit_scores = 0.5 + (1.0 - normalized_remaining) * 0.45\n                \n                priorities[non_exact_indices] = best_fit_scores\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes exact fits, then bins with minimal normalized slack using a stable scoring.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Exact Fit: Highest priority (1.0)\n    exact_fit_indices = np.where(bins_remain_cap == item)[0]\n    priorities[exact_fit_indices] = 1.0\n\n    # Best Fit: Prioritize bins with minimal positive remaining capacity after fitting.\n    # Consider bins that can fit the item and are not exact fits.\n    can_fit_mask = (bins_remain_cap >= item) & (bins_remain_cap != item)\n    fit_indices = np.where(can_fit_mask)[0]\n\n    if len(fit_indices) > 0:\n        remaining_after_fit = bins_remain_cap[fit_indices] - item\n        current_capacities = bins_remain_cap[fit_indices]\n\n        # Calculate normalized slack: (remaining_capacity_after_fit) / (current_bin_capacity)\n        # Smaller normalized slack is better. Add epsilon for numerical stability.\n        normalized_slack = remaining_after_fit / (current_capacities + 1e-9)\n\n        # Assign priorities that are higher for smaller normalized slack.\n        # We use 1.0 - normalized_slack to map smaller slack to higher scores.\n        # Scale these scores to be clearly less than 1.0, e.g., into the range [0.5, 0.99].\n        # A linear scaling: 0.5 + (1.0 - normalized_slack) * 0.49\n        best_fit_scores = 1.0 - normalized_slack\n        scaled_best_fit_priorities = 0.5 + best_fit_scores * 0.49\n\n        priorities[fit_indices] = scaled_best_fit_priorities\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes exact fits, then bins with minimal normalized slack using a stable scoring.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Exact Fit: Highest priority (1.0)\n    exact_fit_indices = np.where(bins_remain_cap == item)[0]\n    priorities[exact_fit_indices] = 1.0\n\n    # Best Fit: Prioritize bins with minimal positive remaining capacity after fitting.\n    # Consider bins that can fit the item and are not exact fits.\n    can_fit_mask = (bins_remain_cap >= item) & (bins_remain_cap != item)\n    fit_indices = np.where(can_fit_mask)[0]\n\n    if len(fit_indices) > 0:\n        remaining_after_fit = bins_remain_cap[fit_indices] - item\n        current_capacities = bins_remain_cap[fit_indices]\n\n        # Calculate normalized slack: (remaining_capacity_after_fit) / (current_bin_capacity)\n        # Smaller normalized slack is better. Add epsilon for numerical stability.\n        normalized_slack = remaining_after_fit / (current_capacities + 1e-9)\n\n        # Assign priorities that are higher for smaller normalized slack.\n        # We use 1.0 - normalized_slack to map smaller slack to higher scores.\n        # Scale these scores to be clearly less than 1.0, e.g., into the range [0.5, 0.99].\n        # A linear scaling: 0.5 + (1.0 - normalized_slack) * 0.49\n        best_fit_scores = 1.0 - normalized_slack\n        scaled_best_fit_priorities = 0.5 + best_fit_scores * 0.49\n\n        priorities[fit_indices] = scaled_best_fit_priorities\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid heuristic: exact fit first, then best-fit by minimizing normalized slack.\n    Prioritizes exact fits with a score of 1.0, then bins that minimize\n    (remaining_capacity - item) / original_bin_capacity.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    # Mask for bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        eligible_indices = np.where(can_fit_mask)[0]\n\n        # Exact fit: highest priority\n        exact_fit_mask = (eligible_bins_remain_cap == item)\n        if np.any(exact_fit_mask):\n            priorities[eligible_indices[exact_fit_mask]] = 1.0\n        \n        # Best fit for non-exact fits: minimize normalized slack\n        # Slack = remaining_capacity - item\n        # Normalized slack = slack / current_bin_capacity\n        # We want to MINIMIZE normalized slack, so HIGHER priority for smaller normalized slack.\n        non_exact_fit_mask = (eligible_bins_remain_cap > item)\n        \n        if np.any(non_exact_fit_mask):\n            non_exact_indices = eligible_indices[non_exact_fit_mask]\n            non_exact_remain_caps = eligible_bins_remain_cap[non_exact_fit_mask]\n            \n            # To get original bin capacities, we'd need to know them.\n            # Assuming the provided 'bins_remain_cap' are from a full set of bins,\n            # and we don't have the original capacities here.\n            # A practical proxy: use the current remaining capacity if it's not too small,\n            # or a fixed large number for normalization if capacity is not available.\n            # However, the prompt implies 'bins_remain_cap' IS the state.\n            # Let's redefine based on common best-fit: minimize remaining capacity after packing.\n            # This is a common \"best-fit\" interpretation.\n            \n            # If we strictly want \"normalized slack\" (slack / original_capacity),\n            # we'd need original capacities. Without it, we fall back to minimizing slack.\n            # The \"Better code\" example used negative slack. Let's refine that.\n            \n            # Strategy: Prioritize bins that leave the LEAST remaining capacity.\n            # This is equivalent to maximizing -(remaining_capacity - item).\n            # To avoid large negative numbers and ensure stable ranking, we can normalize.\n            # Let's use the \"Better code\" logic as it's clean for Best Fit: minimize residual.\n            \n            # Let's take the 'priority_v0' approach of minimizing remaining capacity after fit\n            # but ensure it's distinct from exact fit.\n            \n            # For non-exact fits, score based on how much capacity is left after fitting.\n            # Lower remaining capacity after fitting = higher priority.\n            remaining_after_fit = non_exact_remain_caps - item\n            \n            # To make scores distinct and avoid issues with very small residuals,\n            # we can use a scaled inverse. A common approach is to subtract from a constant\n            # or use a decreasing function.\n            # Let's use a score that is inversely proportional to the residual capacity,\n            # but scaled to be less than 1.0.\n            # Example: 0.5 + 0.4 * (1 - normalized_residual)\n            # Where normalized_residual = residual / max_residual\n            \n            if len(remaining_after_fit) > 0:\n                max_remaining_after_fit = np.max(remaining_after_fit)\n                # Normalize residuals to [0, 1], where 0 is best (min residual)\n                # Add epsilon for stability if all residuals are same\n                normalized_remaining = remaining_after_fit / (max_remaining_after_fit + 1e-9)\n                \n                # Scale to a range below 1.0, e.g., [0.5, 0.95].\n                # This maps best-fit (normalized_remaining near 0) to ~0.95\n                # and worst-fit (normalized_remaining near 1) to ~0.5.\n                best_fit_scores = 0.5 + (1.0 - normalized_remaining) * 0.45\n                \n                priorities[non_exact_indices] = best_fit_scores\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid heuristic: exact fit first, then best-fit by minimizing normalized slack.\n    Prioritizes exact fits with a score of 1.0, then bins that minimize\n    (remaining_capacity - item) / original_bin_capacity.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    # Mask for bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        eligible_indices = np.where(can_fit_mask)[0]\n\n        # Exact fit: highest priority\n        exact_fit_mask = (eligible_bins_remain_cap == item)\n        if np.any(exact_fit_mask):\n            priorities[eligible_indices[exact_fit_mask]] = 1.0\n        \n        # Best fit for non-exact fits: minimize normalized slack\n        # Slack = remaining_capacity - item\n        # Normalized slack = slack / current_bin_capacity\n        # We want to MINIMIZE normalized slack, so HIGHER priority for smaller normalized slack.\n        non_exact_fit_mask = (eligible_bins_remain_cap > item)\n        \n        if np.any(non_exact_fit_mask):\n            non_exact_indices = eligible_indices[non_exact_fit_mask]\n            non_exact_remain_caps = eligible_bins_remain_cap[non_exact_fit_mask]\n            \n            # To get original bin capacities, we'd need to know them.\n            # Assuming the provided 'bins_remain_cap' are from a full set of bins,\n            # and we don't have the original capacities here.\n            # A practical proxy: use the current remaining capacity if it's not too small,\n            # or a fixed large number for normalization if capacity is not available.\n            # However, the prompt implies 'bins_remain_cap' IS the state.\n            # Let's redefine based on common best-fit: minimize remaining capacity after packing.\n            # This is a common \"best-fit\" interpretation.\n            \n            # If we strictly want \"normalized slack\" (slack / original_capacity),\n            # we'd need original capacities. Without it, we fall back to minimizing slack.\n            # The \"Better code\" example used negative slack. Let's refine that.\n            \n            # Strategy: Prioritize bins that leave the LEAST remaining capacity.\n            # This is equivalent to maximizing -(remaining_capacity - item).\n            # To avoid large negative numbers and ensure stable ranking, we can normalize.\n            # Let's use the \"Better code\" logic as it's clean for Best Fit: minimize residual.\n            \n            # Let's take the 'priority_v0' approach of minimizing remaining capacity after fit\n            # but ensure it's distinct from exact fit.\n            \n            # For non-exact fits, score based on how much capacity is left after fitting.\n            # Lower remaining capacity after fitting = higher priority.\n            remaining_after_fit = non_exact_remain_caps - item\n            \n            # To make scores distinct and avoid issues with very small residuals,\n            # we can use a scaled inverse. A common approach is to subtract from a constant\n            # or use a decreasing function.\n            # Let's use a score that is inversely proportional to the residual capacity,\n            # but scaled to be less than 1.0.\n            # Example: 0.5 + 0.4 * (1 - normalized_residual)\n            # Where normalized_residual = residual / max_residual\n            \n            if len(remaining_after_fit) > 0:\n                max_remaining_after_fit = np.max(remaining_after_fit)\n                # Normalize residuals to [0, 1], where 0 is best (min residual)\n                # Add epsilon for stability if all residuals are same\n                normalized_remaining = remaining_after_fit / (max_remaining_after_fit + 1e-9)\n                \n                # Scale to a range below 1.0, e.g., [0.5, 0.95].\n                # This maps best-fit (normalized_remaining near 0) to ~0.95\n                # and worst-fit (normalized_remaining near 1) to ~0.5.\n                best_fit_scores = 0.5 + (1.0 - normalized_remaining) * 0.45\n                \n                priorities[non_exact_indices] = best_fit_scores\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid heuristic: exact fit first, then best-fit by minimizing normalized slack.\n    Prioritizes exact fits with a score of 1.0, then bins that minimize\n    (remaining_capacity - item) / original_bin_capacity.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    # Mask for bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        eligible_indices = np.where(can_fit_mask)[0]\n\n        # Exact fit: highest priority\n        exact_fit_mask = (eligible_bins_remain_cap == item)\n        if np.any(exact_fit_mask):\n            priorities[eligible_indices[exact_fit_mask]] = 1.0\n        \n        # Best fit for non-exact fits: minimize normalized slack\n        # Slack = remaining_capacity - item\n        # Normalized slack = slack / current_bin_capacity\n        # We want to MINIMIZE normalized slack, so HIGHER priority for smaller normalized slack.\n        non_exact_fit_mask = (eligible_bins_remain_cap > item)\n        \n        if np.any(non_exact_fit_mask):\n            non_exact_indices = eligible_indices[non_exact_fit_mask]\n            non_exact_remain_caps = eligible_bins_remain_cap[non_exact_fit_mask]\n            \n            # To get original bin capacities, we'd need to know them.\n            # Assuming the provided 'bins_remain_cap' are from a full set of bins,\n            # and we don't have the original capacities here.\n            # A practical proxy: use the current remaining capacity if it's not too small,\n            # or a fixed large number for normalization if capacity is not available.\n            # However, the prompt implies 'bins_remain_cap' IS the state.\n            # Let's redefine based on common best-fit: minimize remaining capacity after packing.\n            # This is a common \"best-fit\" interpretation.\n            \n            # If we strictly want \"normalized slack\" (slack / original_capacity),\n            # we'd need original capacities. Without it, we fall back to minimizing slack.\n            # The \"Better code\" example used negative slack. Let's refine that.\n            \n            # Strategy: Prioritize bins that leave the LEAST remaining capacity.\n            # This is equivalent to maximizing -(remaining_capacity - item).\n            # To avoid large negative numbers and ensure stable ranking, we can normalize.\n            # Let's use the \"Better code\" logic as it's clean for Best Fit: minimize residual.\n            \n            # Let's take the 'priority_v0' approach of minimizing remaining capacity after fit\n            # but ensure it's distinct from exact fit.\n            \n            # For non-exact fits, score based on how much capacity is left after fitting.\n            # Lower remaining capacity after fitting = higher priority.\n            remaining_after_fit = non_exact_remain_caps - item\n            \n            # To make scores distinct and avoid issues with very small residuals,\n            # we can use a scaled inverse. A common approach is to subtract from a constant\n            # or use a decreasing function.\n            # Let's use a score that is inversely proportional to the residual capacity,\n            # but scaled to be less than 1.0.\n            # Example: 0.5 + 0.4 * (1 - normalized_residual)\n            # Where normalized_residual = residual / max_residual\n            \n            if len(remaining_after_fit) > 0:\n                max_remaining_after_fit = np.max(remaining_after_fit)\n                # Normalize residuals to [0, 1], where 0 is best (min residual)\n                # Add epsilon for stability if all residuals are same\n                normalized_remaining = remaining_after_fit / (max_remaining_after_fit + 1e-9)\n                \n                # Scale to a range below 1.0, e.g., [0.5, 0.95].\n                # This maps best-fit (normalized_remaining near 0) to ~0.95\n                # and worst-fit (normalized_remaining near 1) to ~0.5.\n                best_fit_scores = 0.5 + (1.0 - normalized_remaining) * 0.45\n                \n                priorities[non_exact_indices] = best_fit_scores\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes exact fits, then bins with minimal normalized slack.\n\n    This heuristic combines the \"exact fit\" strategy with a \"best fit\"\n    approach normalized by remaining capacity, ensuring clear ranking.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    exact_fit_mask = bins_remain_cap == item\n    non_exact_fit_mask = bins_remain_cap > item\n    \n    # Prioritize exact fits with a score of 1.0\n    priorities[exact_fit_mask] = 1.0\n    \n    # For non-exact fits, calculate priority based on normalized slack\n    if np.any(non_exact_fit_mask):\n        eligible_bins_remain_cap = bins_remain_cap[non_exact_fit_mask]\n        \n        # Calculate remaining capacity after placing the item\n        remaining_capacities_if_fit = eligible_bins_remain_cap - item\n        \n        # Calculate normalized slack: remaining capacity / current bin capacity\n        # Add epsilon for numerical stability for bins that might have 0 capacity (though unlikely in BPP)\n        epsilon = 1e-9\n        normalized_slack = remaining_capacities_if_fit / (eligible_bins_remain_cap + epsilon)\n        \n        # Priority is 1 - normalized_slack: smaller slack means higher priority (closer to 1.0)\n        # This maps the best fit (smallest normalized slack) to a score close to 1.0,\n        # and progressively lower scores for bins with larger normalized slack.\n        # This also ensures scores are positive and distinct from exact fits (1.0).\n        priorities[non_exact_fit_mask] = 1.0 - normalized_slack\n\n    # If there are exact fits, they are already set to 1.0.\n    # For non-exact fits, scores will be in the range [0, 1).\n    # We can shift non-exact fit scores slightly lower if we want exact fits to be strictly dominant.\n    # For example, subtract a small value from non-exact fit scores if any exact fits exist.\n    # However, the current scheme where exact fits are 1.0 and others are < 1.0 naturally handles this.\n    \n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins by rewarding exact fits and then minimizing normalized slack\n    for non-exact fits, ensuring stability.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n\n    eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    # Prioritize exact fits with a high score\n    exact_fit_mask = np.isclose(eligible_bins_remain_cap, item)\n    priorities[can_fit_mask][exact_fit_mask] = 1.0\n    \n    # For non-exact fits, minimize normalized slack (remaining capacity after fit / original bin capacity)\n    non_exact_fit_mask = ~exact_fit_mask\n    if np.any(non_exact_fit_mask):\n        non_exact_eligible_bins_remain_cap = eligible_bins_remain_cap[non_exact_fit_mask]\n        \n        # Calculate remaining capacity after placing the item\n        remaining_after_fit = non_exact_eligible_bins_remain_cap - item\n        \n        # Original capacities for the eligible non-exact fit bins\n        original_capacities = bins_remain_cap[can_fit_mask][non_exact_fit_mask]\n        \n        # Calculate normalized slack. Add epsilon to denominator for stability.\n        # Higher priority for smaller normalized slack.\n        normalized_slack = remaining_after_fit / (original_capacities + 1e-9)\n        \n        # Invert normalized slack to get priority, so smaller slack gets higher priority\n        # Add 1 to inverted slack to shift values and ensure positive priorities,\n        # making them distinct from exact fit score of 1.0.\n        priorities[can_fit_mask][non_exact_fit_mask] = 1.0 + (1.0 / (normalized_slack + 1e-9))\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines exact fit priority with normalized slack for effective online bin packing.\n\n    Prioritizes bins that achieve an exact fit with a high score (1.0). For other\n    bins, it calculates priority based on minimizing normalized slack, ensuring\n    better-fitting bins receive higher scores.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        current_bin_capacities = bins_remain_cap[can_fit_mask]\n        remaining_capacities_if_fit = current_bin_capacities - item\n        \n        # Exact fit has the highest priority\n        exact_fit_mask = remaining_capacities_if_fit == 0\n        priorities[can_fit_mask][exact_fit_mask] = 1.0\n        \n        # For non-exact fits, calculate priority based on normalized slack\n        # Minimized normalized slack means higher priority.\n        # We use 1.0 - normalized_slack to map smaller slack to higher priority.\n        non_exact_fit_mask = ~exact_fit_mask\n        if np.any(non_exact_fit_mask):\n            non_exact_bins_capacities = current_bin_capacities[non_exact_fit_mask]\n            non_exact_bins_remaining = remaining_capacities_if_fit[non_exact_fit_mask]\n            \n            # Add epsilon for numerical stability, avoid division by zero\n            epsilon = 1e-9\n            normalized_slack = non_exact_bins_remaining / (non_exact_bins_capacities + epsilon)\n            \n            # Priority is higher for smaller normalized slack\n            # Assign priorities in the range (0, 1) to distinguish from exact fits\n            priorities[can_fit_mask][non_exact_fit_mask] = 0.5 * (1.0 - normalized_slack)\n            \n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins by rewarding exact fits and then minimizing normalized slack\n    for non-exact fits, ensuring stability.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n\n    eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    # Prioritize exact fits with a high score\n    exact_fit_mask = np.isclose(eligible_bins_remain_cap, item)\n    priorities[can_fit_mask][exact_fit_mask] = 1.0\n    \n    # For non-exact fits, minimize normalized slack (remaining capacity after fit / original bin capacity)\n    non_exact_fit_mask = ~exact_fit_mask\n    if np.any(non_exact_fit_mask):\n        non_exact_eligible_bins_remain_cap = eligible_bins_remain_cap[non_exact_fit_mask]\n        \n        # Calculate remaining capacity after placing the item\n        remaining_after_fit = non_exact_eligible_bins_remain_cap - item\n        \n        # Original capacities for the eligible non-exact fit bins\n        original_capacities = bins_remain_cap[can_fit_mask][non_exact_fit_mask]\n        \n        # Calculate normalized slack. Add epsilon to denominator for stability.\n        # Higher priority for smaller normalized slack.\n        normalized_slack = remaining_after_fit / (original_capacities + 1e-9)\n        \n        # Invert normalized slack to get priority, so smaller slack gets higher priority\n        # Add 1 to inverted slack to shift values and ensure positive priorities,\n        # making them distinct from exact fit score of 1.0.\n        priorities[can_fit_mask][non_exact_fit_mask] = 1.0 + (1.0 / (normalized_slack + 1e-9))\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Enhanced priority function focusing on exact fits and normalized slack minimization.\n\n    This strategy prioritizes bins that can accommodate the item. Among those,\n    it gives the highest priority to bins that result in an exact fit (zero remaining capacity).\n    For bins that do not result in an exact fit, it prioritizes those with the\n    minimum normalized slack. Normalized slack is defined as (remaining_capacity - item) / original_bin_capacity.\n    Since original bin capacities are not directly available, we approximate this by\n    minimizing (remaining_capacity - item) / (remaining_capacity - item + item),\n    which is (remaining_capacity - item) / remaining_capacity.\n    A higher score indicates a higher priority. Bins that cannot accommodate the item receive -1.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # Calculate the remaining capacity after placing the item\n        remaining_capacity_after_fit = eligible_bins_remain_cap - item\n        \n        # Assign highest priority to exact fits (remaining capacity is 0)\n        exact_fit_mask = remaining_capacity_after_fit == 0\n        priorities[can_fit_mask][exact_fit_mask] = 1e6 # A very high score for exact fits\n        \n        # For bins that are not an exact fit, calculate normalized slack\n        non_exact_fit_mask = ~exact_fit_mask\n        \n        if np.any(non_exact_fit_mask):\n            non_exact_bins_remain_cap = eligible_bins_remain_cap[non_exact_fit_mask]\n            non_exact_remaining_after_fit = remaining_capacity_after_fit[non_exact_fit_mask]\n            \n            # Calculate normalized slack: (remaining_capacity - item) / remaining_capacity\n            # Using bins_remain_cap[can_fit_mask][non_exact_fit_mask] as proxy for original capacity\n            # to normalize the slack.\n            # We want to minimize this normalized slack, so we'll take its negative\n            # to turn minimization into maximization.\n            epsilon = 1e-9 # To avoid division by zero or very small numbers for remaining capacity\n            normalized_slack = non_exact_remaining_after_fit / (non_exact_bins_remain_cap + epsilon)\n            \n            # Assign priorities inversely proportional to normalized slack (higher score for smaller slack)\n            # Scale to ensure it's distinct from exact fit scores but still significant\n            priorities[can_fit_mask][non_exact_fit_mask] = -normalized_slack * 1e5 \n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, exact_fit_score: float = 0.6221939425321547, slack_offset: float = 1.5472562340337874, epsilon: float = 3.468417022637977e-09) -> np.ndarray:\n    \"\"\"Prioritizes exact fits and then applies a scaled inverse slack for remaining bins.\n\n    This heuristic rewards bins that perfectly accommodate the item with a score of `exact_fit_score`.\n    For other bins, it calculates a priority based on the inverse of the remaining\n    capacity after fitting, ensuring numerical stability and favoring tighter fits.\n\n    Args:\n        item: The size of the item to be placed.\n        bins_remain_cap: A numpy array representing the remaining capacity of each bin.\n        exact_fit_score: The score assigned to bins that perfectly fit the item.\n        slack_offset: A value added to the remaining capacity for inverse calculation,\n                      ensuring bins with zero remaining capacity after fit get a high priority.\n        epsilon: A small value to prevent division by zero and handle floating-point inaccuracies.\n\n    Returns:\n        A numpy array representing the priority score for each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Enhanced priority function focusing on exact fits and normalized slack minimization.\n\n    This strategy prioritizes bins that can accommodate the item. Among those,\n    it gives the highest priority to bins that result in an exact fit (zero remaining capacity).\n    For bins that do not result in an exact fit, it prioritizes those with the\n    minimum normalized slack. Normalized slack is defined as (remaining_capacity - item) / original_bin_capacity.\n    Since original bin capacities are not directly available, we approximate this by\n    minimizing (remaining_capacity - item) / (remaining_capacity - item + item),\n    which is (remaining_capacity - item) / remaining_capacity.\n    A higher score indicates a higher priority. Bins that cannot accommodate the item receive -1.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # Calculate the remaining capacity after placing the item\n        remaining_capacity_after_fit = eligible_bins_remain_cap - item\n        \n        # Assign highest priority to exact fits (remaining capacity is 0)\n        exact_fit_mask = remaining_capacity_after_fit == 0\n        priorities[can_fit_mask][exact_fit_mask] = 1e6 # A very high score for exact fits\n        \n        # For bins that are not an exact fit, calculate normalized slack\n        non_exact_fit_mask = ~exact_fit_mask\n        \n        if np.any(non_exact_fit_mask):\n            non_exact_bins_remain_cap = eligible_bins_remain_cap[non_exact_fit_mask]\n            non_exact_remaining_after_fit = remaining_capacity_after_fit[non_exact_fit_mask]\n            \n            # Calculate normalized slack: (remaining_capacity - item) / remaining_capacity\n            # Using bins_remain_cap[can_fit_mask][non_exact_fit_mask] as proxy for original capacity\n            # to normalize the slack.\n            # We want to minimize this normalized slack, so we'll take its negative\n            # to turn minimization into maximization.\n            epsilon = 1e-9 # To avoid division by zero or very small numbers for remaining capacity\n            normalized_slack = non_exact_remaining_after_fit / (non_exact_bins_remain_cap + epsilon)\n            \n            # Assign priorities inversely proportional to normalized slack (higher score for smaller slack)\n            # Scale to ensure it's distinct from exact fit scores but still significant\n            priorities[can_fit_mask][non_exact_fit_mask] = -normalized_slack * 1e5 \n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}