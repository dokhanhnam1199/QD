{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritizes bins using a hybrid approach: favoring exact fits and then\n    best fits by inverting the remaining capacity, while ensuring stability.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate remaining capacity after placing the item for fitting bins\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n    \n    # Calculate priority: higher for bins that will be more full (less remaining capacity)\n    # Adding 1.0 to the denominator to avoid division by zero and to ensure\n    # that bins with zero remaining capacity get a high but finite priority.\n    # This is a stable inversion that prioritizes bins that result in less slack.\n    priorities[can_fit_mask] = 1.0 / (remaining_after_fit + 1.0)\n    \n    # Bins that cannot fit the item receive zero priority, meaning they are not considered.\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Prioritizes bins by favoring exact fits and then best fits using a scaled inverse.\n    Combines the exact fit preference of Best Fit with the scaled inverse approach of Softmax-Based Fit.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    eligible_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(eligible_bins_mask):\n        return priorities\n\n    eligible_bins_remain_cap = bins_remain_cap[eligible_bins_mask]\n    \n    # Prioritize exact fits with a high score\n    exact_fit_mask = np.isclose(eligible_bins_remain_cap, item)\n    priorities[eligible_bins_mask][exact_fit_mask] = 1.0\n    \n    # For non-exact fits, use a scaled inverse of the remaining capacity\n    non_exact_fit_mask = ~exact_fit_mask\n    if np.any(non_exact_fit_mask):\n        non_exact_eligible_bins_remain_cap = eligible_bins_remain_cap[non_exact_fit_mask]\n        \n        # Scale differences to be between 0 and 1 for the inverse calculation\n        # Add 1 to the difference to avoid division by zero and to penalize\n        # bins that are slightly larger than needed.\n        differences = non_exact_eligible_bins_remain_cap - item\n        \n        # Use a robust scaling similar to the softmax approach, but without exponentiation\n        # to avoid potential overflow and maintain a more linear preference for smaller remaining capacities.\n        # Adding 1e-9 for numerical stability.\n        scaled_inverse = 1.0 / (differences + 1.0 + 1e-9)\n        \n        # Normalize these scaled inverse priorities so the highest is 1,\n        # making them comparable to the exact fit score of 1.0.\n        if np.max(scaled_inverse) > 1e-9: # Avoid division by zero if all scaled_inverse are near zero\n            normalized_scaled_inverse = scaled_inverse / np.max(scaled_inverse)\n        else:\n            normalized_scaled_inverse = scaled_inverse # Or handle as a special case if needed\n            \n        priorities[eligible_bins_mask][non_exact_fit_mask] = normalized_scaled_inverse\n\n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1 ([Heuristics 1st]) and Heuristic 7 ([Heuristics 7th]), they are functionally identical, both using `1.0 / (remaining_after_fit + epsilon)` with `epsilon=1.0` in Heuristic 1 and `epsilon=0.8954438612151145` in Heuristic 7. The choice of `epsilon` is a hyperparameter.\n\nComparing Heuristic 2 ([Heuristics 2nd]) and Heuristic 6 ([Heuristics 6th]), they are identical implementations using `1.0 / (differences + 1.0 + 1e-9)`.\n\nComparing Heuristic 3 ([Heuristics 3rd]) and Heuristic 11 ([Heuristics 11th]), both aim to minimize normalized slack `remaining_capacities_if_fit / current_bin_capacities`. Heuristic 3 uses `-(remaining_capacities_if_fit) - epsilon * eligible_bins_remain_cap` while Heuristic 11 uses `1.0 - normalized_slack`. Heuristic 11's `1.0 - normalized_slack` is a clearer objective function for minimizing slack. Heuristic 3's approach of penalizing already fuller bins might be an interesting secondary objective but adds complexity.\n\nComparing Heuristic 9 ([Heuristics 9th]) and Heuristic 11 ([Heuristics 11th]), they are identical, both implementing `1.0 - normalized_slack` where `normalized_slack` is `remaining_capacities_if_fit / (current_bin_capacities + epsilon)`.\n\nComparing Heuristic 10 ([Heuristics 10th]) and Heuristic 12 ([Heuristics 12th]), they are identical, implementing an exact fit priority of 1.0 and then scaling best fit priorities to a range like [0.5, 0.9].\n\nComparing Heuristic 13 ([Heuristics 13th]) and Heuristic 19 ([Heuristics 19th]), they are identical. They prioritize exact fits with 1.0 and then normalize other scaled inverse priorities so the highest is 1.0.\n\nComparing Heuristic 14 ([Heuristics 14th]) and Heuristic 17 ([Heuristics 17th]) and Heuristic 20 ([Heuristics 20th]), they are identical. They prioritize exact fits with 1.0 and then apply `0.1 / (non_exact_bins_remaining + 1.0)` for non-exact fits.\n\nComparing Heuristic 5 ([Heuristics 5th]) and Heuristic 16 ([Heuristics 16th]): Heuristic 5 directly uses `-(bins_remain_cap[can_fit_mask] - item)` which is equivalent to maximizing the negative slack. Heuristic 16 uses a sigmoid function on normalized differences, which is a more complex approach to prioritize smaller differences.\n\nOverall, heuristics that directly prioritize minimizing slack (like `1.0 - normalized_slack` or negative slack) or exact fits with a clear scoring are generally better. The use of `epsilon` or other constants for stability and scaling is important. Combinations of exact fit with best fit are common and effective.\n- \nHere's a redefinition of \"Current self-reflection\" to inform heuristic design, avoiding the pitfalls of \"Ineffective self-reflection\":\n\n*   **Keywords:** Exact fit, slack minimization, normalized slack, stable scoring, distinct ranking.\n*   **Advice:** Design scoring functions that explicitly reward exact fits, and for imperfect fits, prioritize minimizing normalized slack (slack / bin capacity) to robustly compare options across different bin sizes.\n*   **Avoid:** Direct comparisons of raw slack, numerical instability from division by zero or very small capacities, and overly complex scaling that obscures underlying trade-offs.\n*   **Explanation:** Clear, stable scoring ensures the heuristic reliably identifies the best available bin without getting bogged down by numerical quirks or losing interpretability, crucial for effective optimization.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}