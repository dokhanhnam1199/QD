```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Best Fit Decreasing (BFD) inspired priority for Online Bin Packing.

    This strategy aims to find a bin that can accommodate the item and, among those,
    selects the one that leaves the minimum remaining capacity (Best Fit principle).
    To enhance robustness and handle cases where multiple bins might leave the same
    minimal remaining capacity, a tie-breaking mechanism is introduced by prioritizing
    bins with less initial slack (i.e., those that were already closer to being full).
    This encourages packing larger items into bins that can better accommodate them
    without wasting much space, aligning with the spirit of BFD for improved packing density.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Returns:
        Array of priority scores for each bin. Bins that cannot accommodate the item
        receive a priority of -1. Higher scores indicate higher priority.
    """
    priorities = np.full_like(bins_remain_cap, -1.0)
    
    can_fit_mask = bins_remain_cap >= item
    
    if np.any(can_fit_mask):
        fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]
        
        # Calculate remaining capacity after placing the item
        remaining_after_fit = fitting_bins_remain_cap - item
        
        # Priority 1: Minimize remaining capacity after fitting (Best Fit).
        # We want to maximize the negative of remaining_after_fit.
        # A large negative number means a small positive remaining capacity.
        priority_score_bf = -remaining_after_fit
        
        # Priority 2: Tie-breaking - prioritize bins that were closer to full *before* fitting.
        # This means prioritizing bins with smaller *original* remaining capacity
        # among those that can fit the item and result in the same minimum 'remaining_after_fit'.
        # To achieve this, we can penalize bins that have a larger original remaining capacity.
        # We'll subtract the original remaining capacity from a large number, or simply
        # use its negative value. Using the negative of the original remaining capacity
        # means smaller original remaining capacities get higher (less negative) scores.
        priority_score_tiebreaker = -fitting_bins_remain_cap

        # Combine priorities: Primarily Best Fit, secondarily prefer bins with less initial slack.
        # A simple way to combine is to use a weighted sum or lexicographical ordering.
        # Lexicographical ordering is often preferred: sort by the primary criterion first,
        # then by the secondary criterion for ties.
        # To implement this with a single score, we can use a scaled value.
        # For example, score = primary_value * large_constant + secondary_value
        # Here, we want to maximize `priority_score_bf` and then `priority_score_tiebreaker`.
        # We can achieve this by: score = priority_score_bf + (priority_score_tiebreaker / scale)
        # where scale is chosen such that priority_score_bf always dominates priority_score_tiebreaker.
        # A simpler way if we want to assign higher score:
        # Let's assign a large multiplier to the primary goal (minimizing remaining capacity).
        # The secondary goal (less initial slack) will be added.
        # The primary goal is maximizing -(remaining_after_fit).
        # The secondary goal is maximizing -(fitting_bins_remain_cap).

        # We want to maximize the "goodness".
        # Goodness is primarily determined by minimizing remaining_after_fit.
        # So, a higher value of -remaining_after_fit is better.
        # Secondarily, among bins with the same remaining_after_fit, we want to pick
        # the one with smaller original fitting_bins_remain_cap. This means a higher
        # value of -fitting_bins_remain_cap is better.

        # To combine these, we can use a scoring system where the primary factor has
        # a much larger weight.
        # Let's scale the tie-breaking score to be much smaller than the primary score.
        # The range of `remaining_after_fit` could be up to the bin capacity.
        # The range of `fitting_bins_remain_cap` could also be up to the bin capacity.
        # If we simply add them, they might interfere.
        # A common technique is to use a large number for scaling.
        # Let's assume max bin capacity is M.
        # A score like: `-(remaining_after_fit) * (M + 1) + -(fitting_bins_remain_cap)`
        # This ensures that minimizing `remaining_after_fit` is the dominant factor.
        # The tie-breaker `-(fitting_bins_remain_cap)` ensures that among bins with
        # the same `remaining_after_fit`, we pick the one with the smallest original capacity.

        # To avoid hardcoding M, we can use a relative scaling.
        # The maximum possible value for `remaining_after_fit` is bounded by the
        # maximum possible bin capacity. Let's use a sufficiently large constant,
        # or estimate a maximum possible capacity if known, or use a very large number.
        # A safe bet is a number larger than any expected `fitting_bins_remain_cap`.
        # Let's assume a large constant for scaling.
        # A very large multiplier ensures that the primary objective (minimizing remaining space)
        # completely dominates the secondary objective (minimizing initial slack).
        scale_factor = 1e6 # Sufficiently large to dominate any difference in initial capacities

        combined_priorities = priority_score_bf * scale_factor + priority_score_tiebreaker
        
        priorities[can_fit_mask] = combined_priorities

    return priorities
```
