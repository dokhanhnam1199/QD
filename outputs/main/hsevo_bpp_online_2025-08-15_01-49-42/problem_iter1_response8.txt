```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Calculates priority scores for placing an item into bins using an Epsilon-Greedy approach
    biased towards bins with the least remaining capacity that can still fit the item.

    Args:
        item: The size of the item to be packed.
        bins_remain_cap: A NumPy array representing the remaining capacity of each bin.

    Returns:
        A NumPy array of the same size as bins_remain_cap, where each element is the
        priority score for placing the item in the corresponding bin.
    """
    epsilon = 0.2  # Exploration probability
    num_bins = len(bins_remain_cap)
    priorities = np.zeros(num_bins)

    # Identify bins that can fit the item
    possible_bins_indices = np.where(bins_remain_cap >= item)[0]

    if len(possible_bins_indices) == 0:
        return priorities  # No bin can fit the item

    # Greedy part: prioritize bins with least remaining capacity that can fit the item
    # We want to find the bins that have the smallest remaining capacity BUT can still fit the item.
    # This is equivalent to maximizing (bins_remain_cap - item) for bins that can fit.
    # Or, minimizing (bins_remain_cap - item) which is the "waste" if we put the item there.
    # A smaller waste means a tighter fit, which is generally preferred in BPP to save larger spaces.
    if len(possible_bins_indices) > 0:
        valid_capacities = bins_remain_cap[possible_bins_indices]
        # Calculate a "tightness" score: smaller is better (tighter fit)
        # We add a small epsilon to avoid division by zero if capacity is exactly item size
        tightness_scores = valid_capacities - item

        # Normalize tightness scores to be between 0 and 1 (smaller waste -> higher normalized score for greedy choice)
        # To do this, we can use a reverse normalization:
        # Higher values in (max_waste - waste) means smaller waste.
        if len(tightness_scores) > 0:
            min_waste = np.min(tightness_scores)
            max_waste = np.max(tightness_scores)
            if max_waste - min_waste > 0:
                normalized_greedy_scores = (max_waste - tightness_scores) / (max_waste - min_waste)
            else:
                normalized_greedy_scores = np.ones_like(tightness_scores) * 0.5 # All are equally good/bad

            # Assign these greedy scores to the corresponding possible bins
            priorities[possible_bins_indices] = normalized_greedy_scores

    # Epsilon-Greedy exploration: introduce randomness
    # With probability epsilon, pick a random bin that can fit the item
    if np.random.rand() < epsilon and len(possible_bins_indices) > 0:
        random_bin_index = np.random.choice(possible_bins_indices)
        # Give a high, uniform score to the randomly chosen bin to ensure it's considered
        priorities = np.zeros_like(priorities) # Reset priorities
        priorities[random_bin_index] = 1.0 # Assign a high priority to this random choice

    # If no greedy choice was made due to epsilon or no bins fit initially,
    # ensure all possible bins have at least some minimal priority to be considered.
    # This can also happen if all bins have same remaining capacity.
    if np.sum(priorities) == 0 and len(possible_bins_indices) > 0:
        priorities[possible_bins_indices] = 0.5 # Assign a neutral priority if no greedy selection happened

    return priorities
```
