[
  {
    "stdout_filepath": "problem_iter8_response0.txt_stdout.txt",
    "code_path": "problem_iter8_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines exact fit preference with scaled inverse normalized slack for non-exact fits.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    eligible_bins_indices = np.where(can_fit_mask)[0]\n\n    # Prioritize exact fits with a high score of 1.0\n    exact_fit_mask = np.isclose(eligible_bins_remain_cap, item)\n    priorities[eligible_bins_indices[exact_fit_mask]] = 1.0\n\n    # For non-exact fits, prioritize bins with smaller normalized slack\n    non_exact_fit_mask = ~exact_fit_mask\n    if np.any(non_exact_fit_mask):\n        non_exact_eligible_bins_remain_cap = eligible_bins_remain_cap[non_exact_fit_mask]\n        \n        # Calculate remaining capacity after placing the item\n        remaining_after_fit = non_exact_eligible_bins_remain_cap - item\n        \n        # Original capacities for the eligible non-exact fit bins\n        original_capacities = bins_remain_cap[eligible_bins_indices[non_exact_fit_mask]]\n        \n        # Calculate normalized slack, ensuring stability with epsilon\n        normalized_slack = remaining_after_fit / (original_capacities + 1e-9)\n        \n        # Assign priorities as 1.0 minus normalized slack, scaled to be less than 1.0\n        # This rewards smaller normalized slack with higher priority values closer to 1.0.\n        priorities[eligible_bins_indices[non_exact_fit_mask]] = 0.99 * (1.0 - normalized_slack)\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 95.08241808752197,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response1.txt_stdout.txt",
    "code_path": "problem_iter8_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines exact fit, minimized residual capacity, and normalized slack for robust prioritization.\n    Prioritizes exact fits (score 1.0), then bins with minimal remaining capacity after fit,\n    using normalized slack as a tie-breaker.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        eligible_indices = np.where(can_fit_mask)[0]\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        remaining_after_fit = eligible_bins_remain_cap - item\n        \n        # Exact fit: highest priority\n        exact_fit_mask = (remaining_after_fit == 0)\n        priorities[eligible_indices[exact_fit_mask]] = 1.0\n        \n        # Non-exact fits\n        non_exact_fit_mask = ~exact_fit_mask\n        if np.any(non_exact_fit_mask):\n            non_exact_indices = eligible_indices[non_exact_fit_mask]\n            non_exact_remain_caps_after_fit = remaining_after_fit[non_exact_fit_mask]\n            non_exact_current_caps = eligible_bins_remain_cap[non_exact_fit_mask]\n            \n            # Normalize remaining capacity after fit to rank non-exact fits.\n            # Smaller remaining capacity gets higher priority.\n            # Use a score that's inversely related to normalized remaining capacity.\n            # This combines the \"minimize residual\" idea with normalization.\n            epsilon = 1e-9\n            # To avoid division by zero or very small numbers, and to make scores distinct\n            # we can use a transformation that maps smaller values to larger scores.\n            # A simple approach is to use the negative of the normalized remaining capacity\n            # and scale it to be less than 1.0.\n            \n            # Let's try prioritizing bins that leave the *least* amount of space.\n            # This is minimizing `remaining_after_fit`.\n            # We want higher priority for smaller `remaining_after_fit`.\n            \n            # Using a score derived from inverse of remaining capacity after fit.\n            # Higher score for smaller remaining capacity after fit.\n            # Scale to differentiate from exact fits. A range like [0.5, 0.95] is good.\n            \n            # Normalize remaining capacity after fit to a [0, 1] range where 0 is best.\n            max_remaining_after_fit = np.max(non_exact_remain_caps_after_fit)\n            normalized_remaining_after_fit = non_exact_remain_caps_after_fit / (max_remaining_after_fit + epsilon)\n            \n            # Map normalized remaining capacity to a priority score.\n            # 0 (best residual) -> ~0.95, 1 (worst residual) -> ~0.5\n            best_fit_scores = 0.5 + (1.0 - normalized_remaining_after_fit) * 0.45\n            \n            priorities[non_exact_indices] = best_fit_scores\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 3.0,
    "halstead": 128.3789500201924,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response2.txt_stdout.txt",
    "code_path": "problem_iter8_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes exact fits, then bins with minimal normalized slack using a scaled approach.\n    Combines the exact fit priority of v0/v9/v10 with the normalized slack approach of v9/v10.\n    The scoring ensures a clear hierarchy: exact fits > best fits (min normalized slack).\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Exact Fit: Highest priority (1.0)\n    exact_fit_mask = np.isclose(bins_remain_cap, item)\n    priorities[exact_fit_mask] = 1.0\n\n    # Best Fit: Prioritize bins with minimal positive remaining capacity after fitting.\n    # Consider bins that can fit the item and are not exact fits.\n    can_fit_mask = (bins_remain_cap >= item) & ~exact_fit_mask\n    fit_indices = np.where(can_fit_mask)[0]\n\n    if len(fit_indices) > 0:\n        remaining_after_fit = bins_remain_cap[fit_indices] - item\n        current_capacities = bins_remain_cap[fit_indices]\n\n        # Calculate normalized slack: (remaining_capacity_after_fit) / (current_bin_capacity)\n        # Smaller normalized slack is better. Add epsilon for numerical stability.\n        normalized_slack = remaining_after_fit / (current_capacities + 1e-9)\n\n        # Assign priorities that are higher for smaller normalized slack.\n        # We use 1.0 - normalized_slack to map smaller slack to higher scores.\n        # Scale these scores to be clearly less than 1.0, e.g., into the range [0.5, 0.99].\n        # This mirrors the effective scoring of v9/v10.\n        best_fit_scores = 1.0 - normalized_slack\n        scaled_best_fit_priorities = 0.5 + best_fit_scores * 0.49\n\n        priorities[fit_indices] = scaled_best_fit_priorities\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 136.3127518260917,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response3.txt_stdout.txt",
    "code_path": "problem_iter8_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes exact fits, then bins with minimal normalized slack using a stable, tiered scoring.\n\n    This function assigns the highest priority to exact fits. For other bins that can\n    accommodate the item, it calculates a priority based on normalized slack.\n    The scoring is tiered to ensure clear separation between exact fits and other options,\n    and among different levels of slack.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Mask for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    fit_indices = np.where(can_fit_mask)[0]\n\n    if len(fit_indices) == 0:\n        return priorities # No bins can fit the item\n\n    # Separate bins into exact fits and potential fits\n    exact_fit_mask = bins_remain_cap[can_fit_mask] == item\n    exact_fit_indices_filtered = np.where(exact_fit_mask)[0]\n    actual_exact_fit_indices = fit_indices[exact_fit_indices_filtered]\n\n    # Assign highest priority to exact fits\n    priorities[actual_exact_fit_indices] = 1.0\n\n    # Process bins that are not exact fits but can still accommodate the item\n    non_exact_fit_mask = can_fit_mask & ~exact_fit_mask\n    non_exact_fit_indices = np.where(non_exact_fit_mask)[0]\n\n    if len(non_exact_fit_indices) > 0:\n        eligible_bins_for_slack = bins_remain_cap[non_exact_fit_indices]\n        \n        # Calculate remaining capacity after fitting the item\n        remaining_after_fit = eligible_bins_for_slack - item\n        \n        # Calculate normalized slack: (remaining_capacity_after_fit) / (current_bin_capacity)\n        # A smaller normalized slack is better. Add epsilon for numerical stability.\n        # Using the current remaining capacity as a proxy for original bin capacity for normalization.\n        normalized_slack = remaining_after_fit / (eligible_bins_for_slack + 1e-9)\n\n        # Assign priorities for non-exact fits.\n        # We want to favor smaller normalized slack. The scoring should be less than 1.0 (exact fit score)\n        # and greater than 0.0 (default for non-fitting bins).\n        # We use 1.0 - normalized_slack to map smaller slack to higher scores.\n        # Scale these scores to be clearly less than 1.0, e.g., into the range [0.5, 0.99].\n        # A linear scaling: 0.5 + (1.0 - normalized_slack) * 0.49\n        # This approach combines the best aspects of prioritizing exact fits and using\n        # normalized slack for fine-grained selection among other options.\n        best_fit_scores = 1.0 - normalized_slack\n        scaled_best_fit_priorities = 0.5 + best_fit_scores * 0.49\n\n        priorities[non_exact_fit_indices] = scaled_best_fit_priorities\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 168.25742227201613,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response4.txt_stdout.txt",
    "code_path": "problem_iter8_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Best Fit with a penalty for large initial slacks, prioritizing exact fits.\n\n    This heuristic prioritizes exact fits with a high score. For non-exact fits,\n    it favors bins with minimal remaining capacity, applying a penalty based on\n    the bin's original slack to encourage using bins that were already fuller.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # Score 1: Prioritize exact fits with a very high score.\n        exact_fit_mask = fitting_bins_remain_cap == item\n        priorities[can_fit_mask][exact_fit_mask] = 1e6 \n\n        # Score 2: For non-exact fits, prioritize minimizing remaining capacity (Best Fit).\n        # We want to maximize -(remaining_after_fit).\n        non_exact_fit_mask = ~exact_fit_mask\n        if np.any(non_exact_fit_mask):\n            non_exact_fitting_bins_remain_cap = fitting_bins_remain_cap[non_exact_fit_mask]\n            remaining_after_fit = non_exact_fitting_bins_remain_cap - item\n            \n            # Score 3: Tie-breaking - penalize bins with large initial slack.\n            # This encourages using bins that were already closer to full.\n            # We use the negative of original remaining capacity as a secondary scoring metric.\n            # A smaller initial remaining capacity (larger negative value) is better.\n            \n            # Combine Best Fit score and initial slack penalty.\n            # Maximize -(remaining_after_fit) for Best Fit.\n            # Maximize -(fitting_bins_remain_cap) for secondary tie-breaking.\n            # Use a large scale factor to ensure Best Fit dominates.\n            scale_factor = 1e6  # Ensures Best Fit objective is dominant\n            \n            # Priorities for non-exact fits: max(-remaining_after_fit * scale_factor - fitting_bins_remain_cap)\n            combined_priorities = -remaining_after_fit * scale_factor - non_exact_fitting_bins_remain_cap\n            \n            priorities[can_fit_mask][non_exact_fit_mask] = combined_priorities\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 3.0,
    "halstead": 84.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response5.txt_stdout.txt",
    "code_path": "problem_iter8_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines exact fit priority with a scaled Best Fit strategy,\n    using normalized slack and a tie-breaker for bins with less initial slack.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        eligible_indices = np.where(can_fit_mask)[0]\n\n        # Exact fit has the highest priority\n        exact_fit_mask = (eligible_bins_remain_cap == item)\n        priorities[eligible_indices[exact_fit_mask]] = 1.0\n        \n        # For non-exact fits, use Best Fit by minimizing remaining capacity\n        non_exact_fit_mask = (eligible_bins_remain_cap > item)\n        non_exact_indices = eligible_indices[non_exact_fit_mask]\n        non_exact_remain_caps = eligible_bins_remain_cap[non_exact_fit_mask]\n\n        if len(non_exact_remain_caps) > 0:\n            remaining_after_fit = non_exact_remain_caps - item\n            \n            # Normalize remaining capacity to [0, 1], where 0 is best (min residual)\n            max_residual = np.max(remaining_after_fit)\n            # Add epsilon for stability if all residuals are identical\n            normalized_residual = remaining_after_fit / (max_residual + 1e-9)\n            \n            # Tie-breaking: Prefer bins with less *initial* slack (smaller eligible_bins_remain_cap)\n            # We want to maximize the negative of initial slack.\n            # Scale initial slack to be a secondary factor.\n            # Using the negative of initial capacities ensures smaller initial capacities\n            # get higher (less negative) scores.\n            # The scale should be such that the primary factor (normalized_residual) dominates.\n            # A common approach is to use a large constant.\n            scale_factor = 1e6 \n            tiebreaker_scores = -non_exact_remain_caps * scale_factor\n\n            # Combine primary (Best Fit) and secondary (tie-breaker) scores.\n            # Primary goal: minimize normalized_residual (maximize -(normalized_residual))\n            # Secondary goal: minimize initial slack (maximize -(initial_slack))\n            # Score = PrimaryScore * Scale + SecondaryScore\n            # We want to maximize score, so score = -(normalized_residual) * Scale + -(initial_slack)\n            # Equivalently, for maximization:\n            # Score = (1.0 - normalized_residual) * Scale + (-non_exact_remain_caps)\n            # A larger (1.0 - normalized_residual) is better (less residual).\n            # A larger (-non_exact_remain_caps) is better (less initial slack).\n            \n            # Let's reformulate to ensure maximization:\n            # Maximize: (1 - normalized_residual) -- primary\n            # Maximize: (-non_exact_remain_caps) -- secondary (tie-breaker)\n            # Combined score: (1 - normalized_residual) * large_scale + (-non_exact_remain_caps)\n            \n            # Scores for non-exact fits should be less than 1.0 (exact fit priority)\n            # The range of (1 - normalized_residual) is [0, 1].\n            # To make it distinct and higher than 1.0 for exact fit, we can add 1.0.\n            # Or, we can use a range like [0.5, 0.99] and assign 1.0 to exact fit.\n\n            # Let's aim for scores less than 1.0, with higher meaning better.\n            # Best Fit score: higher for smaller normalized_residual\n            # Using (1 - normalized_residual) gives higher scores for better fits.\n            # To incorporate tie-breaking, we use the scaled negative initial slack.\n            # Combined score = (1 - normalized_residual) * scale_factor + (-non_exact_remain_caps)\n            # This ensures that minimizing normalized residual is primary.\n            # For identical normalized residuals, it picks the bin with less initial slack.\n\n            # However, we need scores to be less than 1.0.\n            # Let's use a base score for non-exact fits and add the tie-breaker.\n            # A simple base score for Best Fit: 0.9 - normalized_residual (maps to [0.8, 0.9])\n            # Then add tie-breaker, scaled down.\n            # A better way to use tiebreaker with scale:\n            # Primary score component: (1.0 - normalized_residual) - Higher is better\n            # Secondary score component: (-non_exact_remain_caps) - Higher is better\n            # Final Score = (PrimaryScore * Scale) + SecondaryScore\n            # To ensure scores are below 1.0, we can scale (1.0 - normalized_residual).\n            # Let's use a range like [0.5, 0.99].\n            \n            # For non-exact fits, map normalized_residual to a score.\n            # Normalized residual is [0, 1] where 0 is best.\n            # We want higher scores for better fits. So, use (1 - normalized_residual).\n            # This gives scores in [0, 1].\n            # Let's map this to [0.5, 0.95] to leave room for exact fit (1.0).\n            # Scale factor for mapping [0, 1] to [0.5, 0.95] is 0.45.\n            # Score = 0.5 + (1.0 - normalized_residual) * 0.45\n\n            best_fit_scores = 0.5 + (1.0 - normalized_residual) * 0.45\n            \n            # Incorporate tie-breaker: penalize bins with more initial slack.\n            # We want to maximize the negative of initial slack.\n            # To avoid interfering with the primary score's range, scale it down significantly.\n            # The tie-breaker should only influence choices when primary scores are equal.\n            # Using the initial remaining capacity directly as a tie-breaker (smaller is better):\n            # We want to maximize the negative of initial remaining capacity.\n            # Add this to the best_fit_scores, scaled appropriately.\n            # Example: scaled_tiebreaker = (-non_exact_remain_caps) / large_constant\n            \n            # A more robust way for lexicographical ordering is:\n            # Score = Primary_Score_Component * Large_Scale + Secondary_Score_Component\n            # Where Primary_Score_Component is (1.0 - normalized_residual).\n            # Secondary_Score_Component is (-non_exact_remain_caps).\n            # To keep scores below 1.0 for non-exact fits:\n            # Score = (1.0 - normalized_residual) * (1.0 - epsilon) + (-non_exact_remain_caps) / scale\n            # Let's directly combine them to reflect the BFD spirit:\n            # Prioritize minimizing residual capacity, then minimizing initial slack.\n            # Score = (-(remaining_after_fit)) * scale_factor + (-non_exact_remain_caps)\n            # This is for maximization.\n\n            # Let's use the approach that maps non-exact fits to [0.5, 0.95] and uses\n            # negative initial slack as a tie-breaker.\n            # The tie-breaker needs to be added in a way that it only affects choices\n            # when the primary scores are very close.\n            \n            # Combining scores for non-exact fits:\n            # Higher priority for smaller remaining_after_fit.\n            # Among those, higher priority for smaller non_exact_remain_caps.\n            \n            # Let's create a composite score:\n            # We want to maximize (1 - normalized_residual)\n            # We want to maximize (-non_exact_remain_caps)\n            # To ensure the first term dominates, scale it.\n            # A common approach is: score = primary * scale_factor + secondary\n            # If primary is in [0,1] and secondary is in [-Max, 0], and scale_factor is large.\n            \n            # Let's stick to a structure that ensures non-exact fits are < 1.0 and exact fits are 1.0.\n            # For non-exact fits:\n            # Primary objective: Minimize normalized_residual -> Score component: (1.0 - normalized_residual)\n            # Secondary objective: Minimize initial slack -> Score component: (-non_exact_remain_caps)\n            \n            # We need to combine these such that the first term has more impact.\n            # Using a weighted sum: alpha * (1.0 - normalized_residual) + beta * (-non_exact_remain_caps)\n            # The weights alpha and beta can be chosen. Alpha should be larger.\n            # Let alpha = 0.9 and beta = 0.1.\n            # This gives scores in a range, but doesn't guarantee the range.\n            \n            # A robust way is to use lexicographical sorting implicitly.\n            # Consider pairs: (primary_score, secondary_score)\n            # Primary: (1.0 - normalized_residual)\n            # Secondary: (-non_exact_remain_caps)\n            # We want to maximize these lexicographically.\n            \n            # Let's simplify: use the mapped Best Fit score and add a scaled tie-breaker.\n            # Score = best_fit_scores + (-non_exact_remain_caps) / 1000.0\n            # This ensures the best_fit_scores component is dominant.\n            \n            scaled_tiebreaker = (-non_exact_remain_caps) / 1000.0 # Scale down tie-breaker\n            combined_non_exact_scores = best_fit_scores + scaled_tiebreaker\n            \n            # Ensure scores are less than 1.0 (exact fit priority)\n            # The current combination could exceed 1.0 if tiebreaker is very positive for some reason\n            # (which it shouldn't be with negative initial capacities).\n            # We can clip or rescale if needed, but given the structure, it should be fine.\n            \n            priorities[non_exact_indices] = combined_non_exact_scores\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 3.0,
    "halstead": 220.81007680238335,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response6.txt_stdout.txt",
    "code_path": "problem_iter8_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes exact fits with a high score, then uses scaled inverse slack for others.\n\n    Combines the exact-fit emphasis of v0 with a more nuanced inverse slack calculation\n    inspired by the spirit of other heuristics, ensuring distinct scores and robustness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    suitable_bins_indices = np.where(can_fit_mask)[0]\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_indices]\n\n    # Prioritize exact fits with a high score\n    exact_fit_mask = suitable_bins_remain_cap == item\n    priorities[suitable_bins_indices[exact_fit_mask]] = 1.0\n\n    # For non-exact fits, calculate a scaled inverse slack\n    non_exact_fit_mask = ~exact_fit_mask\n    if np.any(non_exact_fit_mask):\n        non_exact_bins_remain_cap = suitable_bins_remain_cap[non_exact_fit_mask]\n        remaining_after_fit = non_exact_bins_remain_cap - item\n\n        # Use a scaled inverse of (remaining_after_fit + 1) to give higher priority to tighter fits.\n        # Adding 1 to remaining_after_fit ensures that a remaining capacity of 0 (after fitting)\n        # gets a score of 1.0, and smaller positive remaining capacities get scores < 1.0.\n        # A small epsilon prevents division by zero.\n        priorities[suitable_bins_indices[non_exact_fit_mask]] = 0.5 * (1.0 / (remaining_after_fit + 1.0 + 1e-9))\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 109.80793556946902,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response7.txt_stdout.txt",
    "code_path": "problem_iter8_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid heuristic: exact fit, then best-fit by minimizing remaining capacity,\n    with a secondary preference for bins with less initial slack.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        eligible_indices = np.where(can_fit_mask)[0]\n\n        # Exact fit: highest priority\n        exact_fit_mask = (eligible_bins_remain_cap == item)\n        if np.any(exact_fit_mask):\n            priorities[eligible_indices[exact_fit_mask]] = 1.0\n        \n        # For non-exact fits, prioritize bins that leave the minimum remaining capacity.\n        # This is equivalent to maximizing -(remaining_capacity - item).\n        # To ensure these scores are distinct from exact fits (1.0) and\n        # to provide a meaningful range for best-fit, we scale this value.\n        non_exact_fit_mask = (eligible_bins_remain_cap > item)\n        \n        if np.any(non_exact_fit_mask):\n            non_exact_indices = eligible_indices[non_exact_fit_mask]\n            non_exact_remain_caps = eligible_bins_remain_cap[non_exact_fit_mask]\n            \n            # Calculate scores for non-exact fits: maximize ( -(remaining_capacity - item) )\n            # Score is higher for smaller remaining capacity after fitting.\n            # Scale these scores to be less than 1.0, e.g., in the range [0.5, 0.95].\n            \n            remaining_after_fit = non_exact_remain_caps - item\n            \n            # Normalize residuals to [0, 1], where 0 is best (min residual)\n            max_remaining_after_fit = np.max(remaining_after_fit)\n            # Add epsilon for stability if all residuals are the same\n            normalized_remaining = remaining_after_fit / (max_remaining_after_fit + 1e-9)\n            \n            # Scale to a range below 1.0, e.g., [0.5, 0.95].\n            # This maps best-fit (normalized_remaining near 0) to ~0.95\n            # and worst-fit (normalized_remaining near 1) to ~0.5.\n            best_fit_scores = 0.5 + (1.0 - normalized_remaining) * 0.45\n            \n            # Assign these scores to the non-exact fits\n            priorities[non_exact_indices] = best_fit_scores\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 4.0,
    "halstead": 129.32351694048162,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response8.txt_stdout.txt",
    "code_path": "problem_iter8_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_original_caps: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines exact fit, minimized normalized slack, and a tie-breaker.\n    Prioritizes exact fits, then bins with minimal normalized slack, using\n    remaining capacity as a tie-breaker.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    # Mask for bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        eligible_indices = np.where(can_fit_mask)[0]\n        eligible_bins_remain_cap = bins_remain_cap[eligible_indices]\n        eligible_bins_original_caps = bin_original_caps[eligible_indices]\n\n        # 1. Exact Fit: Highest Priority\n        exact_fit_mask = (eligible_bins_remain_cap == item)\n        if np.any(exact_fit_mask):\n            priorities[eligible_indices[exact_fit_mask]] = 1e9  # Very high score for exact fits\n\n        # 2. Non-Exact Fits: Minimize Normalized Slack\n        # Normalized slack = (remaining_capacity - item) / original_bin_capacity\n        # We want to maximize -(normalized_slack) to prioritize smaller slack.\n        non_exact_fit_mask = ~exact_fit_mask\n        \n        if np.any(non_exact_fit_mask):\n            non_exact_indices = eligible_indices[non_exact_fit_mask]\n            current_remain_caps = eligible_bins_remain_cap[non_exact_fit_mask]\n            original_caps = eligible_bins_original_caps[non_exact_fit_mask]\n\n            # Calculate normalized slack. Add epsilon to denominator for stability.\n            normalized_slack = (current_remain_caps - item) / (original_caps + 1e-9)\n            \n            # To make scores distinct from exact fits and order them,\n            # we use a scaled negative normalized slack.\n            # The scale factor ensures they are lower than exact fits.\n            # We also add a term based on remaining capacity as a tie-breaker:\n            # Larger remaining capacity after fit is worse, so we use negative remaining capacity.\n            # The overall score for non-exact fits: -normalized_slack - (remaining_after_fit / original_capacity)\n            # We want to maximize this score.\n            \n            remaining_after_fit = current_remain_caps - item\n            \n            # Score combines minimizing normalized slack and minimizing residual capacity.\n            # The goal is to maximize the combined score.\n            # Higher priority for lower normalized slack and lower residual capacity after fit.\n            # Using negative values to maximize.\n            score_normalized_slack = -normalized_slack\n            score_residual = -(remaining_after_fit / (original_caps + 1e-9))\n\n            # Combine scores: Prioritize normalized slack more, then residual capacity.\n            # Scale normalized slack to have a larger impact.\n            combined_score = score_normalized_slack * 100 + score_residual\n            \n            priorities[non_exact_indices] = combined_score\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\nTypeError: priority_v2() missing 1 required positional argument: 'bin_original_caps'\n4\n178.61670928936152\n"
  },
  {
    "stdout_filepath": "problem_iter8_response9.txt_stdout.txt",
    "code_path": "problem_iter8_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes exact fits, then bins with minimal normalized slack, scaled for clarity.\n\n    Combines exact fit priority with a scaled inverse normalized slack for\n    non-exact fits, ensuring distinct and robust scoring.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    # High priority for exact fits\n    exact_fit_mask = np.isclose(bins_remain_cap, item)\n    priorities[exact_fit_mask] = 1.0\n\n    # For bins that can fit but are not exact fits\n    can_fit_and_not_exact_mask = bins_remain_cap > item\n    \n    if np.any(can_fit_and_not_exact_mask):\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_and_not_exact_mask]\n        \n        # Calculate remaining capacity after placing the item\n        remaining_capacities_if_fit = eligible_bins_remain_cap - item\n        \n        # Normalized slack: remaining capacity / current bin capacity. Smaller is better.\n        epsilon = 1e-9\n        normalized_slack = remaining_capacities_if_fit / (eligible_bins_remain_cap + epsilon)\n        \n        # Priority: Higher score for smaller normalized slack.\n        # We use 1.0 - normalized_slack to map smaller slack to higher priority (closer to 1.0).\n        # Scale these scores to be distinct from exact fits (e.g., between 0.5 and 0.99).\n        # A simple mapping: 0.5 + 0.49 * (1.0 - normalized_slack)\n        # This ensures non-exact fits are always lower than exact fits and have a good range.\n        non_exact_priorities = 0.5 + 0.49 * (1.0 - normalized_slack)\n        \n        priorities[can_fit_and_not_exact_mask] = non_exact_priorities\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 2.0,
    "halstead": 95.90827503317318,
    "exec_success": true
  }
]