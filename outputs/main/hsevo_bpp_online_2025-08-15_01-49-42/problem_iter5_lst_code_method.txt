{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins using a hybrid approach: favoring exact fits and then\n    best fits by inverting the remaining capacity, while ensuring stability.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate remaining capacity after placing the item for fitting bins\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n    \n    # Calculate priority: higher for bins that will be more full (less remaining capacity)\n    # Adding 1.0 to the denominator to avoid division by zero and to ensure\n    # that bins with zero remaining capacity get a high but finite priority.\n    # This is a stable inversion that prioritizes bins that result in less slack.\n    priorities[can_fit_mask] = 1.0 / (remaining_after_fit + 1.0)\n    \n    # Bins that cannot fit the item receive zero priority, meaning they are not considered.\n    \n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins that offer the tightest fit using a combination of inverse scaling and offset for numerical stability.\n\n    This heuristic aims to give higher priority to bins where the remaining capacity is just enough to fit the item,\n    using an inverse relationship with the difference between bin capacity and item size. A small offset is added\n    to the denominator to prevent division by zero and to ensure bins that exactly fit receive a very high priority.\n    \"\"\"\n    suitable_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n\n    if suitable_bins_remain_cap.size > 0:\n        # Calculate the difference between remaining capacity and item size for suitable bins.\n        differences = suitable_bins_remain_cap - item\n        # Assign priorities: inverse of (difference + 1.0 + epsilon).\n        # Adding 1.0 to the difference ensures that bins with zero difference (exact fits)\n        # get a high priority (1/1). Adding a small epsilon (1e-9) handles potential\n        # floating-point issues and ensures non-zero denominators.\n        priorities[suitable_bins_mask] = 1.0 / (differences + 1.0 + 1e-9)\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive Best Fit priority function with capacity normalization.\n\n    This strategy aims to find the bin that minimizes the wasted space (slack)\n    after placing the item, normalized by the bin's original capacity.\n    This normalization helps in comparing bins of different sizes more effectively.\n    It prioritizes bins that are \"best fit\" in a relative sense.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # Calculate remaining capacity after placing the item for eligible bins\n        remaining_capacities_if_fit = eligible_bins_remain_cap - item\n        \n        # To prioritize the \"best fit\" (minimum remaining capacity), we want to maximize\n        # a value that is inversely related to the remaining capacity.\n        # A simple approach is to maximize the negative of the remaining capacity.\n        # To normalize, we can consider the slack relative to the bin's capacity *before* fitting.\n        # However, we only have remaining capacity. A proxy for \"how full\" the bin is\n        # would be related to how much capacity it *had* before this item, which is\n        # `bins_remain_cap[can_fit_mask]`.\n        # We want to prioritize bins that leave minimal slack, and among those,\n        # perhaps those that were already closer to full (i.e., had smaller remaining_cap).\n        \n        # A robust metric is to minimize the *relative* slack.\n        # Relative slack can be defined as (remaining_capacity_after_fit) / (original_capacity_before_fit).\n        # Since we don't have original capacity, we can use the current remaining capacity as a proxy for\n        # how \"full\" the bin is. Bins that are already very full (small bins_remain_cap)\n        # are more sensitive to new items.\n        \n        # Let's define priority as the negative of the remaining capacity after fitting,\n        # but then consider which bins were \"more full\" to begin with.\n        # A good heuristic is to prioritize bins that leave the smallest *absolute* remaining capacity.\n        # If there's a tie in absolute remaining capacity, consider the bin that was closer to full.\n        \n        # Maximize the negative of remaining capacity: higher value for smaller remaining capacity.\n        # This is similar to v1 but we can refine the scoring.\n        \n        # Let's try to maximize `-(remaining_capacity_if_fit)`.\n        # To introduce a preference for bins that were already somewhat full,\n        # we can add a term related to the original remaining capacity.\n        # For instance, we want to minimize `remaining_capacity_if_fit`, and among those,\n        # minimize `bins_remain_cap[can_fit_mask]`.\n        # So, we want to maximize `-(remaining_capacity_if_fit)` and then `-(bins_remain_cap[can_fit_mask])`.\n        \n        # Combine these: prioritize bins with small `remaining_capacities_if_fit`\n        # and among those, prioritize bins with small `bins_remain_cap[can_fit_mask]`.\n        # This can be achieved by maximizing a lexicographical comparison or a weighted sum.\n        \n        # A simple approach that captures \"best fit\" and prefers already fuller bins:\n        # Maximize `-(remaining_capacity_if_fit)`.\n        # To add the \"already fuller\" aspect, let's use a scoring function like:\n        # `-(remaining_capacity_if_fit) - epsilon * bins_remain_cap[can_fit_mask]`\n        # where epsilon is a small positive value. This ensures that if two bins\n        # have the same `remaining_capacity_if_fit`, the one that started with\n        # less remaining capacity (i.e., was fuller) gets a higher score.\n        \n        epsilon = 1e-6 # A small constant to break ties and favor fuller bins\n        \n        # Calculate scores: Higher scores for bins that leave less remaining capacity,\n        # and among those, for bins that were already more full.\n        scores = -(remaining_capacities_if_fit) - epsilon * eligible_bins_remain_cap\n        \n        priorities[can_fit_mask] = scores\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive Best Fit priority function with capacity normalization.\n\n    This strategy aims to find the bin that minimizes the wasted space (slack)\n    after placing the item, normalized by the bin's original capacity.\n    This normalization helps in comparing bins of different sizes more effectively.\n    It prioritizes bins that are \"best fit\" in a relative sense.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # Calculate remaining capacity after placing the item for eligible bins\n        remaining_capacities_if_fit = eligible_bins_remain_cap - item\n        \n        # To prioritize the \"best fit\" (minimum remaining capacity), we want to maximize\n        # a value that is inversely related to the remaining capacity.\n        # A simple approach is to maximize the negative of the remaining capacity.\n        # To normalize, we can consider the slack relative to the bin's capacity *before* fitting.\n        # However, we only have remaining capacity. A proxy for \"how full\" the bin is\n        # would be related to how much capacity it *had* before this item, which is\n        # `bins_remain_cap[can_fit_mask]`.\n        # We want to prioritize bins that leave minimal slack, and among those,\n        # perhaps those that were already closer to full (i.e., had smaller remaining_cap).\n        \n        # A robust metric is to minimize the *relative* slack.\n        # Relative slack can be defined as (remaining_capacity_after_fit) / (original_capacity_before_fit).\n        # Since we don't have original capacity, we can use the current remaining capacity as a proxy for\n        # how \"full\" the bin is. Bins that are already very full (small bins_remain_cap)\n        # are more sensitive to new items.\n        \n        # Let's define priority as the negative of the remaining capacity after fitting,\n        # but then consider which bins were \"more full\" to begin with.\n        # A good heuristic is to prioritize bins that leave the smallest *absolute* remaining capacity.\n        # If there's a tie in absolute remaining capacity, consider the bin that was closer to full.\n        \n        # Maximize the negative of remaining capacity: higher value for smaller remaining capacity.\n        # This is similar to v1 but we can refine the scoring.\n        \n        # Let's try to maximize `-(remaining_capacity_if_fit)`.\n        # To introduce a preference for bins that were already somewhat full,\n        # we can add a term related to the original remaining capacity.\n        # For instance, we want to minimize `remaining_capacity_if_fit`, and among those,\n        # minimize `bins_remain_cap[can_fit_mask]`.\n        # So, we want to maximize `-(remaining_capacity_if_fit)` and then `-(bins_remain_cap[can_fit_mask])`.\n        \n        # Combine these: prioritize bins with small `remaining_capacities_if_fit`\n        # and among those, prioritize bins with small `bins_remain_cap[can_fit_mask]`.\n        # This can be achieved by maximizing a lexicographical comparison or a weighted sum.\n        \n        # A simple approach that captures \"best fit\" and prefers already fuller bins:\n        # Maximize `-(remaining_capacity_if_fit)`.\n        # To add the \"already fuller\" aspect, let's use a scoring function like:\n        # `-(remaining_capacity_if_fit) - epsilon * bins_remain_cap[can_fit_mask]`\n        # where epsilon is a small positive value. This ensures that if two bins\n        # have the same `remaining_capacity_if_fit`, the one that started with\n        # less remaining capacity (i.e., was fuller) gets a higher score.\n        \n        epsilon = 1e-6 # A small constant to break ties and favor fuller bins\n        \n        # Calculate scores: Higher scores for bins that leave less remaining capacity,\n        # and among those, for bins that were already more full.\n        scores = -(remaining_capacities_if_fit) - epsilon * eligible_bins_remain_cap\n        \n        priorities[can_fit_mask] = scores\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Almost Full Fit priority function.\n\n    This strategy prioritizes bins that will be \"almost full\" after placing the item.\n    A bin is considered \"almost full\" if its remaining capacity after placing the item\n    is small. We want to select the bin that leaves the minimum remaining capacity,\n    provided it can accommodate the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        remaining_capacities_if_fit = bins_remain_cap[can_fit_mask] - item\n        \n        # We want to prioritize bins where the remaining capacity is *minimal* after fitting.\n        # So, a smaller remaining capacity should yield a higher priority.\n        # We can invert the remaining capacity values and then scale them or just use\n        # a value inversely proportional to the remaining capacity.\n        # Here, we'll use 1 / (remaining_capacity + epsilon) to avoid division by zero\n        # and to ensure smaller remaining capacities get higher scores.\n        # A simple approach is to subtract from a large number or use a negative linear function.\n        # Let's use a value that is inversely proportional to remaining capacity.\n        # However, to keep it simpler and still capture the \"almost full\" idea,\n        # we can assign a higher priority to bins that leave a smaller remainder.\n        # A very direct interpretation of \"almost full\" is to prioritize the bin\n        # that, after placing the item, has the smallest *positive* remaining capacity.\n        # This can be achieved by minimizing `bins_remain_cap - item`.\n        # So, we want to *maximize* the negative of `bins_remain_cap - item`.\n        \n        priorities[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item)\n        \n        # Alternative: Use a small epsilon to make it robust\n        # epsilon = 1e-9\n        # priorities[can_fit_mask] = 1.0 / (remaining_capacities_if_fit + epsilon)\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins that offer the tightest fit using a combination of inverse scaling and offset for numerical stability.\n\n    This heuristic aims to give higher priority to bins where the remaining capacity is just enough to fit the item,\n    using an inverse relationship with the difference between bin capacity and item size. A small offset is added\n    to the denominator to prevent division by zero and to ensure bins that exactly fit receive a very high priority.\n    \"\"\"\n    suitable_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n\n    if suitable_bins_remain_cap.size > 0:\n        # Calculate the difference between remaining capacity and item size for suitable bins.\n        differences = suitable_bins_remain_cap - item\n        # Assign priorities: inverse of (difference + 1.0 + epsilon).\n        # Adding 1.0 to the difference ensures that bins with zero difference (exact fits)\n        # get a high priority (1/1). Adding a small epsilon (1e-9) handles potential\n        # floating-point issues and ensures non-zero denominators.\n        priorities[suitable_bins_mask] = 1.0 / (differences + 1.0 + 1e-9)\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 0.8954438612151145) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins using a hybrid approach: favoring exact fits and then\n    best fits by inverting the remaining capacity, while ensuring stability.\n\n    Args:\n        item (float): The size of the item to be placed.\n        bins_remain_cap (np.ndarray): An array of remaining capacities of the bins.\n        epsilon (float): A small value to add to the denominator for stability,\n                         preventing division by zero and ensuring finite priorities.\n\n    Returns:\n        np.ndarray: An array of priorities for each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate remaining capacity after placing the item for fitting bins\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n    \n    # Calculate priority: higher for bins that will be more full (less remaining capacity)\n    # Adding epsilon to the denominator to avoid division by zero and to ensure\n    # that bins with zero remaining capacity get a high but finite priority.\n    # This is a stable inversion that prioritizes bins that result in less slack.\n    priorities[can_fit_mask] = 1.0 / (remaining_after_fit + epsilon)\n    \n    # Bins that cannot fit the item receive zero priority, meaning they are not considered.\n    \n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 0.8954438612151145) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins using a hybrid approach: favoring exact fits and then\n    best fits by inverting the remaining capacity, while ensuring stability.\n\n    Args:\n        item (float): The size of the item to be placed.\n        bins_remain_cap (np.ndarray): An array of remaining capacities of the bins.\n        epsilon (float): A small value to add to the denominator for stability,\n                         preventing division by zero and ensuring finite priorities.\n\n    Returns:\n        np.ndarray: An array of priorities for each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate remaining capacity after placing the item for fitting bins\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n    \n    # Calculate priority: higher for bins that will be more full (less remaining capacity)\n    # Adding epsilon to the denominator to avoid division by zero and to ensure\n    # that bins with zero remaining capacity get a high but finite priority.\n    # This is a stable inversion that prioritizes bins that result in less slack.\n    priorities[can_fit_mask] = 1.0 / (remaining_after_fit + epsilon)\n    \n    # Bins that cannot fit the item receive zero priority, meaning they are not considered.\n    \n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive Almost Full Fit with Normalized Slack priority function.\n\n    This strategy prioritizes bins that will be \"almost full\" after placing the item,\n    but it adapts to the item's size relative to the bin's capacity and normalizes\n    the slack to avoid issues with vastly different bin capacities.\n\n    The priority is calculated based on the *normalized slack* after placing the item.\n    A smaller normalized slack (meaning the bin is closer to being full relative\n    to its remaining capacity before the item) indicates higher priority.\n    We also incorporate a slight penalty for bins that are too large relative to the item\n    to encourage tighter packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        current_bin_capacities = bins_remain_cap[can_fit_mask]\n        \n        # Calculate remaining capacity after placing the item\n        remaining_capacities_if_fit = current_bin_capacities - item\n        \n        # Calculate a measure of \"how full\" the bin will be relative to its original capacity\n        # We use the capacity *before* placing the item for normalization.\n        # If a bin has capacity C, and we place item I, it leaves C-I remaining.\n        # The \"fullness\" is related to (C-I)/C. We want to minimize this ratio.\n        # To avoid division by zero if original capacity was 0 (shouldn't happen in BPP but for robustness),\n        # we can use the capacity *before* placing the item for normalization.\n        # A smaller remaining capacity relative to the original bin capacity is better.\n        # We are prioritizing bins that will be \"almost full\" after placement.\n        # This means the remaining capacity (current_bin_capacities - item) should be small.\n        \n        # Normalize the remaining capacity by the capacity *before* placing the item.\n        # This gives a measure of slack relative to the bin's size.\n        # We use the capacity of the bin *before* the item is placed for normalization.\n        # A smaller normalized remaining capacity (slack) is better.\n        \n        # Using `current_bin_capacities` for normalization:\n        # slack_ratio = remaining_capacities_if_fit / current_bin_capacities\n        \n        # A more robust normalization would be to use the capacity *of the bin*.\n        # However, since we only have remaining capacities, we can proxy this by\n        # `current_bin_capacities + item` (the capacity the bin *had* before this item).\n        # But a simpler and often effective approach for \"almost full\" is to focus on\n        # minimizing `remaining_capacities_if_fit`.\n        \n        # Let's define priority as inversely proportional to remaining capacity,\n        # but also consider how large the remaining capacity is relative to the item.\n        # A common heuristic is to prioritize the bin with the smallest *positive* remainder.\n        # This means maximizing -(remaining_capacities_if_fit).\n        \n        # To make it \"better\" and \"adaptive\":\n        # We want to penalize bins that are excessively large for the item.\n        # Consider a bin with capacity 100 and item 1. Remaining is 99.\n        # Consider a bin with capacity 10 and item 1. Remaining is 9.\n        # The second bin is relatively fuller.\n        \n        # Let's use the ratio of (item size / bin capacity before placing item)\n        # Higher ratio means the item takes up more of the bin's original capacity.\n        # Then, subtract this ratio from 1 to get a measure of how much capacity is *left* relative to item size.\n        # Or, simply prioritize bins that minimize (remaining_capacity_if_fit).\n\n        # Refined approach: Prioritize bins that minimize remaining capacity.\n        # To make it adaptive, let's use the ratio of the *remaining capacity after fit*\n        # to the *capacity of the bin before the item*.\n        # We want to *minimize* this ratio.\n        # So, priority will be `-(remaining_capacities_if_fit / current_bin_capacities)`.\n        # This normalizes the remaining capacity by the bin's available space.\n        \n        # Add a small epsilon to the denominator to avoid division by zero for bins with zero capacity.\n        epsilon = 1e-9\n        \n        # Calculate normalized slack: remaining capacity after fitting / current bin capacity.\n        # A smaller normalized slack is preferred.\n        normalized_slack = remaining_capacities_if_fit / (current_bin_capacities + epsilon)\n        \n        # The priority should be higher for smaller normalized_slack.\n        # So, we can use -normalized_slack.\n        # To ensure positive scores for fitting bins and to differentiate them clearly from non-fitting bins,\n        # we can add a base score.\n        # Let's aim for higher scores for better fits.\n        # We want to maximize `1 - normalized_slack`. This means minimizing `normalized_slack`.\n        # So, `priority = 1.0 - normalized_slack`.\n        \n        # Consider the case where `current_bin_capacities` is very large compared to `item`.\n        # `normalized_slack` will be close to 1.0, and `1 - normalized_slack` will be close to 0.\n        # If `current_bin_capacities` is just slightly larger than `item`,\n        # `remaining_capacities_if_fit` is small, `normalized_slack` is small,\n        # and `1 - normalized_slack` is close to 1.0. This is good.\n        \n        priorities[can_fit_mask] = 1.0 - normalized_slack\n\n        # Alternative: Prioritize the bin with the minimum remaining capacity directly.\n        # This is the core of \"almost full fit\".\n        # To make it adaptive, we can scale this minimum remaining capacity.\n        # However, the normalized slack approach is generally more robust across different bin scales.\n        \n        # Let's refine the score to ensure it's always positive and higher for better fits,\n        # and clearly distinguishable from non-fitting bins.\n        # We want to maximize the \"fitness\", where fitness is inversely related to slack.\n        # Fitness = 1 / (normalized_slack + epsilon)\n        # However, this can lead to very large numbers if normalized_slack is tiny.\n        \n        # A simpler, robust approach:\n        # Maximize -(remaining_capacities_if_fit). This favors bins that become most full.\n        # To make it adaptive, normalize this difference by the original capacity.\n        # Priority = -(remaining_capacities_if_fit / (current_bin_capacities + epsilon))\n        # This is essentially `normalized_slack` but negated. Higher values are better.\n        \n        priorities[can_fit_mask] = -normalized_slack\n        \n        # To ensure positive scores and to distinguish from the \"-1\" for non-fitting bins,\n        # and to make the \"best fit\" have the highest score, we can transform this.\n        # For example, map the range of potential `-normalized_slack` values to a positive range.\n        # The range of `normalized_slack` is [0, 1]. So, `-normalized_slack` is [-1, 0].\n        # We want to map this to a positive score, where 0 maps to the highest score.\n        # So, we can use `1 + normalized_slack` (range [0, 1]) or `1 - normalized_slack` (range [0, 1]).\n        # `1 - normalized_slack` means smaller normalized slack -> higher priority. This is aligned.\n        \n        priorities[can_fit_mask] = 1.0 - normalized_slack\n        \n        # Let's consider the heuristic advice: \"Focus on precisely defining objective functions (e.g., exact fit satisfaction, minimizing slack), and consistently normalize or scale capacities to create a common comparison basis.\"\n        # Minimizing slack is key. `remaining_capacities_if_fit` is the slack.\n        # Normalizing it by `current_bin_capacities` gives `normalized_slack`.\n        # We want to minimize `normalized_slack`.\n        # Therefore, we want to maximize `1 - normalized_slack`.\n        # This seems to be a good implementation of the advice.\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Exact Fit First with a normalized Best Fit strategy.\n    Prioritizes exact fits, then best fits using a scaled inverse of residual capacity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # 1. Exact Fit: Highest priority (1.0)\n    exact_fit_indices = np.where(bins_remain_cap == item)[0]\n    priorities[exact_fit_indices] = 1.0\n\n    # 2. Best Fit: Prioritize bins with minimal positive remaining capacity\n    # Only consider bins that can fit the item and are not exact fits\n    can_fit_mask = (bins_remain_cap >= item) & (bins_remain_cap != item)\n    fit_indices = np.where(can_fit_mask)[0]\n\n    if len(fit_indices) > 0:\n        residual_capacities = bins_remain_cap[fit_indices] - item\n        \n        # Normalize residuals to be between 0 and 1, where smaller residual is better.\n        # A common way is 1 - (residual / max_residual).\n        # To avoid division by zero if all residuals are the same and positive, add a small epsilon.\n        max_residual = np.max(residual_capacities)\n        normalized_residuals = residual_capacities / (max_residual + 1e-9)\n        \n        # Assign priorities that are higher for smaller residuals.\n        # Scale between 0.5 (for worst fit among feasible) and 1.0 (for exact fit).\n        # We use 1 - normalized_residuals so that smaller residuals get higher values.\n        # The base priority for exact fit is 1.0. Best fit will be less than 1.0.\n        # Let's map best fit to a range like [0.5, 0.99] to clearly distinguish from exact fit.\n        # So, a smaller residual should yield a higher score in this range.\n        # The term (1 - normalized_residuals) gives values from ~0 (max residual) to ~1 (min residual).\n        # We can scale this to [0.5, 0.99].\n        # desired_range = 0.99 - 0.5\n        # scaled_best_fit_priorities = 0.5 + (1 - normalized_residuals) * desired_range\n        \n        # A simpler approach that still prioritizes better fits:\n        # Assign a priority that decreases as residual increases.\n        # A score like 0.5 + (0.5 * (1 - normalized_residuals)) maps to [0.5, 1.0]\n        # Let's try to map it such that the best fit gets a high score, but less than 1.0.\n        # We can use a fraction of the maximum possible priority (1.0)\n        # For example, priority = 0.8 * (1 - normalized_residuals) + 0.1\n        # This maps best fit (min residual) to ~0.9 and worst fit (max residual) to ~0.1\n        # Let's use a slightly simpler scheme: give higher priority to smaller residuals.\n        # Use a value that decreases with residual capacity.\n        # Example: 0.75 * (1 - normalized_residuals) + 0.25\n        # This maps best fit to 1.0 and worst fit to 0.25.\n        # To ensure it's less than 1.0, we can use a scaling factor.\n        # Let's use a direct inverse scaling but ensure it's lower than exact fit.\n        \n        # Use a value inversely proportional to the residual, scaled down.\n        # Ensure it's less than 1.0.\n        # Use a score like `1.0 - (residual / (max_residual + item + 1e-9))`\n        # This makes smaller residuals higher priority.\n        best_fit_scores = 1.0 - (residual_capacities / (max_residual + item + 1e-9))\n        \n        # Scale these scores to a range below 1.0, e.g., [0.5, 0.9].\n        # The range of best_fit_scores is approximately [0, 1].\n        # Map [0, 1] to [0.5, 0.9]: scale = 0.4, offset = 0.5\n        final_best_fit_priorities = 0.5 + best_fit_scores * 0.4\n        \n        priorities[fit_indices] = final_best_fit_priorities\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive Almost Full Fit with Normalized Slack priority function.\n\n    This strategy prioritizes bins that will be \"almost full\" after placing the item,\n    but it adapts to the item's size relative to the bin's capacity and normalizes\n    the slack to avoid issues with vastly different bin capacities.\n\n    The priority is calculated based on the *normalized slack* after placing the item.\n    A smaller normalized slack (meaning the bin is closer to being full relative\n    to its remaining capacity before the item) indicates higher priority.\n    We also incorporate a slight penalty for bins that are too large relative to the item\n    to encourage tighter packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        current_bin_capacities = bins_remain_cap[can_fit_mask]\n        \n        # Calculate remaining capacity after placing the item\n        remaining_capacities_if_fit = current_bin_capacities - item\n        \n        # Calculate a measure of \"how full\" the bin will be relative to its original capacity\n        # We use the capacity *before* placing the item for normalization.\n        # If a bin has capacity C, and we place item I, it leaves C-I remaining.\n        # The \"fullness\" is related to (C-I)/C. We want to minimize this ratio.\n        # To avoid division by zero if original capacity was 0 (shouldn't happen in BPP but for robustness),\n        # we can use the capacity *before* placing the item for normalization.\n        # A smaller remaining capacity relative to the original bin capacity is better.\n        # We are prioritizing bins that will be \"almost full\" after placement.\n        # This means the remaining capacity (current_bin_capacities - item) should be small.\n        \n        # Normalize the remaining capacity by the capacity *before* placing the item.\n        # This gives a measure of slack relative to the bin's size.\n        # We use the capacity of the bin *before* the item is placed for normalization.\n        # A smaller normalized remaining capacity (slack) is better.\n        \n        # Using `current_bin_capacities` for normalization:\n        # slack_ratio = remaining_capacities_if_fit / current_bin_capacities\n        \n        # A more robust normalization would be to use the capacity *of the bin*.\n        # However, since we only have remaining capacities, we can proxy this by\n        # `current_bin_capacities + item` (the capacity the bin *had* before this item).\n        # But a simpler and often effective approach for \"almost full\" is to focus on\n        # minimizing `remaining_capacities_if_fit`.\n        \n        # Let's define priority as inversely proportional to remaining capacity,\n        # but also consider how large the remaining capacity is relative to the item.\n        # A common heuristic is to prioritize the bin with the smallest *positive* remainder.\n        # This means maximizing -(remaining_capacities_if_fit).\n        \n        # To make it \"better\" and \"adaptive\":\n        # We want to penalize bins that are excessively large for the item.\n        # Consider a bin with capacity 100 and item 1. Remaining is 99.\n        # Consider a bin with capacity 10 and item 1. Remaining is 9.\n        # The second bin is relatively fuller.\n        \n        # Let's use the ratio of (item size / bin capacity before placing item)\n        # Higher ratio means the item takes up more of the bin's original capacity.\n        # Then, subtract this ratio from 1 to get a measure of how much capacity is *left* relative to item size.\n        # Or, simply prioritize bins that minimize (remaining_capacity_if_fit).\n\n        # Refined approach: Prioritize bins that minimize remaining capacity.\n        # To make it adaptive, let's use the ratio of the *remaining capacity after fit*\n        # to the *capacity of the bin before the item*.\n        # We want to *minimize* this ratio.\n        # So, priority will be `-(remaining_capacities_if_fit / current_bin_capacities)`.\n        # This normalizes the remaining capacity by the bin's available space.\n        \n        # Add a small epsilon to the denominator to avoid division by zero for bins with zero capacity.\n        epsilon = 1e-9\n        \n        # Calculate normalized slack: remaining capacity after fitting / current bin capacity.\n        # A smaller normalized slack is preferred.\n        normalized_slack = remaining_capacities_if_fit / (current_bin_capacities + epsilon)\n        \n        # The priority should be higher for smaller normalized_slack.\n        # So, we can use -normalized_slack.\n        # To ensure positive scores for fitting bins and to differentiate them clearly from non-fitting bins,\n        # we can add a base score.\n        # Let's aim for higher scores for better fits.\n        # We want to maximize `1 - normalized_slack`. This means minimizing `normalized_slack`.\n        # So, `priority = 1.0 - normalized_slack`.\n        \n        # Consider the case where `current_bin_capacities` is very large compared to `item`.\n        # `normalized_slack` will be close to 1.0, and `1 - normalized_slack` will be close to 0.\n        # If `current_bin_capacities` is just slightly larger than `item`,\n        # `remaining_capacities_if_fit` is small, `normalized_slack` is small,\n        # and `1 - normalized_slack` is close to 1.0. This is good.\n        \n        priorities[can_fit_mask] = 1.0 - normalized_slack\n\n        # Alternative: Prioritize the bin with the minimum remaining capacity directly.\n        # This is the core of \"almost full fit\".\n        # To make it adaptive, we can scale this minimum remaining capacity.\n        # However, the normalized slack approach is generally more robust across different bin scales.\n        \n        # Let's refine the score to ensure it's always positive and higher for better fits,\n        # and clearly distinguishable from non-fitting bins.\n        # We want to maximize the \"fitness\", where fitness is inversely related to slack.\n        # Fitness = 1 / (normalized_slack + epsilon)\n        # However, this can lead to very large numbers if normalized_slack is tiny.\n        \n        # A simpler, robust approach:\n        # Maximize -(remaining_capacities_if_fit). This favors bins that become most full.\n        # To make it adaptive, normalize this difference by the original capacity.\n        # Priority = -(remaining_capacities_if_fit / (current_bin_capacities + epsilon))\n        # This is essentially `normalized_slack` but negated. Higher values are better.\n        \n        priorities[can_fit_mask] = -normalized_slack\n        \n        # To ensure positive scores and to distinguish from the \"-1\" for non-fitting bins,\n        # and to make the \"best fit\" have the highest score, we can transform this.\n        # For example, map the range of potential `-normalized_slack` values to a positive range.\n        # The range of `normalized_slack` is [0, 1]. So, `-normalized_slack` is [-1, 0].\n        # We want to map this to a positive score, where 0 maps to the highest score.\n        # So, we can use `1 + normalized_slack` (range [0, 1]) or `1 - normalized_slack` (range [0, 1]).\n        # `1 - normalized_slack` means smaller normalized slack -> higher priority. This is aligned.\n        \n        priorities[can_fit_mask] = 1.0 - normalized_slack\n        \n        # Let's consider the heuristic advice: \"Focus on precisely defining objective functions (e.g., exact fit satisfaction, minimizing slack), and consistently normalize or scale capacities to create a common comparison basis.\"\n        # Minimizing slack is key. `remaining_capacities_if_fit` is the slack.\n        # Normalizing it by `current_bin_capacities` gives `normalized_slack`.\n        # We want to minimize `normalized_slack`.\n        # Therefore, we want to maximize `1 - normalized_slack`.\n        # This seems to be a good implementation of the advice.\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Exact Fit First with a normalized Best Fit strategy.\n    Prioritizes exact fits, then best fits using a scaled inverse of residual capacity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # 1. Exact Fit: Highest priority (1.0)\n    exact_fit_indices = np.where(bins_remain_cap == item)[0]\n    priorities[exact_fit_indices] = 1.0\n\n    # 2. Best Fit: Prioritize bins with minimal positive remaining capacity\n    # Only consider bins that can fit the item and are not exact fits\n    can_fit_mask = (bins_remain_cap >= item) & (bins_remain_cap != item)\n    fit_indices = np.where(can_fit_mask)[0]\n\n    if len(fit_indices) > 0:\n        residual_capacities = bins_remain_cap[fit_indices] - item\n        \n        # Normalize residuals to be between 0 and 1, where smaller residual is better.\n        # A common way is 1 - (residual / max_residual).\n        # To avoid division by zero if all residuals are the same and positive, add a small epsilon.\n        max_residual = np.max(residual_capacities)\n        normalized_residuals = residual_capacities / (max_residual + 1e-9)\n        \n        # Assign priorities that are higher for smaller residuals.\n        # Scale between 0.5 (for worst fit among feasible) and 1.0 (for exact fit).\n        # We use 1 - normalized_residuals so that smaller residuals get higher values.\n        # The base priority for exact fit is 1.0. Best fit will be less than 1.0.\n        # Let's map best fit to a range like [0.5, 0.99] to clearly distinguish from exact fit.\n        # So, a smaller residual should yield a higher score in this range.\n        # The term (1 - normalized_residuals) gives values from ~0 (max residual) to ~1 (min residual).\n        # We can scale this to [0.5, 0.99].\n        # desired_range = 0.99 - 0.5\n        # scaled_best_fit_priorities = 0.5 + (1 - normalized_residuals) * desired_range\n        \n        # A simpler approach that still prioritizes better fits:\n        # Assign a priority that decreases as residual increases.\n        # A score like 0.5 + (0.5 * (1 - normalized_residuals)) maps to [0.5, 1.0]\n        # Let's try to map it such that the best fit gets a high score, but less than 1.0.\n        # We can use a fraction of the maximum possible priority (1.0)\n        # For example, priority = 0.8 * (1 - normalized_residuals) + 0.1\n        # This maps best fit (min residual) to ~0.9 and worst fit (max residual) to ~0.1\n        # Let's use a slightly simpler scheme: give higher priority to smaller residuals.\n        # Use a value that decreases with residual capacity.\n        # Example: 0.75 * (1 - normalized_residuals) + 0.25\n        # This maps best fit to 1.0 and worst fit to 0.25.\n        # To ensure it's less than 1.0, we can use a scaling factor.\n        # Let's use a direct inverse scaling but ensure it's lower than exact fit.\n        \n        # Use a value inversely proportional to the residual, scaled down.\n        # Ensure it's less than 1.0.\n        # Use a score like `1.0 - (residual / (max_residual + item + 1e-9))`\n        # This makes smaller residuals higher priority.\n        best_fit_scores = 1.0 - (residual_capacities / (max_residual + item + 1e-9))\n        \n        # Scale these scores to a range below 1.0, e.g., [0.5, 0.9].\n        # The range of best_fit_scores is approximately [0, 1].\n        # Map [0, 1] to [0.5, 0.9]: scale = 0.4, offset = 0.5\n        final_best_fit_priorities = 0.5 + best_fit_scores * 0.4\n        \n        priorities[fit_indices] = final_best_fit_priorities\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins by favoring exact fits and then best fits using a scaled inverse.\n    Combines the exact fit preference of Best Fit with the scaled inverse approach of Softmax-Based Fit.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    eligible_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(eligible_bins_mask):\n        return priorities\n\n    eligible_bins_remain_cap = bins_remain_cap[eligible_bins_mask]\n    \n    # Prioritize exact fits with a high score\n    exact_fit_mask = np.isclose(eligible_bins_remain_cap, item)\n    priorities[eligible_bins_mask][exact_fit_mask] = 1.0\n    \n    # For non-exact fits, use a scaled inverse of the remaining capacity\n    non_exact_fit_mask = ~exact_fit_mask\n    if np.any(non_exact_fit_mask):\n        non_exact_eligible_bins_remain_cap = eligible_bins_remain_cap[non_exact_fit_mask]\n        \n        # Scale differences to be between 0 and 1 for the inverse calculation\n        # Add 1 to the difference to avoid division by zero and to penalize\n        # bins that are slightly larger than needed.\n        differences = non_exact_eligible_bins_remain_cap - item\n        \n        # Use a robust scaling similar to the softmax approach, but without exponentiation\n        # to avoid potential overflow and maintain a more linear preference for smaller remaining capacities.\n        # Adding 1e-9 for numerical stability.\n        scaled_inverse = 1.0 / (differences + 1.0 + 1e-9)\n        \n        # Normalize these scaled inverse priorities so the highest is 1,\n        # making them comparable to the exact fit score of 1.0.\n        if np.max(scaled_inverse) > 1e-9: # Avoid division by zero if all scaled_inverse are near zero\n            normalized_scaled_inverse = scaled_inverse / np.max(scaled_inverse)\n        else:\n            normalized_scaled_inverse = scaled_inverse # Or handle as a special case if needed\n            \n        priorities[eligible_bins_mask][non_exact_fit_mask] = normalized_scaled_inverse\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Best Fit and a scaled inverse for robust prioritization.\n\n    Prioritizes bins that result in the smallest remaining capacity after packing (Best Fit),\n    and for other bins, uses an inverse of the remaining capacity scaled by a small constant\n    to avoid extreme values and provide smoother ranking.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    available_bins_mask = bins_remain_cap >= item\n    available_bins_caps = bins_remain_cap[available_bins_mask]\n\n    if available_bins_caps.size > 0:\n        remaining_after_fit = available_bins_caps - item\n        \n        # Prioritize exact fits (remaining capacity is 0) with a high score\n        exact_fit_mask = remaining_after_fit == 0\n        priorities[available_bins_mask][exact_fit_mask] = 1.0\n\n        # For non-exact fits, use a scaled inverse to prioritize bins with less remaining space\n        non_exact_fit_mask = ~exact_fit_mask\n        non_exact_bins_remaining = remaining_after_fit[non_exact_fit_mask]\n        \n        if non_exact_bins_remaining.size > 0:\n            # Add a small constant to avoid division by zero and to smooth priorities\n            # Scale by a factor to differentiate non-exact fits without overpowering exact fits\n            scaled_inverse = 0.1 / (non_exact_bins_remaining + 1.0) \n            priorities[available_bins_mask][non_exact_fit_mask] = scaled_inverse\n            \n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive Best Fit Decreasing-like priority function with capacity normalization.\n\n    This strategy prioritizes bins that are a \"good fit\" for the item,\n    aiming to minimize wasted space. It considers bins that can fit the item\n    and assigns higher priority to those where the remaining capacity after\n    placement is relatively small compared to the bin's original capacity.\n    This aims to utilize bins more efficiently and potentially leave larger\n    remaining spaces in other bins for future larger items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # Calculate remaining capacity after placing the item\n        remaining_if_fit = fitting_bins_remain_cap - item\n\n        # Normalize remaining capacity by the bin's *original* capacity (approximated by current remaining capacity)\n        # to get a relative measure of wasted space.\n        # A lower relative remaining capacity (less waste) gets a higher score.\n        # We use bins_remain_cap which is the capacity *before* fitting.\n        # To avoid division by zero if a bin is exactly full (though this shouldn't happen if item > 0),\n        # we add a small epsilon.\n        epsilon = 1e-9\n        \n        # Higher priority for bins that leave *less* relative slack.\n        # The slack is (bin_capacity - item). We want to minimize this slack relative to bin_capacity.\n        # So we maximize -(slack / bin_capacity).\n        # We use fitting_bins_remain_cap as an approximation of bin_capacity if it's not empty.\n        # If a bin has 0 remaining capacity, it means it's full. If an item fits, the remaining capacity is 0.\n        # The relative slack is 0 / bin_capacity = 0.\n        \n        # Calculate the \"goodness of fit\" by minimizing the remaining capacity relative to the bin's capacity.\n        # A smaller `remaining_if_fit / fitting_bins_remain_cap` indicates a better fit.\n        # We want to maximize the negative of this value to get higher priorities for better fits.\n        relative_slack = remaining_if_fit / (fitting_bins_remain_cap + epsilon)\n        priorities[can_fit_mask] = -relative_slack\n\n        # An alternative that might be more direct about minimizing wasted space:\n        # Prioritize bins that are \"almost full\" after fitting, but consider the original capacity.\n        # We want to maximize `1 - (remaining_if_fit / fitting_bins_remain_cap)` which is `(fitting_bins_remain_cap - remaining_if_fit) / fitting_bins_remain_cap`.\n        # This is equivalent to maximizing `item / fitting_bins_remain_cap`, which prioritizes bins\n        # where the item takes up a larger proportion of the *available* capacity.\n        # priorities[can_fit_mask] = item / (fitting_bins_remain_cap + epsilon)\n        \n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit and Sigmoid Fit Score.\n    Prioritizes bins that are closest to fitting the item (Best Fit)\n    and uses a sigmoid to smooth prioritization among them.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n        \n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    # Best Fit component: Calculate difference for bins that can fit\n    differences = fitting_bins_remain_cap - item\n    \n    # Sigmoid scaling for smoother prioritization among fitting bins\n    # Normalize differences to a [0, 1] range for sigmoid input\n    # Avoid division by zero if all fitting bins have the same remaining capacity\n    max_diff = np.max(differences)\n    min_diff = np.min(differences)\n    \n    if max_diff == min_diff:\n        scaled_diffs = np.zeros_like(differences) # All fitting bins are equally \"best\"\n    else:\n        scaled_diffs = (differences - min_diff) / (max_diff - min_diff)\n        \n    # Sigmoid function to transform scaled differences into priorities\n    # Steepness parameter (e.g., 5) can be tuned\n    sigmoid_scores = 1 / (1 + np.exp(-5 * (1 - scaled_diffs))) # Invert so smaller diffs get higher scores\n    \n    priorities[can_fit_mask] = sigmoid_scores\n    \n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Best Fit and a scaled inverse for robust prioritization.\n\n    Prioritizes bins that result in the smallest remaining capacity after packing (Best Fit),\n    and for other bins, uses an inverse of the remaining capacity scaled by a small constant\n    to avoid extreme values and provide smoother ranking.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    available_bins_mask = bins_remain_cap >= item\n    available_bins_caps = bins_remain_cap[available_bins_mask]\n\n    if available_bins_caps.size > 0:\n        remaining_after_fit = available_bins_caps - item\n        \n        # Prioritize exact fits (remaining capacity is 0) with a high score\n        exact_fit_mask = remaining_after_fit == 0\n        priorities[available_bins_mask][exact_fit_mask] = 1.0\n\n        # For non-exact fits, use a scaled inverse to prioritize bins with less remaining space\n        non_exact_fit_mask = ~exact_fit_mask\n        non_exact_bins_remaining = remaining_after_fit[non_exact_fit_mask]\n        \n        if non_exact_bins_remaining.size > 0:\n            # Add a small constant to avoid division by zero and to smooth priorities\n            # Scale by a factor to differentiate non-exact fits without overpowering exact fits\n            scaled_inverse = 0.1 / (non_exact_bins_remaining + 1.0) \n            priorities[available_bins_mask][non_exact_fit_mask] = scaled_inverse\n            \n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins that are closest to fitting the item (best fit),\n    while also giving a strong preference to exact fits.\n    It uses inverse of slack for non-exact fits, with a bonus for exact matches.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Mask for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate slack for bins that can fit\n    slack = bins_remain_cap[can_fit_mask] - item\n    \n    # Exact fit bonus: prioritize bins with zero slack\n    exact_fit_mask_local = slack == 0\n    if np.any(exact_fit_mask_local):\n        # Assign a high priority to exact fits\n        priorities[can_fit_mask][exact_fit_mask_local] = 1.0\n    \n    # Non-exact fits: prioritize those with smaller slack (closer to fitting)\n    non_exact_fit_mask_local = slack > 0\n    if np.any(non_exact_fit_mask_local):\n        # Use inverse of slack + 1 to avoid division by zero and give higher priority to smaller slack\n        # Add a small epsilon for numerical stability, though slack > 0 should handle it.\n        priorities[can_fit_mask][non_exact_fit_mask_local] = 1.0 / (slack[non_exact_fit_mask_local] + 1e-9)\n        \n    # Normalize priorities to ensure a consistent scale, giving a slight boost to exact fits\n    # This is inspired by prioritizing exact fits with a score of 1.0 and scaled inverse for others\n    # We can scale non-exact fits relative to the best non-exact fit to make them more distinguishable\n    if np.any(priorities[can_fit_mask][non_exact_fit_mask_local]):\n        max_non_exact_priority = np.max(priorities[can_fit_mask][non_exact_fit_mask_local])\n        if max_non_exact_priority > 0: # Avoid division by zero if only exact fits exist\n            priorities[can_fit_mask][non_exact_fit_mask_local] /= max_non_exact_priority\n            priorities[can_fit_mask][non_exact_fit_mask_local] *= 0.9 # Scale down non-exact fits\n            \n    # Ensure exact fits (priority 1.0) still stand out\n    if np.any(priorities[can_fit_mask][exact_fit_mask_local]):\n         priorities[can_fit_mask][exact_fit_mask_local] = 1.0\n            \n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins by favoring exact fits and then best fits using a scaled inverse.\n    Combines the exact fit preference of Best Fit with the scaled inverse approach of Softmax-Based Fit.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    eligible_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(eligible_bins_mask):\n        return priorities\n\n    eligible_bins_remain_cap = bins_remain_cap[eligible_bins_mask]\n    \n    # Prioritize exact fits with a high score\n    exact_fit_mask = np.isclose(eligible_bins_remain_cap, item)\n    priorities[eligible_bins_mask][exact_fit_mask] = 1.0\n    \n    # For non-exact fits, use a scaled inverse of the remaining capacity\n    non_exact_fit_mask = ~exact_fit_mask\n    if np.any(non_exact_fit_mask):\n        non_exact_eligible_bins_remain_cap = eligible_bins_remain_cap[non_exact_fit_mask]\n        \n        # Scale differences to be between 0 and 1 for the inverse calculation\n        # Add 1 to the difference to avoid division by zero and to penalize\n        # bins that are slightly larger than needed.\n        differences = non_exact_eligible_bins_remain_cap - item\n        \n        # Use a robust scaling similar to the softmax approach, but without exponentiation\n        # to avoid potential overflow and maintain a more linear preference for smaller remaining capacities.\n        # Adding 1e-9 for numerical stability.\n        scaled_inverse = 1.0 / (differences + 1.0 + 1e-9)\n        \n        # Normalize these scaled inverse priorities so the highest is 1,\n        # making them comparable to the exact fit score of 1.0.\n        if np.max(scaled_inverse) > 1e-9: # Avoid division by zero if all scaled_inverse are near zero\n            normalized_scaled_inverse = scaled_inverse / np.max(scaled_inverse)\n        else:\n            normalized_scaled_inverse = scaled_inverse # Or handle as a special case if needed\n            \n        priorities[eligible_bins_mask][non_exact_fit_mask] = normalized_scaled_inverse\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Best Fit and a scaled inverse for robust prioritization.\n\n    Prioritizes bins that result in the smallest remaining capacity after packing (Best Fit),\n    and for other bins, uses an inverse of the remaining capacity scaled by a small constant\n    to avoid extreme values and provide smoother ranking.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    available_bins_mask = bins_remain_cap >= item\n    available_bins_caps = bins_remain_cap[available_bins_mask]\n\n    if available_bins_caps.size > 0:\n        remaining_after_fit = available_bins_caps - item\n        \n        # Prioritize exact fits (remaining capacity is 0) with a high score\n        exact_fit_mask = remaining_after_fit == 0\n        priorities[available_bins_mask][exact_fit_mask] = 1.0\n\n        # For non-exact fits, use a scaled inverse to prioritize bins with less remaining space\n        non_exact_fit_mask = ~exact_fit_mask\n        non_exact_bins_remaining = remaining_after_fit[non_exact_fit_mask]\n        \n        if non_exact_bins_remaining.size > 0:\n            # Add a small constant to avoid division by zero and to smooth priorities\n            # Scale by a factor to differentiate non-exact fits without overpowering exact fits\n            scaled_inverse = 0.1 / (non_exact_bins_remaining + 1.0) \n            priorities[available_bins_mask][non_exact_fit_mask] = scaled_inverse\n            \n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}