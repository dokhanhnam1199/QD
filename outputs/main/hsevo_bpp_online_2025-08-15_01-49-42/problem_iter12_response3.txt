```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    "Best Fit Decreasing" inspired priority for online Bin Packing.

    This strategy aims to mimic the effectiveness of Best Fit Decreasing by
    prioritizing bins that are the "tightest fit" for the current item,
    while also considering the "almost full" aspect. It prioritizes bins
    that leave the least remaining capacity after placing the item, but
    with a stronger emphasis on exact matches or very close fits.

    The scoring mechanism is designed to:
    1. Heavily reward bins that can exactly fit the item (remaining capacity = 0).
    2. For bins that don't exactly fit, reward those with smaller remaining
       capacities more significantly than in v1, using a non-linear scaling
       or a tiered approach. This encourages leaving less "wasted" space.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Returns:
        Array of priority scores for each bin. Bins that cannot accommodate the item
        receive a priority of -1. Higher scores indicate higher priority.
    """
    priorities = np.full_like(bins_remain_cap, -1.0)
    
    can_fit_mask = bins_remain_cap >= item
    
    if np.any(can_fit_mask):
        remaining_capacities_if_fit = bins_remain_cap[can_fit_mask] - item
        
        # Assign a very high base priority for bins that are an exact fit.
        # This is a key heuristic for efficiency.
        exact_fit_mask = (remaining_capacities_if_fit == 0)
        
        # For bins that are not an exact fit, we want to prioritize those with
        # smaller remaining capacities. A simple inverse relationship can be unstable.
        # Instead, we can use a function that gives higher scores to smaller values,
        # but with diminishing returns or a different scaling to avoid over-sensitivity
        # to tiny differences when exact fits are not available.
        # Let's use a tiered approach:
        # Tier 1: Exact fit (highest priority)
        # Tier 2: Very small remainder (e.g., < 10% of item size)
        # Tier 3: Small remainder (e.g., < 30% of item size)
        # Tier 4: Other fits

        # We want to maximize the score, so smaller remaining capacity means higher score.
        # Let's use a transformation that maps small positive remainders to high scores.
        # For example, using a negative exponential or a large constant minus the remainder.
        
        # A simple way to differentiate is to assign scores relative to the item size,
        # encouraging bins that leave a small fraction of the item's size as remainder.
        
        # Assign high scores for exact fits
        priorities[can_fit_mask & exact_fit_mask] = 1e9  # Very high score for exact matches

        # For non-exact fits, use a score that is inversely related to the remaining capacity,
        # but scaled to be lower than exact fits and to differentiate between close fits.
        # We can use a function like `C - remainder` or `1 / (remainder + epsilon)`.
        # Let's try a linear decrease from a base score, ensuring it's still higher than -1
        # but lower than exact fits.
        
        # Calculate scores for non-exact fits. We want smaller `remaining_capacities_if_fit`
        # to result in higher scores.
        non_exact_fit_mask = can_fit_mask & ~exact_fit_mask
        
        if np.any(non_exact_fit_mask):
            non_exact_remainders = remaining_capacities_if_fit[~exact_fit_mask]
            
            # We want to prioritize smaller remainders.
            # A simple approach is `max_possible_score - remainder`.
            # Let's set a maximum score for non-exact fits that is less than exact fits.
            max_score_for_non_exact = 1e8
            
            # We can further refine this by making the score dependent on the item size
            # or bin capacity, but for simplicity, a direct inverse relationship with
            # a capping mechanism works well.
            # A simple scaling: score = max_score - scaled_remainder
            # A logarithmic scale or inverse scaling can also work.
            
            # Let's use a form that gives higher scores for smaller remainders,
            # ensuring these scores are still less than the exact fit score.
            # We can use `1 / (remainder + epsilon)` or `constant - remainder`.
            # `constant - remainder` is more robust to very small remainders.
            
            # To ensure differentiation and avoid issues with very small remainders,
            # let's use a scaled inverse.
            epsilon = 1e-6  # Small constant to avoid division by zero
            # We want smaller remainders to have larger scores.
            # Let's map the remainders to scores such that smaller is better.
            # Example: 1000 - remainder
            
            # A slightly more sophisticated approach: normalize the remainder by item size
            # and use an inverse relationship.
            # `normalized_remainder = non_exact_remainders / item` (careful if item is 0)
            # `score = C / (normalized_remainder + epsilon)`
            
            # Let's stick to a simpler, more robust form that prioritizes smaller remainders:
            # `score = max_score_for_non_exact - (non_exact_remainders * scaling_factor)`
            # The scaling factor should be chosen such that even the largest possible non-exact
            # remainder doesn't get a score equal to or higher than the exact fit.
            
            # Let's use a score that is proportional to the negative of the remaining capacity,
            # but ensure it's capped below the exact fit score.
            # `score = BaseScore - remainder`. Let BaseScore be slightly less than 1e9.
            
            # A simple and effective way to prioritize smaller remaining capacities
            # is to use the negative of the remaining capacity, adjusted.
            # Since we want higher scores for smaller remainders, we can use `-(remainder)`
            # and then add an offset to make them positive and distinct from -1.
            
            # Let's define a range for non-exact fits.
            # Smallest possible remainder -> highest score in this range.
            # Largest possible remainder -> lowest score in this range (but > -1).
            
            # We can define a score like: `MaxNonExactScore - K * remainder`
            # where `K` is a scaling factor.
            # Let's set `MaxNonExactScore` to something like 1e8.
            # The minimum score for a non-exact fit should be > 0, so that it's
            # clearly better than unfillable bins.
            
            # Let's try mapping the remaining capacities to a score range.
            # If `non_exact_remainders` range from `min_rem` to `max_rem`:
            # Score mapping: `Score = MaxScore - (remainder - min_rem) * (MaxScore - MinScore) / (max_rem - min_rem)`
            # This ensures scores are distributed.
            
            # A simpler, robust approach: prioritize smaller absolute remaining capacity.
            # `score = C - remainder`. Let C be large enough.
            # For example, let the score be `1e8 - remaining_capacity`.
            # This prioritizes bins with `0` remaining capacity (handled by exact fit)
            # then bins with `1` remaining capacity, and so on.
            
            # Let's assign scores that are larger for smaller remainders.
            # A good heuristic is to use `1 / (remainder + epsilon)`.
            # But to make it more robust and differentiate better, we can scale it.
            # Consider `C / (remainder + epsilon)` where `C` is a large number.
            # Example: `1e8 / (non_exact_remainders + epsilon)`
            
            # Let's use a score that is a large constant minus the remainder, ensuring
            # it is always less than the exact fit score.
            # The remaining capacities are `bins_remain_cap[can_fit_mask & ~exact_fit_mask] - item`.
            
            # Maximize `remaining_capacities_if_fit` => This is wrong, we want to minimize it.
            # We want to maximize `-remaining_capacities_if_fit`.
            
            # Let's try a score that is directly related to how "full" the bin becomes.
            # A bin with remaining capacity `r` after fitting an item of size `s`
            # has been filled to `(BinCapacity - r)`.
            # If `BinCapacity` is fixed, minimizing `r` maximizes fill.
            
            # The original v1 used `-(bins_remain_cap[can_fit_mask] - item)`.
            # This prioritizes smaller remainders.
            # `priority = -remainder`. Smaller `remainder` -> higher `priority`.
            # Let's enhance this by making the priority scale more aggressively for smaller remainders.
            
            # A simple enhancement: score = `MaxScore - remainder`.
            # This gives highest scores to smallest remainders.
            
            # Let's ensure exact fits are top, and then for non-exact fits,
            # use a score that is high for small remainders.
            
            # For non-exact fits:
            # Score = `PrioritizedConstant - (remainder / item_size)`
            # This penalizes based on the *proportion* of the item size left over.
            # This is more robust across different item sizes.
            
            # Score = `MaxNonExactScore - ScaleFactor * (non_exact_remainders / item)`
            # Let's try `ScaleFactor = 1e8`.
            # `priorities[can_fit_mask & ~exact_fit_mask] = 1e8 - (1e8 * (non_exact_remainders / item))`
            # Ensure `item` is not zero, though typically item sizes are positive.
            
            # A robust inverse relationship:
            # If remainders are `r1, r2, ...`, we want to prioritize `r_i` where `r_i` is smallest.
            # Score proportional to `1 / (r + epsilon)` is a common approach.
            # Let's use `C / (remainder + epsilon)` and ensure it's less than exact fit score.
            
            # Let C = 1e8.
            epsilon = 1e-9
            scores_for_non_exact = 1e8 / (non_exact_remainders + epsilon)
            
            # We need to ensure these scores are distinct from the exact fit score.
            # If `scores_for_non_exact` can exceed `1e9`, we need to cap them or
            # adjust `C`. Since `1e8 / (small_positive + epsilon)` can be very large,
            # this might compete with exact fits.
            
            # Let's use a form that is guaranteed to be lower than exact fits,
            # and still prioritizes smaller remainders.
            # `score = Constant - remainder`.
            # Let `Constant` be `1e8`.
            
            # The scores should be greater than -1 and less than `1e9`.
            # Let's use a linear mapping from remaining capacity to score:
            # `score = A - B * remainder`
            # We want smaller remainder -> higher score.
            # Let the highest score for non-exact fit be `1e8`.
            # Let the lowest score for non-exact fit be `1`.
            # Assume `max_remainder_to_consider` is the largest remainder we want to give a positive score.
            # For simplicity, let's use `1e8 - remainder`. This assigns higher priority to smaller remainders.
            
            # This is similar to v1's `-(remainder)`, but with a large offset.
            # `priorities[can_fit_mask & ~exact_fit_mask] = 1e8 - non_exact_remainders`
            
            # To make it more sensitive to "almost full", we can use a non-linear scaling.
            # For example, `1 / (remainder^p)` or `exp(-k * remainder)`.
            # A simpler heuristic that differentiates well:
            # Score = `MaxScore - remainder * ScalingFactor`.
            # If `ScalingFactor` is large, smaller remainders get much higher scores.
            
            # Let's consider the "Best Fit" aspect more strongly.
            # Best Fit aims to minimize `bins_remain_cap - item`.
            # So, we want to maximize `-(bins_remain_cap - item)`.
            
            # Let's stick with the core idea of penalizing larger remainders.
            # `score = LargeConstant - remainder`.
            # Let `LargeConstant = 1e8`.
            # This means a remainder of 0 gets 1e8, remainder of 1 gets 1e7, etc.
            # This is effectively `1e8 - remainder`.
            
            # However, v1's `-(remainder)` is also trying to do this.
            # The problem with `-(remainder)` is that it's unbounded from below.
            # The problem with `1e8 - remainder` is that if `remainder` is very large,
            # the score can become negative or very small, potentially competing with -1.
            
            # Let's re-evaluate the goal:
            # 1. Exact fits get highest priority.
            # 2. Among non-exact fits, prioritize those with smallest remaining capacity.
            # 3. Provide good differentiation between close fits.
            
            # Heuristic:
            # Priority = HighValue - (Remainder / ItemSize) * HighValue
            # This scales the penalty by the item size.
            # If `item = 0.5`, `remainder = 0.1` => `0.1 / 0.5 = 0.2`
            # If `item = 0.1`, `remainder = 0.1` => `0.1 / 0.1 = 1.0` (exact fit)
            # If `item = 0.1`, `remainder = 0.01` => `0.01 / 0.1 = 0.1`
            
            # Let's define a score based on `1 - (remainder / item)` for non-exact fits.
            # This score is between -infinity and 1 (exclusive of 1 for non-exact).
            # We want it to be positive and less than the exact fit score.
            
            # Let's use a score that is inversely proportional to `remainder + epsilon`,
            # but capped to ensure it's less than exact fit score.
            
            # `score = C / (remainder + epsilon)`
            # Choose C and epsilon carefully.
            # If we want the highest non-exact score to be significantly less than 1e9,
            # say `1e8`.
            # When `remainder` is very small (but not zero), `score` becomes very large.
            # E.g., `1e8 / (1e-9 + 1e-9) = 1e8 / 2e-9 = 5e16`. This is too large.
            
            # Let's use a score that is `MaxScore - remainder`.
            # `MaxScore` for non-exact fits should be < `1e9`. Let `MaxScore = 1e8`.
            # `priorities[can_fit_mask & ~exact_fit_mask] = 1e8 - non_exact_remainders`
            
            # This ensures that smaller remainders get higher scores.
            # The minimum score for a non-exact fit would be `1e8 - largest_remainder`.
            # We need to make sure this minimum score is still positive and better than -1.
            # Assuming `largest_remainder` is not excessively large, this should work.
            # For robustness, we can clip the scores if they go too low.
            
            # Let's refine the scoring for non-exact fits.
            # We want to prioritize bins with smaller `remaining_capacities_if_fit`.
            # A common strategy is to map `x` to `1/x` or `C-x`.
            # To avoid division by zero and scale effectively, `C - x` is often better.
            
            # Let's define the priority for non-exact fits as:
            # `priority = BaseScore - RemainingCapacity`
            # `BaseScore` should be high enough to be clearly better than unfillable bins.
            # And distinct from exact fit scores.
            
            # Let's set `BaseScore = 1000.0`.
            # And `priorities[can_fit_mask & ~exact_fit_mask] = 1000.0 - non_exact_remainders`
            # This prioritizes smaller remainders.
            
            # Consider the "almost full" aspect. If a bin becomes nearly full,
            # its remaining capacity is small.
            
            # A key insight from "Better" heuristics often involves normalization or
            # relative comparisons.
            # Instead of absolute remaining capacity, consider `remainder / item_size`.
            # Smaller `remainder / item_size` is better.
            
            # Score = `C * (1 - remainder / item_size)` for non-exact fits.
            # If `remainder = 0.1`, `item = 0.5`, ratio = 0.2. Score = `C * 0.8`.
            # If `remainder = 0.05`, `item = 0.5`, ratio = 0.1. Score = `C * 0.9`.
            # This makes sense: smaller relative remainder is better.
            
            # Let's use `C = 1e8`.
            # We need to handle `item == 0` (though unlikely in BPP) and `item > 0`.
            
            valid_item_mask = item > 1e-9 # Check for non-zero item size
            
            if valid_item_mask:
                non_exact_remainders_for_valid_item = non_exact_remainders[item[can_fit_mask & ~exact_fit_mask] > 1e-9]
                corresponding_items = item[can_fit_mask & ~exact_fit_mask][item[can_fit_mask & ~exact_fit_mask] > 1e-9]
                
                if len(non_exact_remainders_for_valid_item) > 0:
                    ratios = non_exact_remainders_for_valid_item / corresponding_items
                    
                    # We want to maximize `1 - ratio`. So minimize `ratio`.
                    # Scores = `1e8 * (1 - ratios)`
                    # Clamp scores to be less than 1e9 and greater than -1.
                    scores_for_non_exact = 1e8 * (1 - ratios)
                    
                    # Ensure scores are positive and distinct from exact fits.
                    # If `ratios` is very close to 0, score is close to 1e8.
                    # If `ratios` is close to 1, score is close to 0.
                    
                    # Let's use a simplified approach that is robust and differentiates well:
                    # Priority = `max_score - remainder`
                    # This naturally gives higher scores to smaller remainders.
                    # It's also computationally simple.
                    
                    # Revert to the `max_score - remainder` idea, but ensure it's scaled.
                    # Let's use `1e8 - non_exact_remainders`. This directly penalizes
                    # larger remaining capacities.
                    
                    # What if we want to bias towards bins that are "more full" in an absolute sense?
                    # E.g., a bin with remaining capacity 0.1 is "more full" than a bin with 0.5.
                    # This is what `1e8 - remainder` does.
                    
                    # Consider robustness: what if `non_exact_remainders` are very small,
                    # like `1e-10`? `1e8 - 1e-10` is still close to `1e8`.
                    # This is good, as it means very tight fits get high scores.
                    
                    # The key differentiator is making the scores for non-exact fits
                    # clearly lower than exact fits, but still high for good fits.
                    
                    # Let's combine the exact fit reward with a scaled remainder penalty.
                    # Priority = `ScoreExactFit` if exact fit.
                    # Priority = `ScoreNonExactFitBase - Penalty` if non-exact fit.
                    
                    # `ScoreExactFit = 1e9`
                    # `ScoreNonExactFitBase = 1e8`
                    # `Penalty = non_exact_remainders * ScalingFactor`
                    
                    # If `ScalingFactor` is large, small remainders get small penalties -> high scores.
                    # If `ScalingFactor` is small, small remainders get small penalties -> scores closer to `1e8`.
                    
                    # Let's use `ScalingFactor = 1000.0`
                    # `priorities[can_fit_mask & ~exact_fit_mask] = 1e8 - (non_exact_remainders * 1000.0)`
                    
                    # This ensures that smaller remainders result in higher scores.
                    # The scores will be between `1e8 - max_remainder * 1000` and close to `1e8`.
                    # We need to ensure `1e8 - max_remainder * 1000 > -1`.
                    # If `max_remainder` is `0.5`, score is `1e8 - 500`, which is very high.
                    
                    # This approach seems robust and aligns with the "Best Fit" principle
                    # of minimizing remaining space.
                    
                    # Let's consider the absolute remaining capacity for non-exact fits.
                    # We want to prioritize smaller `remaining_capacities_if_fit`.
                    # Using `MaxScore - remainder` is a direct way to achieve this.
                    
                    # The definition of "almost full" suggests that a bin with a very small
                    # remaining capacity (after placing the item) is preferred.
                    # This is exactly what `MaxScore - remainder` does.
                    
                    # Let's use `1e8 - non_exact_remainders`.
                    # This provides a good range of scores for non-exact fits, prioritizing
                    # those with less leftover space.
                    priorities[can_fit_mask & ~exact_fit_mask] = 1e8 - non_exact_remainders

            # Ensure scores are not too low for valid non-exact fits.
            # If `1e8 - non_exact_remainders` becomes less than 0, set it to a small positive value.
            # This handles cases where `non_exact_remainders` might be very large.
            # However, typically `non_exact_remainders` will be less than the bin capacity.
            # A simple clip at 0 is sufficient if we are sure scores won't exceed 1e9.
            
            # Clip scores to be at least 0 for non-exact fits.
            priorities[can_fit_mask & ~exact_fit_mask] = np.maximum(priorities[can_fit_mask & ~exact_fit_mask], 0.0)

    return priorities
```
