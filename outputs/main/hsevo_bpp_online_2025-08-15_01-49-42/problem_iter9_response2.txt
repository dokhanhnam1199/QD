```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Hybrid Priority for Online Bin Packing.

    This strategy combines the "almost full" concept with a penalty for
    bins that are too empty, aiming for a more balanced packing.
    It prioritizes bins that leave a small remaining capacity (similar to V1),
    but also penalizes bins that would have a very large remaining capacity
    after packing, thus encouraging fuller bins over very empty ones.

    The scoring is designed to:
    1. Favor bins where `bins_remain_cap - item` is minimized (most "full").
    2. Penalize bins where `bins_remain_cap - item` is large (too empty).
    3. Assign a neutral or slightly negative score to bins that perfectly fit
       the item, to differentiate them from those that leave a small gap.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Returns:
        Array of priority scores for each bin. Bins that cannot accommodate the item
        receive a priority of -1. Higher scores indicate higher priority.
    """
    priorities = np.full_like(bins_remain_cap, -1.0)
    
    can_fit_mask = bins_remain_cap >= item
    
    if np.any(can_fit_mask):
        remaining_capacities_if_fit = bins_remain_cap[can_fit_mask] - item
        
        # Objective 1: Minimize remaining capacity (maximize negative remaining capacity)
        # This rewards bins that become "almost full".
        score_almost_full = -remaining_capacities_if_fit

        # Objective 2: Penalize large remaining capacities.
        # We want to down-weight bins that will still be very empty.
        # A simple way is to subtract a scaled version of the remaining capacity.
        # We can use a function like - (remaining_capacity_if_fit)^2 or
        # a sigmoid-like function to make the penalty grow as remaining capacity increases.
        # For simplicity and effectiveness, let's use a linear penalty that increases
        # with remaining capacity, but ensure it doesn't dominate the "almost full" score.
        # A robust approach is to use a scaled version of the inverse:
        # A bin that becomes very full (small remaining capacity) is good.
        # A bin that remains very empty (large remaining capacity) is less good.

        # Let's create a score that rewards small `remaining_capacities_if_fit`
        # and punishes large `remaining_capacities_if_fit`.
        # We can use a quadratic function that is minimized at 0 remaining capacity,
        # or a linear function with a slope.

        # Consider a score that is high for small `remaining_capacities_if_fit`
        # and decreases as `remaining_capacities_if_fit` increases.
        # e.g., score = 100 - remaining_capacities_if_fit
        # This is essentially maximizing `100 - remaining_capacities_if_fit`.
        # This is equivalent to minimizing `remaining_capacities_if_fit`, but with
        # a large constant that can be adjusted.

        # To differentiate, let's try to reward being "tight" but also penalize "slack".
        # A score could be: Max(0, C - (bins_remain_cap - item)) - PenaltyFactor * max(0, (bins_remain_cap - item))
        # where C is a constant representing "ideal fullness" and PenaltyFactor penalizes slack.

        # Let's use a simpler approach that is still a hybrid:
        # Score = (MaxPossibleScore - remaining_capacity) - penalty_factor * remaining_capacity
        # This combines a desire for small remaining_capacity with a penalty for it.
        # Effectively, we want to maximize `(Constant - remaining_capacity) - penalty_factor * remaining_capacity`.
        # This simplifies to maximizing `Constant - (1 + penalty_factor) * remaining_capacity`.
        # Which means minimizing `remaining_capacity * (1 + penalty_factor)`.
        # This is still very close to V1.

        # Let's try to integrate two objectives:
        # 1. Minimizing slack (rewarding `bins_remain_cap - item` close to 0)
        # 2. Maximizing bin utilization across all bins (implicitly).
        # If we prioritize bins that are *almost full*, we might leave many bins
        # with a moderate amount of remaining capacity.

        # A better hybrid might involve ranking or scaled values.
        # Consider the value of `bins_remain_cap[can_fit_mask]`.
        # Bins with lower remaining capacity are generally better.
        # Let's try to reward bins that are "just right" or "almost full".
        # We can use a function that peaks when `bins_remain_cap[can_fit_mask]` is close to `item`.
        # Or, we can reward small `remaining_capacities_if_fit` and penalize very large ones.

        # Let's try a score based on how "tight" the fit is, but with a diminishing return
        # for extremely tight fits (to avoid fragmentation if item is slightly smaller than bin capacity)
        # and a penalty for slack.
        # We can use a function that is high for small positive `remaining_capacities_if_fit`,
        # goes to zero or negative for larger `remaining_capacities_if_fit`.

        # For "differentiated scores", we can assign different levels of priority based on
        # the magnitude of remaining capacity.

        # Simple hybrid: Maximize `(MaxCapacity - (bins_remain_cap[can_fit_mask] - item))`
        # This rewards bins that, after packing, have a large capacity. This is counter-intuitive.

        # Let's go back to minimizing `remaining_capacities_if_fit`.
        # To differentiate, we can add a term that penalizes large remaining capacities.
        # Consider the target remaining capacity after packing to be small.
        # Score = -(remaining_capacities_if_fit) - penalty_for_slack * (remaining_capacities_if_fit)^2
        # Or, more simply: Score = -(remaining_capacities_if_fit) - penalty_for_slack * remaining_capacities_if_fit
        # This is equivalent to minimizing `remaining_capacities_if_fit * (1 + penalty_for_slack)`.
        # Still essentially the same structure.

        # Let's consider the "context". The context is the set of available bins.
        # We want to select a bin that is good *in this context*.
        # A bin that is almost full is good.
        # A bin that is extremely empty is bad.
        # A bin that perfectly fits is also good.

        # Let's define a score that is high for small, non-negative remaining capacity.
        # We can use a function like `1 / (remaining_capacity + 1)` which decreases as remaining_capacity increases.
        # Or, more linearly: `Constant - remaining_capacity`.
        # To penalize slack, we can make the score decrease faster.
        # e.g., Score = K - remaining_capacity - penalty_factor * remaining_capacity
        # Maximize Score => Minimize `remaining_capacity * (1 + penalty_factor)`

        # A more nuanced approach might be to consider the variance of remaining capacities
        # or the overall utilization. However, for a per-item priority function, we need
        # to evaluate based on the item and current bin states.

        # Let's try a score that is high for small `remaining_capacities_if_fit`
        # and then decays as `remaining_capacities_if_fit` increases.
        # We can use a piecewise function or a function like `exp(-k * remaining_capacity)`.
        # A simple linear approach: Score = C - remaining_capacity.
        # To penalize slack, we can make the "C" decrease for larger remaining capacities.

        # Consider the goal: minimize number of bins.
        # This often implies filling bins as much as possible.
        # Priority should be given to bins that become "most full" without overflowing.
        # "Most full" after packing means `bins_remain_cap - item` is minimal.

        # Let's try to assign scores that are relative to the *average* remaining capacity
        # among feasible bins. This introduces context.
        # However, this might be too complex for a simple priority function.

        # Let's stick to a form that enhances V1:
        # V1: `priorities[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item)`
        # This directly maximizes `bins_remain_cap - item` being minimal.

        # To add differentiation and robustness:
        # We want to reward bins that are "tight" but not too tight, and penalize slack.
        # A good score might be one that is high for small positive `remaining_capacities_if_fit`,
        # drops off for larger values, and is perhaps slightly penalized even for zero remaining capacity
        # if it means we could have used a slightly larger bin. This is getting complicated.

        # Let's try a score that is inversely proportional to the remaining capacity after packing,
        # but with a penalty that grows faster than linearly with remaining capacity.
        # Score = 1 / (epsilon + remaining_capacities_if_fit)  # Favors small remaining capacity.
        # To penalize slack, we can subtract a term that grows with remaining_capacities_if_fit.
        # Score = 1 / (epsilon + remaining_capacities_if_fit) - penalty_factor * remaining_capacities_if_fit

        # A simpler heuristic that differentiates:
        # We want to maximize `(BinCapacity - item) - slack_penalty_factor * slack`
        # where `slack = bins_remain_cap - item`.
        # So, maximize `(BinCapacity - item) - slack_penalty_factor * (BinCapacity - item)`.
        # This means we want to minimize `(BinCapacity - item) * (1 + slack_penalty_factor)`.

        # Let's use a scoring function that is high when `remaining_capacities_if_fit` is small,
        # and decreases more rapidly for larger values.
        # Example: A negative quadratic function of `remaining_capacities_if_fit` that peaks at 0.
        # Score = C - k * (remaining_capacities_if_fit)^2
        # This rewards small remaining capacities, and the penalty increases quadratically.

        # Let's combine a primary goal (minimize remaining capacity) with a secondary goal (penalize slack).
        # A common technique is to use a weighted sum.
        # Score = w1 * (1 / (epsilon + remaining_capacities_if_fit)) - w2 * remaining_capacities_if_fit
        # Or, to avoid division by zero and keep it simple:
        # Score = w1 * (-remaining_capacities_if_fit) + w2 * (-remaining_capacities_if_fit^2)
        # This still prioritizes negative remaining capacity.

        # Let's try a simpler form. The core idea of V1 is to pick the bin that becomes "most full".
        # This is equivalent to picking the bin with the smallest `bins_remain_cap - item`.
        # A common enhancement is to consider the "waste" in the bin.

        # Consider a score that reflects "how well" the item fits, focusing on minimizing wasted space.
        # Wasted space in a bin *after* packing: `bins_remain_cap - item`.
        # We want to minimize this.
        # Let's use a function that is high for small values of `bins_remain_cap - item`.

        # For differentiation, we can add a term that emphasizes being "almost full" over "moderately full".
        # A simple way is to subtract a small penalty for larger remaining capacities.
        # Score = -(bins_remain_cap[can_fit_mask] - item) - penalty_factor * (bins_remain_cap[can_fit_mask] - item)**2

        # A robust approach is to map remaining capacity to a score.
        # Low remaining capacity -> high score.
        # Large remaining capacity -> low score.

        # Let's implement a score that is `1 / (1 + remaining_capacity_if_fit)`.
        # This gives a score between (0, 1], where 1 is for 0 remaining capacity.
        # This is similar to V1 but bounded and might be more stable.
        # To differentiate: we can adjust the steepness.
        # A function like `exp(-k * remaining_capacity_if_fit)` also works.
        # A linear function: `C - remaining_capacities_if_fit` is what V1 is doing essentially.

        # Let's try to combine "tight fit" and "avoiding large residual bins".
        # Score = 100 - (bins_remain_cap[can_fit_mask] - item)  # Favors minimal remainder.
        # To penalize slack:
        # Score = 100 - (bins_remain_cap[can_fit_mask] - item) - penalty_factor * (bins_remain_cap[can_fit_mask] - item)
        # This is still just minimizing `remaining_capacity * (1 + penalty_factor)`.

        # A key aspect of "differentiated scores" is to create a range of scores that clearly rank options.
        # Let's use a score that is `MaxScore - f(remaining_capacity_if_fit)`, where `f` is an increasing function.
        # To differentiate, make `f` grow faster than linear.
        # Let f(x) = x + x^2 / C. Or f(x) = x^2.
        # Score = MaxScore - (remaining_capacities_if_fit)^2.
        # This rewards small remaining capacity, but penalizes larger ones more heavily.

        max_possible_score_base = 100.0 # A baseline to ensure positive scores before penalty
        penalty_factor = 0.5 # Controls how aggressively large remaining capacities are penalized

        # Score: Reward small remaining capacity, penalize larger remaining capacities quadratically.
        # The idea is to pick a bin that leaves a small gap, but avoid bins that leave a moderately large gap.
        priorities[can_fit_mask] = max_possible_score_base - remaining_capacities_if_fit - penalty_factor * (remaining_capacities_if_fit ** 2)

        # Ensure that bins with exactly zero remaining capacity get a good score,
        # but not necessarily the absolute maximum if there are other beneficial properties.
        # The current formula works well for this: if remaining_capacities_if_fit is 0, score is max_possible_score_base.
        # If remaining_capacities_if_fit is small positive (e.g., 0.1), score is slightly less.
        # If remaining_capacities_if_fit is larger (e.g., 1.0), score is significantly less due to the penalty.

    return priorities
```
