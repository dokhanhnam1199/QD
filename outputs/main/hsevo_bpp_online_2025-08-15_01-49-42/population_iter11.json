[
  {
    "stdout_filepath": "problem_iter11_response0.txt_stdout.txt",
    "code_path": "problem_iter11_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines exact fit priority with scaled inverse normalized slack for non-exact fits.\n    Prioritizes exact fits, then bins with minimal normalized slack to promote balanced packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Mask for bins that can potentially fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Identify bins that are an exact fit\n    exact_fit_mask = np.isclose(bins_remain_cap, item)\n    \n    # Assign highest priority to exact fits\n    priorities[exact_fit_mask] = 1.0\n    \n    # Consider bins that can fit the item but are not exact fits\n    non_exact_fit_mask = can_fit_mask & ~exact_fit_mask\n    non_exact_indices = np.where(non_exact_fit_mask)[0]\n    \n    if len(non_exact_indices) > 0:\n        # Calculate remaining capacity after fitting the item\n        remaining_after_fit = bins_remain_cap[non_exact_indices] - item\n        current_capacities = bins_remain_cap[non_exact_indices]\n        \n        # Calculate normalized slack: (remaining_capacity_after_fit) / (current_bin_capacity)\n        # Smaller normalized slack is better. Add epsilon for numerical stability.\n        normalized_slack = remaining_after_fit / (current_capacities + 1e-9)\n        \n        # Assign priorities: higher score for smaller normalized slack.\n        # Use 1.0 - normalized_slack to map smaller slack to higher scores.\n        # Scale these scores to be less than 1.0, ensuring exact fits are always preferred.\n        # A range of [0.5, 0.99] effectively differentiates good fits.\n        best_fit_scores = 1.0 - normalized_slack\n        scaled_best_fit_priorities = 0.5 + best_fit_scores * 0.49\n        \n        priorities[non_exact_indices] = scaled_best_fit_priorities\n        \n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 136.3127518260917,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response1.txt_stdout.txt",
    "code_path": "problem_iter11_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines exact fit priority with scaled inverse normalized slack for non-exact fits.\n    Prioritizes bins that perfectly fit the item, then bins that leave minimal normalized slack.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities # No bins can fit the item\n\n    # Calculate remaining capacities for bins that can fit the item\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n    \n    # Assign high priority to exact fits (remaining capacity is zero)\n    exact_fit_mask = remaining_after_fit == 0\n    priorities[can_fit_mask][exact_fit_mask] = 1.0\n\n    # Assign scores to non-exact fits based on normalized slack (inverse)\n    # Higher score for smaller remaining capacity relative to original capacity.\n    # Normalized slack = (bin_capacity - item) / bin_capacity\n    # We want to maximize 1 - normalized_slack, which means minimizing normalized slack.\n    # Smaller slack -> higher priority.\n    # Score range for non-exact fits: [0.5, 0.99] to be less than exact fits.\n    non_exact_fit_indices = np.where(can_fit_mask)[0][~exact_fit_mask]\n    \n    if non_exact_fit_indices.size > 0:\n        bins_for_non_exact = bins_remain_cap[can_fit_mask][~exact_fit_mask]\n        remaining_for_non_exact = remaining_after_fit[~exact_fit_mask]\n\n        # Calculate normalized slack: remaining_capacity / original_capacity\n        # Use a small epsilon to avoid division by zero if original capacity was 0 (should not happen if item fits)\n        epsilon = 1e-9\n        normalized_slack = remaining_for_non_exact / (bins_for_non_exact + epsilon)\n        \n        # Scale scores for non-exact fits to be between 0.5 and 0.99\n        # We want to maximize (1 - normalized_slack), so we scale (1 - normalized_slack)\n        # The value (1 - normalized_slack) ranges from approximately 0 (for large slack) to 1 (for very small slack).\n        # We map this to [0.5, 0.99].\n        # Scale factor: 0.49 (range of 0.99 - 0.5)\n        # Offset: 0.5\n        scaled_scores = 0.5 + 0.49 * (1.0 - normalized_slack)\n        \n        priorities[can_fit_mask][~exact_fit_mask] = scaled_scores\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 3.0,
    "halstead": 187.48684196024655,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response2.txt_stdout.txt",
    "code_path": "problem_iter11_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid heuristic prioritizing exact fits and then Best Fit with a penalty for extreme slack.\n\n    This heuristic assigns the highest priority to bins that perfectly fit the item.\n    For bins that do not offer an exact fit, it prioritizes those with the smallest\n    remaining capacity (Best Fit). Additionally, it penalizes bins that would leave\n    a disproportionately large amount of remaining capacity relative to the item size,\n    promoting more balanced utilization.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0, dtype=float)\n    \n    # Define a score for exact fits to give them highest priority\n    exact_fit_score = 1e6  # A very high score for perfect matches\n\n    # Define a penalty factor for large slack relative to the item size.\n    # This encourages more balanced packing by down-weighting bins that become too empty.\n    slack_penalty_factor = 0.1\n    \n    # Define a small epsilon to handle potential division by zero or near-zero item sizes\n    epsilon = 1e-9\n\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        available_bins_indices = np.where(can_fit_mask)[0]\n        \n        # Calculate slack for bins that can fit the item\n        slack = bins_remain_cap[available_bins_indices] - item\n        \n        # --- Scoring Logic ---\n        \n        # 1. Prioritize exact fits\n        exact_fit_indices = np.where(slack < epsilon)[0]\n        if exact_fit_indices.size > 0:\n            priorities[available_bins_indices[exact_fit_indices]] = exact_fit_score\n            \n            # Remove exact fits from further consideration for secondary scoring\n            # to ensure they retain the highest priority.\n            non_exact_fit_indices = np.delete(np.arange(len(available_bins_indices)), exact_fit_indices)\n            if non_exact_fit_indices.size == 0:\n                return priorities # All fitting bins were exact fits\n\n            # Update available_bins_indices to only include non-exact fits\n            available_bins_indices = available_bins_indices[non_exact_fit_indices]\n            slack = slack[non_exact_fit_indices]\n        \n        # 2. For non-exact fits, use Best Fit (minimize slack) as primary\n        # Score is proportional to negative slack. Higher value for smaller slack.\n        best_fit_scores = -slack\n        \n        # 3. Add a penalty for large slack relative to item size.\n        # This discourages bins that remain too empty after packing.\n        # Penalty is proportional to `slack / item` (or just `slack` if item is zero)\n        # We use `slack / (item + epsilon)` to avoid division by zero.\n        relative_slack = slack / (item + epsilon)\n        \n        # The penalty reduces the score for bins with high relative slack.\n        # We subtract the penalty term.\n        combined_scores = best_fit_scores - slack_penalty_factor * relative_slack\n        \n        priorities[available_bins_indices] = combined_scores\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 4.0,
    "halstead": 138.24238017775622,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response3.txt_stdout.txt",
    "code_path": "problem_iter11_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes exact fits, then bins with minimal normalized slack, offering robust differentiation.\n    Combines exact fit priority with scaled normalized slack for non-exact fits.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    # High priority for exact fits\n    exact_fit_mask = np.isclose(bins_remain_cap, item)\n    priorities[exact_fit_mask] = 1.0\n\n    # For bins that can fit but are not exact fits\n    can_fit_and_not_exact_mask = bins_remain_cap > item\n    \n    if np.any(can_fit_and_not_exact_mask):\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_and_not_exact_mask]\n        \n        # Calculate remaining capacity after placing the item\n        remaining_capacities_if_fit = eligible_bins_remain_cap - item\n        \n        # Normalized slack: remaining capacity / current bin capacity. Smaller is better.\n        # This is similar to \"Normalized Fit\" or \"Normalized Slack\" strategy.\n        epsilon = 1e-9\n        normalized_slack = remaining_capacities_if_fit / (eligible_bins_remain_cap + epsilon)\n        \n        # Priority: Higher score for smaller normalized slack.\n        # We use 1.0 - normalized_slack to map smaller slack to higher priority (closer to 1.0).\n        # Scale these scores to be distinct from exact fits, e.g., between 0.5 and 0.99.\n        # This strategy provides a good differentiation for non-exact fits.\n        non_exact_priorities = 0.5 + 0.49 * (1.0 - normalized_slack)\n        \n        priorities[can_fit_and_not_exact_mask] = non_exact_priorities\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 2.0,
    "halstead": 95.90827503317318,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response4.txt_stdout.txt",
    "code_path": "problem_iter11_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid prioritization: Exact Fit + Normalized Slack.\n    Prioritizes exact fits, then uses normalized slack to differentiate others.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        available_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # Score 1: Exact Fit (highest priority)\n        # A bin is an exact fit if remaining capacity equals item size.\n        exact_fit_mask = available_bins_remain_cap == item\n        priorities[can_fit_mask][exact_fit_mask] = 1.0\n        \n        # Score 2: Differentiated Slack for non-exact fits\n        # For bins that don't provide an exact fit, use normalized slack.\n        # Normalized slack = (remaining_cap - item) / bins_remain_cap.\n        # We want to minimize normalized slack, so we maximize its negative.\n        # To ensure these scores are lower than exact fits, we scale them.\n        non_exact_fit_mask = ~exact_fit_mask\n        \n        if np.any(non_exact_fit_mask):\n            non_exact_bins_remain_cap = available_bins_remain_cap[non_exact_fit_mask]\n            \n            # Calculate normalized slack: (remaining_cap - item) / initial_remaining_cap\n            # Higher score means less slack relative to bin size.\n            # We want to minimize slack, so prioritize bins with smaller slack.\n            # A lower slack value means the bin becomes 'more full' relative to its original capacity.\n            # To map this to higher priority, we can use:\n            # 1. A transformation that makes smaller slack values result in higher scores.\n            # 2. Scale these scores to be less than 1.0 (to ensure exact fits are always preferred).\n            \n            # Calculate slack: remaining_cap - item\n            slack = non_exact_bins_remain_cap - item\n            \n            # Normalize slack: slack / original_remaining_capacity\n            # Using initial remaining capacity of the subset of bins\n            # Add epsilon to avoid division by zero if a bin had 0 capacity initially (though covered by can_fit_mask, good practice)\n            epsilon = 1e-9\n            normalized_slack = slack / (non_exact_bins_remain_cap + epsilon)\n            \n            # Invert and scale: We want to maximize values for smaller normalized slack.\n            # A common range for non-exact fits is [0.5, 0.99].\n            # If normalized_slack is 0 (perfect fit, already handled by exact_fit_mask), it gets high score.\n            # If normalized_slack is close to 1 (item takes up almost no space), it gets low score.\n            # So, we can use 1 - normalized_slack to prioritize smaller normalized slack.\n            # Scale this to a range below 1.0, e.g., [0.5, 0.99].\n            # Let's use a linear mapping:\n            # normalized_slack = 0  -> score = 0.99\n            # normalized_slack = 1  -> score = 0.5\n            # score = m * (1 - normalized_slack) + c\n            # 0.99 = m * 1 + c\n            # 0.5 = m * 0 + c  => c = 0.5\n            # 0.99 = m + 0.5 => m = 0.49\n            # So, score = 0.49 * (1 - normalized_slack) + 0.5\n            \n            scaled_priority = 0.49 * (1.0 - normalized_slack) + 0.5\n            priorities[can_fit_mask][non_exact_fit_mask] = scaled_priority\n            \n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 3.0,
    "halstead": 124.86408532184433,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response5.txt_stdout.txt",
    "code_path": "problem_iter11_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines exact fit priority with a scaled Best Fit strategy using normalized slack.\n    Prioritizes exact fits, then bins with minimal normalized slack, ensuring clear hierarchy.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Exact Fit: Highest priority (score 1.0)\n    exact_fit_mask = np.isclose(bins_remain_cap, item)\n    priorities[exact_fit_mask] = 1.0\n\n    # Best Fit for non-exact fits: Prioritize bins with minimal normalized slack.\n    # Consider bins that can fit the item and are not exact fits.\n    can_fit_mask = (bins_remain_cap >= item) & ~exact_fit_mask\n    fit_indices = np.where(can_fit_mask)[0]\n\n    if len(fit_indices) > 0:\n        remaining_after_fit = bins_remain_cap[fit_indices] - item\n        current_capacities = bins_remain_cap[fit_indices]\n\n        # Calculate normalized slack: (remaining_capacity_after_fit) / (current_bin_capacity)\n        # Lower normalized slack is better. Add epsilon for numerical stability.\n        normalized_slack = remaining_after_fit / (current_capacities + 1e-9)\n\n        # Assign priorities: scores are higher for smaller normalized slack.\n        # Map (1.0 - normalized_slack) to a range clearly below 1.0, e.g., [0.5, 0.99].\n        # This ensures exact fits (1.0) are always preferred.\n        best_fit_scores = 1.0 - normalized_slack\n        # Scale scores to be in the range [0.5, 0.99]\n        scaled_best_fit_priorities = 0.5 + best_fit_scores * 0.49 \n\n        priorities[fit_indices] = scaled_best_fit_priorities\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 136.3127518260917,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response6.txt_stdout.txt",
    "code_path": "problem_iter11_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes exact fits, then bins with minimal normalized slack, using tiered scoring.\n    This heuristic combines the clarity of exact fit prioritization with nuanced differentiation\n    among non-exact fits based on relative space utilization for better packing efficiency.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    can_fit_mask = bins_remain_cap >= item\n    fit_indices = np.where(can_fit_mask)[0]\n\n    if len(fit_indices) == 0:\n        return priorities\n\n    eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    exact_fit_mask = np.abs(eligible_bins_remain_cap - item) < epsilon\n    exact_fit_indices_filtered = np.where(exact_fit_mask)[0]\n    actual_exact_fit_indices = fit_indices[exact_fit_indices_filtered]\n\n    priorities[actual_exact_fit_indices] = 1.0\n\n    non_exact_fit_mask = can_fit_mask & ~exact_fit_mask\n    non_exact_fit_indices = np.where(non_exact_fit_mask)[0]\n\n    if len(non_exact_fit_indices) > 0:\n        eligible_bins_for_slack_subset = bins_remain_cap[non_exact_fit_indices]\n        \n        remaining_after_fit = eligible_bins_for_slack_subset - item\n        \n        # Prioritize bins that leave minimal space after fitting the item.\n        # Normalize this residual capacity relative to the bin's capacity before fitting.\n        # This captures both 'best fit' and 'normalized slack' ideas.\n        # Higher score for smaller normalized remaining capacity.\n        normalized_remaining_capacity = remaining_after_fit / (eligible_bins_for_slack_subset + epsilon)\n        \n        # Map to scores less than 1.0 (exact fit score) to differentiate.\n        # A score of 1 - normalized_remaining_capacity (scaled) gives higher scores to bins\n        # that have less remaining space after fitting, thus being more \"full\".\n        # Scale to be in a range like [0.5, 0.99] for clear distinction from exact fits.\n        best_fit_scores = 1.0 - normalized_remaining_capacity\n        scaled_best_fit_priorities = 0.5 + best_fit_scores * 0.49\n\n        priorities[non_exact_fit_indices] = scaled_best_fit_priorities\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 186.46184263312372,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response7.txt_stdout.txt",
    "code_path": "problem_iter11_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes exact fits with a high score, then uses scaled negative remaining\n    capacity (Best Fit) for differentiation, offering robust bin selection.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        remaining_capacities_if_fit = eligible_bins_remain_cap - item\n\n        # Assign highest priority to exact fits\n        exact_fit_mask = remaining_capacities_if_fit == 0\n        priorities[can_fit_mask][exact_fit_mask] = 1.0\n\n        # For non-exact fits, prioritize those with smallest remaining capacity (Best Fit)\n        # Use a score that differentiates well for small remaining capacities.\n        # A linear scale `C - remaining_capacity` works, but `-log(remaining_capacity + epsilon)`\n        # offers better differentiation for near-perfect fits.\n        # Let's use `-remaining_capacity` for simplicity and robustness, scaled to be\n        # clearly less than the exact fit score.\n        non_exact_priorities = -remaining_capacities_if_fit\n        \n        # Scale these scores to be distinct from exact fits (e.g., between 0 and 0.99)\n        # We can normalize the `non_exact_priorities` or simply shift them.\n        # Let's map the best non-exact fit (smallest positive remaining capacity) to 0.99\n        # and the worst non-exact fit (largest remaining capacity) to a lower value.\n        \n        if np.any(~exact_fit_mask):\n            non_exact_eligible_indices = np.where(can_fit_mask)[0][~exact_fit_mask]\n            \n            # Find the range of non-exact remaining capacities\n            min_non_exact_rem = np.min(remaining_capacities_if_fit[~exact_fit_mask])\n            max_non_exact_rem = np.max(remaining_capacities_if_fit[~exact_fit_mask])\n\n            # Map the remaining capacities to a [0, 0.99] range\n            # Best Fit (min remaining) maps to 0.99, worst Fit (max remaining) maps to a lower value.\n            if max_non_exact_rem > min_non_exact_rem: # Avoid division by zero if all non-exact fits are identical\n                scaled_non_exact_priorities = 0.99 * (1.0 - (remaining_capacities_if_fit[~exact_fit_mask] - min_non_exact_rem) / (max_non_exact_rem - min_non_exact_rem))\n            else: # All non-exact fits have the same remaining capacity\n                scaled_non_exact_priorities = np.full_like(remaining_capacities_if_fit[~exact_fit_mask], 0.5) # Assign a medium score\n\n            priorities[non_exact_eligible_indices] = scaled_non_exact_priorities\n\n    # Ensure bins that cannot fit have the lowest possible priority\n    priorities[~can_fit_mask] = -np.inf \n    \n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 50, in priority_v2\n    # Score = 0.5 + (0.99 - 0.5) * (1 - normalized_rem)\nOverflowError: cannot convert float infinity to integer\n4\n218.26124091941205\n"
  },
  {
    "stdout_filepath": "problem_iter11_response8.txt_stdout.txt",
    "code_path": "problem_iter11_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid Exact-Fit and Scaled Slack priority.\n    Prioritizes exact fits with a high score, then uses scaled remaining capacity\n    for non-exact fits to differentiate between bins, favoring tighter fits.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        available_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # Exact fit: Highest priority (e.g., 1.0)\n        exact_fit_mask = available_bins_remain_cap == item\n        \n        # Non-exact fit: Scale remaining capacity to a range, e.g., [0.5, 0.99]\n        # We want to minimize remaining capacity, so we map small remainders to higher scores.\n        non_exact_fit_mask = ~exact_fit_mask\n        \n        if np.any(exact_fit_mask):\n            priorities[can_fit_mask][exact_fit_mask] = 1.0\n            \n        if np.any(non_exact_fit_mask):\n            non_exact_bins_remain_cap = available_bins_remain_cap[non_exact_fit_mask]\n            # Scale remaining capacity: Higher score for smaller remaining capacity.\n            # Map the minimum possible remaining capacity (just above 0) to ~0.99\n            # and the maximum possible remaining capacity (bins_remain_cap[non_exact_fit_mask] - item)\n            # to ~0.5.\n            # Simple linear scaling: priority = min_score + (max_score - min_score) * (1 - normalized_slack)\n            # where normalized_slack = (current_slack - min_slack) / (max_slack - min_slack)\n            # For simplicity and robustness, let's use a direct inverse relationship within a range.\n            # Let's map remaining capacity (r) to a score. We want smaller r to have higher score.\n            # Score ~ 1 - (r / max_possible_remainder_in_this_set)\n            # A more stable approach might be to use a monotonic function that maps to [0.5, 0.99]\n            \n            # Let's take the range of remaining capacities for non-exact fits\n            min_rem_non_exact = np.min(non_exact_bins_remain_cap)\n            max_rem_non_exact = np.max(non_exact_bins_remain_cap)\n            \n            # If all non-exact fits have the same remaining capacity, assign a mid-range score\n            if min_rem_non_exact == max_rem_non_exact:\n                non_exact_priorities = np.full(non_exact_bins_remain_cap.shape, 0.75) # Mid-range score\n            else:\n                # Scale remaining capacity to [0, 1] where 0 is min_rem, 1 is max_rem\n                normalized_rem = (non_exact_bins_remain_cap - min_rem_non_exact) / (max_rem_non_exact - min_rem_non_exact)\n                # Invert and scale to [0.5, 0.99]: Higher score for smaller remaining capacity\n                # Score = 0.5 + (0.99 - 0.5) * (1 - normalized_rem)\n                non_exact_priorities = 0.5 + 0.49 * (1.0 - normalized_rem)\n\n            priorities[can_fit_mask][non_exact_fit_mask] = non_exact_priorities\n            \n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 5.0,
    "halstead": 140.2304206377674,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response9.txt_stdout.txt",
    "code_path": "problem_iter11_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid heuristic prioritizing exact fits and then employing a scaled\n    Best Fit approach with tie-breaking based on initial bin fullness.\n\n    This strategy assigns the highest priority to bins that perfectly fit the item.\n    For other bins, it prioritizes those that minimize the remaining capacity\n    after packing (Best Fit), using a scaled score. As a tie-breaker, it\n    favors bins that were initially fuller (less remaining capacity).\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0, dtype=float)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # --- Primary objective: Exact Fit ---\n        # Assign a very high score for bins that perfectly fit the item.\n        exact_fit_mask = fitting_bins_remain_cap == item\n        \n        # Use a large constant for exact fits to ensure they are always preferred.\n        exact_fit_score = 1e9\n        priorities[can_fit_mask][exact_fit_mask] = exact_fit_score\n        \n        # --- Secondary objective: Best Fit (for non-exact fits) ---\n        non_exact_fit_mask = ~exact_fit_mask\n        \n        if np.any(non_exact_fit_mask):\n            non_exact_fitting_bins_remain_cap = fitting_bins_remain_cap[non_exact_fit_mask]\n            \n            # Calculate remaining capacity after fitting the item.\n            remaining_after_fit = non_exact_fitting_bins_remain_cap - item\n            \n            # Score for Best Fit: Higher score for smaller `remaining_after_fit`.\n            # We maximize `-remaining_after_fit`.\n            best_fit_score_base = -remaining_after_fit\n            \n            # --- Tertiary objective: Tie-breaking based on initial bin fullness ---\n            # For bins with the same `remaining_after_fit` score (or very close),\n            # prefer the bin that was initially fuller. This means preferring\n            # bins with less `bins_remain_cap`.\n            # We can achieve this by adding a term proportional to `-bins_remain_cap`.\n            # A larger negative value (more initial capacity used) is better.\n            \n            # Combine Best Fit score with tie-breaker. Use a scaling factor\n            # to ensure Best Fit is the dominant criterion.\n            scale_factor = 1e6  # Ensures Best Fit dominates tie-breaking.\n            \n            # Combined score for non-exact fits:\n            # Maximize: (scale_factor * -remaining_after_fit) + (-initial_remaining_capacity)\n            # This prioritizes minimal `remaining_after_fit`, then minimal `initial_remaining_capacity`.\n            combined_priorities = scale_factor * best_fit_score_base - non_exact_fitting_bins_remain_cap\n            \n            priorities[can_fit_mask][non_exact_fit_mask] = combined_priorities\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 3.0,
    "halstead": 84.0,
    "exec_success": true
  }
]