[
  {
    "stdout_filepath": "problem_iter11_response0.txt_stdout.txt",
    "code_path": "problem_iter11_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines exact fit priority with scaled inverse normalized slack for non-exact fits.\n    Prioritizes exact fits, then bins with minimal normalized slack to promote balanced packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Mask for bins that can potentially fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Identify bins that are an exact fit\n    exact_fit_mask = np.isclose(bins_remain_cap, item)\n    \n    # Assign highest priority to exact fits\n    priorities[exact_fit_mask] = 1.0\n    \n    # Consider bins that can fit the item but are not exact fits\n    non_exact_fit_mask = can_fit_mask & ~exact_fit_mask\n    non_exact_indices = np.where(non_exact_fit_mask)[0]\n    \n    if len(non_exact_indices) > 0:\n        # Calculate remaining capacity after fitting the item\n        remaining_after_fit = bins_remain_cap[non_exact_indices] - item\n        current_capacities = bins_remain_cap[non_exact_indices]\n        \n        # Calculate normalized slack: (remaining_capacity_after_fit) / (current_bin_capacity)\n        # Smaller normalized slack is better. Add epsilon for numerical stability.\n        normalized_slack = remaining_after_fit / (current_capacities + 1e-9)\n        \n        # Assign priorities: higher score for smaller normalized slack.\n        # Use 1.0 - normalized_slack to map smaller slack to higher scores.\n        # Scale these scores to be less than 1.0, ensuring exact fits are always preferred.\n        # A range of [0.5, 0.99] effectively differentiates good fits.\n        best_fit_scores = 1.0 - normalized_slack\n        scaled_best_fit_priorities = 0.5 + best_fit_scores * 0.49\n        \n        priorities[non_exact_indices] = scaled_best_fit_priorities\n        \n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 136.3127518260917,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response1.txt_stdout.txt",
    "code_path": "problem_iter11_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines exact fit priority with scaled inverse normalized slack for non-exact fits.\n    Prioritizes bins that perfectly fit the item, then bins that leave minimal normalized slack.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities # No bins can fit the item\n\n    # Calculate remaining capacities for bins that can fit the item\n    remaining_after_fit = bins_remain_cap[can_fit_mask] - item\n    \n    # Assign high priority to exact fits (remaining capacity is zero)\n    exact_fit_mask = remaining_after_fit == 0\n    priorities[can_fit_mask][exact_fit_mask] = 1.0\n\n    # Assign scores to non-exact fits based on normalized slack (inverse)\n    # Higher score for smaller remaining capacity relative to original capacity.\n    # Normalized slack = (bin_capacity - item) / bin_capacity\n    # We want to maximize 1 - normalized_slack, which means minimizing normalized slack.\n    # Smaller slack -> higher priority.\n    # Score range for non-exact fits: [0.5, 0.99] to be less than exact fits.\n    non_exact_fit_indices = np.where(can_fit_mask)[0][~exact_fit_mask]\n    \n    if non_exact_fit_indices.size > 0:\n        bins_for_non_exact = bins_remain_cap[can_fit_mask][~exact_fit_mask]\n        remaining_for_non_exact = remaining_after_fit[~exact_fit_mask]\n\n        # Calculate normalized slack: remaining_capacity / original_capacity\n        # Use a small epsilon to avoid division by zero if original capacity was 0 (should not happen if item fits)\n        epsilon = 1e-9\n        normalized_slack = remaining_for_non_exact / (bins_for_non_exact + epsilon)\n        \n        # Scale scores for non-exact fits to be between 0.5 and 0.99\n        # We want to maximize (1 - normalized_slack), so we scale (1 - normalized_slack)\n        # The value (1 - normalized_slack) ranges from approximately 0 (for large slack) to 1 (for very small slack).\n        # We map this to [0.5, 0.99].\n        # Scale factor: 0.49 (range of 0.99 - 0.5)\n        # Offset: 0.5\n        scaled_scores = 0.5 + 0.49 * (1.0 - normalized_slack)\n        \n        priorities[can_fit_mask][~exact_fit_mask] = scaled_scores\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 3.0,
    "halstead": 187.48684196024655,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response2.txt_stdout.txt",
    "code_path": "problem_iter11_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid heuristic prioritizing exact fits and then Best Fit with a penalty for extreme slack.\n\n    This heuristic assigns the highest priority to bins that perfectly fit the item.\n    For bins that do not offer an exact fit, it prioritizes those with the smallest\n    remaining capacity (Best Fit). Additionally, it penalizes bins that would leave\n    a disproportionately large amount of remaining capacity relative to the item size,\n    promoting more balanced utilization.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0, dtype=float)\n    \n    # Define a score for exact fits to give them highest priority\n    exact_fit_score = 1e6  # A very high score for perfect matches\n\n    # Define a penalty factor for large slack relative to the item size.\n    # This encourages more balanced packing by down-weighting bins that become too empty.\n    slack_penalty_factor = 0.1\n    \n    # Define a small epsilon to handle potential division by zero or near-zero item sizes\n    epsilon = 1e-9\n\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        available_bins_indices = np.where(can_fit_mask)[0]\n        \n        # Calculate slack for bins that can fit the item\n        slack = bins_remain_cap[available_bins_indices] - item\n        \n        # --- Scoring Logic ---\n        \n        # 1. Prioritize exact fits\n        exact_fit_indices = np.where(slack < epsilon)[0]\n        if exact_fit_indices.size > 0:\n            priorities[available_bins_indices[exact_fit_indices]] = exact_fit_score\n            \n            # Remove exact fits from further consideration for secondary scoring\n            # to ensure they retain the highest priority.\n            non_exact_fit_indices = np.delete(np.arange(len(available_bins_indices)), exact_fit_indices)\n            if non_exact_fit_indices.size == 0:\n                return priorities # All fitting bins were exact fits\n\n            # Update available_bins_indices to only include non-exact fits\n            available_bins_indices = available_bins_indices[non_exact_fit_indices]\n            slack = slack[non_exact_fit_indices]\n        \n        # 2. For non-exact fits, use Best Fit (minimize slack) as primary\n        # Score is proportional to negative slack. Higher value for smaller slack.\n        best_fit_scores = -slack\n        \n        # 3. Add a penalty for large slack relative to item size.\n        # This discourages bins that remain too empty after packing.\n        # Penalty is proportional to `slack / item` (or just `slack` if item is zero)\n        # We use `slack / (item + epsilon)` to avoid division by zero.\n        relative_slack = slack / (item + epsilon)\n        \n        # The penalty reduces the score for bins with high relative slack.\n        # We subtract the penalty term.\n        combined_scores = best_fit_scores - slack_penalty_factor * relative_slack\n        \n        priorities[available_bins_indices] = combined_scores\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 4.0,
    "halstead": 138.24238017775622,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response3.txt_stdout.txt",
    "code_path": "problem_iter11_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes exact fits, then bins with minimal normalized slack, offering robust differentiation.\n    Combines exact fit priority with scaled normalized slack for non-exact fits.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    # High priority for exact fits\n    exact_fit_mask = np.isclose(bins_remain_cap, item)\n    priorities[exact_fit_mask] = 1.0\n\n    # For bins that can fit but are not exact fits\n    can_fit_and_not_exact_mask = bins_remain_cap > item\n    \n    if np.any(can_fit_and_not_exact_mask):\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_and_not_exact_mask]\n        \n        # Calculate remaining capacity after placing the item\n        remaining_capacities_if_fit = eligible_bins_remain_cap - item\n        \n        # Normalized slack: remaining capacity / current bin capacity. Smaller is better.\n        # This is similar to \"Normalized Fit\" or \"Normalized Slack\" strategy.\n        epsilon = 1e-9\n        normalized_slack = remaining_capacities_if_fit / (eligible_bins_remain_cap + epsilon)\n        \n        # Priority: Higher score for smaller normalized slack.\n        # We use 1.0 - normalized_slack to map smaller slack to higher priority (closer to 1.0).\n        # Scale these scores to be distinct from exact fits, e.g., between 0.5 and 0.99.\n        # This strategy provides a good differentiation for non-exact fits.\n        non_exact_priorities = 0.5 + 0.49 * (1.0 - normalized_slack)\n        \n        priorities[can_fit_and_not_exact_mask] = non_exact_priorities\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 2.0,
    "halstead": 95.90827503317318,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response4.txt_stdout.txt",
    "code_path": "problem_iter11_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid prioritization: Exact Fit + Normalized Slack.\n    Prioritizes exact fits, then uses normalized slack to differentiate others.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        available_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # Score 1: Exact Fit (highest priority)\n        # A bin is an exact fit if remaining capacity equals item size.\n        exact_fit_mask = available_bins_remain_cap == item\n        priorities[can_fit_mask][exact_fit_mask] = 1.0\n        \n        # Score 2: Differentiated Slack for non-exact fits\n        # For bins that don't provide an exact fit, use normalized slack.\n        # Normalized slack = (remaining_cap - item) / bins_remain_cap.\n        # We want to minimize normalized slack, so we maximize its negative.\n        # To ensure these scores are lower than exact fits, we scale them.\n        non_exact_fit_mask = ~exact_fit_mask\n        \n        if np.any(non_exact_fit_mask):\n            non_exact_bins_remain_cap = available_bins_remain_cap[non_exact_fit_mask]\n            \n            # Calculate normalized slack: (remaining_cap - item) / initial_remaining_cap\n            # Higher score means less slack relative to bin size.\n            # We want to minimize slack, so prioritize bins with smaller slack.\n            # A lower slack value means the bin becomes 'more full' relative to its original capacity.\n            # To map this to higher priority, we can use:\n            # 1. A transformation that makes smaller slack values result in higher scores.\n            # 2. Scale these scores to be less than 1.0 (to ensure exact fits are always preferred).\n            \n            # Calculate slack: remaining_cap - item\n            slack = non_exact_bins_remain_cap - item\n            \n            # Normalize slack: slack / original_remaining_capacity\n            # Using initial remaining capacity of the subset of bins\n            # Add epsilon to avoid division by zero if a bin had 0 capacity initially (though covered by can_fit_mask, good practice)\n            epsilon = 1e-9\n            normalized_slack = slack / (non_exact_bins_remain_cap + epsilon)\n            \n            # Invert and scale: We want to maximize values for smaller normalized slack.\n            # A common range for non-exact fits is [0.5, 0.99].\n            # If normalized_slack is 0 (perfect fit, already handled by exact_fit_mask), it gets high score.\n            # If normalized_slack is close to 1 (item takes up almost no space), it gets low score.\n            # So, we can use 1 - normalized_slack to prioritize smaller normalized slack.\n            # Scale this to a range below 1.0, e.g., [0.5, 0.99].\n            # Let's use a linear mapping:\n            # normalized_slack = 0  -> score = 0.99\n            # normalized_slack = 1  -> score = 0.5\n            # score = m * (1 - normalized_slack) + c\n            # 0.99 = m * 1 + c\n            # 0.5 = m * 0 + c  => c = 0.5\n            # 0.99 = m + 0.5 => m = 0.49\n            # So, score = 0.49 * (1 - normalized_slack) + 0.5\n            \n            scaled_priority = 0.49 * (1.0 - normalized_slack) + 0.5\n            priorities[can_fit_mask][non_exact_fit_mask] = scaled_priority\n            \n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 3.0,
    "halstead": 124.86408532184433,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response5.txt_stdout.txt",
    "code_path": "problem_iter11_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines exact fit priority with a scaled Best Fit strategy using normalized slack.\n    Prioritizes exact fits, then bins with minimal normalized slack, ensuring clear hierarchy.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Exact Fit: Highest priority (score 1.0)\n    exact_fit_mask = np.isclose(bins_remain_cap, item)\n    priorities[exact_fit_mask] = 1.0\n\n    # Best Fit for non-exact fits: Prioritize bins with minimal normalized slack.\n    # Consider bins that can fit the item and are not exact fits.\n    can_fit_mask = (bins_remain_cap >= item) & ~exact_fit_mask\n    fit_indices = np.where(can_fit_mask)[0]\n\n    if len(fit_indices) > 0:\n        remaining_after_fit = bins_remain_cap[fit_indices] - item\n        current_capacities = bins_remain_cap[fit_indices]\n\n        # Calculate normalized slack: (remaining_capacity_after_fit) / (current_bin_capacity)\n        # Lower normalized slack is better. Add epsilon for numerical stability.\n        normalized_slack = remaining_after_fit / (current_capacities + 1e-9)\n\n        # Assign priorities: scores are higher for smaller normalized slack.\n        # Map (1.0 - normalized_slack) to a range clearly below 1.0, e.g., [0.5, 0.99].\n        # This ensures exact fits (1.0) are always preferred.\n        best_fit_scores = 1.0 - normalized_slack\n        # Scale scores to be in the range [0.5, 0.99]\n        scaled_best_fit_priorities = 0.5 + best_fit_scores * 0.49 \n\n        priorities[fit_indices] = scaled_best_fit_priorities\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 136.3127518260917,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response6.txt_stdout.txt",
    "code_path": "problem_iter11_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes exact fits, then bins with minimal normalized slack, using tiered scoring.\n    This heuristic combines the clarity of exact fit prioritization with nuanced differentiation\n    among non-exact fits based on relative space utilization for better packing efficiency.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    can_fit_mask = bins_remain_cap >= item\n    fit_indices = np.where(can_fit_mask)[0]\n\n    if len(fit_indices) == 0:\n        return priorities\n\n    eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    exact_fit_mask = np.abs(eligible_bins_remain_cap - item) < epsilon\n    exact_fit_indices_filtered = np.where(exact_fit_mask)[0]\n    actual_exact_fit_indices = fit_indices[exact_fit_indices_filtered]\n\n    priorities[actual_exact_fit_indices] = 1.0\n\n    non_exact_fit_mask = can_fit_mask & ~exact_fit_mask\n    non_exact_fit_indices = np.where(non_exact_fit_mask)[0]\n\n    if len(non_exact_fit_indices) > 0:\n        eligible_bins_for_slack_subset = bins_remain_cap[non_exact_fit_indices]\n        \n        remaining_after_fit = eligible_bins_for_slack_subset - item\n        \n        # Prioritize bins that leave minimal space after fitting the item.\n        # Normalize this residual capacity relative to the bin's capacity before fitting.\n        # This captures both 'best fit' and 'normalized slack' ideas.\n        # Higher score for smaller normalized remaining capacity.\n        normalized_remaining_capacity = remaining_after_fit / (eligible_bins_for_slack_subset + epsilon)\n        \n        # Map to scores less than 1.0 (exact fit score) to differentiate.\n        # A score of 1 - normalized_remaining_capacity (scaled) gives higher scores to bins\n        # that have less remaining space after fitting, thus being more \"full\".\n        # Scale to be in a range like [0.5, 0.99] for clear distinction from exact fits.\n        best_fit_scores = 1.0 - normalized_remaining_capacity\n        scaled_best_fit_priorities = 0.5 + best_fit_scores * 0.49\n\n        priorities[non_exact_fit_indices] = scaled_best_fit_priorities\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 186.46184263312372,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response7.txt_stdout.txt",
    "code_path": "problem_iter11_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes exact fits with a high score, then uses scaled negative remaining\n    capacity (Best Fit) for differentiation, offering robust bin selection.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        remaining_capacities_if_fit = eligible_bins_remain_cap - item\n\n        # Assign highest priority to exact fits\n        exact_fit_mask = remaining_capacities_if_fit == 0\n        priorities[can_fit_mask][exact_fit_mask] = 1.0\n\n        # For non-exact fits, prioritize those with smallest remaining capacity (Best Fit)\n        # Use a score that differentiates well for small remaining capacities.\n        # A linear scale `C - remaining_capacity` works, but `-log(remaining_capacity + epsilon)`\n        # offers better differentiation for near-perfect fits.\n        # Let's use `-remaining_capacity` for simplicity and robustness, scaled to be\n        # clearly less than the exact fit score.\n        non_exact_priorities = -remaining_capacities_if_fit\n        \n        # Scale these scores to be distinct from exact fits (e.g., between 0 and 0.99)\n        # We can normalize the `non_exact_priorities` or simply shift them.\n        # Let's map the best non-exact fit (smallest positive remaining capacity) to 0.99\n        # and the worst non-exact fit (largest remaining capacity) to a lower value.\n        \n        if np.any(~exact_fit_mask):\n            non_exact_eligible_indices = np.where(can_fit_mask)[0][~exact_fit_mask]\n            \n            # Find the range of non-exact remaining capacities\n            min_non_exact_rem = np.min(remaining_capacities_if_fit[~exact_fit_mask])\n            max_non_exact_rem = np.max(remaining_capacities_if_fit[~exact_fit_mask])\n\n            # Map the remaining capacities to a [0, 0.99] range\n            # Best Fit (min remaining) maps to 0.99, worst Fit (max remaining) maps to a lower value.\n            if max_non_exact_rem > min_non_exact_rem: # Avoid division by zero if all non-exact fits are identical\n                scaled_non_exact_priorities = 0.99 * (1.0 - (remaining_capacities_if_fit[~exact_fit_mask] - min_non_exact_rem) / (max_non_exact_rem - min_non_exact_rem))\n            else: # All non-exact fits have the same remaining capacity\n                scaled_non_exact_priorities = np.full_like(remaining_capacities_if_fit[~exact_fit_mask], 0.5) # Assign a medium score\n\n            priorities[non_exact_eligible_indices] = scaled_non_exact_priorities\n\n    # Ensure bins that cannot fit have the lowest possible priority\n    priorities[~can_fit_mask] = -np.inf \n    \n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 50, in priority_v2\n    # Score = 0.5 + (0.99 - 0.5) * (1 - normalized_rem)\nOverflowError: cannot convert float infinity to integer\n4\n218.26124091941205\n"
  },
  {
    "stdout_filepath": "problem_iter11_response8.txt_stdout.txt",
    "code_path": "problem_iter11_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid Exact-Fit and Scaled Slack priority.\n    Prioritizes exact fits with a high score, then uses scaled remaining capacity\n    for non-exact fits to differentiate between bins, favoring tighter fits.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        available_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # Exact fit: Highest priority (e.g., 1.0)\n        exact_fit_mask = available_bins_remain_cap == item\n        \n        # Non-exact fit: Scale remaining capacity to a range, e.g., [0.5, 0.99]\n        # We want to minimize remaining capacity, so we map small remainders to higher scores.\n        non_exact_fit_mask = ~exact_fit_mask\n        \n        if np.any(exact_fit_mask):\n            priorities[can_fit_mask][exact_fit_mask] = 1.0\n            \n        if np.any(non_exact_fit_mask):\n            non_exact_bins_remain_cap = available_bins_remain_cap[non_exact_fit_mask]\n            # Scale remaining capacity: Higher score for smaller remaining capacity.\n            # Map the minimum possible remaining capacity (just above 0) to ~0.99\n            # and the maximum possible remaining capacity (bins_remain_cap[non_exact_fit_mask] - item)\n            # to ~0.5.\n            # Simple linear scaling: priority = min_score + (max_score - min_score) * (1 - normalized_slack)\n            # where normalized_slack = (current_slack - min_slack) / (max_slack - min_slack)\n            # For simplicity and robustness, let's use a direct inverse relationship within a range.\n            # Let's map remaining capacity (r) to a score. We want smaller r to have higher score.\n            # Score ~ 1 - (r / max_possible_remainder_in_this_set)\n            # A more stable approach might be to use a monotonic function that maps to [0.5, 0.99]\n            \n            # Let's take the range of remaining capacities for non-exact fits\n            min_rem_non_exact = np.min(non_exact_bins_remain_cap)\n            max_rem_non_exact = np.max(non_exact_bins_remain_cap)\n            \n            # If all non-exact fits have the same remaining capacity, assign a mid-range score\n            if min_rem_non_exact == max_rem_non_exact:\n                non_exact_priorities = np.full(non_exact_bins_remain_cap.shape, 0.75) # Mid-range score\n            else:\n                # Scale remaining capacity to [0, 1] where 0 is min_rem, 1 is max_rem\n                normalized_rem = (non_exact_bins_remain_cap - min_rem_non_exact) / (max_rem_non_exact - min_rem_non_exact)\n                # Invert and scale to [0.5, 0.99]: Higher score for smaller remaining capacity\n                # Score = 0.5 + (0.99 - 0.5) * (1 - normalized_rem)\n                non_exact_priorities = 0.5 + 0.49 * (1.0 - normalized_rem)\n\n            priorities[can_fit_mask][non_exact_fit_mask] = non_exact_priorities\n            \n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 5.0,
    "halstead": 140.2304206377674,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response9.txt_stdout.txt",
    "code_path": "problem_iter11_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid heuristic prioritizing exact fits and then employing a scaled\n    Best Fit approach with tie-breaking based on initial bin fullness.\n\n    This strategy assigns the highest priority to bins that perfectly fit the item.\n    For other bins, it prioritizes those that minimize the remaining capacity\n    after packing (Best Fit), using a scaled score. As a tie-breaker, it\n    favors bins that were initially fuller (less remaining capacity).\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0, dtype=float)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # --- Primary objective: Exact Fit ---\n        # Assign a very high score for bins that perfectly fit the item.\n        exact_fit_mask = fitting_bins_remain_cap == item\n        \n        # Use a large constant for exact fits to ensure they are always preferred.\n        exact_fit_score = 1e9\n        priorities[can_fit_mask][exact_fit_mask] = exact_fit_score\n        \n        # --- Secondary objective: Best Fit (for non-exact fits) ---\n        non_exact_fit_mask = ~exact_fit_mask\n        \n        if np.any(non_exact_fit_mask):\n            non_exact_fitting_bins_remain_cap = fitting_bins_remain_cap[non_exact_fit_mask]\n            \n            # Calculate remaining capacity after fitting the item.\n            remaining_after_fit = non_exact_fitting_bins_remain_cap - item\n            \n            # Score for Best Fit: Higher score for smaller `remaining_after_fit`.\n            # We maximize `-remaining_after_fit`.\n            best_fit_score_base = -remaining_after_fit\n            \n            # --- Tertiary objective: Tie-breaking based on initial bin fullness ---\n            # For bins with the same `remaining_after_fit` score (or very close),\n            # prefer the bin that was initially fuller. This means preferring\n            # bins with less `bins_remain_cap`.\n            # We can achieve this by adding a term proportional to `-bins_remain_cap`.\n            # A larger negative value (more initial capacity used) is better.\n            \n            # Combine Best Fit score with tie-breaker. Use a scaling factor\n            # to ensure Best Fit is the dominant criterion.\n            scale_factor = 1e6  # Ensures Best Fit dominates tie-breaking.\n            \n            # Combined score for non-exact fits:\n            # Maximize: (scale_factor * -remaining_after_fit) + (-initial_remaining_capacity)\n            # This prioritizes minimal `remaining_after_fit`, then minimal `initial_remaining_capacity`.\n            combined_priorities = scale_factor * best_fit_score_base - non_exact_fitting_bins_remain_cap\n            \n            priorities[can_fit_mask][non_exact_fit_mask] = combined_priorities\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 3.0,
    "halstead": 84.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response0.txt_stdout.txt",
    "code_path": "problem_iter12_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid Prioritization: Best Fit + Nearly Exact Fit.\n\n    This heuristic combines the strengths of Best Fit (minimizing remaining capacity)\n    with a preference for bins that can *exactly* fit the item or leave a very small\n    positive remainder. It aims for a more decisive prioritization.\n\n    The scoring works as follows:\n    1. Bins that can exactly fit the item (remaining capacity == item) get the highest priority.\n    2. Bins that can fit the item and leave a small positive remaining capacity (item < remaining_capacity < item + epsilon)\n       get a high priority, inversely proportional to the remaining capacity. This is prioritized over larger remainders.\n    3. Bins that can fit the item but leave a larger remaining capacity get a lower priority, still inversely proportional\n       to the remaining capacity to favor tighter fits.\n    4. Bins that cannot accommodate the item receive a priority of -1.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # Calculate remaining capacities if the item fits\n        remaining_capacities_if_fit = eligible_bins_remain_cap - item\n        \n        # Define a small tolerance for \"nearly exact\" fits\n        epsilon = 1e-6  # A small positive value\n\n        # Priority 1: Exact Fit (remaining capacity is 0)\n        exact_fit_mask = (remaining_capacities_if_fit == 0)\n        priorities[can_fit_mask][exact_fit_mask] = 1e10 # Very high score for exact fit\n\n        # Priority 2: Nearly Exact Fit (small positive remaining capacity)\n        # These bins are good as they leave minimal waste, but not perfect.\n        # We want to prioritize smaller positive remainders.\n        nearly_exact_fit_mask = (remaining_capacities_if_fit > 0) & (remaining_capacities_if_fit < epsilon)\n        if np.any(nearly_exact_fit_mask):\n            # Assign scores inversely proportional to the small remainder\n            # Add a base score to differentiate from larger remainders\n            priorities[can_fit_mask][nearly_exact_fit_mask] = 1e9 - remaining_capacities_if_fit[nearly_exact_fit_mask] * 1e8\n\n        # Priority 3: Standard Best Fit (larger positive remaining capacity)\n        # These are bins that fit, but leave more space. We still prefer tighter fits.\n        standard_fit_mask = (remaining_capacities_if_fit >= epsilon)\n        if np.any(standard_fit_mask):\n            # Assign scores that are inversely proportional to remaining capacity.\n            # Using `1 / (remainder + small_constant)` to avoid division by zero\n            # and to ensure larger remainders get smaller scores.\n            # Add a large offset to ensure these scores are lower than exact/nearly exact fits.\n            small_constant = 1e-9\n            priorities[can_fit_mask][standard_fit_mask] = 1e8 - (remaining_capacities_if_fit[standard_fit_mask] / (remaining_capacities_if_fit[standard_fit_mask] + small_constant)) * 1e7\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 4.0,
    "halstead": 201.18251441994926,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response1.txt_stdout.txt",
    "code_path": "problem_iter12_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid Priority: Best Fit + Differentiated Slack.\n\n    This strategy aims to improve upon \"Almost Full Fit\" by first prioritizing\n    bins that leave a small, specific remaining capacity, and then using\n    a more nuanced approach for bins that don't create an \"almost full\" state.\n    It differentiates between bins that are a perfect fit or leave a very small\n    slack, and bins that have more capacity.\n\n    The core idea is to:\n    1. Prioritize bins that can accommodate the item. Bins that cannot fit get -1.\n    2. Among fitting bins, prioritize those that leave a very small, positive\n       remaining capacity. This is a refined version of \"almost full.\"\n       We can define \"almost full\" as having a remaining capacity between 0 and some threshold,\n       or simply the smallest positive remaining capacity.\n    3. For bins that have larger remaining capacities, we still want to prefer\n       those that leave less residual space, but with a less aggressive scoring.\n       This helps in cases where no \"almost full\" bin exists.\n\n    We will use a scoring system that:\n    - Assigns a high score to bins that fit and leave a small remainder.\n    - Assigns a moderate score to bins that fit and leave a larger remainder.\n    - The scoring function aims to differentiate clearly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        remaining_capacities_if_fit = bins_remain_cap[can_fit_mask] - item\n        \n        # Define a threshold for \"tight fit\" or \"almost full\".\n        # This could be a small percentage of the bin capacity, or a fixed small value.\n        # For simplicity, let's consider a small absolute remainder as high priority.\n        # Let's say a remainder < 10% of the bin capacity or a fixed small epsilon.\n        # A more robust approach is to normalize the remaining capacity by the original bin capacity\n        # if the original bin capacities were available. Since they are not, we work with remaining.\n        \n        # We want to prioritize minimal positive remaining capacity.\n        # A common way to differentiate is to use a piecewise function or a scaled inverse.\n        # Let's try a score that is higher for smaller remaining capacities.\n        # To ensure differentiation and avoid issues with division by near-zero,\n        # we can use a function like `max(0, threshold - x)` or `1 / (x + epsilon)`.\n        \n        # Approach:\n        # 1. Prioritize bins that leave a very small remainder (e.g., close to 0).\n        # 2. Among these, perhaps prioritize the one with the absolute smallest remainder.\n        # 3. For larger remainders, still prefer smaller ones, but with less impact.\n\n        # Let's assign scores such that smaller `remaining_capacities_if_fit` get higher scores.\n        # We can use a transformation that is strictly decreasing.\n        # For example, `-(remaining_capacity)` as in v1, but maybe scaled or with adjustments.\n        \n        # A key insight from the advice: \"use a hierarchical approach, prioritizing exact matches,\n        # then finely tuned slack minimization\".\n        # Exact matches: remaining_capacity_if_fit == 0.\n        # Finely tuned slack minimization: small positive remaining_capacity_if_fit.\n        \n        # Let's define a base score for fitting bins.\n        # We want to maximize the negative of remaining capacity.\n        # To differentiate, we can add a term that rewards smaller remainders more strongly.\n        \n        # Consider the 'Best Fit' aspect: minimize `bins_remain_cap - item`.\n        # This means maximizing `-(bins_remain_cap - item)`.\n        # Let's enhance this by making the penalty for larger remainders less severe\n        # or by giving a boost to \"almost full\" bins.\n        \n        # A common strategy is to use a score that is inversely related to the remaining capacity.\n        # However, to differentiate, let's consider a score that has a higher gradient for small remainders.\n        \n        # Option 1: Scaled Negative Remainder with a boost for small remainders.\n        # score = -remaining_capacity_if_fit\n        # This is similar to v1.\n\n        # Option 2: Inversely proportional to remaining capacity + a term that penalizes slack.\n        # Let's use a function that decreases rapidly for small remainders and then more slowly.\n        # Example: `1 / (x + epsilon)` or `max_capacity - x` if we knew max_capacity.\n        \n        # A simpler, yet effective strategy is to assign higher priority to bins that leave\n        # a remainder *closer* to zero, and among those, prioritize the one that is *exactly* zero.\n        \n        # Let's try a score based on the inverse of remaining capacity, but capped or scaled\n        # to avoid extreme values and ensure differentiability.\n        \n        # A robust approach is to make the priority score `f(remaining_capacity_if_fit)`\n        # where f is a decreasing function.\n        # To differentiate, we want f'(x) to be \"large negative\" for small x, and\n        # \"small negative\" for large x.\n        \n        # Example: `f(x) = -log(x + epsilon)` or `f(x) = -sqrt(x + epsilon)`.\n        # Or a piecewise linear function.\n        \n        # Let's try a score that is a large positive number minus the remaining capacity,\n        # but scaled.\n        \n        # Let's use a strategy that prioritizes bins that are \"almost full\" (small remainder)\n        # more aggressively than v1.\n        # We can achieve this by using a steeper decreasing function for the priority score.\n        \n        # Consider a scoring function like: `Constant - k * remaining_capacity`.\n        # If k is large, it's very sensitive to small remainders.\n        # If k is small, it's less sensitive.\n        \n        # Let's try to make the priority value higher for smaller remaining capacities.\n        # A common pattern in optimization is to use `1 / (x + epsilon)` for small x,\n        # or `max_val - x`.\n        \n        # Let's use a score that prioritizes smaller remaining capacities.\n        # We can use the negative of the remaining capacity as a base, and then\n        # add a small penalty for larger remainders.\n        \n        # Let's try to assign a score that is inversely proportional to the remaining capacity,\n        # but we need to ensure stability and differentiation.\n        \n        # Consider the objective of making the bins as full as possible.\n        # This means we want to minimize the remaining capacity.\n        # So, a bin with remaining capacity `r` should have a higher priority than one with `r' > r`.\n        \n        # Let's enhance the priority by considering the *relative* remaining capacity if we\n        # had bin capacity information. Since we don't, we focus on absolute remaining capacity.\n        \n        # Hybrid approach:\n        # If remaining_capacity_if_fit is very small (e.g., < 0.1 * item_size or a fixed small value),\n        # give it a high score.\n        # Otherwise, give it a score that is inversely proportional to the remaining capacity.\n        \n        # Let's try a smooth function that is steeper for small remainders.\n        # For example, `score = -remaining_capacity ** 0.5` or `score = -log(remaining_capacity + epsilon)`.\n        # Let's use `-(remaining_capacity_if_fit + epsilon)` for simplicity and stability,\n        # but this is still linear.\n        \n        # To ensure better differentiation for \"almost full\" bins, let's assign\n        # a significantly higher priority to bins that result in a very small remaining capacity.\n        # We can use a threshold to distinguish between \"tight fits\" and \"looser fits\".\n        \n        # Let's define a threshold for what constitutes an \"almost full\" bin.\n        # A simple threshold could be a small fraction of the item size itself, or a fixed value.\n        # For example, `threshold = 0.1 * item`.\n        # Or, more generally, `threshold = min_possible_positive_remainder`.\n        \n        # Let's try a scoring mechanism where:\n        # - Bins with `remaining_capacity_if_fit` close to 0 get a high, distinct score.\n        # - Bins with larger `remaining_capacity_if_fit` get scores that are still decreasing,\n        #   but with a lower magnitude of decrease.\n        \n        # A practical way to achieve this is by using a combination of linear and\n        # inverse proportional scoring, or a power function.\n        \n        # Let's use `score = - (remaining_capacity_if_fit + small_constant)`. This is linear.\n        # To make it more sensitive to small remainders, we can use `score = - (remaining_capacity_if_fit ** 0.5)`.\n        # Or even more aggressive: `score = -log(remaining_capacity_if_fit + epsilon)`.\n        \n        # Let's try a robust approach using inverse remaining capacity but with a slight modification\n        # to give a boost to bins that are 'almost full'.\n        \n        # We want to maximize `f(r)` where `f` is decreasing.\n        # Let's use a form that is highly sensitive to small `r`.\n        # `score = M - r` where M is a large constant.\n        # If we want to differentiate \"almost full\" vs \"not so full\", we can add a term.\n        \n        # Consider a piecewise approach for clarity and differentiation:\n        # If `remaining_capacity_if_fit < epsilon_tight`: high priority, proportional to `-remaining_capacity_if_fit`.\n        # Else: medium priority, proportional to `-remaining_capacity_if_fit`.\n        \n        # Let's use a simpler, effective continuous function that prioritizes small remainders.\n        # A form that is highly sensitive to small remainders is `1 / (x + epsilon)`.\n        # However, this can lead to very large values.\n        \n        # Let's refine the idea:\n        # Prioritize bins that minimize `remaining_capacity_if_fit`.\n        # This means we want to maximize `-remaining_capacity_if_fit`.\n        # To differentiate, we can consider a score that is `MAX_SCORE - (remaining_capacity_if_fit / SCALE)`.\n        # A larger `SCALE` means less differentiation. A smaller `SCALE` means more differentiation.\n        \n        # Let's use a score that is strongly decreasing for small `remaining_capacity_if_fit`.\n        # A good candidate is a function like `exp(-k * remaining_capacity_if_fit)` where `k` is positive.\n        # Or `1 / (remaining_capacity_if_fit + epsilon)`.\n        \n        # Let's try to combine the \"Best Fit\" (minimal remaining capacity) with a \"First Fit Decreasing\" spirit\n        # by giving a bonus to bins that become \"almost full\".\n        \n        # A more structured scoring:\n        # For bins that can fit:\n        # Calculate `r = bins_remain_cap[can_fit_mask] - item`\n        # Let's define a threshold `T`.\n        # If `r <= T`, the score is `BaseScore + Bonus - r`.\n        # If `r > T`, the score is `BaseScore - r / PenaltyFactor`.\n        \n        # For simplicity and robustness, let's use a score that emphasizes minimal remaining capacity\n        # without creating extreme values.\n        # `score = -remaining_capacity_if_fit` (like v1) is okay but doesn't differentiate much.\n        \n        # Let's try a score that is proportional to the inverse of the remaining capacity,\n        # but ensure stability and prevent extreme values.\n        # A common practice is to use a linear transformation of the inverse.\n        # `score = C - K * remaining_capacity_if_fit` where C and K are constants.\n        # To prioritize smaller remainders, K should be positive.\n        # To differentiate small remainders more, K could be larger for smaller remainders.\n        \n        # Let's try a scoring mechanism that strongly prefers bins with very small remainders.\n        # For example, if `remaining_capacity_if_fit` is 0, it's the best.\n        # If `remaining_capacity_if_fit` is small positive, it's very good.\n        # If `remaining_capacity_if_fit` is larger, it's less good.\n        \n        # Let's use a score that increases as `remaining_capacity_if_fit` decreases.\n        # A simple increasing function is `f(x) = C - x`.\n        # To differentiate more for small x, we could use `f(x) = C - sqrt(x)`.\n        # Or `f(x) = C - log(x + epsilon)`.\n        \n        # Let's implement a scoring function that is inversely related to the remaining capacity,\n        # but scaled to ensure distinct priorities.\n        # We want to maximize `priorities[can_fit_mask]`.\n        \n        # Let `r_vals = remaining_capacities_if_fit`.\n        # A good heuristic priority might be related to `1 / (r_vals + epsilon)`.\n        # To make it more stable and to ensure we don't get excessively large values,\n        # we can normalize or use a different function.\n        \n        # Consider a score like `-(r_vals + epsilon)`. This is v1's core idea.\n        # To improve differentiation:\n        # Let's use a score that is more sensitive to smaller values of `r_vals`.\n        # A power function can achieve this: `-(r_vals**p)` where `0 < p < 1`.\n        # For example, `p = 0.5` (square root).\n        \n        # Let's try `score = - np.sqrt(remaining_capacities_if_fit + 1e-9)`.\n        # This will give higher scores to smaller remaining capacities.\n        # The addition of `1e-9` avoids issues with `sqrt(0)`.\n        \n        # The \"Advice\" section mentions \"finely tuned slack minimization\".\n        # This implies we want to strongly favor bins that leave minimal slack.\n        \n        # Let's try a score that is inversely proportional to the remaining capacity.\n        # `score = 1.0 / (remaining_capacities_if_fit + epsilon)`\n        # However, this can lead to extreme values.\n        \n        # A balanced approach:\n        # Prioritize bins with minimal remaining capacity.\n        # `score = -remaining_capacity_if_fit` (similar to v1)\n        \n        # Let's make it more aggressive for \"almost full\" bins.\n        # Consider a score like: `-(remaining_capacity_if_fit + 0.1 * item)`\n        # This penalizes larger remainders more, but we want to reward smaller ones.\n        \n        # Let's try a strategy that assigns a higher value to bins that are \"more full\".\n        # `priority = bins_remain_cap[can_fit_mask] - item` (this is remaining capacity)\n        # We want to minimize this. So, priority should be high for small values.\n        \n        # A simple way to differentiate is to use a large constant minus the remaining capacity.\n        # `score = LargeConstant - remaining_capacity_if_fit`\n        # To make it more sensitive to small remainders, we can make `LargeConstant` dependent on the problem,\n        # or use a non-linear function.\n        \n        # Let's try a robust scoring function that emphasizes minimal remaining capacity.\n        # `score = 1.0 / (remaining_capacity_if_fit + 1e-6)`\n        # This gives higher scores to smaller remainders.\n        # The `1e-6` is a small epsilon for numerical stability.\n        \n        # Let's try a different formulation that differentiates \"tight fits\" better.\n        # Consider a score based on how \"full\" the bin becomes.\n        # If a bin has remaining capacity `C_rem` and we place item `I`, the new remaining capacity is `C_rem - I`.\n        # We want `C_rem - I` to be as small as possible (but non-negative).\n        \n        # Let's use a function that rewards smaller remaining capacities.\n        # A simple way to do this is by using the negative of the remaining capacity itself,\n        # as in v1.\n        # `score = -(remaining_capacities_if_fit)`\n        \n        # To make it \"better\", we need more differentiation.\n        # Consider a scenario:\n        # Item size = 0.5\n        # Bins remaining capacities: [0.6, 0.7, 1.0]\n        # Possible remaining capacities after fitting: [0.1, 0.2, 0.5]\n        # v1 scores: [-0.1, -0.2, -0.5] -> Bin 1 is preferred.\n        \n        # We want to prioritize the bin that leaves 0.1, then 0.2, then 0.5.\n        # This means scores should be decreasing: score(0.1) > score(0.2) > score(0.5).\n        \n        # Let's use a score that is inversely proportional to remaining capacity.\n        # `score = 1.0 / (remaining_capacities_if_fit + 1e-6)`\n        # Scores: [1.0/0.1, 1.0/0.2, 1.0/0.5] = [10.0, 5.0, 2.0]\n        # This clearly prioritizes the smallest remainder.\n        \n        # This seems to align well with the goal of prioritizing bins that are \"almost full\".\n        # It provides good differentiation.\n        \n        epsilon = 1e-9\n        priorities[can_fit_mask] = 1.0 / (remaining_capacities_if_fit + epsilon)\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 2.0,
    "halstead": 50.18947501009619,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response2.txt_stdout.txt",
    "code_path": "problem_iter12_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        bins_that_fit_remain_cap = bins_remain_cap[can_fit_mask]\n        \n        # Calculate remaining capacities after placing the item\n        remaining_capacities_if_fit = bins_that_fit_remain_cap - item\n        \n        # Primary objective: prioritize exact fits (remaining capacity is 0)\n        # Assign a very high priority to exact fits.\n        exact_fit_mask = (bins_that_fit_remain_cap == item)\n        \n        # Secondary objective: For bins that are not exact fits, prioritize those\n        # that leave the *smallest positive* remaining capacity.\n        # This is equivalent to minimizing `remaining_capacities_if_fit` among non-exact fits.\n        # To give higher priority to smaller remainders, we can use a transformation.\n        # A common technique is to use `1 / (remainder + epsilon)` or a large value minus the remainder.\n        # Let's use a score inversely proportional to the remainder, but ensure exact fits get top priority.\n        \n        # Calculate scores for non-exact fits\n        non_exact_fit_mask = ~exact_fit_mask\n        \n        if np.any(non_exact_fit_mask):\n            # We want smaller remaining capacity to have a higher score.\n            # Using `-(remaining_capacity)` means smaller positive values get higher scores.\n            # For example, 0.1 > -0.5.\n            priorities[can_fit_mask][non_exact_fit_mask] = -remaining_capacities_if_fit[non_exact_fit_mask]\n        \n        # Assign the highest priority to exact fits\n        if np.any(exact_fit_mask):\n            # Set a value significantly higher than any possible score from non-exact fits.\n            # Since non-exact fits are negative or zero (if remainder is 0),\n            # a large positive number works.\n            priorities[can_fit_mask][exact_fit_mask] = 1e6 \n            \n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 4.0,
    "halstead": 51.89147427955947,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response3.txt_stdout.txt",
    "code_path": "problem_iter12_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    \"Best Fit Decreasing\" inspired priority for online Bin Packing.\n\n    This strategy aims to mimic the effectiveness of Best Fit Decreasing by\n    prioritizing bins that are the \"tightest fit\" for the current item,\n    while also considering the \"almost full\" aspect. It prioritizes bins\n    that leave the least remaining capacity after placing the item, but\n    with a stronger emphasis on exact matches or very close fits.\n\n    The scoring mechanism is designed to:\n    1. Heavily reward bins that can exactly fit the item (remaining capacity = 0).\n    2. For bins that don't exactly fit, reward those with smaller remaining\n       capacities more significantly than in v1, using a non-linear scaling\n       or a tiered approach. This encourages leaving less \"wasted\" space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        remaining_capacities_if_fit = bins_remain_cap[can_fit_mask] - item\n        \n        # Assign a very high base priority for bins that are an exact fit.\n        # This is a key heuristic for efficiency.\n        exact_fit_mask = (remaining_capacities_if_fit == 0)\n        \n        # For bins that are not an exact fit, we want to prioritize those with\n        # smaller remaining capacities. A simple inverse relationship can be unstable.\n        # Instead, we can use a function that gives higher scores to smaller values,\n        # but with diminishing returns or a different scaling to avoid over-sensitivity\n        # to tiny differences when exact fits are not available.\n        # Let's use a tiered approach:\n        # Tier 1: Exact fit (highest priority)\n        # Tier 2: Very small remainder (e.g., < 10% of item size)\n        # Tier 3: Small remainder (e.g., < 30% of item size)\n        # Tier 4: Other fits\n\n        # We want to maximize the score, so smaller remaining capacity means higher score.\n        # Let's use a transformation that maps small positive remainders to high scores.\n        # For example, using a negative exponential or a large constant minus the remainder.\n        \n        # A simple way to differentiate is to assign scores relative to the item size,\n        # encouraging bins that leave a small fraction of the item's size as remainder.\n        \n        # Assign high scores for exact fits\n        priorities[can_fit_mask & exact_fit_mask] = 1e9  # Very high score for exact matches\n\n        # For non-exact fits, use a score that is inversely related to the remaining capacity,\n        # but scaled to be lower than exact fits and to differentiate between close fits.\n        # We can use a function like `C - remainder` or `1 / (remainder + epsilon)`.\n        # Let's try a linear decrease from a base score, ensuring it's still higher than -1\n        # but lower than exact fits.\n        \n        # Calculate scores for non-exact fits. We want smaller `remaining_capacities_if_fit`\n        # to result in higher scores.\n        non_exact_fit_mask = can_fit_mask & ~exact_fit_mask\n        \n        if np.any(non_exact_fit_mask):\n            non_exact_remainders = remaining_capacities_if_fit[~exact_fit_mask]\n            \n            # We want to prioritize smaller remainders.\n            # A simple approach is `max_possible_score - remainder`.\n            # Let's set a maximum score for non-exact fits that is less than exact fits.\n            max_score_for_non_exact = 1e8\n            \n            # We can further refine this by making the score dependent on the item size\n            # or bin capacity, but for simplicity, a direct inverse relationship with\n            # a capping mechanism works well.\n            # A simple scaling: score = max_score - scaled_remainder\n            # A logarithmic scale or inverse scaling can also work.\n            \n            # Let's use a form that gives higher scores for smaller remainders,\n            # ensuring these scores are still less than the exact fit score.\n            # We can use `1 / (remainder + epsilon)` or `constant - remainder`.\n            # `constant - remainder` is more robust to very small remainders.\n            \n            # To ensure differentiation and avoid issues with very small remainders,\n            # let's use a scaled inverse.\n            epsilon = 1e-6  # Small constant to avoid division by zero\n            # We want smaller remainders to have larger scores.\n            # Let's map the remainders to scores such that smaller is better.\n            # Example: 1000 - remainder\n            \n            # A slightly more sophisticated approach: normalize the remainder by item size\n            # and use an inverse relationship.\n            # `normalized_remainder = non_exact_remainders / item` (careful if item is 0)\n            # `score = C / (normalized_remainder + epsilon)`\n            \n            # Let's stick to a simpler, more robust form that prioritizes smaller remainders:\n            # `score = max_score_for_non_exact - (non_exact_remainders * scaling_factor)`\n            # The scaling factor should be chosen such that even the largest possible non-exact\n            # remainder doesn't get a score equal to or higher than the exact fit.\n            \n            # Let's use a score that is proportional to the negative of the remaining capacity,\n            # but ensure it's capped below the exact fit score.\n            # `score = BaseScore - remainder`. Let BaseScore be slightly less than 1e9.\n            \n            # A simple and effective way to prioritize smaller remaining capacities\n            # is to use the negative of the remaining capacity, adjusted.\n            # Since we want higher scores for smaller remainders, we can use `-(remainder)`\n            # and then add an offset to make them positive and distinct from -1.\n            \n            # Let's define a range for non-exact fits.\n            # Smallest possible remainder -> highest score in this range.\n            # Largest possible remainder -> lowest score in this range (but > -1).\n            \n            # We can define a score like: `MaxNonExactScore - K * remainder`\n            # where `K` is a scaling factor.\n            # Let's set `MaxNonExactScore` to something like 1e8.\n            # The minimum score for a non-exact fit should be > 0, so that it's\n            # clearly better than unfillable bins.\n            \n            # Let's try mapping the remaining capacities to a score range.\n            # If `non_exact_remainders` range from `min_rem` to `max_rem`:\n            # Score mapping: `Score = MaxScore - (remainder - min_rem) * (MaxScore - MinScore) / (max_rem - min_rem)`\n            # This ensures scores are distributed.\n            \n            # A simpler, robust approach: prioritize smaller absolute remaining capacity.\n            # `score = C - remainder`. Let C be large enough.\n            # For example, let the score be `1e8 - remaining_capacity`.\n            # This prioritizes bins with `0` remaining capacity (handled by exact fit)\n            # then bins with `1` remaining capacity, and so on.\n            \n            # Let's assign scores that are larger for smaller remainders.\n            # A good heuristic is to use `1 / (remainder + epsilon)`.\n            # But to make it more robust and differentiate better, we can scale it.\n            # Consider `C / (remainder + epsilon)` where `C` is a large number.\n            # Example: `1e8 / (non_exact_remainders + epsilon)`\n            \n            # Let's use a score that is a large constant minus the remainder, ensuring\n            # it is always less than the exact fit score.\n            # The remaining capacities are `bins_remain_cap[can_fit_mask & ~exact_fit_mask] - item`.\n            \n            # Maximize `remaining_capacities_if_fit` => This is wrong, we want to minimize it.\n            # We want to maximize `-remaining_capacities_if_fit`.\n            \n            # Let's try a score that is directly related to how \"full\" the bin becomes.\n            # A bin with remaining capacity `r` after fitting an item of size `s`\n            # has been filled to `(BinCapacity - r)`.\n            # If `BinCapacity` is fixed, minimizing `r` maximizes fill.\n            \n            # The original v1 used `-(bins_remain_cap[can_fit_mask] - item)`.\n            # This prioritizes smaller remainders.\n            # `priority = -remainder`. Smaller `remainder` -> higher `priority`.\n            # Let's enhance this by making the priority scale more aggressively for smaller remainders.\n            \n            # A simple enhancement: score = `MaxScore - remainder`.\n            # This gives highest scores to smallest remainders.\n            \n            # Let's ensure exact fits are top, and then for non-exact fits,\n            # use a score that is high for small remainders.\n            \n            # For non-exact fits:\n            # Score = `PrioritizedConstant - (remainder / item_size)`\n            # This penalizes based on the *proportion* of the item size left over.\n            # This is more robust across different item sizes.\n            \n            # Score = `MaxNonExactScore - ScaleFactor * (non_exact_remainders / item)`\n            # Let's try `ScaleFactor = 1e8`.\n            # `priorities[can_fit_mask & ~exact_fit_mask] = 1e8 - (1e8 * (non_exact_remainders / item))`\n            # Ensure `item` is not zero, though typically item sizes are positive.\n            \n            # A robust inverse relationship:\n            # If remainders are `r1, r2, ...`, we want to prioritize `r_i` where `r_i` is smallest.\n            # Score proportional to `1 / (r + epsilon)` is a common approach.\n            # Let's use `C / (remainder + epsilon)` and ensure it's less than exact fit score.\n            \n            # Let C = 1e8.\n            epsilon = 1e-9\n            scores_for_non_exact = 1e8 / (non_exact_remainders + epsilon)\n            \n            # We need to ensure these scores are distinct from the exact fit score.\n            # If `scores_for_non_exact` can exceed `1e9`, we need to cap them or\n            # adjust `C`. Since `1e8 / (small_positive + epsilon)` can be very large,\n            # this might compete with exact fits.\n            \n            # Let's use a form that is guaranteed to be lower than exact fits,\n            # and still prioritizes smaller remainders.\n            # `score = Constant - remainder`.\n            # Let `Constant` be `1e8`.\n            \n            # The scores should be greater than -1 and less than `1e9`.\n            # Let's use a linear mapping from remaining capacity to score:\n            # `score = A - B * remainder`\n            # We want smaller remainder -> higher score.\n            # Let the highest score for non-exact fit be `1e8`.\n            # Let the lowest score for non-exact fit be `1`.\n            # Assume `max_remainder_to_consider` is the largest remainder we want to give a positive score.\n            # For simplicity, let's use `1e8 - remainder`. This assigns higher priority to smaller remainders.\n            \n            # This is similar to v1's `-(remainder)`, but with a large offset.\n            # `priorities[can_fit_mask & ~exact_fit_mask] = 1e8 - non_exact_remainders`\n            \n            # To make it more sensitive to \"almost full\", we can use a non-linear scaling.\n            # For example, `1 / (remainder^p)` or `exp(-k * remainder)`.\n            # A simpler heuristic that differentiates well:\n            # Score = `MaxScore - remainder * ScalingFactor`.\n            # If `ScalingFactor` is large, smaller remainders get much higher scores.\n            \n            # Let's consider the \"Best Fit\" aspect more strongly.\n            # Best Fit aims to minimize `bins_remain_cap - item`.\n            # So, we want to maximize `-(bins_remain_cap - item)`.\n            \n            # Let's stick with the core idea of penalizing larger remainders.\n            # `score = LargeConstant - remainder`.\n            # Let `LargeConstant = 1e8`.\n            # This means a remainder of 0 gets 1e8, remainder of 1 gets 1e7, etc.\n            # This is effectively `1e8 - remainder`.\n            \n            # However, v1's `-(remainder)` is also trying to do this.\n            # The problem with `-(remainder)` is that it's unbounded from below.\n            # The problem with `1e8 - remainder` is that if `remainder` is very large,\n            # the score can become negative or very small, potentially competing with -1.\n            \n            # Let's re-evaluate the goal:\n            # 1. Exact fits get highest priority.\n            # 2. Among non-exact fits, prioritize those with smallest remaining capacity.\n            # 3. Provide good differentiation between close fits.\n            \n            # Heuristic:\n            # Priority = HighValue - (Remainder / ItemSize) * HighValue\n            # This scales the penalty by the item size.\n            # If `item = 0.5`, `remainder = 0.1` => `0.1 / 0.5 = 0.2`\n            # If `item = 0.1`, `remainder = 0.1` => `0.1 / 0.1 = 1.0` (exact fit)\n            # If `item = 0.1`, `remainder = 0.01` => `0.01 / 0.1 = 0.1`\n            \n            # Let's define a score based on `1 - (remainder / item)` for non-exact fits.\n            # This score is between -infinity and 1 (exclusive of 1 for non-exact).\n            # We want it to be positive and less than the exact fit score.\n            \n            # Let's use a score that is inversely proportional to `remainder + epsilon`,\n            # but capped to ensure it's less than exact fit score.\n            \n            # `score = C / (remainder + epsilon)`\n            # Choose C and epsilon carefully.\n            # If we want the highest non-exact score to be significantly less than 1e9,\n            # say `1e8`.\n            # When `remainder` is very small (but not zero), `score` becomes very large.\n            # E.g., `1e8 / (1e-9 + 1e-9) = 1e8 / 2e-9 = 5e16`. This is too large.\n            \n            # Let's use a score that is `MaxScore - remainder`.\n            # `MaxScore` for non-exact fits should be < `1e9`. Let `MaxScore = 1e8`.\n            # `priorities[can_fit_mask & ~exact_fit_mask] = 1e8 - non_exact_remainders`\n            \n            # This ensures that smaller remainders get higher scores.\n            # The minimum score for a non-exact fit would be `1e8 - largest_remainder`.\n            # We need to make sure this minimum score is still positive and better than -1.\n            # Assuming `largest_remainder` is not excessively large, this should work.\n            # For robustness, we can clip the scores if they go too low.\n            \n            # Let's refine the scoring for non-exact fits.\n            # We want to prioritize bins with smaller `remaining_capacities_if_fit`.\n            # A common strategy is to map `x` to `1/x` or `C-x`.\n            # To avoid division by zero and scale effectively, `C - x` is often better.\n            \n            # Let's define the priority for non-exact fits as:\n            # `priority = BaseScore - RemainingCapacity`\n            # `BaseScore` should be high enough to be clearly better than unfillable bins.\n            # And distinct from exact fit scores.\n            \n            # Let's set `BaseScore = 1000.0`.\n            # And `priorities[can_fit_mask & ~exact_fit_mask] = 1000.0 - non_exact_remainders`\n            # This prioritizes smaller remainders.\n            \n            # Consider the \"almost full\" aspect. If a bin becomes nearly full,\n            # its remaining capacity is small.\n            \n            # A key insight from \"Better\" heuristics often involves normalization or\n            # relative comparisons.\n            # Instead of absolute remaining capacity, consider `remainder / item_size`.\n            # Smaller `remainder / item_size` is better.\n            \n            # Score = `C * (1 - remainder / item_size)` for non-exact fits.\n            # If `remainder = 0.1`, `item = 0.5`, ratio = 0.2. Score = `C * 0.8`.\n            # If `remainder = 0.05`, `item = 0.5`, ratio = 0.1. Score = `C * 0.9`.\n            # This makes sense: smaller relative remainder is better.\n            \n            # Let's use `C = 1e8`.\n            # We need to handle `item == 0` (though unlikely in BPP) and `item > 0`.\n            \n            valid_item_mask = item > 1e-9 # Check for non-zero item size\n            \n            if valid_item_mask:\n                non_exact_remainders_for_valid_item = non_exact_remainders[item[can_fit_mask & ~exact_fit_mask] > 1e-9]\n                corresponding_items = item[can_fit_mask & ~exact_fit_mask][item[can_fit_mask & ~exact_fit_mask] > 1e-9]\n                \n                if len(non_exact_remainders_for_valid_item) > 0:\n                    ratios = non_exact_remainders_for_valid_item / corresponding_items\n                    \n                    # We want to maximize `1 - ratio`. So minimize `ratio`.\n                    # Scores = `1e8 * (1 - ratios)`\n                    # Clamp scores to be less than 1e9 and greater than -1.\n                    scores_for_non_exact = 1e8 * (1 - ratios)\n                    \n                    # Ensure scores are positive and distinct from exact fits.\n                    # If `ratios` is very close to 0, score is close to 1e8.\n                    # If `ratios` is close to 1, score is close to 0.\n                    \n                    # Let's use a simplified approach that is robust and differentiates well:\n                    # Priority = `max_score - remainder`\n                    # This naturally gives higher scores to smaller remainders.\n                    # It's also computationally simple.\n                    \n                    # Revert to the `max_score - remainder` idea, but ensure it's scaled.\n                    # Let's use `1e8 - non_exact_remainders`. This directly penalizes\n                    # larger remaining capacities.\n                    \n                    # What if we want to bias towards bins that are \"more full\" in an absolute sense?\n                    # E.g., a bin with remaining capacity 0.1 is \"more full\" than a bin with 0.5.\n                    # This is what `1e8 - remainder` does.\n                    \n                    # Consider robustness: what if `non_exact_remainders` are very small,\n                    # like `1e-10`? `1e8 - 1e-10` is still close to `1e8`.\n                    # This is good, as it means very tight fits get high scores.\n                    \n                    # The key differentiator is making the scores for non-exact fits\n                    # clearly lower than exact fits, but still high for good fits.\n                    \n                    # Let's combine the exact fit reward with a scaled remainder penalty.\n                    # Priority = `ScoreExactFit` if exact fit.\n                    # Priority = `ScoreNonExactFitBase - Penalty` if non-exact fit.\n                    \n                    # `ScoreExactFit = 1e9`\n                    # `ScoreNonExactFitBase = 1e8`\n                    # `Penalty = non_exact_remainders * ScalingFactor`\n                    \n                    # If `ScalingFactor` is large, small remainders get small penalties -> high scores.\n                    # If `ScalingFactor` is small, small remainders get small penalties -> scores closer to `1e8`.\n                    \n                    # Let's use `ScalingFactor = 1000.0`\n                    # `priorities[can_fit_mask & ~exact_fit_mask] = 1e8 - (non_exact_remainders * 1000.0)`\n                    \n                    # This ensures that smaller remainders result in higher scores.\n                    # The scores will be between `1e8 - max_remainder * 1000` and close to `1e8`.\n                    # We need to ensure `1e8 - max_remainder * 1000 > -1`.\n                    # If `max_remainder` is `0.5`, score is `1e8 - 500`, which is very high.\n                    \n                    # This approach seems robust and aligns with the \"Best Fit\" principle\n                    # of minimizing remaining space.\n                    \n                    # Let's consider the absolute remaining capacity for non-exact fits.\n                    # We want to prioritize smaller `remaining_capacities_if_fit`.\n                    # Using `MaxScore - remainder` is a direct way to achieve this.\n                    \n                    # The definition of \"almost full\" suggests that a bin with a very small\n                    # remaining capacity (after placing the item) is preferred.\n                    # This is exactly what `MaxScore - remainder` does.\n                    \n                    # Let's use `1e8 - non_exact_remainders`.\n                    # This provides a good range of scores for non-exact fits, prioritizing\n                    # those with less leftover space.\n                    priorities[can_fit_mask & ~exact_fit_mask] = 1e8 - non_exact_remainders\n\n            # Ensure scores are not too low for valid non-exact fits.\n            # If `1e8 - non_exact_remainders` becomes less than 0, set it to a small positive value.\n            # This handles cases where `non_exact_remainders` might be very large.\n            # However, typically `non_exact_remainders` will be less than the bin capacity.\n            # A simple clip at 0 is sufficient if we are sure scores won't exceed 1e9.\n            \n            # Clip scores to be at least 0 for non-exact fits.\n            priorities[can_fit_mask & ~exact_fit_mask] = np.maximum(priorities[can_fit_mask & ~exact_fit_mask], 0.0)\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 295, in priority_v2\nIndexError: invalid index to scalar variable.\n5\n421.96572261594497\n"
  },
  {
    "stdout_filepath": "problem_iter12_response4.txt_stdout.txt",
    "code_path": "problem_iter12_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid \"Best Fit\" and \"Worst Fit\" with capacity normalization priority function.\n\n    This strategy aims to improve upon simple \"almost full\" by considering two aspects:\n    1.  Prioritizing bins that are \"tight\" fits (leaving minimal remaining capacity),\n        similar to Best Fit, but without being overly sensitive to small differences.\n    2.  As a secondary consideration, and to avoid clustering items into only the smallest\n        remaining capacity bins (which might lead to fragmentation later), it also\n        slightly favors bins that have more remaining capacity, up to a certain point,\n        acting as a \"soft\" worst fit to spread items better.\n    3.  It normalizes remaining capacities to handle varying bin sizes or item scales more robustly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n\n    can_fit_mask = bins_remain_cap >= item\n\n    if np.any(can_fit_mask):\n        eligible_capacities = bins_remain_cap[can_fit_mask]\n        remaining_capacities_if_fit = eligible_capacities - item\n\n        # Primary score component: Prioritize bins that leave minimal remaining capacity.\n        # We use a score that is inversely related to the remaining capacity.\n        # Adding epsilon to denominator for numerical stability and to avoid zero division.\n        # Small remaining capacity -> large positive score.\n        epsilon = 1e-9\n        tight_fit_score = 1.0 / (remaining_capacities_if_fit + epsilon)\n\n        # Secondary score component: Introduce a slight preference for bins with more capacity,\n        # acting as a \"soft\" worst fit to prevent premature clustering.\n        # This component is scaled to be less dominant than the tight fit.\n        # Larger remaining capacity -> larger score.\n        # We can normalize the remaining capacities relative to the *maximum* possible remaining capacity\n        # among eligible bins to make this component more stable.\n        # If all eligible bins have the same remaining capacity, this score will be uniform.\n        if np.max(eligible_capacities) > 0:\n             normalized_slack = eligible_capacities / np.max(eligible_capacities)\n        else:\n             normalized_slack = np.zeros_like(eligible_capacities) # Handle case where max capacity is 0\n\n        # Combine scores: Prioritize tight fits, then spread items.\n        # The weight (0.3) balances tight fitting vs. spreading. Adjust as needed.\n        combined_score = tight_fit_score * 0.7 + normalized_slack * 0.3\n\n        priorities[can_fit_mask] = combined_score\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 3.0,
    "halstead": 131.18329672565338,
    "exec_success": true
  }
]