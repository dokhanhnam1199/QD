{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Exact Fit with Normalized Slack Minimization priority function.\n\n    This strategy prioritizes bins that provide an exact fit for the item.\n    If no exact fit is available, it prioritizes bins that minimize the\n    \"normalized slack\" after placing the item. Normalized slack is defined\n    as (remaining_capacity - item) / original_bin_capacity. This helps\n    to favor bins that have a smaller relative waste, regardless of their\n    absolute remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n        bin_capacities: Array of original capacities for each bin.\n\n    Returns:\n        Array of priority scores for each bin. Bins that cannot accommodate the item\n        receive a priority of -1. Higher scores indicate higher priority.\n        Exact fits receive the highest possible score (e.g., a large positive number).\n        Other fits are ranked by the negative of their normalized slack (to maximize).\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    # Assume bin_capacities are available or can be inferred/passed.\n    # For this example, let's assume a constant bin capacity of 1.0 if not provided.\n    # In a real scenario, bin_capacities would likely be an input or stored with bins.\n    # We'll use a placeholder if bin_capacities is not passed implicitly.\n    # A more robust implementation would pass bin_capacities explicitly.\n    \n    # Placeholder for original bin capacities. In a real application, this would be known.\n    # Let's assume for demonstration purposes that all bins have a capacity of 1.0\n    # or that this information is accessible. If not, this heuristic needs adaptation.\n    # A practical approach would be to pass `bin_capacities` as an argument.\n    # For this problem, we'll simulate it assuming a fixed capacity for all bins\n    # to make the \"normalized slack\" concept work. A better design would pass it.\n    \n    # If `bins_remain_cap` were derived from `original_capacity - current_fill`,\n    # then `original_capacity` would be available. For a standalone function,\n    # we'll use a proxy: assume original capacity is related to current fill + remaining.\n    # A common simplification is to assume a standard bin capacity if not explicitly given.\n    # Let's assume a nominal bin capacity for the normalization.\n    # A safer approach is to actually pass the original bin capacities.\n    # For this exercise, we'll make a simplifying assumption:\n    # If item <= 1.0, and bins_remain_cap are used, it implies bins of capacity >= 1.0.\n    # Let's assume all bins have an implicit capacity of 1.0 for normalization purposes.\n    # If the actual bin capacities vary and are not provided, this normalization is problematic.\n    # Assuming a fixed conceptual bin capacity for normalization.\n    \n    # Let's try to infer a capacity if possible or use a default.\n    # A more robust way is to pass `original_bin_capacities` to the function.\n    # For the purpose of this example, we will assume a common bin capacity\n    # if bin_capacities is not an explicit parameter.\n    # If we can't assume a fixed capacity, the normalization needs careful handling.\n\n    # A common pattern in BPP is that items are a fraction of bin capacity,\n    # so if item sizes are like 0.5, 0.2, etc., bin capacity is often 1.0.\n    # Let's use 1.0 as the *reference* capacity for normalization if no better info.\n    # This is a critical assumption.\n    reference_capacity = 1.0 # This should ideally be passed as an argument\n\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        # Prioritize exact fits with a high score\n        exact_fit_mask = (bins_remain_cap == item) & can_fit_mask\n        priorities[exact_fit_mask] = 1e9  # High priority for exact fits\n\n        # For bins that can fit but are not exact fits\n        non_exact_fit_mask = can_fit_mask & ~exact_fit_mask\n        \n        if np.any(non_exact_fit_mask):\n            remaining_after_fit = bins_remain_cap[non_exact_fit_mask] - item\n            \n            # Calculate normalized slack: (remaining_capacity - item) / reference_capacity\n            # We want to MINIMIZE normalized slack, so we maximize its negative.\n            # Add a small epsilon to the denominator to avoid division by zero if reference_capacity is 0\n            # or if we were normalizing by `bins_remain_cap[non_exact_fit_mask]` itself.\n            # Using a fixed reference capacity avoids issues with bins that are already very full.\n            \n            # Normalized slack = (bins_remain_cap[non_exact_fit_mask] - item) / reference_capacity\n            # We want to maximize -(normalized slack)\n            \n            # Using a simple inversion strategy for non-exact fits, prioritizing smaller remainders.\n            # The key is to make it stable and distinct from exact fits.\n            # We can scale the negative remainder.\n            # Maximizing the negative of the slack.\n            \n            # A common way to implement \"minimize slack\" is to use `-(slack)` where slack is positive.\n            # So, for `bins_remain_cap[non_exact_fit_mask] - item`, we want to maximize this value if it's negative,\n            # or minimize it if it's positive.\n            # The \"slack\" is `bins_remain_cap[non_exact_fit_mask] - item`.\n            # We want to minimize this slack. Thus, we maximize `- (slack)`.\n            \n            # Let's prioritize bins that leave smaller positive remaining capacity.\n            # If we want to prioritize MINIMIZING the slack `(bins_remain_cap[non_exact_fit_mask] - item)`\n            # we maximize `-(bins_remain_cap[non_exact_fit_mask] - item)`.\n            \n            # To incorporate \"normalized slack\" and avoid issues with very small bins,\n            # we normalize the slack by a reference capacity.\n            # slack = bins_remain_cap[non_exact_fit_mask] - item\n            # normalized_slack = slack / reference_capacity\n            # priority = -normalized_slack\n            \n            normalized_slack = (bins_remain_cap[non_exact_fit_mask] - item) / reference_capacity\n            priorities[non_exact_fit_mask] = -normalized_slack\n            \n            # A small adjustment to ensure non-exact fits are always less than exact fits,\n            # and to make scores more distinct if needed.\n            # Adding a large offset to the non-exact fit scores ensures they are distinct\n            # from the exact fit scores, but still ordered by their slack.\n            # However, -normalized_slack already achieves ordering.\n            # The key is that `1e9` is significantly larger than any possible `-normalized_slack`.\n            \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Hybrid heuristic: exact fit first, then best-fit by minimizing normalized slack.\n    Prioritizes exact fits with a score of 1.0, then bins that minimize\n    (remaining_capacity - item) / original_bin_capacity.\n    \"\"\"\n    priorities = np.full_like(bins_remain_cap, -1.0)\n    \n    # Mask for bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    if np.any(can_fit_mask):\n        eligible_bins_remain_cap = bins_remain_cap[can_fit_mask]\n        eligible_indices = np.where(can_fit_mask)[0]\n\n        # Exact fit: highest priority\n        exact_fit_mask = (eligible_bins_remain_cap == item)\n        if np.any(exact_fit_mask):\n            priorities[eligible_indices[exact_fit_mask]] = 1.0\n        \n        # Best fit for non-exact fits: minimize normalized slack\n        # Slack = remaining_capacity - item\n        # Normalized slack = slack / current_bin_capacity\n        # We want to MINIMIZE normalized slack, so HIGHER priority for smaller normalized slack.\n        non_exact_fit_mask = (eligible_bins_remain_cap > item)\n        \n        if np.any(non_exact_fit_mask):\n            non_exact_indices = eligible_indices[non_exact_fit_mask]\n            non_exact_remain_caps = eligible_bins_remain_cap[non_exact_fit_mask]\n            \n            # To get original bin capacities, we'd need to know them.\n            # Assuming the provided 'bins_remain_cap' are from a full set of bins,\n            # and we don't have the original capacities here.\n            # A practical proxy: use the current remaining capacity if it's not too small,\n            # or a fixed large number for normalization if capacity is not available.\n            # However, the prompt implies 'bins_remain_cap' IS the state.\n            # Let's redefine based on common best-fit: minimize remaining capacity after packing.\n            # This is a common \"best-fit\" interpretation.\n            \n            # If we strictly want \"normalized slack\" (slack / original_capacity),\n            # we'd need original capacities. Without it, we fall back to minimizing slack.\n            # The \"Better code\" example used negative slack. Let's refine that.\n            \n            # Strategy: Prioritize bins that leave the LEAST remaining capacity.\n            # This is equivalent to maximizing -(remaining_capacity - item).\n            # To avoid large negative numbers and ensure stable ranking, we can normalize.\n            # Let's use the \"Better code\" logic as it's clean for Best Fit: minimize residual.\n            \n            # Let's take the 'priority_v0' approach of minimizing remaining capacity after fit\n            # but ensure it's distinct from exact fit.\n            \n            # For non-exact fits, score based on how much capacity is left after fitting.\n            # Lower remaining capacity after fitting = higher priority.\n            remaining_after_fit = non_exact_remain_caps - item\n            \n            # To make scores distinct and avoid issues with very small residuals,\n            # we can use a scaled inverse. A common approach is to subtract from a constant\n            # or use a decreasing function.\n            # Let's use a score that is inversely proportional to the residual capacity,\n            # but scaled to be less than 1.0.\n            # Example: 0.5 + 0.4 * (1 - normalized_residual)\n            # Where normalized_residual = residual / max_residual\n            \n            if len(remaining_after_fit) > 0:\n                max_remaining_after_fit = np.max(remaining_after_fit)\n                # Normalize residuals to [0, 1], where 0 is best (min residual)\n                # Add epsilon for stability if all residuals are same\n                normalized_remaining = remaining_after_fit / (max_remaining_after_fit + 1e-9)\n                \n                # Scale to a range below 1.0, e.g., [0.5, 0.95].\n                # This maps best-fit (normalized_remaining near 0) to ~0.95\n                # and worst-fit (normalized_remaining near 1) to ~0.5.\n                best_fit_scores = 0.5 + (1.0 - normalized_remaining) * 0.45\n                \n                priorities[non_exact_indices] = best_fit_scores\n\n    return priorities\n\n### Analyze & experience\n- *   **Heuristics 1 vs 2:** Heuristic 1 prioritizes exact fits (score 1.0) and then uses an inverse of remaining capacity for others. Heuristic 2 implements a BFD-inspired approach, maximizing negative remaining capacity and using negative initial slack as a tie-breaker, scaled by a large factor. Heuristic 1's scoring for non-exact fits (1/(remaining+1)) is simpler but might not distinguish as well as Heuristic 2's combined score. Heuristic 2's explicit tie-breaking and scaling seem more robust for BFD.\n\n*   **Heuristics 2 vs 5:** Heuristic 2 uses a scaled combination of minimizing remaining capacity and minimizing initial slack. Heuristic 5 focuses solely on minimizing remaining capacity (equivalent to maximizing negative remaining capacity). Heuristic 2's tie-breaking mechanism (considering initial slack) adds a refinement that Heuristic 5 lacks, potentially leading to better packing in cases of identical minimum remainders.\n\n*   **Heuristics 5 vs 7:** These heuristics appear to be identical in their core logic: prioritizing bins that leave the minimum remaining capacity after fitting an item. Both assign a score as the negative of the remaining capacity after fit.\n\n*   **Heuristics 1 vs 9:** Heuristic 1 rewards exact fits with 1.0 and uses inverse remaining capacity for others. Heuristic 9 prioritizes exact fits with 1.0 and then uses a normalized slack (remaining / current capacity) for non-exact fits, scaled to be between 0.5 and 0.99. Heuristic 9's normalization and scaling for non-exact fits offer a more nuanced approach than Heuristic 1's simple inverse.\n\n*   **Heuristics 9 vs 10:** Heuristics 9 and 10 are identical. They both prioritize exact fits with 1.0 and then use a scaled normalized slack (1 - normalized_slack) for non-exact fits, mapping to [0.5, 0.99].\n\n*   **Heuristics 10 vs 14:** Heuristic 10 prioritizes exact fits with 1.0 and then uses a scaled normalized slack (1 - normalized_slack) for non-exact fits, mapping to [0.5, 0.99]. Heuristic 14 also prioritizes exact fits with 1.0 and uses (1 - normalized slack) for non-exact fits, but these scores are not explicitly scaled to a range like [0.5, 0.99], implying they could be [0, 1). Both use normalized slack, but Heuristic 10's explicit scaling might offer more control.\n\n*   **Heuristics 14 vs 16:** Heuristic 14 prioritizes exact fits with 1.0 and uses `1.0 - normalized_slack` for non-exact fits. Heuristic 16 prioritizes exact fits with 1.0 and uses `0.5 * (1.0 - normalized_slack)` for non-exact fits. Heuristic 16's scaling factor of 0.5 ensures non-exact fits are always distinctly lower than exact fits, potentially offering clearer separation.\n\n*   **Heuristics 16 vs 17:** Heuristic 16 prioritizes exact fits with 1.0 and uses `0.5 * (1.0 - normalized_slack)` for non-exact fits. Heuristic 17 prioritizes exact fits with 1.0 and then uses `1.0 + (1.0 / (normalized_slack + 1e-9))` for non-exact fits. Heuristic 17's scoring for non-exact fits is much higher and seems to invert the normalized slack, making smaller slack yield larger scores. This approach might overvalue non-exact fits.\n\n*   **Heuristics 17 vs 15:** Heuristic 17 prioritizes exact fits with 1.0 and uses `1.0 + (1.0 / (normalized_slack + 1e-9))` for non-exact fits. Heuristic 15 prioritizes exact fits with 1.0 and uses `1.0 + (1.0 / (normalized_slack + 1e-9))` for non-exact fits. These appear identical.\n\n*   **Heuristics 15 vs 18:** Heuristic 15 prioritizes exact fits with 1.0 and uses `1.0 + (1.0 / (normalized_slack + 1e-9))` for non-exact fits. Heuristic 18 prioritizes exact fits with a very high score (1e6) and then uses `-normalized_slack * 1e5` for non-exact fits. Heuristic 18's high score for exact fits and negative scaling for non-exact fits is a different approach. The negative scaling for non-exact fits is unusual for \"higher score = higher priority.\"\n\n*   **Heuristics 18 vs 20:** Heuristics 18 and 20 are identical. They prioritize exact fits with a very high score (1e6) and then use `-normalized_slack * 1e5` for non-exact fits, which appears to have the intention of maximizing the negative normalized slack (minimizing slack).\n\n*   **Heuristics 19 vs 20:** Heuristic 19 is incomplete but aims for exact fits with a specific score and inverse slack. Heuristic 20 prioritizes exact fits with a very high score (1e6) and then uses `-normalized_slack * 1e5` for non-exact fits. Heuristic 20's explicit high score for exact fits and the negative scaling for non-exact fits are concrete implementations.\n\n*   **Overall:** Heuristics 2 and 10/9/14/16 offer robust BFD-like strategies by combining primary (minimizing residual/slack) and secondary (initial slack) objectives or by using normalized slack. Heuristics 18/20 have a clear hierarchy with a very high score for exact fits and negative scaled slack for others, but the negative scaling for priority is counter-intuitive. Heuristics 15/17 use an unusual inversion for non-exact fits. Heuristics 1/5/7 focus on simple inverse remaining capacity.\n- \nHere's a redefined approach to self-reflection for heuristic design:\n\n*   **Keywords:** Differentiated Scores, Scaled Objective Integration, Robustness, Contextual Prioritization.\n*   **Advice:** Design self-reflection to create *distinct, contextually relevant scores* for candidate solutions. Integrate multiple objectives (e.g., fit quality, resource utilization) using scaling or weighted sums that reflect their relative importance.\n*   **Avoid:** Overly simplistic scoring (e.g., direct inverse slack), manual prioritization that's not data-driven, and brittle numerical operations.\n*   **Explanation:** This focuses on creating nuanced, comparable scores that guide the heuristic towards robust, well-reasoned choices by considering the interplay of various factors and ensuring numerical stability.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}