[
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority scores for each bin. \n    Prioritizes bins with just enough capacity and breaks ties with random noise.\n    \"\"\"\n    # Check if the item can fit into the bin\n    valid_bins = (bins_remain_cap >= item).astype(float)\n    \n    # Prioritize bins that are just enough for the item\n    priority = valid_bins * (-(bins_remain_cap - item))\n    \n    # Add a small random noise to break ties, only for valid bins\n    priority += valid_bins * np.random.rand(*priority.shape) * 1e-6\n    \n    return priority",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 95.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority scores for adding an item to bins.\n    Combines remaining capacity and 'fullness' of bins, with tie-breaking noise.\n    \"\"\"\n    # Calculate max capacity assuming all bins have the same max capacity\n    max_capacity = np.max(bins_remain_cap) + item\n    \n    # Priority score: negative remaining capacity after addition, \n    # plus a 'fullness' factor, and a small random noise to break ties\n    priority_scores = np.where(bins_remain_cap >= item, \n                               -(bins_remain_cap - item) + (max_capacity - bins_remain_cap - item) / max_capacity + np.random.uniform(0, 1e-6, size=len(bins_remain_cap)), \n                               -np.inf)\n    \n    # Normalize scores to avoid extreme values\n    finite_scores = priority_scores[np.isfinite(priority_scores)]\n    if len(finite_scores) > 0:\n        min_score, max_score = np.min(finite_scores), np.max(finite_scores)\n        if max_score != min_score:\n            priority_scores[np.isfinite(priority_scores)] = (finite_scores - min_score) / (max_score - min_score)\n    \n    return priority_scores",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 95.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response2.txt_stdout.txt",
    "code_path": "problem_iter5_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority scores for adding an item to each bin.\n    Combines remaining capacity and 'fullness' of bins, with tie-breaking noise.\n    \"\"\"\n    # Calculate priority scores for bins with enough capacity\n    mask = bins_remain_cap >= item\n    priority_scores = np.full_like(bins_remain_cap, -np.inf)\n    # Prioritize bins with just enough capacity and consider 'fullness'\n    priority_scores[mask] = -(bins_remain_cap[mask] - item) / (bins_remain_cap[mask] + 1e-6) + 1 / (bins_remain_cap[mask] + 1e-6)\n    # Add small noise to break ties\n    priority_scores[mask] += np.random.uniform(0, 1e-6, size=np.sum(mask))\n    \n    return priority_scores",
    "response_id": 2,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 14, in priority_v2\n    priority += valid_bins * (np.log(num_bins / (1 + np.arange(num_bins))) + np.random.rand(*priority.shape) * 1e-6)\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n5\n1\n116.75790004038474\n90.79741968124088\n95\n"
  },
  {
    "stdout_filepath": "problem_iter5_response3.txt_stdout.txt",
    "code_path": "problem_iter5_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority scores for adding an item to each bin.\n    \n    Combines the First-Fit decreasing heuristic with a tie-breaker based on bin index.\n    \"\"\"\n    # Calculate priority scores based on remaining capacity\n    priority_scores = np.where(bins_remain_cap >= item, -(bins_remain_cap - item), -np.inf)\n    \n    # Add a small random noise to break ties\n    num_bins = len(bins_remain_cap)\n    priority_scores = np.where(priority_scores != -np.inf, \n                               priority_scores + np.log(num_bins / (1 + np.arange(num_bins))), \n                               -np.inf)\n    \n    return priority_scores",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.068607897885915,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 95.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response4.txt_stdout.txt",
    "code_path": "problem_iter5_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority scores for each bin. \n    Prioritizes bins with just enough capacity and breaks ties with a combination of random noise and bin index.\n    \"\"\"\n    # Check if the item can fit into the bin and prioritize bins with less remaining capacity after addition\n    valid_bins = (bins_remain_cap >= item).astype(float)\n    priority = valid_bins * (-(bins_remain_cap - item))  # Prioritize bins that are just enough for the item\n    \n    # Add a small factor considering the bin index (older bins are prioritized) and random noise to break ties\n    num_bins = len(bins_remain_cap)\n    priority += valid_bins * (np.log(num_bins / (1 + np.arange(num_bins))) + np.random.rand(*priority.shape) * 1e-6)\n    \n    return priority",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.068607897885915,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 95.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response5.txt_stdout.txt",
    "code_path": "problem_iter5_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority scores for adding an item to each bin.\n    Prioritizes bins with just enough capacity, considering remaining capacity and 'fullness'.\n    \"\"\"\n    # Calculate priority score for bins that can accommodate the item\n    mask = bins_remain_cap >= item\n    priority = np.where(mask, \n                        -(bins_remain_cap - item) / (bins_remain_cap + 1e-6) + 1 / (bins_remain_cap + 1e-6), \n                        -np.inf)\n    # Add a small random noise to break ties\n    priority[mask] += np.random.uniform(0, 1e-6, np.sum(mask))\n    return priority",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 95.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response6.txt_stdout.txt",
    "code_path": "problem_iter5_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority scores for adding an item to bins based on remaining capacity and 'fullness'.\n    Prioritizes bins that fit the item tightly, with a small random noise to break ties.\n    \"\"\"\n    # Calculate priority scores: negative remaining capacity after adding the item\n    mask = bins_remain_cap >= item  # Mask for bins that can accommodate the item\n    priority_scores = np.where(mask, -(bins_remain_cap - item), -np.inf)\n    \n    # Add a small random noise to break ties, only for valid bins\n    noise = np.random.uniform(0, 1e-6, size=np.sum(mask))\n    priority_scores[mask] += noise\n    \n    return priority_scores",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 95.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response7.txt_stdout.txt",
    "code_path": "problem_iter5_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, \n                random_noise_upper_bound: float = 0.000512910372337147, \n                invalid_bin_priority: float = -3582939133.573016) -> np.ndarray:\n    \"\"\"\n    Priority score for each bin by considering remaining capacity and bin index, with random tie-breaking.\n    \"\"\"\n    # Calculate the number of available bins\n    num_bins = len(bins_remain_cap)\n    \n    # Prioritize bins with enough capacity, considering remaining capacity and bin index\n    priority = np.where(bins_remain_cap >= item, \n                        -(bins_remain_cap - item) + np.log(num_bins / (1 + np.arange(num_bins))) + np.random.uniform(0, random_noise_upper_bound, size=num_bins), \n                        invalid_bin_priority)\n    \n    return priority",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.068607897885915,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 95.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response8.txt_stdout.txt",
    "code_path": "problem_iter5_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority scores for adding an item to each bin.\n    Combines remaining capacity and 'fullness' with tie-breaking noise.\n    \"\"\"\n    # Calculate max capacity assuming all bins have the same max capacity\n    max_capacity = np.max(bins_remain_cap) + item\n    \n    # Priority score for bins that can fit the item\n    mask = bins_remain_cap >= item\n    priority = np.where(mask, \n                        -(bins_remain_cap - item) + (max_capacity - bins_remain_cap - item) / max_capacity + np.random.uniform(0, 1e-6, size=len(bins_remain_cap)), \n                        -np.inf)\n    \n    # Normalize scores to avoid extreme values\n    finite_scores = priority[np.isfinite(priority)]\n    if len(finite_scores) > 0:\n        min_score, max_score = np.min(finite_scores), np.max(finite_scores)\n        if max_score != min_score:\n            priority[np.isfinite(priority)] = (finite_scores - min_score) / (max_score - min_score)\n    \n    return priority",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 95.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response9.txt_stdout.txt",
    "code_path": "problem_iter5_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority scores for adding an item to each bin.\n    Prioritizes bins with just enough capacity, considering remaining capacity and fullness.\n    \"\"\"\n    # Calculate priority score for bins that can accommodate the item\n    mask = bins_remain_cap >= item\n    priority = np.where(mask, -(bins_remain_cap - item) / (bins_remain_cap + 1e-6) + 1 / (bins_remain_cap + 1e-6), -np.inf)\n    # Add a small random noise to break ties\n    priority[mask] += np.random.uniform(0, 1e-6, np.sum(mask))\n    return priority",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 95.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This function implements a hybrid heuristic that considers both the remaining capacity \n    after adding the item and the number of items already packed in the bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the priority score for each bin\n    # We want to prioritize bins that have just enough capacity for the item\n    # and have fewer items already packed (i.e., larger remaining capacity initially)\n    initial_capacities = np.full_like(bins_remain_cap, 1.0)  # assuming initial capacity is 1.0\n    priority_scores = np.where(bins_remain_cap >= item, \n                               -(bins_remain_cap - item) + 0.1 * (initial_capacities - bins_remain_cap), \n                               -np.inf)\n    \n    return priority_scores",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 60.98577262186291,
    "token_count": 69.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response1.txt_stdout.txt",
    "code_path": "problem_iter6_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This function implements a heuristic that prioritizes bins based on their remaining capacity and the item size.\n    It combines the benefits of First-Fit and Best-Fit heuristics.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    \n    # Calculate the priority score for each bin\n    # We want to prioritize bins that have just enough capacity for the item (like Best-Fit)\n    # and also consider the bins that are already filled the most (like First-Fit with a twist)\n    # So, we use a combination of the negative of the remaining capacity after adding the item and the current fill level\n    priority_scores = np.where(bins_remain_cap >= item, \n                               -(bins_remain_cap - item) + 0.1 * bins_remain_cap,  # Add a small bonus for more filled bins\n                               -np.inf)\n    \n    # To break ties, we can slightly prioritize bins with more remaining capacity\n    # However, this is already handled by the term -(bins_remain_cap - item)\n    \n    return priority_scores",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 60.98577262186291,
    "token_count": 69.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response2.txt_stdout.txt",
    "code_path": "problem_iter6_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This function implements a more sophisticated heuristic that takes into account \n    both the remaining capacity after adding the item and the number of bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    \n    # Calculate the priority score for each bin\n    # We want to prioritize bins that have just enough capacity for the item\n    # So, we use a combination of the negative of the remaining capacity after adding the item and a bin utilization factor\n    # If the item doesn't fit, the priority score is negative infinity\n    \n    # Calculate the utilization factor for each bin if the item is added\n    utilization_factor = (bins_remain_cap - item) / bins_remain_cap\n    \n    # For bins that can fit the item, assign a priority score based on the utilization factor and remaining capacity\n    priority_scores = np.where(bins_remain_cap >= item, -np.abs(utilization_factor) - (bins_remain_cap - item) / np.max(bins_remain_cap), -np.inf)\n    \n    # To break ties, we can add a small random noise to the priority scores\n    # However, for simplicity and reproducibility, we will not add noise here\n    \n    return priority_scores",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 60.98577262186291,
    "token_count": 69.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response3.txt_stdout.txt",
    "code_path": "problem_iter6_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This function implements a more nuanced heuristic that considers both the \n    remaining capacity after adding the item and the number of items already \n    packed in the bin (not directly available but can be inferred from the remaining capacity).\n    It prioritizes bins that have just enough capacity for the item and are relatively fuller.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the priority score for each bin\n    # We want to prioritize bins that have just enough capacity for the item\n    # and are relatively fuller (i.e., have less remaining capacity)\n    # So, we use a combination of the negative of the remaining capacity after \n    # adding the item and the current remaining capacity as a tie-breaker\n    # If the item doesn't fit, the priority score is negative infinity\n    priority_scores = np.where(bins_remain_cap >= item, \n                               -(bins_remain_cap - item) + 0.1 * bins_remain_cap.max() - 0.1 * bins_remain_cap, \n                               -np.inf)\n    \n    return priority_scores",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 60.98577262186291,
    "token_count": 69.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response4.txt_stdout.txt",
    "code_path": "problem_iter6_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This function implements a hybrid heuristic that combines the benefits of \n    First-Fit decreasing and Best-Fit heuristics. It prioritizes bins that have \n    just enough capacity for the item and also considers the number of bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the priority score for each bin\n    # We want to prioritize bins that have just enough capacity for the item\n    # So, we use a combination of the negative of the remaining capacity after \n    # adding the item and the number of non-empty bins\n    priority_scores = np.where(bins_remain_cap >= item, \n                               -(bins_remain_cap - item) + 0.1 * (bins_remain_cap != 1.0), \n                               -np.inf)\n    \n    return priority_scores",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 60.98577262186291,
    "token_count": 69.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_response0.txt_stdout.txt",
    "code_path": "problem_iter7_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, \n                noise_weight: float = 4.9723798067088914e-05) -> np.ndarray:\n    \"\"\"\n    Returns priority scores for each bin. \n    Prioritizes bins with just enough capacity and breaks ties with random noise.\n    \"\"\"\n    # Check if the item can fit into the bin\n    valid_bins = (bins_remain_cap >= item).astype(float)\n    \n    # Prioritize bins that are just enough for the item\n    priority = valid_bins * (-(bins_remain_cap - item))\n    \n    # Add a small random noise to break ties, only for valid bins\n    priority += valid_bins * np.random.rand(*priority.shape) * noise_weight\n    \n    return priority",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 78.13781191217038,
    "mi": 92.60471814134101,
    "token_count": 87.0,
    "exec_success": true
  }
]