[
  {
    "stdout_filepath": "problem_iter8_response0.txt_stdout.txt",
    "code_path": "problem_iter8_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority scores for each bin. \n    Prioritizes bins with just enough capacity and breaks ties using remaining capacity and bin index.\n    \"\"\"\n    # Calculate priority score for bins that can fit the item\n    valid_bins = (bins_remain_cap >= item).astype(float)\n    # Prioritize bins that are just enough for the item and have less remaining capacity\n    priority = valid_bins * (-(bins_remain_cap - item) + 0.1 * bins_remain_cap.max() - 0.1 * bins_remain_cap)\n    \n    # Add a small factor considering the bin index to break ties\n    num_bins = len(bins_remain_cap)\n    priority += valid_bins * np.log(num_bins / (1 + np.arange(num_bins))) * 1e-3\n    \n    # Set priority to negative infinity for bins that cannot fit the item\n    priority = np.where(bins_remain_cap >= item, priority, -np.inf)\n    \n    return priority",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 102.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response1.txt_stdout.txt",
    "code_path": "problem_iter8_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority scores for each bin.\n    Combines effective prioritization with robust tie-breaking.\n    \"\"\"\n    # Prioritize bins with just enough capacity\n    utilization_factor = (bins_remain_cap - item) / np.maximum(bins_remain_cap, 1e-9)  # Avoid division by zero\n    priority = np.where(bins_remain_cap >= item, -np.abs(utilization_factor) - (bins_remain_cap - item) / np.max(bins_remain_cap), -np.inf)\n    \n    # Add a small factor considering the bin index to break ties\n    num_bins = len(bins_remain_cap)\n    priority += (bins_remain_cap >= item) * (np.log(num_bins / (1 + np.arange(num_bins))) * 1e-3)  # Use a smaller coefficient\n    \n    return priority",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 102.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response2.txt_stdout.txt",
    "code_path": "problem_iter8_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority scores for adding an item to each bin.\n    Prioritizes bins with just enough capacity, considering remaining capacity and adding random noise to break ties.\n    \"\"\"\n    # Calculate priority score for bins that can accommodate the item\n    mask = bins_remain_cap >= item\n    # Combine the effective prioritization strategy from priority_v0 with a more sophisticated tie-breaking from priority_v1\n    priority = np.where(mask, \n                        -(bins_remain_cap - item) / (bins_remain_cap + 1e-6) + 1 / (bins_remain_cap + 1e-6), \n                        -np.inf)\n    # Add a small factor considering the bin index (older bins are prioritized) and random noise to break ties\n    num_bins = len(bins_remain_cap)\n    priority[mask] += np.log(num_bins / (1 + np.arange(num_bins))[mask]) * 1e-3 + np.random.uniform(0, 1e-6, np.sum(mask))\n    return priority",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 102.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response3.txt_stdout.txt",
    "code_path": "problem_iter8_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority scores for adding an item to each bin.\n    Combines effective prioritization with a robust tie-breaking strategy.\n    \"\"\"\n    # Prioritize bins with just enough capacity\n    priority_scores = np.where(bins_remain_cap >= item, -(bins_remain_cap - item), -np.inf)\n    \n    # Tie-break using a combination of remaining capacity and bin index\n    num_bins = len(bins_remain_cap)\n    priority_scores = np.where(priority_scores != -np.inf, \n                               priority_scores + 0.1 * bins_remain_cap.max() - 0.1 * bins_remain_cap + np.log(num_bins / (1 + np.arange(num_bins))), \n                               -np.inf)\n    \n    return priority_scores",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.078579976067022,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 102.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response4.txt_stdout.txt",
    "code_path": "problem_iter8_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines effective prioritization of bins with just enough capacity and robust tie-breaking.\n    \"\"\"\n    # Check if the item can fit into the bin\n    valid_bins = (bins_remain_cap >= item).astype(float)\n    \n    # Prioritize bins that are just enough for the item, with a simpler formula\n    priority = valid_bins * (-(bins_remain_cap - item))\n    \n    # Add a small random noise and consider bin index for tie-breaking\n    num_bins = len(bins_remain_cap)\n    priority += valid_bins * (np.log(num_bins / (1 + np.arange(num_bins))) + np.random.rand(*priority.shape) * 1e-6)\n    \n    return priority",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.068607897885915,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 102.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response5.txt_stdout.txt",
    "code_path": "problem_iter8_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority scores for adding an item to bins, combining \n    remaining capacity and 'fullness' with a tie-breaker based on bin index.\n    \"\"\"\n    # Calculate max capacity assuming all bins have the same max capacity\n    max_capacity = np.max(bins_remain_cap) + item\n    \n    # Priority score: negative remaining capacity after addition, \n    # plus a 'fullness' factor\n    priority_scores = np.where(bins_remain_cap >= item, \n                               -(bins_remain_cap - item) + (max_capacity - bins_remain_cap - item) / max_capacity, \n                               -np.inf)\n    \n    # Add a tie-breaker based on bin index\n    num_bins = len(bins_remain_cap)\n    priority_scores = np.where(priority_scores != -np.inf, \n                               priority_scores + np.log(num_bins / (1 + np.arange(num_bins))) + np.random.uniform(0, 1e-6, size=num_bins), \n                               -np.inf)\n    \n    # Normalize scores to avoid extreme values\n    finite_scores = priority_scores[np.isfinite(priority_scores)]\n    if len(finite_scores) > 0:\n        min_score, max_score = np.min(finite_scores), np.max(finite_scores)\n        if max_score != min_score:\n            priority_scores[np.isfinite(priority_scores)] = (finite_scores - min_score) / (max_score - min_score)\n    \n    return priority_scores",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.068607897885915,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 102.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response6.txt_stdout.txt",
    "code_path": "problem_iter8_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, \n                noise_weight: float = 4.9723798067088914e-05, \n                random_noise_upper_bound: float = 0.000512910372337147) -> np.ndarray:\n    \"\"\"\n    Combines effective prioritization and tie-breaking strategies.\n    Prioritizes bins with just enough capacity and breaks ties with a combination of random noise and bin index.\n    \"\"\"\n    # Check if the item can fit into the bin\n    valid_bins = (bins_remain_cap >= item).astype(float)\n    \n    # Prioritize bins that are just enough for the item\n    priority = valid_bins * (-(bins_remain_cap - item))\n    \n    # Add a small random noise and consider bin index to break ties, only for valid bins\n    num_bins = len(bins_remain_cap)\n    priority += valid_bins * (np.random.uniform(0, random_noise_upper_bound, size=num_bins) + np.log(num_bins / (1 + np.arange(num_bins)))) * noise_weight\n    \n    # Set a very low priority for invalid bins\n    priority = np.where(valid_bins == 1, priority, -1e10)\n    \n    return priority",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 102.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response7.txt_stdout.txt",
    "code_path": "problem_iter8_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines remaining capacity and 'fullness' with a tie-breaker based on bin index.\n    \"\"\"\n    # Calculate max capacity assuming all bins have the same max capacity\n    max_capacity = np.max(bins_remain_cap) + item\n    \n    # Priority score for bins that can fit the item\n    mask = bins_remain_cap >= item\n    priority = np.where(mask, \n                        -(bins_remain_cap - item) + (max_capacity - bins_remain_cap - item) / max_capacity, \n                        -np.inf)\n    \n    # Add a tie-breaker based on bin index\n    num_bins = len(bins_remain_cap)\n    priority = np.where(priority != -np.inf, \n                        priority + np.log(num_bins / (1 + np.arange(num_bins))) + np.random.uniform(0, 1e-6, size=num_bins), \n                        -np.inf)\n    \n    # Normalize scores to avoid extreme values\n    finite_scores = priority[np.isfinite(priority)]\n    if len(finite_scores) > 0:\n        min_score, max_score = np.min(finite_scores), np.max(finite_scores)\n        if max_score != min_score:\n            priority[np.isfinite(priority)] = (finite_scores - min_score) / (max_score - min_score)\n    \n    return priority",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.068607897885915,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 102.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response8.txt_stdout.txt",
    "code_path": "problem_iter8_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines remaining capacity and 'fullness' with tie-breaking using bin index and random noise.\n    \"\"\"\n    # Calculate max capacity assuming all bins have the same max capacity\n    max_capacity = np.max(bins_remain_cap) + item\n    \n    # Number of available bins\n    num_bins = len(bins_remain_cap)\n    \n    # Priority score for bins that can fit the item\n    mask = bins_remain_cap >= item\n    priority = np.where(mask, \n                        -(bins_remain_cap - item) +  # Prioritize bins with just enough capacity\n                        (max_capacity - bins_remain_cap - item) / max_capacity +  # Consider 'fullness'\n                        np.log(num_bins / (1 + np.arange(num_bins))) +  # Tie-break using bin index\n                        np.random.uniform(0, 1e-6, size=num_bins),  # Add random noise for further tie-breaking\n                        -np.inf)  # Invalid bins have -inf priority\n    \n    # Normalize scores to avoid extreme values\n    finite_scores = priority[np.isfinite(priority)]\n    if len(finite_scores) > 0:\n        min_score, max_score = np.min(finite_scores), np.max(finite_scores)\n        if max_score != min_score:\n            priority[np.isfinite(priority)] = (finite_scores - min_score) / (max_score - min_score)\n    \n    return priority",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.068607897885915,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 102.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response9.txt_stdout.txt",
    "code_path": "problem_iter8_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority scores for each bin. \n    Combines prioritizing bins with just enough capacity and a robust tie-breaking strategy.\n    \"\"\"\n    # Prioritize bins that have just enough capacity for the item\n    priority_scores = np.where(bins_remain_cap >= item, -(bins_remain_cap - item), -np.inf)\n    \n    # Add a small factor considering the initial remaining capacity and random noise to break ties\n    initial_capacities = np.full_like(bins_remain_cap, 1.0)  \n    priority_scores += 0.1 * np.where(bins_remain_cap >= item, (initial_capacities - bins_remain_cap), 0) + np.random.rand(*priority_scores.shape) * 1e-6\n    \n    return priority_scores",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 116.75790004038474,
    "mi": 90.79741968124088,
    "token_count": 102.0,
    "exec_success": true
  }
]