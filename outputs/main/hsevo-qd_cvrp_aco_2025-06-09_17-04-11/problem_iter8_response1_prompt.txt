{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling. CVRP requires finding the shortest path that visits all given nodes and returns to the starting node. Each node has a demand and each vehicle has a capacity. The total demand of the nodes visited by a vehicle cannot exceed the vehicle capacity. When the total demand exceeds the vehicle capacity, the vehicle must return to the starting node.\nThe `heuristics` function takes as input a distance matrix (shape: n by n), Euclidean coordinates of nodes (shape: n by 2), a vector of customer demands (shape: n), and the integer capacity of vehicle capacity. It returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the distance_matrix. The depot node is indexed by 0.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"\n    CVRP heuristic: Combines distance, demand, depot proximity, angle,\n    and adaptive sparsification based on edge importance. Includes customer clustering\n    based on demand and location relative to the depot to focus search.\n    \"\"\"\n    n_nodes = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix)\n\n    # Node Proximity to Depot\n    depot_distances = distance_matrix[0, :]\n    max_depot_distance = np.max(depot_distances)\n    normalized_depot_distances = depot_distances / max_depot_distance if max_depot_distance > 0 else np.zeros_like(depot_distances)\n\n    # Demand Considerations\n    normalized_demands = demands / capacity\n\n    # Angle to Depot\n    angles = np.zeros((n_nodes, n_nodes))\n    for i in range(1, n_nodes):\n        for j in range(1, n_nodes):\n            if i != j:\n                vec_i = coordinates[i] - coordinates[0]\n                vec_j = coordinates[j] - coordinates[0]\n\n                norm_i = np.linalg.norm(vec_i)\n                norm_j = np.linalg.norm(vec_j)\n\n                if norm_i > 0 and norm_j > 0:\n                    cos_angle = np.dot(vec_i, vec_j) / (norm_i * norm_j)\n                    angles[i, j] = np.arccos(np.clip(cos_angle, -1.0, 1.0))\n                else:\n                    angles[i, j] = np.pi\n    normalized_angles = angles / np.pi\n\n    # Customer Clustering (Simplified - can be enhanced)\n    # Assign customers to \"clusters\" based on demand and angular position\n    cluster_assignments = np.zeros(n_nodes, dtype=int)\n    num_clusters = min(4, int(np.ceil(np.sum(demands) / capacity))) # Aim for a few clusters based on total demand\n\n    if num_clusters > 1:\n        angles_to_depot = np.arctan2(coordinates[1:, 1] - coordinates[0, 1], coordinates[1:, 0] - coordinates[0, 0])\n        angles_to_depot = (angles_to_depot + np.pi) % (2 * np.pi)  # Normalize to 0-2pi\n        angle_increments = np.linspace(0, 2 * np.pi, num_clusters + 1)\n\n        for i in range(1, n_nodes):\n            for k in range(num_clusters):\n                if angle_increments[k] <= angles_to_depot[i-1] < angle_increments[k+1]:\n                    cluster_assignments[i] = k\n\n    # Edge Importance (Adaptive Sparsification)\n    edge_importance = np.zeros_like(distance_matrix)\n\n    for i in range(n_nodes):\n        for j in range(n_nodes):\n            if i == j:\n                continue\n\n            distance = distance_matrix[i, j]\n            if distance == 0:\n                continue\n\n            # Cluster Awareness: Favor edges within the same cluster\n            cluster_bonus = 1.0\n            if num_clusters > 1 and cluster_assignments[i] != 0 and cluster_assignments[j] != 0 and cluster_assignments[i] == cluster_assignments[j]:\n                cluster_bonus = 1.2  # Increase weight if nodes are in the same cluster\n\n            heuristic_value = (1 / distance) * (1 - normalized_demands[j]) * (1 - normalized_depot_distances[j]) * (1 - normalized_angles[i,j]) * cluster_bonus\n\n            heuristic_matrix[i, j] = heuristic_value\n            edge_importance[i, j] = (1 / distance) * (demands[i] + demands[j])\n\n    # Adaptive Sparsification\n    mean_importance = np.mean(edge_importance[edge_importance > 0])\n    std_importance = np.std(edge_importance[edge_importance > 0])\n\n    threshold = mean_importance - 0.5 * std_importance\n\n    heuristic_matrix[edge_importance < threshold] = 0\n\n    # Additional Sparsification based on heuristic value itself\n    heuristic_threshold = np.mean(heuristic_matrix[heuristic_matrix > 0]) * 0.1\n    heuristic_matrix[heuristic_matrix < heuristic_threshold] = 0\n\n\n    return heuristic_matrix\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n    return 1 / distance_matrix\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic incorporates node proximity to the depot, demand considerations, angle to the depot, customer clustering, edge importance, and adaptive sparsification, while the worst only considers the inverse of the distance matrix.\nComparing (2nd best) vs (second worst), both are identical to the best heuristic. The 19th is also identical to the worst.\nComparing (1st) vs (2nd), they are identical.\nComparing (3rd) vs (4th), they are also identical, meaning that the clustering is not influencing the rankings as the clustering code is in the better approaches.\nComparing (second worst) vs (worst), both are identical.\nComparing (14th) vs (16th), both leverage distance, demand and node proximity. 14th then proceeds to sparsify the heuristic matrix using a dynamic threshold. The 16th lacks sparsification.\nOverall: The best heuristics combine distance, demand, depot proximity, angle, customer clustering and adaptive sparsification based on edge importance. Sparsification helps prune the search space.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, let's redefine \"Current Self-Reflection\" for designing CVRP heuristics to be more effective and actionable, avoiding the pitfalls of generic advice.\n\nHere's a refined approach:\n\n*   **Keywords:** Multi-factor, Adaptive Sparsification, Iterative Refinement, Performance Metrics, Solution Diversity, Constraint Handling.\n\n*   **Advice:** Quantify factor influence (distance, demand, depot proximity, angles, etc.) on solution quality. Focus on balancing exploration and exploitation through sparsification.\n\n*   **Avoid:** Vague recommendations (e.g., \"consider multiple factors\"). Premature optimization without establishing a baseline.\n\n*   **Explanation:** Rigorously test each heuristic component's impact using performance metrics like solution cost, runtime, and solution diversity. Consider constraint handling violations.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}