```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Enhanced heuristic for online bin packing problem that dynamically adjusts scaling and rewards/penalties.
    """
    # Constants for tuning the heuristic
    INITIAL_SCALE_FACTOR = 100.0
    EXACT_FIT_BONUS = 1000.0
    INEFFICIENCY_PENALTY = -1000.0
    UNDERUTILIZATION_PENALTY = -500.0
    ADAPTIVE_SCALING_DECAY = 0.95
    EFFICIENCY_THRESHOLD = 0.9
    SIGMOID_SLOPE = 1.2
    SIGMOID_OFFSET = 0.5

    # Calculate the exact fit indicator
    exact_fit_mask = bins_remain_cap == item
    priority_scores = exact_fit_mask * EXACT_FIT_BONUS

    # Adaptive scaling based on remaining capacity for non-exact fits
    non_exact_fit_mask = np.logical_and(bins_remain_cap >= item, ~exact_fit_mask)
    if np.any(non_exact_fit_mask):
        remaining_cap = bins_remain_cap[non_exact_fit_mask]
        adaptive_scale_factor = INITIAL_SCALE_FACTOR * np.exp(-np.abs(remaining_cap - item) / item)
        priority_scores[non_exact_fit_mask] = adaptive_scale_factor

    # Dynamically adjust scaling factor based on current bin utilization
    utilization = bins_remain_cap / bins_remain_cap.max()
    dynamic_scale = np.mean(utilization) * ADAPTIVE_SCALING_DECAY
    priority_scores *= dynamic_scale

    # Reward for efficient usage of bin capacity
    efficient_usage_mask = utilization >= EFFICIENCY_THRESHOLD
    efficiency_reward = efficient_usage_mask * (bins_remain_cap - item) * 10.
    priority_scores += efficiency_reward

    # Penalties for inefficiencies and underutilization
    inefficiency_penalty_mask = utilization < EFFICIENCY_THRESHOLD
    inefficiency_penalty = inefficiency_penalty_mask * INEFFICIENCY_PENALTY
    underutilization_penalty = (bins_remain_cap < item).astype(float) * UNDERUTILIZATION_PENALTY
    priority_scores += inefficiency_penalty + underutilization_penalty

    # Sigmoid reward for non-exact fits to encourage balanced loading
    if np.any(non_exact_fit_mask):
        reward = 1 / (1 + np.exp(-SIGMOID_SLOPE * (remaining_cap / bins_remain_cap.max() - SIGMOID_OFFSET)))
        reward = np.clip(reward, 0.0, 1.0)
        priority_scores[non_exact_fit_mask] *= reward

    return priority_scores
```
