{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version uses adaptive scaling and a reward/penalty system to prioritize bins that are more likely to close, promoting efficient use of space.\n    \n    Adaptive scaling adjusts the priority based on the ratio of item size to remaining capacity, encouraging filling of bins to a similar extent.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: Adaptive scaling based on the item size relative to the remaining capacity\n    base_priority = item / (bins_remain_cap + 0.1)  # adding a small epsilon to avoid division by zero\n    \n    # Specific reward for bins that would be filled to capacity by this item\n    exact_fill_reward = np.where(bins_remain_cap == item, 1.0, 0.0)\n    \n    # Penalty for very small remaining capacities to avoid precision issues with very small numbers\n    small_capacity_penalty = np.where((bins_remain_cap < item) & (bins_remain_cap > 0.1), 0.1, 0.0)\n    \n    # Combined priority score\n    priority_score = base_priority + exact_fill_reward - small_capacity_penalty\n    \n    return priority_score\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    item: float, \n    bins_remain_cap: np.ndarray, \n    penalty: float = -3586.2115429161977,\n    sigmoid_threshold_min: float = 0.7607170824887122,\n    sigmoid_threshold_max: float = 0.42411238386705796) -> np.ndarray:\n    \"\"\"\n    Combines exact fit prioritization with adaptive sigmoid reward to balance filling bins effectively.\n    \"\"\"\n    priority_scores = np.zeros_like(bins_remain_cap)\n    \n    # Exact fit gets highest priority\n    exact_fit_mask = bins_remain_cap == item\n    priority_scores[exact_fit_mask] = 1.0\n    \n    # Non-exact fits are rewarded based on a sigmoid function for capacity utilization\n    non_exact_fit_mask = np.logical_and(bins_remain_cap >= item, ~exact_fit_mask)\n    if np.any(non_exact_fit_mask):\n        new_remain_cap = bins_remain_cap[non_exact_fit_mask] - item\n        reward = 1 / (1 + np.exp(-new_remain_cap))\n        priority_scores[non_exact_fit_mask] = reward\n    \n    # Penalize bins that cannot fit the item\n    priority_scores = np.where(bins_remain_cap < item, penalty, priority_scores)\n    \n    return priority_scores\n\n### Analyze & experience\n- Comparing (best) vs (worst), we see that the best heuristic uses an adaptive scoring system with exact fit prioritization, sigmoid rewards for partial fits, and penalties for unsuitable bins, finely tuned with specific parameters. The worst heuristic simply applies a penalty to insufficient bins and a reward inversely proportional to the remaining capacity, without the refined adjustments seen in the best heuristic. Comparing (second best) vs (second worst), the second best retains most characteristics of the best heuristic, while the second worst follows the simplistic scoring of the worst heuristic with minor variations. Overall, the best heuristics incorporate multiple strategic adjustments and adaptive scaling, whereas the worst heuristics lack these nuances, relying on a basic reward-penalty mechanism.\n- \n- **Keywords**: Adaptive scaling, exact fit rewards, penalties, inefficiency, nuanced control, avoidance of simplism\n\n- **Advice**:\n  - Design heuristics that dynamically adjust parameters based on the current state or previous outcomes (adaptive scaling).\n  - Implement precise reward systems for obtaining exact fits to encourage optimal packing decisions.\n  - Introduce penalties for underutilization or inefficient placements to discourage poor configurations.\n  - Emphasize the importance of balancing multiple factors with fine-grained control mechanisms.\n\n- **Avoid**:\n  - Over-reliance on simplistic balancing measures like penalizing large leftover spaces without contextual considerations.\n  - Neglecting the complexity required for designing robust and adaptive heuristics.\n  - Simplicity in heuristic design to the point of overlooking nuanced aspects of efficient solutions.\n\n- **Explanation**: By focusing on adaptive scaling and strategic reward/penalty systems, the heuristic design becomes more dynamic and responsive to various scenarios, leading to better packing efficiency. Avoiding simplism ensures that the heuristic can handle the complexity and nuance of real-world problems, ultimately yielding more efficient results.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}