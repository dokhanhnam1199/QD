{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version uses adaptive scaling and a reward/penalty system to prioritize bins that are more likely to close, promoting efficient use of space.\n    \n    Adaptive scaling adjusts the priority based on the ratio of item size to remaining capacity, encouraging filling of bins to a similar extent.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Base priority: Adaptive scaling based on the item size relative to the remaining capacity\n    base_priority = item / (bins_remain_cap + 0.1)  # adding a small epsilon to avoid division by zero\n    \n    # Specific reward for bins that would be filled to capacity by this item\n    exact_fill_reward = np.where(bins_remain_cap == item, 1.0, 0.0)\n    \n    # Penalty for very small remaining capacities to avoid precision issues with very small numbers\n    small_capacity_penalty = np.where((bins_remain_cap < item) & (bins_remain_cap > 0.1), 0.1, 0.0)\n    \n    # Combined priority score\n    priority_score = base_priority + exact_fill_reward - small_capacity_penalty\n    \n    return priority_score\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This heuristic emphasizes adaptability and simplicity by prioritizing bins that \n    can immediately accommodate the item while still considering how full the bins are.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Priority score based on whether the bin can fit the item and remaining capacity\n    can_fit = (bins_remain_cap >= item).astype(float)\n    return can_fit * (bins_remain_cap / item)\n\n### Analyze & experience\n- Comparing (best) vs (worst), we see that the best heuristic uses an adaptive reward/penalty system combined with sigmoid functions to balance utilization efficiently, while the worst only considers whether an item can fit into a bin, ignoring remaining capacity or penalties for very full bins. (Second best) vs (second worst) also highlights a sophisticated reward system for exact fits and penalties for bins with very small remaining capacities, whereas the second worst still lacks in dynamic decision-making based on capacity. Comparing (1st) vs (2nd), we see both using similar base priority mechanisms but the 1st includes additional nuanced rewards and penalties. (3rd) vs (4th) shows slight variations but both prioritize bins that can accommodate the item and use a reward system but without significant differences in complexity. Comparing (second worst) vs (worst), we see minimal differences as both focus on whether the item fits, without adaptive mechanisms. Overall: The best heuristics incorporate adaptive mechanisms, rewards, and penalties for smarter decision-making, whereas the worst focus solely on feasibility of item fitting.\n- \n- **Keywords**: Adaptive mechanisms, strategic rewards, item placement efficiency, simplicity\n- **Advice**: Focus on dynamic parameter tuning based on solution progress; design rewards that encourage proximity to optimal solutions; streamline decision-making processes by clearly defining criteria for penalties.\n- **Avoid**: Excessive penalties/reward schemes that complicate decision logic; overfitting the heuristic to specific instances rather than maintaining generality.\n- **Explanation**: By focusing on adaptive mechanisms, the heuristic can improve over time and iterations without being overly complex. Strategic rewards should be targeted and meaningful to guide the solution towards better outcomes. Simplicity ensures that the heuristic remains robust and applicable across a wide range of scenarios, avoiding the pitfalls of overly intricate designs.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}