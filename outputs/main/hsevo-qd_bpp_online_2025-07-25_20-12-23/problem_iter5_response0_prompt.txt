{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines exact fit priority and remaining capacity to minimize waste.\"\"\"\n    priority_scores = np.zeros_like(bins_remain_cap)\n    \n    # Exact fit has highest priority\n    exact_fit_mask = bins_remain_cap == item\n    priority_scores[exact_fit_mask] = 1.0\n    \n    # For non-exact fits, prioritize those close to being full\n    non_exact_fit_mask = bins_remain_cap >= item\n    if np.any(non_exact_fit_mask):\n        # Calculate priority based on remaining space after adding item\n        priority_scores[non_exact_fit_mask] = (bins_remain_cap[non_exact_fit_mask] - item) / bins_remain_cap[non_exact_fit_mask]\n        priority_scores[non_exact_fit_mask] = 1 - priority_scores[non_exact_fit_mask]  # Closer to full is better\n    \n    return priority_scores\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Balanced heuristic prioritizing tight fit and initial bin size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of priority scores for each bin.\n    \"\"\"\n    # High priority if adding this item leaves minimal space in the bin\n    ifbinsfit = bins_remain_cap >= item\n    priority = np.where(ifbinsfit, bins_remain_cap - item, -np.inf)\n    # Relative space left factor to consider initial bin size\n    relative_space_left_factor = bins_remain_cap / np.max(bins_remain_cap, initial=1.0)\n    # Combine factors with a balance\n    return priority + 0.5 * relative_space_left_factor\n\n### Analyze & experience\n- Comparing (best) vs (worst), we see that the best heuristic (1st) combines exact fit rewards and penalizes leftover space with exact and adjustable weights, showing balance and adaptability. The worst heuristic (20th) simply assigns priority based on item fit and relative space, which is less nuanced and lacks specific reward structures.\n(Second best) vs (second worst) contrasts the detailed penalty and reward system of the second-best heuristic (2nd) with the simpler, less dynamic approach of the second-worst (19th). Both use sigmoid functions but the second-best strategically rewards and penalizes more explicitly.\nComparing (1st) vs (2nd), we see minor similarities in approach but the first leverages weights for exact fits and non-fits more effectively.\n(3rd) vs (4th) illustrates a more specific reward structure (3rd) compared to a generic inverse of remaining capacity (4th); the third approach targets bins that leave minimal space more precisely.\nComparing (second worst) vs (worst), we see subtle improvements in considering relative space left in the second worst heuristic (19th) which adjusts scores based on bin initial sizes whereas the worst (20th) fails to adapt to bigger bin initial sizes effectively.\nOverall: The top heuristics combine detailed balancing mechanisms with explicit penalties and rewards, making them more adaptable and effective. The lower heuristics are simpler, often omitting weights, explicit penalties/rewards, and adaptive scaling.\n- \n- **Keywords**: Adaptive scaling, efficiency, simplicity, specific reward/penalty\n- **Advice**: Emphasize simplicity in heuristic structure while implementing adaptive scaling for efficiency improvements. Use specific reward/penalty mechanisms thoughtfully to enhance heuristic robustness.\n- **Avoid**: Overcomplicating the heuristic with unnecessary functions; only use penalties/rewards that significantly improve efficiency.\n- **Explanation**: By focusing on simplicity, you maintain clarity and ease of implementation, reducing potential errors and enhancing speed. Adaptive scaling allows the heuristic to adjust dynamically to diverse problem landscapes, improving robustness. Specific rewards/penalties ensure that the heuristic is guided effectively towards optimal solutions without being misled by less relevant metrics.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}