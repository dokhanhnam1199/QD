[
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority score for each bin considering item size and remaining capacity.\n\n    This heuristic combines remaining capacity, closeness to item size, and penalizes overcrowding.\n    \"\"\"\n    # Preference for bins with remaining capacity close to the item size\n    close_bins = np.clip(bins_remain_cap - item, 0, 1) * 1.5\n    \n    # Preference for bins with largest remaining capacity\n    largest_first_fit = bins_remain_cap\n    \n    # Penalize bins that would be overcrowded by the item\n    size_penalty = np.where(bins_remain_cap < 2 * item, bins_remain_cap**item / 50, 0)\n    \n    # Combine priorities with appropriate weights\n    priorities = close_bins + largest_first_fit - size_penalty\n    \n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 88.67171918627844,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response1.txt_stdout.txt",
    "code_path": "problem_iter2_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines remaining capacity and minimal leftover space to prioritize bins.\"\"\"\n    can_fit = bins_remain_cap >= item\n    space_left = bins_remain_cap - item\n    # Priority for bins that fit the item, penalizing leftover space\n    priority_fit = can_fit * (1 - (space_left / bins_remain_cap))\n    # Encouragement for bins with capacity close to item size\n    close_fit = np.clip(bins_remain_cap - item, 0, 1)\n    # Combine priorities with dynamic weighting\n    priority = priority_fit + 0.5 * close_fit\n    return priority",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.9760670123653865,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Balanced heuristic combining remaining space, compactness, and adaptive penalties.\"\"\"\n    \n    # High priority if adding this item leaves minimal space in the bin (similar to v1)\n    close_fit_priority = np.where(bins_remain_cap >= item, bins_remain_cap - item, -np.inf)\n    \n    # Ward priority from v0: target filling tighter bins first\n    ward_priority = (bins_remain_cap - item) / bins_remain_cap\n    \n    # Compactness priority from v0: prefer bins that are already more filled\n    compactness_priority = np.ones_like(bins_remain_cap) - 1 / np.clip(bins_remain_cap, a_min=1e-3, a_max=None)\n    \n    # Size penalty from v0: penalize large items that would nearly fill a bin\n    size_penalty = np.where(bins_remain_cap < 2 * item, bins_remain_cap ** item / 50, 0)\n    \n    # Combine priorities: close fit, ward priority, compactness, and size penalties\n    priorities = close_fit_priority + ward_priority + compactness_priority - size_penalty\n    \n    # Ensure dynamic adjustment by normalizing priorities based on current state\n    priorities /= np.max(priorities, initial=1.0)\n    \n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 88.67171918627844,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response3.txt_stdout.txt",
    "code_path": "problem_iter2_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines remaining capacity and minimal leftover space to prioritize bins.\"\"\"\n    can_fit = bins_remain_cap >= item\n    space_left = bins_remain_cap - item\n    # Priority for bins that fit the item, penalizing leftover space\n    priority_fit = can_fit * (1 - (space_left / bins_remain_cap))\n    # Encouragement for bins with capacity close to item size\n    close_fit = np.clip(bins_remain_cap - item, 0, 1)\n    # Combine priorities with dynamic weighting\n    priority = priority_fit + 0.5 * close_fit\n    return priority",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.9760670123653865,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response4.txt_stdout.txt",
    "code_path": "problem_iter2_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines remaining capacity and minimal leftover space to prioritize bins.\"\"\"\n    can_fit = bins_remain_cap >= item\n    space_left = bins_remain_cap - item\n    # Priority for bins that fit the item, penalizing leftover space\n    priority_fit = can_fit * (1 - (space_left / bins_remain_cap))\n    # Encouragement for bins with capacity close to item size\n    close_fit = np.clip(bins_remain_cap - item, 0, 1)\n    # Combine priorities with dynamic weighting\n    priority = priority_fit + 0.5 * close_fit\n    return priority",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.9760670123653865,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Balanced heuristic combining remaining capacity and waste reduction with dynamic adjustments.\"\"\"\n    # Calculate waste reduction if item is added to each bin\n    waste_reduction = bins_remain_cap - item\n    # Penalize bins that cannot fit the item\n    priority_score = np.where(waste_reduction >= 0, waste_reduction, -1000)\n    # Encourage using less full bins with a sinusoidal function\n    capacity_factor = np.sin(np.pi / 2 * (bins_remain_cap / (np.max(bins_remain_cap) + 1e-6)))\n    # Combine waste reduction with capacity factor\n    combined_score = priority_score * (1 + capacity_factor)\n    return combined_score",
    "response_id": 5,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response6.txt_stdout.txt",
    "code_path": "problem_iter2_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Balanced heuristic combining remaining capacity, compactness, and size penalties.\"\"\"\n    # Sinusoidal prioritization for tight bins\n    sinusoidal_priority = 1.0 / (bins_remain_cap + 1e-6) * np.sin(np.pi / 2 * (bins_remain_cap / (np.max(bins_remain_cap) + 1e-6)))\n    # Ward priority adjusted for current item size\n    ward_priority = (bins_remain_cap - item) / bins_remain_cap\n    # Compactness priority to avoid greenfield bins\n    compactness_priority = 1 - 1 / np.clip(bins_remain_cap, a_min=1e-3, a_max=None)\n    # Size penalty for large items in small remaining space\n    size_penalty = np.where(bins_remain_cap < 2 * item, bins_remain_cap**item / 50, 0)\n    # Combined priority score\n    return sinusoidal_priority + ward_priority + compactness_priority - size_penalty",
    "response_id": 6,
    "tryHS": false,
    "obj": 88.67171918627844,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response7.txt_stdout.txt",
    "code_path": "problem_iter2_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines remaining capacity and penalty for leftover space, with encouragement for less full bins.\"\"\"\n    can_fit = bins_remain_cap >= item\n    space_left = bins_remain_cap - item\n    priority = can_fit * (1 - (space_left / bins_remain_cap))\n    epsilon = 0.01\n    encouragement = (bins_remain_cap - np.max(bins_remain_cap)) * epsilon\n    return priority + encouragement",
    "response_id": 7,
    "tryHS": false,
    "obj": 86.7670522536897,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response8.txt_stdout.txt",
    "code_path": "problem_iter2_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines remaining capacity and minimal leftover space to prioritize bins.\"\"\"\n    can_fit = bins_remain_cap >= item\n    space_left = bins_remain_cap - item\n    # Priority for bins that fit the item, penalizing leftover space\n    priority_fit = can_fit * (1 - (space_left / bins_remain_cap))\n    # Encouragement for bins with capacity close to item size\n    close_fit = np.clip(bins_remain_cap - item, 0, 1)\n    # Combine priorities with dynamic weighting\n    priority = priority_fit + 0.5 * close_fit\n    return priority",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.9760670123653865,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response9.txt_stdout.txt",
    "code_path": "problem_iter2_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Balanced priority score combining available space and relative initial space, penalizing large empty spaces.\"\"\"\n    can_fit = bins_remain_cap >= item\n    space_left = bins_remain_cap - item\n    space_penalty = 1 - (space_left / bins_remain_cap) ** 2  # Penalize large empty spaces more strongly\n    relative_initial_space = bins_remain_cap / np.max(bins_remain_cap, initial=1.0)\n    priority = can_fit * (space_penalty + relative_initial_space)\n    return priority",
    "response_id": 9,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter3_response0.txt_stdout.txt",
    "code_path": "problem_iter3_code0.py",
    "code": "import numpy as np\n\nclass AdaptiveBPP:\n    def __init__(self):\n        self.weights = np.array([1.0, 1.0])  # Initial weights for criteria\n        self.learning_rate = 0.01  # Learning rate for adaptation\n\n    def update_weights(self, selected_bin, item, bins_remain_cap):\n        # Simple adaptive learning: penalize high leftover space more if it leads to frequent small bin usage\n        # Here we assume a simple feedback mechanism where we decrease weights if leftover space is large\n        leftover_space = bins_remain_cap[selected_bin] - item\n        if leftover_space > np.mean(bins_remain_cap):\n            self.weights[0] += self.learning_rate\n        else:\n            self.weights[0] -= self.learning_rate * 0.5  # Less adjustment if space is okay\n\n        # Additional criteria could be added here, e.g., future waste prediction\n        self.weights = np.clip(self.weights, 0.1, 2.0)  # Clamp weights to prevent extremes\n\n    def priority_v2(self, item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n        can_fit = bins_remain_cap >= item\n        space_left = bins_remain_cap - item\n        space_left_normalized = space_left / bins_remain_cap\n        space_efficiency = 1 - space_left_normalized\n\n        # Future waste prediction: Estimate how future items would fit if packed into this bin\n        # Here we use a simple heuristic: sum of squared differences of space left\n        future_waste = np.array([np.sum((bins_remain_cap - np.roll(bins_remain_cap, -1)) ** 2) for _ in bins_remain_cap])\n        future_waste[selected_bin] = 0  # No waste in selected bin\n        future_waste_normalized = future_waste / np.max(future_waste)\n\n        # Weighted multi-criteria scoring\n        priority_score = can_fit * (self.weights[0] * space_efficiency - self.weights[1] * future_waste_normalized)\n        return priority_score\n\n# Example usage\nadaptive_bpp = AdaptiveBPP()\nitem = 0.5\nbins_remain_cap = np.array([0.8, 0.7, 1.0])\npriority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\nselected_bin = np.argmax(priority_scores)\nadaptive_bpp.update_weights(selected_bin, item, bins_remain_cap)",
    "response_id": 0,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 40, in <module>\n    priority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 29, in priority_v2\n    future_waste[selected_bin] = 0  # No waste in selected bin\nNameError: name 'selected_bin' is not defined\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/SLOC.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 40, in <module>\n    priority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 29, in priority_v2\n    future_waste[selected_bin] = 0  # No waste in selected bin\nNameError: name 'selected_bin' is not defined\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/cyclomatic_complexity.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 40, in <module>\n    priority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 29, in priority_v2\n    future_waste[selected_bin] = 0  # No waste in selected bin\nNameError: name 'selected_bin' is not defined\n"
  },
  {
    "stdout_filepath": "problem_iter3_response1.txt_stdout.txt",
    "code_path": "problem_iter3_code1.py",
    "code": "import numpy as np\n\nclass AdaptiveBPP:\n    def __init__(self):\n        self.weights = np.array([1.0, 1.0])  # Initial weights for criteria\n        self.learning_rate = 0.01  # Learning rate for adaptation\n\n    def update_weights(self, selected_bin, item, bins_remain_cap):\n        # Simple adaptive learning: penalize high leftover space more if it leads to frequent small bin usage\n        # Here we assume a simple feedback mechanism where we decrease weights if leftover space is large\n        leftover_space = bins_remain_cap[selected_bin] - item\n        if leftover_space > np.mean(bins_remain_cap):\n            self.weights[0] += self.learning_rate\n        else:\n            self.weights[0] -= self.learning_rate * 0.5  # Less adjustment if space is okay\n\n        # Additional criteria could be added here, e.g., future waste prediction\n        self.weights = np.clip(self.weights, 0.1, 2.0)  # Clamp weights to prevent extremes\n\n    def priority_v2(self, item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n        can_fit = bins_remain_cap >= item\n        space_left = bins_remain_cap - item\n        space_left_normalized = space_left / bins_remain_cap\n        space_efficiency = 1 - space_left_normalized\n\n        # Future waste prediction: Estimate how future items would fit if packed into this bin\n        # Here we use a simple heuristic: sum of squared differences of space left\n        future_waste = np.array([np.sum((bins_remain_cap - np.roll(bins_remain_cap, -1)) ** 2) for _ in bins_remain_cap])\n        future_waste[selected_bin] = 0  # No waste in selected bin\n        future_waste_normalized = future_waste / np.max(future_waste)\n\n        # Weighted multi-criteria scoring\n        priority_score = can_fit * (self.weights[0] * space_efficiency - self.weights[1] * future_waste_normalized)\n        return priority_score\n\n# Example usage\nadaptive_bpp = AdaptiveBPP()\nitem = 0.5\nbins_remain_cap = np.array([0.8, 0.7, 1.0])\npriority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\nselected_bin = np.argmax(priority_scores)\nadaptive_bpp.update_weights(selected_bin, item, bins_remain_cap)",
    "response_id": 1,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 40, in <module>\n    priority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 29, in priority_v2\n    future_waste[selected_bin] = 0  # No waste in selected bin\nNameError: name 'selected_bin' is not defined\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/SLOC.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 40, in <module>\n    priority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 29, in priority_v2\n    future_waste[selected_bin] = 0  # No waste in selected bin\nNameError: name 'selected_bin' is not defined\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/cyclomatic_complexity.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 40, in <module>\n    priority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 29, in priority_v2\n    future_waste[selected_bin] = 0  # No waste in selected bin\nNameError: name 'selected_bin' is not defined\n"
  },
  {
    "stdout_filepath": "problem_iter3_response2.txt_stdout.txt",
    "code_path": "problem_iter3_code2.py",
    "code": "import numpy as np\n\nclass AdaptiveBPP:\n    def __init__(self):\n        self.weights = np.array([1.0, 1.0])  # Initial weights for criteria\n        self.learning_rate = 0.01  # Learning rate for adaptation\n\n    def update_weights(self, selected_bin, item, bins_remain_cap):\n        # Simple adaptive learning: penalize high leftover space more if it leads to frequent small bin usage\n        # Here we assume a simple feedback mechanism where we decrease weights if leftover space is large\n        leftover_space = bins_remain_cap[selected_bin] - item\n        if leftover_space > np.mean(bins_remain_cap):\n            self.weights[0] += self.learning_rate\n        else:\n            self.weights[0] -= self.learning_rate * 0.5  # Less adjustment if space is okay\n\n        # Additional criteria could be added here, e.g., future waste prediction\n        self.weights = np.clip(self.weights, 0.1, 2.0)  # Clamp weights to prevent extremes\n\n    def priority_v2(self, item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n        can_fit = bins_remain_cap >= item\n        space_left = bins_remain_cap - item\n        space_left_normalized = space_left / bins_remain_cap\n        space_efficiency = 1 - space_left_normalized\n\n        # Future waste prediction: Estimate how future items would fit if packed into this bin\n        # Here we use a simple heuristic: sum of squared differences of space left\n        future_waste = np.array([np.sum((bins_remain_cap - np.roll(bins_remain_cap, -1)) ** 2) for _ in bins_remain_cap])\n        future_waste[selected_bin] = 0  # No waste in selected bin\n        future_waste_normalized = future_waste / np.max(future_waste)\n\n        # Weighted multi-criteria scoring\n        priority_score = can_fit * (self.weights[0] * space_efficiency - self.weights[1] * future_waste_normalized)\n        return priority_score\n\n# Example usage\nadaptive_bpp = AdaptiveBPP()\nitem = 0.5\nbins_remain_cap = np.array([0.8, 0.7, 1.0])\npriority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\nselected_bin = np.argmax(priority_scores)\nadaptive_bpp.update_weights(selected_bin, item, bins_remain_cap)",
    "response_id": 2,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 40, in <module>\n    priority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 29, in priority_v2\n    future_waste[selected_bin] = 0  # No waste in selected bin\nNameError: name 'selected_bin' is not defined\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/SLOC.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 40, in <module>\n    priority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 29, in priority_v2\n    future_waste[selected_bin] = 0  # No waste in selected bin\nNameError: name 'selected_bin' is not defined\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/cyclomatic_complexity.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 40, in <module>\n    priority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 29, in priority_v2\n    future_waste[selected_bin] = 0  # No waste in selected bin\nNameError: name 'selected_bin' is not defined\n"
  },
  {
    "stdout_filepath": "problem_iter3_response3.txt_stdout.txt",
    "code_path": "problem_iter3_code3.py",
    "code": "import numpy as np\n\nclass AdaptiveBPP:\n    def __init__(self):\n        self.weights = np.array([1.0, 1.0])  # Initial weights for criteria\n        self.learning_rate = 0.01  # Learning rate for adaptation\n\n    def update_weights(self, selected_bin, item, bins_remain_cap):\n        # Simple adaptive learning: penalize high leftover space more if it leads to frequent small bin usage\n        # Here we assume a simple feedback mechanism where we decrease weights if leftover space is large\n        leftover_space = bins_remain_cap[selected_bin] - item\n        if leftover_space > np.mean(bins_remain_cap):\n            self.weights[0] += self.learning_rate\n        else:\n            self.weights[0] -= self.learning_rate * 0.5  # Less adjustment if space is okay\n\n        # Additional criteria could be added here, e.g., future waste prediction\n        self.weights = np.clip(self.weights, 0.1, 2.0)  # Clamp weights to prevent extremes\n\n    def priority_v2(self, item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n        can_fit = bins_remain_cap >= item\n        space_left = bins_remain_cap - item\n        space_left_normalized = space_left / bins_remain_cap\n        space_efficiency = 1 - space_left_normalized\n\n        # Future waste prediction: Estimate how future items would fit if packed into this bin\n        # Here we use a simple heuristic: sum of squared differences of space left\n        future_waste = np.array([np.sum((bins_remain_cap - np.roll(bins_remain_cap, -1)) ** 2) for _ in bins_remain_cap])\n        future_waste[selected_bin] = 0  # No waste in selected bin\n        future_waste_normalized = future_waste / np.max(future_waste)\n\n        # Weighted multi-criteria scoring\n        priority_score = can_fit * (self.weights[0] * space_efficiency - self.weights[1] * future_waste_normalized)\n        return priority_score\n\n# Example usage\nadaptive_bpp = AdaptiveBPP()\nitem = 0.5\nbins_remain_cap = np.array([0.8, 0.7, 1.0])\npriority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\nselected_bin = np.argmax(priority_scores)\nadaptive_bpp.update_weights(selected_bin, item, bins_remain_cap)",
    "response_id": 3,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 40, in <module>\n    priority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 29, in priority_v2\n    future_waste[selected_bin] = 0  # No waste in selected bin\nNameError: name 'selected_bin' is not defined\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/SLOC.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 40, in <module>\n    priority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 29, in priority_v2\n    future_waste[selected_bin] = 0  # No waste in selected bin\nNameError: name 'selected_bin' is not defined\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/cyclomatic_complexity.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 40, in <module>\n    priority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 29, in priority_v2\n    future_waste[selected_bin] = 0  # No waste in selected bin\nNameError: name 'selected_bin' is not defined\n"
  },
  {
    "stdout_filepath": "problem_iter3_response4.txt_stdout.txt",
    "code_path": "problem_iter3_code4.py",
    "code": "import numpy as np\n\nclass AdaptiveBPP:\n    def __init__(self):\n        self.weights = np.array([1.0, 1.0])  # Initial weights for criteria\n        self.learning_rate = 0.01  # Learning rate for adaptation\n\n    def update_weights(self, selected_bin, item, bins_remain_cap):\n        # Simple adaptive learning: penalize high leftover space more if it leads to frequent small bin usage\n        # Here we assume a simple feedback mechanism where we decrease weights if leftover space is large\n        leftover_space = bins_remain_cap[selected_bin] - item\n        if leftover_space > np.mean(bins_remain_cap):\n            self.weights[0] += self.learning_rate\n        else:\n            self.weights[0] -= self.learning_rate * 0.5  # Less adjustment if space is okay\n\n        # Additional criteria could be added here, e.g., future waste prediction\n        self.weights = np.clip(self.weights, 0.1, 2.0)  # Clamp weights to prevent extremes\n\n    def priority_v2(self, item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n        can_fit = bins_remain_cap >= item\n        space_left = bins_remain_cap - item\n        space_left_normalized = space_left / bins_remain_cap\n        space_efficiency = 1 - space_left_normalized\n\n        # Future waste prediction: Estimate how future items would fit if packed into this bin\n        # Here we use a simple heuristic: sum of squared differences of space left\n        future_waste = np.array([np.sum((bins_remain_cap - np.roll(bins_remain_cap, -1)) ** 2) for _ in bins_remain_cap])\n        future_waste[selected_bin] = 0  # No waste in selected bin\n        future_waste_normalized = future_waste / np.max(future_waste)\n\n        # Weighted multi-criteria scoring\n        priority_score = can_fit * (self.weights[0] * space_efficiency - self.weights[1] * future_waste_normalized)\n        return priority_score\n\n# Example usage\nadaptive_bpp = AdaptiveBPP()\nitem = 0.5\nbins_remain_cap = np.array([0.8, 0.7, 1.0])\npriority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\nselected_bin = np.argmax(priority_scores)\nadaptive_bpp.update_weights(selected_bin, item, bins_remain_cap)",
    "response_id": 4,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 9, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 40, in <module>\n    priority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 29, in priority_v2\n    future_waste[selected_bin] = 0  # No waste in selected bin\nNameError: name 'selected_bin' is not defined\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/SLOC.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 40, in <module>\n    priority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 29, in priority_v2\n    future_waste[selected_bin] = 0  # No waste in selected bin\nNameError: name 'selected_bin' is not defined\nTraceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/cyclomatic_complexity.py\", line 7, in <module>\n    from gpt import priority_v2 as priority\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 40, in <module>\n    priority_scores = adaptive_bpp.priority_v2(item, bins_remain_cap)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 29, in priority_v2\n    future_waste[selected_bin] = 0  # No waste in selected bin\nNameError: name 'selected_bin' is not defined\n"
  }
]