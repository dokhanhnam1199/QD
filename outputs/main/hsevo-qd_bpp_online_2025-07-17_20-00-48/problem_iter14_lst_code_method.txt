{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors, including utilization,\n    fragmentation avoidance, pressure, best fit, and empty bin preference, with adaptive adjustments\n    based on item size and bin characteristics. It aims to improve upon priority_v1 by dynamically\n    adjusting penalties and bonuses to better handle diverse item sizes and bin configurations,\n    and adding a bin diversity term.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    max_cap = np.max(bins_remain_cap)\n    num_bins = len(bins_remain_cap)\n\n    # 0. Hard constraint: Item must fit. Bins that can't fit get -inf priority.\n    priorities[bins_remain_cap < item] = -np.inf\n\n    fit_mask = bins_remain_cap >= item\n\n    if not np.any(fit_mask):\n        return priorities  # No bin can fit the item\n\n    # 1. Utilization Term: Favor better utilization, but scale based on item size.\n    utilization = item / max_cap\n    remaining_capacity_after_fit = bins_remain_cap - item\n    utilization_score = (1 - remaining_capacity_after_fit / max_cap) * utilization\n    priorities[fit_mask] += utilization_score[fit_mask]\n\n    # 2. Fragmentation Avoidance: Penalize bins that will result in tiny fragments.\n    tiny_fragment_threshold = 0.05 * max_cap\n    small_fragment_threshold = 0.2 * max_cap\n\n    # Adaptive penalty based on item size: Larger items impose a heavier penalty for tiny fragments\n    tiny_fragment_penalty = -5.0 - 5.0 * utilization  # Higher penalty for larger items\n    small_fragment_penalty = -1.0 - 1.0 * utilization\n    \n    tiny_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit <= tiny_fragment_threshold)\n    small_fragment_mask = (remaining_capacity_after_fit > tiny_fragment_threshold) & (remaining_capacity_after_fit <= small_fragment_threshold)\n\n    priorities[tiny_fragment_mask] += tiny_fragment_penalty\n    priorities[small_fragment_mask] += small_fragment_penalty\n\n    # 3. \"Pressure\" Term: Bins with higher remaining capacity exert more \"pressure\".  Adjust scaling dynamically.\n    pressure = bins_remain_cap / max_cap * (1 - utilization)\n    priorities[fit_mask] += 0.5 * pressure[fit_mask]\n\n    # 4. Best Fit Bonus: Reward the bin that provides the absolute best fit (smallest waste).\n    diffs = bins_remain_cap - item\n    min_diff = np.min(diffs[diffs >= 0]) if np.any(diffs >= 0) else np.inf\n    best_fit_bonus = np.where(diffs == min_diff, 1.0 + 0.5 * (1 - utilization), 0)  # Adaptive bonus\n    priorities += best_fit_bonus\n\n    # 5. Empty Bin Preference (Adaptive): If the item is a significant fraction of bin size, strongly prefer an empty bin.\n    empty_bin_mask = bins_remain_cap == max_cap\n    empty_bin_threshold = 0.6 * max_cap\n    if item >= empty_bin_threshold and np.any(empty_bin_mask):\n        priorities[empty_bin_mask] += 2.0 + 1.0 * utilization  # Stronger adaptive preference\n    \n    # 6. Bin Diversity Bonus: Encourage spreading items across different bins.\n    # This penalizes using bins with similar remaining capacities if there are other options.\n    if num_bins > 1:\n        std_dev = np.std(bins_remain_cap[fit_mask])  # Standard deviation of remaining capacities\n        diversity_bonus = std_dev / max_cap # Normalize\n        priorities[fit_mask] += 0.25 * diversity_bonus # Moderate diversity bonus\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors, including utilization,\n    fragmentation avoidance, pressure, best fit, and empty bin preference, with adaptive adjustments\n    based on item size and bin characteristics. It aims to improve upon priority_v1 by dynamically\n    adjusting penalties and bonuses to better handle diverse item sizes and bin configurations,\n    and adding a bin diversity term.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    max_cap = np.max(bins_remain_cap)\n    num_bins = len(bins_remain_cap)\n\n    # 0. Hard constraint: Item must fit. Bins that can't fit get -inf priority.\n    priorities[bins_remain_cap < item] = -np.inf\n\n    fit_mask = bins_remain_cap >= item\n\n    if not np.any(fit_mask):\n        return priorities  # No bin can fit the item\n\n    # 1. Utilization Term: Favor better utilization, but scale based on item size.\n    utilization = item / max_cap\n    remaining_capacity_after_fit = bins_remain_cap - item\n    utilization_score = (1 - remaining_capacity_after_fit / max_cap) * utilization\n    priorities[fit_mask] += utilization_score[fit_mask]\n\n    # 2. Fragmentation Avoidance: Penalize bins that will result in tiny fragments.\n    tiny_fragment_threshold = 0.05 * max_cap\n    small_fragment_threshold = 0.2 * max_cap\n\n    # Adaptive penalty based on item size: Larger items impose a heavier penalty for tiny fragments\n    tiny_fragment_penalty = -5.0 - 5.0 * utilization  # Higher penalty for larger items\n    small_fragment_penalty = -1.0 - 1.0 * utilization\n    \n    tiny_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit <= tiny_fragment_threshold)\n    small_fragment_mask = (remaining_capacity_after_fit > tiny_fragment_threshold) & (remaining_capacity_after_fit <= small_fragment_threshold)\n\n    priorities[tiny_fragment_mask] += tiny_fragment_penalty\n    priorities[small_fragment_mask] += small_fragment_penalty\n\n    # 3. \"Pressure\" Term: Bins with higher remaining capacity exert more \"pressure\".  Adjust scaling dynamically.\n    pressure = bins_remain_cap / max_cap * (1 - utilization)\n    priorities[fit_mask] += 0.5 * pressure[fit_mask]\n\n    # 4. Best Fit Bonus: Reward the bin that provides the absolute best fit (smallest waste).\n    diffs = bins_remain_cap - item\n    min_diff = np.min(diffs[diffs >= 0]) if np.any(diffs >= 0) else np.inf\n    best_fit_bonus = np.where(diffs == min_diff, 1.0 + 0.5 * (1 - utilization), 0)  # Adaptive bonus\n    priorities += best_fit_bonus\n\n    # 5. Empty Bin Preference (Adaptive): If the item is a significant fraction of bin size, strongly prefer an empty bin.\n    empty_bin_mask = bins_remain_cap == max_cap\n    empty_bin_threshold = 0.6 * max_cap\n    if item >= empty_bin_threshold and np.any(empty_bin_mask):\n        priorities[empty_bin_mask] += 2.0 + 1.0 * utilization  # Stronger adaptive preference\n    \n    # 6. Bin Diversity Bonus: Encourage spreading items across different bins.\n    # This penalizes using bins with similar remaining capacities if there are other options.\n    if num_bins > 1:\n        std_dev = np.std(bins_remain_cap[fit_mask])  # Standard deviation of remaining capacities\n        diversity_bonus = std_dev / max_cap # Normalize\n        priorities[fit_mask] += 0.25 * diversity_bonus # Moderate diversity bonus\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors, including utilization,\n    fragmentation avoidance, pressure, best fit, and empty bin preference, with adaptive adjustments\n    based on item size and bin characteristics. It aims to improve upon priority_v1 by dynamically\n    adjusting penalties and bonuses to better handle diverse item sizes and bin configurations,\n    and adding a bin diversity term.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    max_cap = np.max(bins_remain_cap)\n    num_bins = len(bins_remain_cap)\n\n    # 0. Hard constraint: Item must fit. Bins that can't fit get -inf priority.\n    priorities[bins_remain_cap < item] = -np.inf\n\n    fit_mask = bins_remain_cap >= item\n\n    if not np.any(fit_mask):\n        return priorities  # No bin can fit the item\n\n    # 1. Utilization Term: Favor better utilization, but scale based on item size.\n    utilization = item / max_cap\n    remaining_capacity_after_fit = bins_remain_cap - item\n    utilization_score = (1 - remaining_capacity_after_fit / max_cap) * utilization\n    priorities[fit_mask] += utilization_score[fit_mask]\n\n    # 2. Fragmentation Avoidance: Penalize bins that will result in tiny fragments.\n    tiny_fragment_threshold = 0.05 * max_cap\n    small_fragment_threshold = 0.2 * max_cap\n\n    # Adaptive penalty based on item size: Larger items impose a heavier penalty for tiny fragments\n    tiny_fragment_penalty = -5.0 - 5.0 * utilization  # Higher penalty for larger items\n    small_fragment_penalty = -1.0 - 1.0 * utilization\n    \n    tiny_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit <= tiny_fragment_threshold)\n    small_fragment_mask = (remaining_capacity_after_fit > tiny_fragment_threshold) & (remaining_capacity_after_fit <= small_fragment_threshold)\n\n    priorities[tiny_fragment_mask] += tiny_fragment_penalty\n    priorities[small_fragment_mask] += small_fragment_penalty\n\n    # 3. \"Pressure\" Term: Bins with higher remaining capacity exert more \"pressure\".  Adjust scaling dynamically.\n    pressure = bins_remain_cap / max_cap * (1 - utilization)\n    priorities[fit_mask] += 0.5 * pressure[fit_mask]\n\n    # 4. Best Fit Bonus: Reward the bin that provides the absolute best fit (smallest waste).\n    diffs = bins_remain_cap - item\n    min_diff = np.min(diffs[diffs >= 0]) if np.any(diffs >= 0) else np.inf\n    best_fit_bonus = np.where(diffs == min_diff, 1.0 + 0.5 * (1 - utilization), 0)  # Adaptive bonus\n    priorities += best_fit_bonus\n\n    # 5. Empty Bin Preference (Adaptive): If the item is a significant fraction of bin size, strongly prefer an empty bin.\n    empty_bin_mask = bins_remain_cap == max_cap\n    empty_bin_threshold = 0.6 * max_cap\n    if item >= empty_bin_threshold and np.any(empty_bin_mask):\n        priorities[empty_bin_mask] += 2.0 + 1.0 * utilization  # Stronger adaptive preference\n    \n    # 6. Bin Diversity Bonus: Encourage spreading items across different bins.\n    # This penalizes using bins with similar remaining capacities if there are other options.\n    if num_bins > 1:\n        std_dev = np.std(bins_remain_cap[fit_mask])  # Standard deviation of remaining capacities\n        diversity_bonus = std_dev / max_cap # Normalize\n        priorities[fit_mask] += 0.25 * diversity_bonus # Moderate diversity bonus\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors, now including a simulated \"pressure\"\n    analogy and adaptive adjustments for large and small items, and explicitly avoids creating extremely small\n    fragments by rejecting bins that would lead to near-zero remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    max_cap = np.max(bins_remain_cap)\n\n    # 0. Hard constraint: Item must fit.  Bins that can't fit get -inf priority.\n    priorities[bins_remain_cap < item] = -np.inf\n\n    fit_mask = bins_remain_cap >= item\n\n    if not np.any(fit_mask):\n        return priorities  # No bin can fit the item\n\n    # 1. Utilization Term:  Favor better utilization, but scale based on item size.\n    # Larger items get a bigger utilization bonus.\n    utilization = item / max_cap  # Item size relative to maximum capacity\n    remaining_capacity_after_fit = bins_remain_cap - item\n    utilization_score = (1 - remaining_capacity_after_fit / max_cap) * utilization\n    priorities[fit_mask] += utilization_score[fit_mask]\n\n    # 2. Fragmentation Avoidance:  Strongly penalize bins that will result in tiny fragments.\n    # Also, penalize moderately if it creates a slightly larger, but still small fragment.\n    tiny_fragment_threshold = 0.05 * max_cap  # Significantly smaller than before, more aggressive\n    small_fragment_threshold = 0.2 * max_cap   #Adjusted threshold\n    \n    tiny_fragment_penalty = -10.0 #Very strong penalty\n    small_fragment_penalty = -2.0\n\n    tiny_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit <= tiny_fragment_threshold)\n    small_fragment_mask = (remaining_capacity_after_fit > tiny_fragment_threshold) & (remaining_capacity_after_fit <= small_fragment_threshold)\n    \n    priorities[tiny_fragment_mask] += tiny_fragment_penalty\n    priorities[small_fragment_mask] += small_fragment_penalty\n    \n    # 3. \"Pressure\" Term:  Simulate bins as containers with \"pressure.\"  Bins with higher remaining\n    # capacity exert more \"pressure\" to accept the item, but scale down with item size to prevent overfilling.\n    pressure = bins_remain_cap / max_cap * (1 - utilization)\n    priorities[fit_mask] += 0.5 * pressure[fit_mask]\n\n    # 4. Best Fit Bonus:  Reward the bin that provides the absolute best fit (smallest waste).\n    diffs = bins_remain_cap - item\n    min_diff = np.min(diffs[diffs >= 0]) if np.any(diffs >= 0) else np.inf\n    best_fit_bonus = np.where(diffs == min_diff, 1.5, 0)\n    priorities += best_fit_bonus\n    \n    # 5. Empty Bin Preference (Adaptive): If the item is a significant fraction of bin size, strongly prefer\n    # an empty bin.  The threshold is now adaptive and more stringent.\n    empty_bin_mask = bins_remain_cap == max_cap\n    empty_bin_threshold = 0.6 * max_cap\n    if item >= empty_bin_threshold and np.any(empty_bin_mask):\n        priorities[empty_bin_mask] += 3.0 # Strong preference\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function refines the priority calculation by incorporating a refined fragmentation penalty,\n    a capacity-aware best-fit bonus, a bin-emptiness gradient, and an advanced diversity measure\n    that considers both remaining capacity and the number of items already packed.  Adaptive scaling\n    is used throughout to adjust to varying item and bin sizes.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    max_cap = np.max(bins_remain_cap)\n    num_bins = len(bins_remain_cap)\n\n    # 0. Hard constraint: Item must fit. Bins that can't fit get -inf priority.\n    priorities[bins_remain_cap < item] = -np.inf\n\n    fit_mask = bins_remain_cap >= item\n\n    if not np.any(fit_mask):\n        return priorities  # No bin can fit the item\n\n    # 1. Utilization Term: Favor better utilization, but scale based on item size.\n    utilization = item / max_cap\n    remaining_capacity_after_fit = bins_remain_cap - item\n    utilization_score = (1 - remaining_capacity_after_fit / max_cap) * utilization\n    priorities[fit_mask] += utilization_score[fit_mask]\n\n    # 2. Refined Fragmentation Avoidance: Penalize bins that will result in tiny or small fragments,\n    # with adaptive penalties based on the item's relative size compared to the bin.\n    tiny_fragment_threshold = 0.05 * max_cap\n    small_fragment_threshold = 0.2 * max_cap\n\n    # Adaptive penalty based on item size: Larger items impose a heavier penalty for tiny fragments\n    tiny_fragment_penalty = -5.0 - 7.0 * utilization  # Enhanced penalty for larger items causing tiny fragments\n    small_fragment_penalty = -1.0 - 2.0 * utilization  # Enhanced penalty for larger items causing small fragments\n\n    tiny_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit <= tiny_fragment_threshold)\n    small_fragment_mask = (remaining_capacity_after_fit > tiny_fragment_threshold) & (remaining_capacity_after_fit <= small_fragment_threshold)\n\n    priorities[tiny_fragment_mask] += tiny_fragment_penalty\n    priorities[small_fragment_mask] += small_fragment_penalty\n\n    # 3. \"Pressure\" Term: Bins with higher remaining capacity exert more \"pressure\". Adjust scaling dynamically.\n    pressure = bins_remain_cap / max_cap * (1 - utilization)\n    priorities[fit_mask] += 0.5 * pressure[fit_mask]\n\n    # 4. Capacity-Aware Best Fit Bonus: Reward the bin that provides the absolute best fit (smallest waste),\n    # with a bonus that increases as the bin's capacity increases.\n    diffs = bins_remain_cap - item\n    min_diff = np.min(diffs[diffs >= 0]) if np.any(diffs >= 0) else np.inf\n    best_fit_bonus = np.where(diffs == min_diff, (1.0 + 0.5 * (1 - utilization)) * (bins_remain_cap / max_cap), 0)  # Adaptive bonus\n    priorities += best_fit_bonus\n\n    # 5. Empty Bin Preference (Adaptive Gradient): If the item is a significant fraction of bin size, strongly prefer an empty bin.\n    # Add a gradient based on how close the bin is to empty.\n    empty_bin_mask = bins_remain_cap == max_cap\n    nearly_empty_mask = (bins_remain_cap > 0.9 * max_cap) & (bins_remain_cap < max_cap)\n    empty_bin_threshold = 0.6 * max_cap\n\n    if item >= empty_bin_threshold:\n        if np.any(empty_bin_mask):\n            priorities[empty_bin_mask] += 2.5 + 1.5 * utilization  # Stronger adaptive preference\n\n        if np.any(nearly_empty_mask):\n            priorities[nearly_empty_mask] += 1.0 + 0.5 * utilization\n\n    # 6. Advanced Bin Diversity Bonus: Encourage spreading items across different bins, considering both\n    # remaining capacity and the number of items already packed in each bin.  This encourages more balanced loading.\n    if num_bins > 1:\n        # Estimate 'fullness' based on how close to the original max_cap each bin is.\n        bin_fullness = (max_cap - bins_remain_cap) / max_cap\n        diversity_metric = np.std(bin_fullness[fit_mask])  # Std dev of fullness\n        diversity_bonus = diversity_metric  # Normalize\n        priorities[fit_mask] += 0.3 * diversity_bonus  # Moderate diversity bonus\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines utilization, fragmentation, best fit, and empty bin.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    small_number = 1e-9\n    frag_threshold_ratio = 4.0\n    frag_penalty_weight = 0.2\n    best_fit_bonus_value = 0.1\n    large_item_threshold_ratio = 0.75\n    empty_bin_bonus = 0.3\n\n    # 1. Bin Utilization\n    utilization = (item / (np.max(bins_remain_cap) + small_number))\n    remaining_percentage = (bins_remain_cap - item) / (np.max(bins_remain_cap) + small_number)\n\n    priorities[bins_remain_cap < item] = -np.inf\n    fit_mask = bins_remain_cap >= item\n    if np.any(fit_mask):\n        priorities[fit_mask] += (1 - remaining_percentage[fit_mask]) * utilization\n\n    # 2. Fragmentation\n    frag_threshold = item / frag_threshold_ratio\n    frag_penalty = np.exp(-np.abs(bins_remain_cap - item - frag_threshold) / (frag_threshold + small_number))\n    if np.any(fit_mask):\n        priorities[fit_mask] -= frag_penalty_weight * frag_penalty[fit_mask]\n\n    # 3. Best Fit\n    diffs = bins_remain_cap - item\n    min_diff = np.min(diffs[diffs >= 0]) if np.any(diffs >= 0) else np.inf\n    best_fit_bonus = np.where(diffs == min_diff, best_fit_bonus_value, 0)\n    priorities += best_fit_bonus\n\n    # 4. Empty Bin\n    empty_bin_mask = bins_remain_cap == np.max(bins_remain_cap)\n    large_item_threshold = large_item_threshold_ratio * np.max(bins_remain_cap)\n    if item > large_item_threshold and np.any(empty_bin_mask):\n        priorities[empty_bin_mask] += empty_bin_bonus\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors, focusing on\n    bin utilization and fragmentation reduction. It adaptively adjusts parameters\n    based on item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Bin Utilization Term: Favor bins that will be well-utilized after adding the item.\n    #    This encourages filling bins more completely.\n    utilization = (item / (np.max(bins_remain_cap) + 1e-9)) # Normalized item size relative to max bin size\n    remaining_percentage = (bins_remain_cap - item) / (np.max(bins_remain_cap) + 1e-9) # %age of bin remaining after packing\n\n    # Penalize bins where item doesn't fit:\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # If the item fits, then it adds priority\n    fit_mask = bins_remain_cap >= item\n    if np.any(fit_mask):\n        priorities[fit_mask] += (1 - remaining_percentage[fit_mask]) * utilization\n\n    # 2. Fragmentation Term: Discourage creating very small remaining spaces.\n    #    Bins with remaining capacity close to a small threshold are penalized.\n    frag_threshold = item / 4.0  # Adjust as needed; smaller items shouldn't create very small fragments\n    frag_penalty = np.exp(-np.abs(bins_remain_cap - item - frag_threshold) / (frag_threshold + 1e-9)) #frag threshold is deviation penalty\n\n    #Only apply penalty for bins that will contain the item:\n    priorities[fit_mask] -= 0.2 * frag_penalty[fit_mask] # Lower weight than utilization\n\n    # 3. Best Fit term - gives some extra credit if this is the best fit option:\n    diffs = bins_remain_cap - item\n    min_diff = np.min(diffs[diffs >= 0]) if np.any(diffs >= 0) else np.inf\n    best_fit_bonus = np.where(diffs == min_diff, 0.1, 0)\n    priorities += best_fit_bonus\n\n\n    # 4. Empty Bin Consideration: Prefer using empty bins if the item is relatively large.\n    empty_bin_mask = bins_remain_cap == np.max(bins_remain_cap) # Check for bins with the original capacity\n    large_item_threshold = 0.75 * np.max(bins_remain_cap)\n    if item > large_item_threshold and np.any(empty_bin_mask):\n        priorities[empty_bin_mask] += 0.3 # Prefer to put large item in empty bin\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines utilization, fragmentation, best fit, and empty bin.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    small_number = 1e-9\n    frag_threshold_ratio = 4.0\n    frag_penalty_weight = 0.2\n    best_fit_bonus_value = 0.1\n    large_item_threshold_ratio = 0.75\n    empty_bin_bonus = 0.3\n\n    # 1. Bin Utilization\n    utilization = (item / (np.max(bins_remain_cap) + small_number))\n    remaining_percentage = (bins_remain_cap - item) / (np.max(bins_remain_cap) + small_number)\n\n    priorities[bins_remain_cap < item] = -np.inf\n    fit_mask = bins_remain_cap >= item\n    if np.any(fit_mask):\n        priorities[fit_mask] += (1 - remaining_percentage[fit_mask]) * utilization\n\n    # 2. Fragmentation\n    frag_threshold = item / frag_threshold_ratio\n    frag_penalty = np.exp(-np.abs(bins_remain_cap - item - frag_threshold) / (frag_threshold + small_number))\n    if np.any(fit_mask):\n        priorities[fit_mask] -= frag_penalty_weight * frag_penalty[fit_mask]\n\n    # 3. Best Fit\n    diffs = bins_remain_cap - item\n    min_diff = np.min(diffs[diffs >= 0]) if np.any(diffs >= 0) else np.inf\n    best_fit_bonus = np.where(diffs == min_diff, best_fit_bonus_value, 0)\n    priorities += best_fit_bonus\n\n    # 4. Empty Bin\n    empty_bin_mask = bins_remain_cap == np.max(bins_remain_cap)\n    large_item_threshold = large_item_threshold_ratio * np.max(bins_remain_cap)\n    if item > large_item_threshold and np.any(empty_bin_mask):\n        priorities[empty_bin_mask] += empty_bin_bonus\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines utilization, fragmentation, best fit, and empty bin.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    small_number = 1e-9\n    frag_threshold_ratio = 4.0\n    frag_penalty_weight = 0.2\n    best_fit_bonus_value = 0.1\n    large_item_threshold_ratio = 0.75\n    empty_bin_bonus = 0.3\n\n    # 1. Bin Utilization\n    utilization = (item / (np.max(bins_remain_cap) + small_number))\n    remaining_percentage = (bins_remain_cap - item) / (np.max(bins_remain_cap) + small_number)\n\n    priorities[bins_remain_cap < item] = -np.inf\n    fit_mask = bins_remain_cap >= item\n    if np.any(fit_mask):\n        priorities[fit_mask] += (1 - remaining_percentage[fit_mask]) * utilization\n\n    # 2. Fragmentation\n    frag_threshold = item / frag_threshold_ratio\n    frag_penalty = np.exp(-np.abs(bins_remain_cap - item - frag_threshold) / (frag_threshold + small_number))\n    if np.any(fit_mask):\n        priorities[fit_mask] -= frag_penalty_weight * frag_penalty[fit_mask]\n\n    # 3. Best Fit\n    diffs = bins_remain_cap - item\n    min_diff = np.min(diffs[diffs >= 0]) if np.any(diffs >= 0) else np.inf\n    best_fit_bonus = np.where(diffs == min_diff, best_fit_bonus_value, 0)\n    priorities += best_fit_bonus\n\n    # 4. Empty Bin\n    empty_bin_mask = bins_remain_cap == np.max(bins_remain_cap)\n    large_item_threshold = large_item_threshold_ratio * np.max(bins_remain_cap)\n    if item > large_item_threshold and np.any(empty_bin_mask):\n        priorities[empty_bin_mask] += empty_bin_bonus\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors inspired by physics.\n    It considers the 'energy' required to place the item (smaller remaining capacity = higher energy),\n    a 'potential well' effect (bins with capacities slightly larger than the item are favored),\n    and a 'repulsion' effect (bins with capacities much larger than the item are discouraged).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 'Energy' term: Higher priority for bins that are almost full\n    energy = 1.0 / (bins_remain_cap + 1e-9)  # Avoid division by zero\n    priorities += energy\n\n    # 'Potential well' term: Favor bins with capacities slightly larger than the item\n    diff = bins_remain_cap - item\n    potential_well = np.exp(-(diff**2) / (2 * (item/3)**2)) #Gaussian centered at item. Larger variance when item size is bigger\n    priorities += potential_well\n\n    # 'Repulsion' term: Discourage bins with capacities much larger than the item\n    repulsion = np.exp(-bins_remain_cap / (item*5))  # Exponential decay with bin capacity. Higher decay if item is small\n    priorities -= 0.5 * repulsion # We don't want it to be the dominating factor\n\n    # Consider bins where item doesn't fit as non viable\n    priorities[bins_remain_cap < item] = -np.inf\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors inspired by physics.\n    It considers the 'energy' required to place the item (smaller remaining capacity = higher energy),\n    a 'potential well' effect (bins with capacities slightly larger than the item are favored),\n    and a 'repulsion' effect (bins with capacities much larger than the item are discouraged).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 'Energy' term: Higher priority for bins that are almost full\n    energy = 1.0 / (bins_remain_cap + 1e-9)  # Avoid division by zero\n    priorities += energy\n\n    # 'Potential well' term: Favor bins with capacities slightly larger than the item\n    diff = bins_remain_cap - item\n    potential_well = np.exp(-(diff**2) / (2 * (item/3)**2)) #Gaussian centered at item. Larger variance when item size is bigger\n    priorities += potential_well\n\n    # 'Repulsion' term: Discourage bins with capacities much larger than the item\n    repulsion = np.exp(-bins_remain_cap / (item*5))  # Exponential decay with bin capacity. Higher decay if item is small\n    priorities -= 0.5 * repulsion # We don't want it to be the dominating factor\n\n    # Consider bins where item doesn't fit as non viable\n    priorities[bins_remain_cap < item] = -np.inf\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors inspired by physics.\n    It considers the 'energy' required to place the item (smaller remaining capacity = higher energy),\n    a 'potential well' effect (bins with capacities slightly larger than the item are favored),\n    and a 'repulsion' effect (bins with capacities much larger than the item are discouraged).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 'Energy' term: Higher priority for bins that are almost full\n    energy = 1.0 / (bins_remain_cap + 1e-9)  # Avoid division by zero\n    priorities += energy\n\n    # 'Potential well' term: Favor bins with capacities slightly larger than the item\n    diff = bins_remain_cap - item\n    potential_well = np.exp(-(diff**2) / (2 * (item/3)**2)) #Gaussian centered at item. Larger variance when item size is bigger\n    priorities += potential_well\n\n    # 'Repulsion' term: Discourage bins with capacities much larger than the item\n    repulsion = np.exp(-bins_remain_cap / (item*5))  # Exponential decay with bin capacity. Higher decay if item is small\n    priorities -= 0.5 * repulsion # We don't want it to be the dominating factor\n\n    # Consider bins where item doesn't fit as non viable\n    priorities[bins_remain_cap < item] = -np.inf\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors inspired by physics.\n    It considers the 'energy' required to place the item (smaller remaining capacity = higher energy),\n    a 'potential well' effect (bins with capacities slightly larger than the item are favored),\n    and a 'repulsion' effect (bins with capacities much larger than the item are discouraged).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 'Energy' term: Higher priority for bins that are almost full\n    energy = 1.0 / (bins_remain_cap + 1e-9)  # Avoid division by zero\n    priorities += energy\n\n    # 'Potential well' term: Favor bins with capacities slightly larger than the item\n    diff = bins_remain_cap - item\n    potential_well = np.exp(-(diff**2) / (2 * (item/3)**2)) #Gaussian centered at item. Larger variance when item size is bigger\n    priorities += potential_well\n\n    # 'Repulsion' term: Discourage bins with capacities much larger than the item\n    repulsion = np.exp(-bins_remain_cap / (item*5))  # Exponential decay with bin capacity. Higher decay if item is small\n    priorities -= 0.5 * repulsion # We don't want it to be the dominating factor\n\n    # Consider bins where item doesn't fit as non viable\n    priorities[bins_remain_cap < item] = -np.inf\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines capacity & wasted space with physics-inspired scaling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        # Hybrid approach: capacity + inverse waste\n        priorities[valid_bins] = bins_remain_cap[valid_bins] / (1 + waste)\n    else:\n        priorities = np.full_like(bins_remain_cap, -np.inf)\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines capacity & wasted space with physics-inspired scaling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        # Hybrid approach: capacity + inverse waste\n        priorities[valid_bins] = bins_remain_cap[valid_bins] / (1 + waste)\n    else:\n        priorities = np.full_like(bins_remain_cap, -np.inf)\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines capacity & wasted space with physics-inspired scaling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        # Hybrid approach: capacity + inverse waste\n        priorities[valid_bins] = bins_remain_cap[valid_bins] / (1 + waste)\n    else:\n        priorities = np.full_like(bins_remain_cap, -np.inf)\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, *,\n                 tiny_fragment_threshold_fraction: float = 0.0965737114130352,\n                 small_fragment_threshold_fraction: float = 0.2976749170583864,\n                 tiny_fragment_penalty: float = -19.035781294528093,\n                 small_fragment_penalty: float = -2.9898952738151054,\n                 pressure_weight: float = 0.5918140088284347,\n                 best_fit_bonus_value: float = 1.3079400824759972,\n                 empty_bin_threshold_fraction: float = 0.46099185424258277,\n                 empty_bin_preference: float = 3.136501304787648) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors, now including a simulated \"pressure\"\n    analogy and adaptive adjustments for large and small items, and explicitly avoids creating extremely small\n    fragments by rejecting bins that would lead to near-zero remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        tiny_fragment_threshold_fraction: Fraction of max_cap to define tiny fragments.\n        small_fragment_threshold_fraction: Fraction of max_cap to define small fragments.\n        tiny_fragment_penalty: Penalty for creating a tiny fragment.\n        small_fragment_penalty: Penalty for creating a small fragment.\n        pressure_weight: Weight of the pressure term.\n        best_fit_bonus_value: Bonus for the best fit bin.\n        empty_bin_threshold_fraction: Fraction of max_cap to consider an item large for empty bin preference.\n        empty_bin_preference: Preference for empty bins when item is large.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    max_cap = np.max(bins_remain_cap)\n\n    # 0. Hard constraint: Item must fit.  Bins that can't fit get -inf priority.\n    priorities[bins_remain_cap < item] = -np.inf\n\n    fit_mask = bins_remain_cap >= item\n\n    if not np.any(fit_mask):\n        return priorities  # No bin can fit the item\n\n[Heuristics 18th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, *,\n                 tiny_fragment_threshold_fraction: float = 0.0965737114130352,\n                 small_fragment_threshold_fraction: float = 0.2976749170583864,\n                 tiny_fragment_penalty: float = -19.035781294528093,\n                 small_fragment_penalty: float = -2.9898952738151054,\n                 pressure_weight: float = 0.5918140088284347,\n                 best_fit_bonus_value: float = 1.3079400824759972,\n                 empty_bin_threshold_fraction: float = 0.46099185424258277,\n                 empty_bin_preference: float = 3.136501304787648) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors, now including a simulated \"pressure\"\n    analogy and adaptive adjustments for large and small items, and explicitly avoids creating extremely small\n    fragments by rejecting bins that would lead to near-zero remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        tiny_fragment_threshold_fraction: Fraction of max_cap to define tiny fragments.\n        small_fragment_threshold_fraction: Fraction of max_cap to define small fragments.\n        tiny_fragment_penalty: Penalty for creating a tiny fragment.\n        small_fragment_penalty: Penalty for creating a small fragment.\n        pressure_weight: Weight of the pressure term.\n        best_fit_bonus_value: Bonus for the best fit bin.\n        empty_bin_threshold_fraction: Fraction of max_cap to consider an item large for empty bin preference.\n        empty_bin_preference: Preference for empty bins when item is large.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    max_cap = np.max(bins_remain_cap)\n\n    # 0. Hard constraint: Item must fit.  Bins that can't fit get -inf priority.\n    priorities[bins_remain_cap < item] = -np.inf\n\n    fit_mask = bins_remain_cap >= item\n\n    if not np.any(fit_mask):\n        return priorities  # No bin can fit the item\n\n[Heuristics 19th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}