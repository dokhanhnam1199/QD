```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    This function prioritizes bins based on a combination of dynamically weighted factors,
    including utilization, fragmentation avoidance, pressure, best fit, empty bin preference,
    bin diversity, and a novel "balance" term. Weights adapt based on item size, bin
    characteristics, and overall packing state.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    max_cap = np.max(bins_remain_cap)
    num_bins = len(bins_remain_cap)

    # 0. Hard constraint: Item must fit. Bins that can't fit get -inf priority.
    priorities[bins_remain_cap < item] = -np.inf
    fit_mask = bins_remain_cap >= item

    if not np.any(fit_mask):
        return priorities  # No bin can fit the item

    # Precompute some values used repeatedly
    remaining_capacity_after_fit = bins_remain_cap - item
    utilization = item / max_cap
    
    # 1. Utilization Term: Favor better utilization, scaled by item size.
    utilization_score = (1 - remaining_capacity_after_fit / max_cap) * utilization
    utilization_weight = 1.0 + 0.5 * utilization  # Increase weight for larger items
    priorities[fit_mask] += utilization_score[fit_mask] * utilization_weight

    # 2. Fragmentation Avoidance: Penalize bins that lead to tiny or small fragments.
    tiny_fragment_threshold = 0.05 * max_cap
    small_fragment_threshold = 0.2 * max_cap

    # Adaptive penalty based on item size and bin fill level
    tiny_fragment_penalty = -5.0 - 5.0 * utilization * (1 + (bins_remain_cap / max_cap) -1 )
    small_fragment_penalty = -1.0 - 1.0 * utilization * (1 + (bins_remain_cap / max_cap) - 1)

    tiny_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit <= tiny_fragment_threshold)
    small_fragment_mask = (remaining_capacity_after_fit > tiny_fragment_threshold) & (remaining_capacity_after_fit <= small_fragment_threshold)

    priorities[tiny_fragment_mask] += tiny_fragment_penalty
    priorities[small_fragment_mask] += small_fragment_penalty
    
    # 3. "Pressure" Term: Bins with higher remaining capacity exert more "pressure".
    pressure = bins_remain_cap / max_cap * (1 - utilization)
    pressure_weight = 0.5 + 0.25 * utilization # Adaptive scaling
    priorities[fit_mask] += pressure[fit_mask] * pressure_weight

    # 4. Best Fit Bonus: Reward the bin that provides the absolute best fit.
    diffs = bins_remain_cap - item
    min_diff = np.min(diffs[diffs >= 0]) if np.any(diffs >= 0) else np.inf
    best_fit_bonus = np.where(diffs == min_diff, 1.0 + 0.5 * (1 - utilization), 0)
    priorities += best_fit_bonus

    # 5. Empty Bin Preference (Adaptive): Strongly prefer empty bins for large items.
    empty_bin_mask = bins_remain_cap == max_cap
    empty_bin_threshold = 0.6 * max_cap
    if item >= empty_bin_threshold and np.any(empty_bin_mask):
        empty_bin_bonus = 2.0 + 1.0 * utilization
        priorities[empty_bin_mask] += empty_bin_bonus

    # 6. Bin Diversity Bonus: Encourage spreading items across bins with varying fill levels.
    if num_bins > 1:
        std_dev = np.std(bins_remain_cap[fit_mask])
        diversity_bonus = std_dev / max_cap
        diversity_weight = 0.25 + 0.1 * utilization
        priorities[fit_mask] += diversity_bonus * diversity_weight

    # 7. Balance Term: Encourage filling bins to a similar *relative* level.
    #    Penalize bins that are significantly emptier than the average filled bin.
    filled_bins = bins_remain_cap[bins_remain_cap < max_cap]
    if len(filled_bins) > 0:  # Only apply if there are partially filled bins
        average_filled_capacity = np.mean(filled_bins)
        balance_diff = bins_remain_cap - average_filled_capacity
        
        #Adaptive Weighting: Heavier Penalty if the item is large
        balance_penalty = -0.1 * np.maximum(0, balance_diff / max_cap) * (1 + utilization)
        priorities[fit_mask] += balance_penalty[fit_mask]
        
    return priorities
```
