```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Returns priority with which we want to add item to each bin.

    This version incorporates a more sophisticated approach by focusing on:
    1. Relative fit: How well does the item "fit" relative to the bin's capacity?
    2. Waste Ratio: The ratio of the resulting waste to the item size.
    3. Adaptive Fragmentation Penalty: Fragmentation is penalized more heavily when the item is small.
    4. Bin State Awareness: Prioritizes bins based on their "state" (nearly full, nearly empty, etc.).

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    max_cap = np.max(bins_remain_cap)
    num_bins = len(bins_remain_cap)

    # 0. Hard constraint: Item must fit.
    fit_mask = bins_remain_cap >= item
    priorities[~fit_mask] = -np.inf

    if not np.any(fit_mask):
        return priorities

    # Calculate remaining capacity after fit for all bins
    remaining_capacity_after_fit = bins_remain_cap - item

    # 1. Relative Fit Term:
    relative_fit = item / bins_remain_cap
    priorities[fit_mask] += 0.5 * relative_fit[fit_mask]  # Encourage better relative fit.

    # 2. Waste Ratio: Penalize bins where the resulting waste is a large fraction of the item size
    waste = np.clip(remaining_capacity_after_fit, a_min=0, a_max=None) # handles cases where item > bin size (post filtering)
    waste_ratio = waste / item
    waste_penalty = -2.0 * waste_ratio  # Higher waste ratio, higher penalty.
    priorities[fit_mask] += waste_penalty[fit_mask]
    
    # 3. Adaptive Fragmentation Penalty:
    tiny_fragment_threshold = 0.05 * max_cap
    small_fragment_threshold = 0.2 * max_cap

    # Fragmentation penalty is more severe if the item itself is small relative to the bin size.
    item_size_ratio = item / max_cap

    tiny_fragment_penalty = -5.0 * (1 + 2 * (1 - item_size_ratio))
    small_fragment_penalty = -1.0 * (1 + (1 - item_size_ratio))

    tiny_fragment_mask = (remaining_capacity_after_fit >= 0) & (remaining_capacity_after_fit <= tiny_fragment_threshold)
    small_fragment_mask = (remaining_capacity_after_fit > tiny_fragment_threshold) & (remaining_capacity_after_fit <= small_fragment_threshold)

    priorities[tiny_fragment_mask] += tiny_fragment_penalty
    priorities[small_fragment_mask] += small_fragment_penalty

    # 4. Bin State Awareness:
    nearly_full_threshold = 0.1 * max_cap
    nearly_empty_threshold = 0.9 * max_cap

    nearly_full_mask = (bins_remain_cap >= item) & (bins_remain_cap <= nearly_full_threshold + item) # ensure item fits
    nearly_empty_mask = (bins_remain_cap >= item) & (bins_remain_cap >= nearly_empty_threshold)
    
    # Prefer nearly full bins to consolidate, but only if it doesn't create tiny fragments.
    priorities[nearly_full_mask & ~tiny_fragment_mask] += 1.5

    # Strongly prefer nearly empty bins if item is large.
    if item > 0.7 * max_cap:
        priorities[nearly_empty_mask] += 3.0

    # 5. Best Fit Adjustment (with tolerance):
    diffs = bins_remain_cap - item
    min_diff = np.min(diffs[diffs >= 0]) if np.any(diffs >= 0) else np.inf
    best_fit_tolerance = 0.02 * max_cap  # Tolerate slightly worse fits for better overall packing.

    best_fit_mask = (diffs >= 0) & (diffs <= min_diff + best_fit_tolerance)
    priorities[best_fit_mask] += 0.75

    # 6. Diversity Bonus (adjusted)
    if num_bins > 1:
        std_dev = np.std(bins_remain_cap[fit_mask])
        diversity_bonus = std_dev / max_cap
        priorities[fit_mask] += 0.3 * diversity_bonus

    return priorities
```
