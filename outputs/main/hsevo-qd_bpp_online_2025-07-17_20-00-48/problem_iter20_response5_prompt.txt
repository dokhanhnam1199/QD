{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors, now including a simulated \"pressure\"\n    analogy and adaptive adjustments for large and small items, and explicitly avoids creating extremely small\n    fragments by rejecting bins that would lead to near-zero remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    max_cap = np.max(bins_remain_cap)\n\n    # 0. Hard constraint: Item must fit.  Bins that can't fit get -inf priority.\n    priorities[bins_remain_cap < item] = -np.inf\n\n    fit_mask = bins_remain_cap >= item\n\n    if not np.any(fit_mask):\n        return priorities  # No bin can fit the item\n\n    # 1. Utilization Term:  Favor better utilization, but scale based on item size.\n    # Larger items get a bigger utilization bonus.\n    utilization = item / max_cap  # Item size relative to maximum capacity\n    remaining_capacity_after_fit = bins_remain_cap - item\n    utilization_score = (1 - remaining_capacity_after_fit / max_cap) * utilization\n    priorities[fit_mask] += utilization_score[fit_mask]\n\n    # 2. Fragmentation Avoidance:  Strongly penalize bins that will result in tiny fragments.\n    # Also, penalize moderately if it creates a slightly larger, but still small fragment.\n    tiny_fragment_threshold = 0.05 * max_cap  # Significantly smaller than before, more aggressive\n    small_fragment_threshold = 0.2 * max_cap   #Adjusted threshold\n    \n    tiny_fragment_penalty = -10.0 #Very strong penalty\n    small_fragment_penalty = -2.0\n\n    tiny_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit <= tiny_fragment_threshold)\n    small_fragment_mask = (remaining_capacity_after_fit > tiny_fragment_threshold) & (remaining_capacity_after_fit <= small_fragment_threshold)\n    \n    priorities[tiny_fragment_mask] += tiny_fragment_penalty\n    priorities[small_fragment_mask] += small_fragment_penalty\n    \n    # 3. \"Pressure\" Term:  Simulate bins as containers with \"pressure.\"  Bins with higher remaining\n    # capacity exert more \"pressure\" to accept the item, but scale down with item size to prevent overfilling.\n    pressure = bins_remain_cap / max_cap * (1 - utilization)\n    priorities[fit_mask] += 0.5 * pressure[fit_mask]\n\n    # 4. Best Fit Bonus:  Reward the bin that provides the absolute best fit (smallest waste).\n    diffs = bins_remain_cap - item\n    min_diff = np.min(diffs[diffs >= 0]) if np.any(diffs >= 0) else np.inf\n    best_fit_bonus = np.where(diffs == min_diff, 1.5, 0)\n    priorities += best_fit_bonus\n    \n    # 5. Empty Bin Preference (Adaptive): If the item is a significant fraction of bin size, strongly prefer\n    # an empty bin.  The threshold is now adaptive and more stringent.\n    empty_bin_mask = bins_remain_cap == max_cap\n    empty_bin_threshold = 0.6 * max_cap\n    if item >= empty_bin_threshold and np.any(empty_bin_mask):\n        priorities[empty_bin_mask] += 3.0 # Strong preference\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors, including utilization,\n    fragmentation avoidance, pressure, best fit, and empty bin preference, with adaptive adjustments\n    based on item size and bin characteristics. It aims to improve upon priority_v1 by dynamically\n    adjusting penalties and bonuses to better handle diverse item sizes and bin configurations,\n    and adding a bin diversity term. It also incorporates a level-based bin selection mechanism.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    max_cap = np.max(bins_remain_cap)\n    num_bins = len(bins_remain_cap)\n\n    # 0. Hard constraint: Item must fit. Bins that can't fit get -inf priority.\n    priorities[bins_remain_cap < item] = -np.inf\n\n    fit_mask = bins_remain_cap >= item\n\n    if not np.any(fit_mask):\n        return priorities  # No bin can fit the item\n\n    # --- Level-Based Bin Selection ---\n    # Divide bins into levels based on remaining capacity.\n    level1_threshold = 0.25 * max_cap  # Lowest 25%\n    level2_threshold = 0.50 * max_cap  # 25% to 50%\n    level3_threshold = 0.75 * max_cap  # 50% to 75%\n\n    level1_mask = (bins_remain_cap >= item) & (bins_remain_cap <= level1_threshold)\n    level2_mask = (bins_remain_cap > level1_threshold) & (bins_remain_cap <= level2_threshold)\n    level3_mask = (bins_remain_cap > level2_threshold) & (bins_remain_cap <= level3_threshold)\n    level4_mask = (bins_remain_cap > level3_threshold)\n\n    # Adjust priorities based on levels: Favor levels that provide a tighter fit.\n    level_bonus = np.zeros_like(bins_remain_cap, dtype=float)\n    level_bonus[level1_mask] += 0.5\n    level_bonus[level2_mask] += 0.3\n    level_bonus[level3_mask] += 0.1\n    priorities += level_bonus\n    # --- End Level-Based Bin Selection ---\n\n    # 1. Utilization Term: Favor better utilization, but scale based on item size.\n    utilization = item / max_cap\n    remaining_capacity_after_fit = bins_remain_cap - item\n    utilization_score = (1 - remaining_capacity_after_fit / max_cap) * utilization\n    priorities[fit_mask] += utilization_score[fit_mask]\n\n    # 2. Fragmentation Avoidance: Penalize bins that will result in tiny fragments.\n    tiny_fragment_threshold = 0.05 * max_cap\n    small_fragment_threshold = 0.2 * max_cap\n\n    # Adaptive penalty based on item size: Larger items impose a heavier penalty for tiny fragments\n    tiny_fragment_penalty = -5.0 - 5.0 * utilization  # Higher penalty for larger items\n    small_fragment_penalty = -1.0 - 1.0 * utilization\n    \n    tiny_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit <= tiny_fragment_threshold)\n    small_fragment_mask = (remaining_capacity_after_fit > tiny_fragment_threshold) & (remaining_capacity_after_fit <= small_fragment_threshold)\n\n    priorities[tiny_fragment_mask] += tiny_fragment_penalty\n    priorities[small_fragment_mask] += small_fragment_penalty\n\n    # 3. \"Pressure\" Term: Bins with higher remaining capacity exert more \"pressure\".  Adjust scaling dynamically.\n    pressure = bins_remain_cap / max_cap * (1 - utilization)\n    priorities[fit_mask] += 0.5 * pressure[fit_mask]\n\n    # 4. Best Fit Bonus: Reward the bin that provides the absolute best fit (smallest waste).\n    diffs = bins_remain_cap - item\n    min_diff = np.min(diffs[diffs >= 0]) if np.any(diffs >= 0) else np.inf\n    best_fit_bonus = np.where(diffs == min_diff, 1.0 + 0.5 * (1 - utilization), 0)  # Adaptive bonus\n    priorities += best_fit_bonus\n\n    # 5. Empty Bin Preference (Adaptive): If the item is a significant fraction of bin size, strongly prefer an empty bin.\n    empty_bin_mask = bins_remain_cap == max_cap\n    empty_bin_threshold = 0.6 * max_cap\n    if item >= empty_bin_threshold and np.any(empty_bin_mask):\n        priorities[empty_bin_mask] += 2.0 + 1.0 * utilization  # Stronger adaptive preference\n    \n    # 6. Bin Diversity Bonus: Encourage spreading items across different bins.\n    # This penalizes using bins with similar remaining capacities if there are other options.\n    if num_bins > 1:\n        std_dev = np.std(bins_remain_cap[fit_mask])  # Standard deviation of remaining capacities\n        diversity_bonus = std_dev / max_cap # Normalize\n        priorities[fit_mask] += 0.25 * diversity_bonus # Moderate diversity bonus\n\n    # 7. Item Size Awareness: Adjust bonus/penalty depending on item size.\n    if item > 0.7 * max_cap:  # Large Item\n        priorities[fit_mask] -= 0.2  # Slight penalty to discourage filling almost completely\n    elif item < 0.3 * max_cap: # Small Item\n        priorities[fit_mask] += 0.1 # Encourage packing smaller items together\n    \n    return priorities\n\n### Analyze & experience\n- *   Comparing (1st) vs (20th), we see a significant difference in complexity and the number of factors considered. The 1st heuristic combines utilization, fragmentation, pressure, best fit, and diversity, while the 20th uses a simple logarithmic ratio.\n*   Comparing (2nd best) vs (second worst), we observe that heuristic 2 focuses on utilization, fragmentation, pressure, best fit and diversity. Heuristic 19 only checks item fit, then returns.\n*   Comparing (1st) vs (2nd), we see no difference, which means they are the same.\n*   Comparing (3rd) vs (4th), we see no difference, which means they are the same.\n*   Comparing (second worst) vs (worst), we see that heuristic 19 only checks item fit, then returns. Heuristic 20 computes priorities based on the log of ratios, which at least considers relative sizes, even if simply.\n*   Comparing (8th) vs (9th), heuristic 8 considers bin diversity while heuristic 9 doesn't.\n*   Comparing (10th) vs (11th), we see no difference, which means they are the same.\n* Comparing (12th) vs (13th), we see no difference, which means they are the same.\n* Comparing (14th) vs (15th), we see no difference, which means they are the same.\n* Comparing (16th) vs (17th), (18th), (19th), we see they are nearly the same.\n*   Overall: The better heuristics incorporate more factors, including utilization, fragmentation avoidance, pressure, best fit, and diversity. They also use adaptive adjustments based on item size and bin characteristics. Simpler heuristics relying on basic ratios or single factors tend to perform worse. Adding more parameters without a clear strategy doesn't necessarily improve performance.\n- \nOkay, I'm ready to earn that tip! Let's redefine \"Current Self-Reflection\" for better heuristic design:\n\n*   **Keywords:** Multi-faceted, Adaptive, Validation, Balance, Context-aware.\n\n*   **Advice:** Focus on *interactions* between factors (utilization, fragmentation, item characteristics). Build heuristics that adapt to these interactions, not just individual factors. Design with testability and parameter tuning in mind *from the start*.\n\n*   **Avoid:** Adding complexity without demonstrable benefit. Rigid, pre-set weights. Over-reliance on any single strategy (best-fit only, for example). Premature optimization.\n\n*   **Explanation:** Effective heuristics consider the problem's *context* and adapt dynamically. Think about feedback loops: how does one factor affect others as the packing progresses? Rigorous testing and tuning are non-negotiable to prevent unintended consequences.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}