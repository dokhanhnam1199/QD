[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Give negative priority to bins that can't fit the item\n    priorities[bins_remain_cap < item] = -np.inf\n\n    # Calculate waste if item is added to each bin\n    waste = bins_remain_cap - item\n    waste[waste < 0] = np.inf  # Mark bins that can't fit as infinite waste\n\n    # Prioritize bins with least waste (First Fit Decreasing heuristic)\n    priorities = -waste\n    \n    # Add a small bonus to bins that are almost full after packing\n    almost_full_threshold = 0.1  # e.g., bins should be at least 90% full\n    almost_full_mask = (item / (bins_remain_cap - waste)) > (1 - almost_full_threshold)\n    priorities[almost_full_mask] += 1\n\n    # Slightly penalize very empty bins (to encourage filling existing ones)\n    empty_threshold = 0.5  # e.g., bins should have at most 50% capacity remaining before packing\n    empty_mask = bins_remain_cap > empty_threshold\n    priorities[empty_mask] -= 0.1\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 16, in priority_v2\n    Array of same size as bins_remain_cap with priority score of each bin.\nOverflowError: cannot convert float infinity to integer\n8\n1\n74.23092131656186\n72.08234061130545\n97\n"
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors inspired by physics.\n    It considers the 'energy' required to place the item (smaller remaining capacity = higher energy),\n    a 'potential well' effect (bins with capacities slightly larger than the item are favored),\n    and a 'repulsion' effect (bins with capacities much larger than the item are discouraged).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 'Energy' term: Higher priority for bins that are almost full\n    energy = 1.0 / (bins_remain_cap + 1e-9)  # Avoid division by zero\n    priorities += energy\n\n    # 'Potential well' term: Favor bins with capacities slightly larger than the item\n    diff = bins_remain_cap - item\n    potential_well = np.exp(-(diff**2) / (2 * (item/3)**2)) #Gaussian centered at item. Larger variance when item size is bigger\n    priorities += potential_well\n\n    # 'Repulsion' term: Discourage bins with capacities much larger than the item\n    repulsion = np.exp(-bins_remain_cap / (item*5))  # Exponential decay with bin capacity. Higher decay if item is small\n    priorities -= 0.5 * repulsion # We don't want it to be the dominating factor\n\n    # Consider bins where item doesn't fit as non viable\n    priorities[bins_remain_cap < item] = -np.inf\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 3.9190267251695206,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response2.txt_stdout.txt",
    "code_path": "problem_iter1_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by my laws of motion and gravity. The \"force\" of attraction\n    between the item and the bin is proportional to the product of their\n    \"masses\" (related to sizes/capacity) and inversely proportional to the\n    \"distance\" (difference in remaining capacity and item size, scaled).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Ensure positive remaining capacity to avoid division by zero.\n    safe_bins_remain_cap = np.maximum(bins_remain_cap, 1e-9)\n\n    # Potential bins where the item fits. Give others a low negative priority.\n    fit_mask = safe_bins_remain_cap >= item\n    priorities = np.full_like(safe_bins_remain_cap, -1e9)\n    priorities[~fit_mask] = -np.inf # should never choose bins with item > capacity\n\n    # Define masses: item size as mass_item, remaining capacity as mass_bin.\n    mass_item = item\n    mass_bin = safe_bins_remain_cap\n\n    # Define distance: difference between remaining capacity and item size, plus small number to avoid inf\n    distance = np.abs(safe_bins_remain_cap - item) + 1e-9\n\n    # Calculate \"gravitational force\" (priority):  G * (mass_item * mass_bin) / distance^2\n    # We can drop G because we are only interested in relative priorities.\n    priorities[fit_mask] = (mass_item * mass_bin[fit_mask]) / (distance[fit_mask]**2)\n\n    # Add small bonus for bins that are nearly full (packing efficiency) but make sure it won't override invalid bins.\n    nearly_full_bonus = np.zeros_like(priorities)\n    nearly_full_mask = (safe_bins_remain_cap - item) < (0.1 * safe_bins_remain_cap)\n    nearly_full_bonus[nearly_full_mask & fit_mask] = 10\n\n    priorities += nearly_full_bonus\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response3.txt_stdout.txt",
    "code_path": "problem_iter1_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # First priority: Bins that can fit the item\n    can_fit = bins_remain_cap >= item\n    priorities[can_fit] += 1  # Give these bins a baseline priority\n\n    # Second priority: Fill rate (how much of the bin will be used) - maximize it within feasible bins\n    fill_rate = item / bins_remain_cap\n    fill_rate[~can_fit] = -1 # set fill_rate to -1 for bins that don't fit, so that they are ignored in next step.\n\n    priorities += fill_rate\n\n    # Third priority: Minimize wasted space. Add small bonus if item perfectly fits.\n    perfect_fit = bins_remain_cap == item\n    priorities[perfect_fit] += 2\n\n    # Fourth priority: prefer partially filled bins (minimize number of bins used)\n    partially_filled = (bins_remain_cap > 0) & (bins_remain_cap < 1) # assuming binsize of 1, could be generalized. But, let's not overcomplicate it.\n    priorities[partially_filled] += 0.5\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 23, in priority_v2\n    priorities[valid_bins] = space_utilization # * (1+np.exp(-remaining_after_fit*10)) # amplify reward when almost perfectly packed\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n8\n1\n74.23092131656186\n72.08234061130545\n97\n"
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        # 1. Fill the almost full bins first. High reward for bins that fit the item tightly.\n        # 2. Avoid fragmentation by prioritizing bins that use space most efficiently.\n\n        remaining_after_fit = bins_remain_cap[valid_bins] - item\n        space_utilization = item / bins_remain_cap[valid_bins]  # item size / bin size\n        # prioritize bins which space utilization is close to 1.\n        priorities[valid_bins] = space_utilization # * (1+np.exp(-remaining_after_fit*10)) # amplify reward when almost perfectly packed\n\n        # Avoid creating very small gaps by penalizing creating very small gaps\n        very_small_gap = remaining_after_fit < 0.1\n        priorities[valid_bins][very_small_gap] = -1\n\n    else:\n        # No bin can accommodate the item, assign very low priority\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response5.txt_stdout.txt",
    "code_path": "problem_iter1_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by the celestial dance, where larger bodies exert a stronger gravitational pull,\n    we prioritize bins whose remaining capacity is closest to the item size. This aims to minimize wasted space.\n    Furthermore, to encourage exploration and avoid prematurely filling bins, a slight stochastic element is added,\n    mirroring the imperfect predictability of planetary orbits. Bins with sufficient capacity will\n    have increased probability.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Calculate the difference between bin capacity and item size. Smaller difference is better\n    diff = np.abs(bins_remain_cap - item)\n    # Introduce small value to avoid division by zero.\n    epsilon = 1e-6\n    # Transform into a priority score (higher is better), with emphasis on sufficient capacity.\n    priorities = np.where(bins_remain_cap >= item, 1 / (diff + epsilon), -np.inf)\n    # Add a capacity-based bias, which favores bins with more capacity, avoiding premature fill.\n    priorities = priorities + 0.1*bins_remain_cap\n\n    # Adding small degree of exploration with a random value to explore new bins\n    random_noise = np.random.rand(len(bins_remain_cap)) * 0.01\n    priorities = priorities + random_noise\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 86.58755484643,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response6.txt_stdout.txt",
    "code_path": "problem_iter1_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that can fit the item snugly,\n    while also discouraging near-empty bins and overflow.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Filter out bins that cannot fit the item at all.\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        #No valid bins available. return smallest possible priority.\n        return priorities - np.inf\n\n    # 2. Calculate remaining space after placing the item.\n    remaining_space = bins_remain_cap - item\n\n    # 3. Give higher priority to bins where the remaining space is small\n    # (i.e., a tighter fit), but not too small.\n\n    fit_score = np.exp(-np.abs(remaining_space / item)) #Smaller remaining space => larger fit_score\n    fit_score[remaining_space < 0] = -np.inf # Disqualify overflow cases\n\n    priorities = fit_score\n\n    # 4. Penalize bins that are nearly empty relative to item size.\n    empty_penalty = np.exp(-bins_remain_cap / item)\n    priorities -= empty_penalty\n\n    #Ensure that invalid bins have the smallest possible priority\n    priorities[~valid_bins] = -np.inf\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that are \"just right\" - not too small, not too big.\n    It introduces a penalty for bins that are too close in size to the item, and for those\n    that have vast unused capacity after packing.  A quantum fluctuation inspired factor\n    is also introduced for randomness.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, cap in enumerate(bins_remain_cap):\n        if cap < item:\n            priorities[i] = -np.inf  # Cannot fit\n        else:\n            # Basic fit score (higher is better if it fits)\n            fit_score = cap - item\n\n            # \"Just right\" heuristic - penalize close fit and too much space\n            # The penalty is quadratic to incentivize central values\n            close_fit_penalty = np.exp(-((cap - item) / item)**2)\n            waste_penalty = np.exp(-((cap - item) / (bins_remain_cap.max() + 1e-9))**2) #normalize the scale\n\n            # Add small random 'quantum' fluctuation. This should nudge the system out of local minima.\n            quantum_fluctuation = np.random.normal(0, 0.01)  #mean, standard deviation\n\n            priorities[i] = fit_score - 0.5*close_fit_penalty-0.5*waste_penalty+quantum_fluctuation\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997283000084 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response8.txt_stdout.txt",
    "code_path": "problem_iter1_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that can fit the item but are not too much larger than the item.\n    It uses a combination of remaining capacity and \"waste\" calculation to achieve this.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Assign very low priority if the item doesn't fit\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    # Calculate remaining capacity after adding the item\n    remaining_after_add = bins_remain_cap - item\n    \n    # Calculate waste (remaining capacity) for feasible bins\n    waste = remaining_after_add\n    waste[infeasible_mask] = np.inf  # Ensure infeasible bins have infinite waste.\n    \n    # Priority score is calculated as a combination of\n    # 1. Higher priority for bins with enough space\n    # 2. Lower priority for bins with a lot of wasted space after adding the item\n    # We use a modified logarithmic function to scale the priority inversely proportional to waste. \n    #  and some scaling factor alpha to make the remaining capacity (bins_remain_cap) more influential.\n    alpha = 0.5 # Adjust alpha based on testing - relative importance of remain capacity.\n\n    feasible_mask = ~infeasible_mask\n\n    priorities[feasible_mask] = alpha * bins_remain_cap[feasible_mask] - np.log(1 + waste[feasible_mask])\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response9.txt_stdout.txt",
    "code_path": "problem_iter1_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version prioritizes bins that can accommodate the item with minimal wasted space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Iterate through each bin's remaining capacity\n    for i, remaining_capacity in enumerate(bins_remain_cap):\n        # If the item fits in the bin\n        if remaining_capacity >= item:\n            # Calculate the wasted space\n            wasted_space = remaining_capacity - item\n\n            # A lower wasted space is more desirable, so we use its inverse\n            # Plus a small amount to avoid the divide by zero problems.\n\n            priorities[i] = 1.0 / (wasted_space + 0.0001)\n\n        else:\n            # Item does not fit, assign a very low priority.  Setting to a large negative number ensures that\n            # only bins that fit the item will be considered.  Zero might allow bins to be chosen at random\n            # when there is no good place for them\n\n            priorities[i] = -1000  # or np.NINF\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Calculate remaining capacity after adding the item\n    remaining_cap_after_add = bins_remain_cap - item\n    \n    # Give a very low priority to bins that can't fit the item\n    priorities[remaining_cap_after_add < 0] = -np.inf\n    \n    # Calculate waste if the item is placed in the bin\n    waste = bins_remain_cap - item\n\n    # Prioritize bins with less waste but not completely full\n    priorities[remaining_cap_after_add >= 0] = 1 / (waste[remaining_cap_after_add >= 0] + 1e-6)  # Avoid division by zero\n\n    #Heuristic to use the bin with space nearest to the item.\n    #priorities = bins_remain_cap - item\n    #priorities[priorities < 0] = -np.inf #If it does not fit, put negative infinity\n\n    return priorities",
    "response_id": 10,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 19, in priority_v2\n    sufficient_space = bins_remain_cap >= item\nOverflowError: cannot convert float infinity to integer\n8\n1\n74.23092131656186\n72.08234061130545\n97\n"
  },
  {
    "stdout_filepath": "problem_iter1_response11.txt_stdout.txt",
    "code_path": "problem_iter1_code11.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Initialize priorities with a base value (e.g., all bins are equally likely at first)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1.  Encourage filling bins that have sufficient space.\n    #     A bin with ample space for the item should get a higher initial boost.\n    sufficient_space = bins_remain_cap >= item\n    priorities[sufficient_space] += 1.0  # Simple boost for now.  May adjust weight later\n\n    # 2. Penalize bins with very little space left after placing the item, or not enough to fit the item\n    near_full = (bins_remain_cap - item) < 0.1  # Check within 10% near fullness (example)\n\n    insufficient_space = bins_remain_cap < item\n    priorities[insufficient_space] = -np.inf #Never pick these ones.\n    \n    priorities[near_full & sufficient_space] -= 0.5 # Discourage from picking nearly full sufficient bins\n\n\n    #3. Add incentive for bins that after filling the item will have an occupancy closest to a target percentage.\n    #   Example: Ideally fill the bin up to 75%.\n    target_occupancy = 0.75\n    current_occupancy = (bins_remain_cap - item) / np.max(bins_remain_cap)\n    occupancy_diff = np.abs(current_occupancy - target_occupancy)\n    occupancy_priority = -occupancy_diff # Smaller difference to target gives higher priority\n\n    priorities[sufficient_space] += occupancy_priority[sufficient_space]\n   \n    # Add some randomness to avoid getting stuck\n    randomness = np.random.rand(len(bins_remain_cap)) * 0.01  # small amount of noise\n    priorities += randomness\n\n    return priorities",
    "response_id": 11,
    "tryHS": false,
    "obj": 138.45233346629436,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response12.txt_stdout.txt",
    "code_path": "problem_iter1_code12.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if np.any(valid_bins):\n        # 1. Minimize wasted space: Favour bins where the item fits best. Smallest gap\n        #waste = bins_remain_cap[valid_bins] - item\n        #priorities[valid_bins] = -waste # Larger the waste, smaller priority.\n        # 2. Balancing bin use (first fit decreasing inspired)\n        priorities[valid_bins] = bins_remain_cap[valid_bins] / np.sum(bins_remain_cap[valid_bins])\n        #3. Hybrid : Encourage packing into partially full bins, with emphasis to fit in as tight as possible\n        #waste = bins_remain_cap[valid_bins] - item\n        #priorities[valid_bins] = (bins_remain_cap[valid_bins] / np.sum(bins_remain_cap[valid_bins])) - waste\n\n        #Newtonian gravitation inspired: Inverse square relation of waste, proportional to total capacity\n        #waste = bins_remain_cap[valid_bins] - item\n        #priorities[valid_bins] = bins_remain_cap[valid_bins] / (1+waste**2)\n        #Normalised ratio, favour near fits\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] = (bins_remain_cap[valid_bins] - waste) / bins_remain_cap[valid_bins]\n    else:\n        priorities = np.full_like(bins_remain_cap, -np.inf)\n    return priorities",
    "response_id": 12,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response13.txt_stdout.txt",
    "code_path": "problem_iter1_code13.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by the tendency of radioactive elements to fill available spaces,\n    we prioritize bins based on a combination of how well the item fits\n    and how full the bin would become after insertion.  We discourage\n    leaving bins mostly empty.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if item <= cap:\n            # Fit score: Closer fit is better, but not perfect fit (to avoid local optima)\n            fit_score = np.exp(-np.abs((cap - item) / (item + 1e-9))) # Exponential decay\n\n            # Fullness score: Reward bins that become fuller, but penalize near-empty bins\n            fullness_score = (item / (cap+ 1e-9)) * (1 - (cap-item) / (cap + 1e-9))\n            #Consider cases where the bin is almost full\n            if cap - item < 1e-9: #Very close to full\n                fullness_score = 1.0 #set to max val\n                fit_score = 1.0\n            \n            if cap - item > cap *0.9: # almost empty\n                fullness_score = -0.5\n\n            priorities[i] = fit_score + fullness_score\n        else:\n            priorities[i] = -np.inf  # Cannot fit, so lowest priority\n    return priorities",
    "response_id": 13,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.999968680000165 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that can accommodate the item without excessive waste,\n    but also discourages using bins that are almost perfectly filled by the item (to avoid fragmentation).\n    It uses a combination of remaining capacity and a \"sweet spot\" around a certain waste percentage.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Define a preferred waste percentage range (e.g., 10-30%)\n    preferred_waste_low = 0.10\n    preferred_waste_high = 0.30\n\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            waste = (cap - item) / cap\n            if preferred_waste_low <= waste <= preferred_waste_high:\n                # Ideal waste, give high priority\n                priorities[i] = 10  #Arbitrary high value. Consider function of cap/item\n            elif waste < preferred_waste_low and waste > 0:\n                # Too little waste (almost full), give lower priority (penalize)\n                priorities[i] = 10 * waste / preferred_waste_low # linear decrease to 0\n            elif waste > preferred_waste_high:\n                # Excessive waste, give moderate priority, prefer less waste over more.\n                priorities[i] = 5 * np.exp(-5 * (waste - preferred_waste_high))\n\n    return priorities",
    "response_id": 14,
    "tryHS": false,
    "obj": 6.80095731950539,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins with just enough space, but also considers the remaining wasted space.\n    It introduces a penalty for bins that are too large or too small relative to the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # First, filter out bins that cannot fit the item\n    valid_bins = bins_remain_cap >= item\n\n    # Calculate \"fit score\" (how close the item size is to the remaining capacity). High values = good fit\n    fit_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    fit_scores[valid_bins] = np.exp(-np.abs(bins_remain_cap[valid_bins] - item) / item)\n\n    # Calculate \"waste score\" (lower waste = better). Higher values = less waste\n    waste_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    waste_scores[valid_bins] = 1 / (bins_remain_cap[valid_bins] - item + 0.0001) # Avoid division by zero. Can be any small value\n    waste_scores[~valid_bins] = -1  # Very bad score if item doesn't fit\n\n    #Combine scores to assign priorities\n    priorities = fit_scores * waste_scores\n\n    return priorities",
    "response_id": 15,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities with a base value. Add a small amount to avoid zero division.\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Calculate the waste if the item were placed in each bin.\n    waste = bins_remain_cap - item\n    \n    # Give high priority to bins where the item fits (positive waste).\n    # Prioritize bins with smallest waste after placing the item. A smaller\n    # waste means a fuller bin, which we want. Avoid putting a small item\n    # into an empty bin.\n\n    fit_mask = waste >= 0\n\n    if np.any(fit_mask):\n        priorities[fit_mask] = 1 / (waste[fit_mask] + 1e-6) # Adding a small value for stability\n    else:\n        # If item does not fit in any bin, assign a low priority to bins. The idea here\n        # is to discourage creating new bins unless really needed. In such case,\n        # negative waste represents the overflow - minimize the absolute overflow is the\n        # next goal.\n        priorities = 1 / (np.abs(waste) + 1e-6)\n        \n    return priorities",
    "response_id": 16,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response17.txt_stdout.txt",
    "code_path": "problem_iter1_code17.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Heuristics:\n    1.  Encourage packing into bins that are already somewhat full (First-Fit Decreasing).\n    2.  Discourage placing the item into bins that would result in a very small remaining capacity\n        after the item is placed (to avoid fragmentation).\n    3. Add some stochasticity to avoid local optima.\n    \"\"\"\n    # Epsilon to avoid division by zero\n    epsilon = 1e-9\n\n    # 1. First-Fit Decreasing (but modified to fit a priority score)\n    # Prioritize bins with higher (but not excessively high) utilization if we packed the item in it.\n    potential_remain_cap = bins_remain_cap - item\n    potential_utilization = (bins_remain_cap - potential_remain_cap) / (bins_remain_cap + epsilon)\n    ffd_priority = potential_utilization\n\n    # 2. Fragmentation Avoidance\n    # Penalize bins that will have very small remaining capacity after packing\n    fragmentation_penalty = np.where(potential_remain_cap > 0, np.exp(-10*potential_remain_cap), -np.inf) # Heavily penalize negative remaining capacities\n    # Scale down penalty\n    fragmentation_penalty *= 0.5\n\n    # 3. Stochasticity\n    stochasticity = np.random.rand(len(bins_remain_cap)) * 0.1\n\n    # Combine the priorities\n    priorities = ffd_priority + fragmentation_penalty + stochasticity\n\n    return priorities",
    "response_id": 17,
    "tryHS": false,
    "obj": 5.175508575987245,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response18.txt_stdout.txt",
    "code_path": "problem_iter1_code18.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Filter out bins that cannot fit the item\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        # If no bin can fit the item, prioritize the fullest bin (least remaining capacity)\n        # This might open up space for future items\n        priorities = -bins_remain_cap\n        return priorities\n    \n    \n    # Calculate remaining capacity after placing the item\n    remaining_after_placement = bins_remain_cap[valid_bins] - item\n\n    # Prioritize bins that would have a high fill rate after item placement\n    fill_rate = (bins_remain_cap[valid_bins] - remaining_after_placement) / bins_remain_cap[valid_bins]\n    priorities[valid_bins] = fill_rate\n\n    # Smallest Waste Heuristic :\n    # Adjust priorities by penalizing bins with small remaining space after placement. This favors more complete fills\n    # and tries to avoid very fragmented bins.\n    \n    waste_penalty = np.exp(-remaining_after_placement) # Exponential decay based on wasted space\n    priorities[valid_bins] *= waste_penalty\n\n    # Adjust the scaling so that the priorities of bins which *cannot* take the item are at the far negative end\n    priorities[~valid_bins] = -np.inf\n\n    return priorities",
    "response_id": 18,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that have enough space for the item\n    but penalizes those with too much or too little space to reduce fragmentation.\n    It also considers filling bins to near-full capacity as a high priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    available_bins = bins_remain_cap >= item\n\n    if not np.any(available_bins):\n        return priorities # No suitable bin, all priorities remain 0\n\n    for i in range(len(bins_remain_cap)):\n        if available_bins[i]:\n            remaining_space = bins_remain_cap[i] - item\n            # Reward bins with minimal wasted space\n            waste_penalty = np.abs(remaining_space) # Linear penalty\n\n            #Heuristic 1: Favour bins that have exactly enough capacity for the item\n            exact_fit_reward = 0\n            if remaining_space == 0:\n              exact_fit_reward = 10\n\n            #Heuristic 2: Reduce Fragmentation\n            frag_penalty = 0\n            if remaining_space > 0: #some wasted space\n                frag_penalty = remaining_space / np.sum(bins_remain_cap) #Normalizing remaining space to capacity\n\n            #Heuristic 3: Maximize Bin utilization\n            bin_util = item / (bins_remain_cap[i] + item)\n\n            #Priority calculations. Combine heuristic aspects\n            priorities[i] = 100 - waste_penalty - (frag_penalty * 50) + exact_fit_reward + bin_util*20\n        else:\n            priorities[i] = -np.inf  # Impossible to fit\n\n    return priorities",
    "response_id": 19,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997030999839 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response20.txt_stdout.txt",
    "code_path": "problem_iter1_code20.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Very large penalty if the item doesn't fit\n    priorities[bins_remain_cap < item] = -np.inf\n    \n    # Give a bonus if the item fits perfectly. This reduces fragmentation.\n    perfect_fit = np.isclose(bins_remain_cap, item)\n    priorities[perfect_fit] = np.inf\n    \n    # Prioritize bins that can accommodate the item with minimal remaining space.\n    # This encourages filling bins completely.  Avoids creating bins with tiny spaces\n    # that will be hard to fill later. Use a capped inverse to limit extreme preference for tiny residual spaces.\n    \n    residual_space = bins_remain_cap - item\n    valid_bins = bins_remain_cap >= item\n    \n    # Calculate priority only for bins where the item fits\n    if np.any(valid_bins):\n        # Cap residual_space to a max value to avoid overly prioritizing bins with extremely small remaining capacity.\n        capped_residual_space = np.minimum(residual_space[valid_bins], 0.5)  # Example: cap at 0.5\n        priorities[valid_bins] += 1.0 / (capped_residual_space + 0.0000001) # Adding small constant to avoid division by zero\n\n    return priorities",
    "response_id": 20,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Inspired by the concept of spacetime curvature, bins with remaining capacity closer\n    to the item size will experience a stronger \"gravitational pull.\" We also add a\n    factor to avoid filling bins too greedily early on, preserving space for potentially\n    larger future items (analogous to maintaining spacetime stability). A small random\n    component is added, like Brownian motion, to explore near-optimal configurations.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero (bins with zero remaining capacity).  Give them very low priority.\n    bins_remain_cap_safe = np.where(bins_remain_cap <= 0, np.inf, bins_remain_cap)\n\n    # Calculate the \"gravitational potential\" based on how well the item fits.\n    # A value close to 0 suggests a good fit.  Add a small number to remaining\n    # capacity so item fits.\n    potential = np.abs(bins_remain_cap_safe - item)\n\n    # Use a Gaussian-like function to convert potential to \"gravitational force\" or priority.\n    # The smaller the potential (closer the fit), the higher the priority.\n    priority_base = np.exp(-(potential**2) / (2 * (item / 2)**2))  # sigma proportional to item size\n\n    # Penalize bins that are getting too full (analogy to \"spacetime distortion\").\n    # Reduce priority for bins that have been filled past some percentage, for example 80%.\n    fill_ratio = (1 - bins_remain_cap_safe / np.max(bins_remain_cap)) #Use max cap for reference\n    full_bin_penalty = np.where(fill_ratio > 0.8, 1-fill_ratio, 1) # Penalize bins filled >80%\n\n    priorities = priority_base * full_bin_penalty\n\n    # Add a small random component to encourage exploration.\n    priorities += np.random.normal(0, 0.01, size=bins_remain_cap.shape)\n\n    # Set bins with insufficient capacity to negative infinity.\n    priorities = np.where(bins_remain_cap < item, -np.inf, priorities)\n\n    return priorities",
    "response_id": 21,
    "tryHS": false,
    "obj": 6.172716394096539,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response22.txt_stdout.txt",
    "code_path": "problem_iter1_code22.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Employing a combination of heuristics, considering both space utilization\n    and a probabilistic element to explore different bin assignments.  This is\n    inspired by the balance between gravity (deterministic) and random molecular motion\n    (stochastic) in the physical world. We favour bins where the item fits relatively\n    well (higher utilization) and introduce a small chance of using a less-optimal\n    bin to explore the solution space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    # First, give a very low priority to bins that cannot contain the item\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Ensure these bins are never chosen if possible\n\n    # For feasible bins, calculate a \"gravity\" score based on space utilization.\n    # Higher utilization (smaller remaining capacity after packing) is preferred.\n    feasible_mask = ~infeasible_mask\n    if np.any(feasible_mask):\n        utilization = item / bins_remain_cap[feasible_mask]\n        priorities[feasible_mask] = utilization\n\n        # Introduce a probabilistic element (\"Brownian motion\") to encourage exploration.\n        # This helps escape local optima. The 'temperature' parameter controls the\n        # magnitude of the random perturbation.\n\n        temperature = 0.1  # Adjust this parameter as needed\n        random_noise = np.random.normal(0, temperature, size=np.sum(feasible_mask))\n        priorities[feasible_mask] += random_noise\n\n\n        # A small bonus to using bins already somewhat full to reduce fragmentation.\n        fullness_bonus = bins_remain_cap[feasible_mask] / np.max(bins_remain_cap)\n        priorities[feasible_mask] += 0.1* (1-fullness_bonus)\n\n\n    return priorities",
    "response_id": 22,
    "tryHS": false,
    "obj": 4.637016354208217,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response23.txt_stdout.txt",
    "code_path": "problem_iter1_code23.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    A higher priority indicates the bin is a better fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Heuristic 1: Reward bins that can fit the item\n    fit_mask = bins_remain_cap >= item\n    priorities[fit_mask] += 1\n\n    # Heuristic 2: Prioritize bins with smallest remaining capacity after adding the item,\n    # but only consider bins that fit. Minimizes wasted space.\n    remaining_after_fit = bins_remain_cap[fit_mask] - item\n    if remaining_after_fit.size > 0:  # Check if there are bins to consider\n        min_remaining = np.min(remaining_after_fit)\n        close_to_min_mask = np.isclose(remaining_after_fit, min_remaining) #handle multiple min_remaining\n        indices = np.where(fit_mask)[0][close_to_min_mask] #get correct bin indices for final priority\n        priorities[indices] += 2\n\n    # Heuristic 3: Penalize bins where adding the item leaves very little space left (<= 10% of bin size)\n    small_space_mask = (bins_remain_cap > item) & ((bins_remain_cap - item) / bins_remain_cap <= 0.1)\n    priorities[small_space_mask] += 0.5 #slightly less than finding a minimum but better than nothing.\n\n    # Heuristic 4: if all bins are over capacity for the item, choose the one with the LEAST OVERFLOW.\n    if not np.any(fit_mask): #if no bin can fit the item\n        overflow = item - bins_remain_cap\n        min_overflow = np.min(overflow) #smallest possible overflow\n        indices = np.where(np.isclose(overflow,min_overflow))[0] #handles multiple occurrances\n        priorities[indices] += 0.1 #very low score\n\n    return priorities",
    "response_id": 23,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 31, in priority_v2\n    return priorities\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n8\n1\n74.23092131656186\n72.08234061130545\n97\n"
  },
  {
    "stdout_filepath": "problem_iter1_response24.txt_stdout.txt",
    "code_path": "problem_iter1_code24.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Tesla's Resonance Principle: Favour bins close to the item size but avoid overflow.\n            proximity = 1 - abs(cap - item) / item if item > 0 else 0 # Normalized distance to item size\n            utilization = item / cap # How well we are filling the bin.\n\n            # The Grand Unification: Combine proximity and utilization for optimal harmony.\n            # High proximity is good, and we want to increase the utilization.\n            priorities[i] = 5 * proximity + 2 * utilization  # Tuned for balanced performance.\n\n            # Introduce slight encouragement for filling up relatively empty bins\n            # if (cap > 2 * item):\n            #     priorities[i] -= 0.5 * utilization\n        else:\n            # Invalid bins get minimum priority\n            priorities[i] = -np.inf\n\n    return priorities",
    "response_id": 24,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response25.txt_stdout.txt",
    "code_path": "problem_iter1_code25.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # First, let's avoid overflowing bins completely\n    valid_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    if not np.any(valid_bins):\n        # No bin can fit. Put it in the fullest bin (least remaining cap), but penalize heavily.\n        priorities = -np.abs(bins_remain_cap - item) # make it very negative\n        return priorities\n\n    # For valid bins, we want to prioritize bins which can almost completely fill up after putting the item\n    fill_levels = (bins_remain_cap[valid_bins] - item)\n    # Give higher priority if the bin can be filled up more after adding the item.\n\n    #Calculate the 'wastage' after inserting the item:\n    wastage = bins_remain_cap[valid_bins] - item\n\n    # We prioritize the bins with smallest wastage.\n    priorities[valid_bins] = -wastage # Use negative to turn \"smallest\" to \"largest\" priority\n\n    # Additionally, if a bin can be filled perfectly, give it very high priority:\n    perfect_fit = np.abs(bins_remain_cap[valid_bins] - item) < 1e-6  # Tolerance for floating-point errors\n    priorities[valid_bins][perfect_fit] = 1e9  # A very large number\n\n    return priorities",
    "response_id": 25,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response26.txt_stdout.txt",
    "code_path": "problem_iter1_code26.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Encourage packing into bins that can fit the item, but penalize leaving tiny gaps.\n    # Reward almost-full bins, to mimic First-Fit-Decreasing's advantages.\n\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Give a baseline priority boost for fitting. Higher cap leads to lower base priority.\n            priorities[i] += 1.0 / (cap + 1e-9)  #Avoid division by 0, and penalize full bins.\n\n            # Calculate the remaining space after placing the item\n            remaining_space = cap - item\n\n            # High reward for filling up space nearly completely\n            if remaining_space < 0.1: # Threshold of 0.1. can be tuned\n                priorities[i] += 10 # Higher number = greater chance of putting the item in almost filled bin\n            elif remaining_space > 0.9 * cap: #If the item barely fills anything\n                priorities[i] -= 2\n\n            #Prioritize utilization, i.e prefer filling half empty containers vs almost empty\n            priorities[i] += np.exp(-remaining_space)\n\n        else:\n            priorities[i] = -np.inf # Impossible to put item into, so reject\n\n    return priorities",
    "response_id": 26,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.9999759300008 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response27.txt_stdout.txt",
    "code_path": "problem_iter1_code27.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by the quantum world, where probabilities guide our actions. We'll use a heuristic blending first-fit and best-fit ideas, with a touch of 'quantum tunneling'.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # First, eliminate bins that can't possibly hold the item\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf  # Make them infinitely bad\n\n    # Calculate the 'energy gap' (waste) if the item were placed in each feasible bin.\n    energy_gaps = bins_remain_cap - item\n    energy_gaps[infeasible_bins] = np.inf #prevent from influencing\n\n    # Best Fit Component: Smaller gaps are generally better, think 'ground state'\n    #We use reciprocal of squared energy gap as best fit heuristics to favor smaller wastes\n    best_fit_priority = 1.0 / (energy_gaps**2 + 1e-9)  # Adding a small constant for numerical stability. Prevents division by zero if we perfectly fill\n\n    # First Fit Component: We also encourage early bins, so avoid filling all the bins.\n    first_fit_priority = np.exp(-np.arange(len(bins_remain_cap)) * 0.1) #Exponential decay encourages filling bins at beginning\n\n    #A quantum term: Tunneling: Introduce a small probability of selecting 'almost full' bins to avoid local minima\n    tunneling_threshold = 0.95\n    almost_full = (item / bins_remain_cap) > tunneling_threshold\n    tunneling_priority = np.where(almost_full,1/(1-item/bins_remain_cap+1e-9),0)\n    # Combine components with weights.\n    #Experimenting with different weighs might imporve result further\n    priorities = 0.6 * best_fit_priority + 0.3 * first_fit_priority + 0.1*tunneling_priority\n\n\n    return priorities",
    "response_id": 27,
    "tryHS": false,
    "obj": 4.028719585161557,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response28.txt_stdout.txt",
    "code_path": "problem_iter1_code28.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities with a base value (e.g., 0).\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Assign a high priority to bins that can fit the item.  Prioritize bins where item is close to filling bin\n    fit_mask = bins_remain_cap >= item\n    priorities[fit_mask] = (bins_remain_cap[fit_mask] - item) / bins_remain_cap[fit_mask]\n\n    priorities[fit_mask] = 1 - priorities[fit_mask] # Make small waste have high priority\n\n    # Very bad to exceed capacity\n    overflow_mask = bins_remain_cap < item\n    priorities[overflow_mask] = -np.inf\n\n    return priorities",
    "response_id": 28,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that can fit the item snugly (minimize wasted space),\n    but also includes a component to encourage filling bins rather than leaving them mostly empty.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Fit Score: Higher if item fits well (little wasted space)\n    fit_scores = bins_remain_cap - item\n    fit_scores[fit_scores < 0] = -np.inf  # Cannot fit, very low priority\n    fit_scores = -np.abs(fit_scores) #Smaller difference gets a higher score\n\n    # Capacity Utilization Score: Higher if the bin is already somewhat full\n    utilization_scores = (1 - bins_remain_cap) #Originally was just \"- bins_remain_cap\", but this is less effective. We want the reciprocal so higher the utilization the higher the score.\n\n    # Combine the scores, weighing fit slightly higher.\n    priorities = fit_scores + 0.5*utilization_scores  # Weighted sum.\n    return priorities",
    "response_id": 29,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 74.23092131656186,
    "mi": 72.08234061130545,
    "token_count": 97.0,
    "exec_success": true
  }
]