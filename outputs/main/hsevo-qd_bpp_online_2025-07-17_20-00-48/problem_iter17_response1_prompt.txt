{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors, including utilization,\n    fragmentation avoidance, pressure, best fit, and empty bin preference, with adaptive adjustments\n    based on item size and bin characteristics. It aims to improve upon priority_v1 by dynamically\n    adjusting penalties and bonuses to better handle diverse item sizes and bin configurations,\n    and adding a bin diversity term, and considering the number of available bins. It also adjusts fragmentation penalties based on item size relative to bin size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    max_cap = np.max(bins_remain_cap)\n    num_bins = len(bins_remain_cap)\n\n    # 0. Hard constraint: Item must fit. Bins that can't fit get -inf priority.\n    priorities[bins_remain_cap < item] = -np.inf\n\n    fit_mask = bins_remain_cap >= item\n\n    if not np.any(fit_mask):\n        return priorities  # No bin can fit the item\n\n    # 1. Utilization Term: Favor better utilization, but scale based on item size.\n    utilization = item / max_cap\n    remaining_capacity_after_fit = bins_remain_cap - item\n    utilization_score = (1 - remaining_capacity_after_fit / max_cap) * utilization\n    priorities[fit_mask] += utilization_score[fit_mask]\n\n    # 2. Fragmentation Avoidance: Penalize bins that will result in tiny fragments.\n    tiny_fragment_threshold = 0.05 * max_cap\n    small_fragment_threshold = 0.2 * max_cap\n\n    # Adaptive penalty based on item size: Larger items impose a heavier penalty for tiny fragments\n    # Adjust penalty based on how large the item is relative to the bin.\n    item_size_ratio = item / max_cap\n    tiny_fragment_penalty = -5.0 - 5.0 * utilization * (1 + item_size_ratio)\n    small_fragment_penalty = -1.0 - 1.0 * utilization * (1 + item_size_ratio)\n    \n    tiny_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit <= tiny_fragment_threshold)\n    small_fragment_mask = (remaining_capacity_after_fit > tiny_fragment_threshold) & (remaining_capacity_after_fit <= small_fragment_threshold)\n\n    priorities[tiny_fragment_mask] += tiny_fragment_penalty\n    priorities[small_fragment_mask] += small_fragment_penalty\n\n    # 3. \"Pressure\" Term: Bins with higher remaining capacity exert more \"pressure\".  Adjust scaling dynamically.\n    pressure = bins_remain_cap / max_cap * (1 - utilization)\n    priorities[fit_mask] += 0.5 * pressure[fit_mask]\n\n    # 4. Best Fit Bonus: Reward the bin that provides the absolute best fit (smallest waste).\n    diffs = bins_remain_cap - item\n    min_diff = np.min(diffs[diffs >= 0]) if np.any(diffs >= 0) else np.inf\n    best_fit_bonus = np.where(diffs == min_diff, 1.0 + 0.5 * (1 - utilization), 0)  # Adaptive bonus\n    priorities += best_fit_bonus\n\n    # 5. Empty Bin Preference (Adaptive): If the item is a significant fraction of bin size, strongly prefer an empty bin.\n    empty_bin_mask = bins_remain_cap == max_cap\n    empty_bin_threshold = 0.6 * max_cap\n    if item >= empty_bin_threshold and np.any(empty_bin_mask):\n        priorities[empty_bin_mask] += 2.0 + 1.0 * utilization  # Stronger adaptive preference\n    \n    # 6. Bin Diversity Bonus: Encourage spreading items across different bins.\n    # This penalizes using bins with similar remaining capacities if there are other options.\n    if num_bins > 1:\n        std_dev = np.std(bins_remain_cap[fit_mask])  # Standard deviation of remaining capacities\n        diversity_bonus = std_dev / max_cap # Normalize\n        diversity_weight = min(0.25, 0.1 * num_bins)  # Reduce diversity bonus if there are few bins\n        priorities[fit_mask] += diversity_weight * diversity_bonus\n\n    # 7. Number of bins term: If we have a lot of bins, be more aggressive in filling them up.\n    # If we have few bins, try to conserve space better.\n\n    bin_quantity_scaling = 1.0 + 0.1 * num_bins\n    priorities[fit_mask] *= bin_quantity_scaling\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines utilization, fragmentation, and best-fit for bin priority.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Bin Utilization\n    utilization = item / (np.max(bins_remain_cap) + 1e-9)\n    remaining_percentage = (bins_remain_cap - item) / (np.max(bins_remain_cap) + 1e-9)\n\n    # Infeasible bin penalty\n    priorities[bins_remain_cap < item] = -np.inf\n    fit_mask = bins_remain_cap >= item\n    if np.any(fit_mask):\n        priorities[fit_mask] += (1 - remaining_percentage[fit_mask]) * utilization\n\n    # 2. Fragmentation penalty\n    frag_threshold = item / 4.0\n    frag_penalty = np.exp(-np.abs(bins_remain_cap - item - frag_threshold) / (frag_threshold + 1e-9))\n    priorities[fit_mask] -= 0.2 * frag_penalty[fit_mask]\n\n    # 3. Best Fit Bonus\n    diffs = bins_remain_cap - item\n    min_diff = np.min(diffs[diffs >= 0]) if np.any(diffs >= 0) else np.inf\n    best_fit_bonus = np.where(diffs == min_diff, 0.1, 0)\n    priorities += best_fit_bonus\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see a significant difference in complexity and the number of factors considered. The 1st heuristic incorporates utilization, fragmentation avoidance, pressure, best fit, empty bin preference, and bin diversity, while the 20th only uses a simple ratio and logarithm. (2nd) is almost identical to (1st) with just a copy, so the performance is probably the same. Comparing (1st) vs (10th), the 1st utilizes more adaptive and nuanced methods for fragmentation avoidance and includes empty bin and bin diversity preferences, while the 10th uses a simpler fragmentation term and a potential well. Comparing (3rd) vs (4th), the 3rd adds a term for the number of bins available and adjusts fragmentation penalties based on item size, while the 4th focuses on simulated pressure and stricter fragment avoidance. Comparing (2nd worst) vs (worst), heuristics 19th and 20th showcase a significant drop in the number of considerations and the complexity of calculations. 19th includes parameters, while 20th only uses a ratio of item size to bin remaining capacity, with a logarithm applied. Overall: Better heuristics consider multiple factors, adapt to item size and bin characteristics, and carefully balance different objectives like utilization, fragmentation avoidance, and diversity. Simpler heuristics may be faster but often lead to suboptimal packing. The inclusion of adaptive parameters and bonuses/penalties based on different item sizes leads to better performance.\n- \nOkay, let's redefine \"Current Self-Reflection\" to design better heuristics, avoiding the pitfalls of \"Ineffective Self-Reflection.\" Here's a breakdown:\n\n*   **Keywords:** Multi-factor, adaptive, interactions, validation, refinement, edge cases, parsimony (simplicity).\n\n*   **Advice:** Design heuristics that intelligently combine multiple relevant factors, dynamically adapting to item and bin properties. Pay special attention to the *interactions* between the factors.\n\n*   **Avoid:** Simply adding complexity without thorough validation or neglecting edge cases.\n\n*   **Explanation:** Focus on adaptive heuristics that address multiple concerns. Balance component heuristics' weights by careful testing. Prioritize clear logic and avoid overcomplicating code, but not at the detriment of performance or functionality.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}