{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Heuristics:\n    1.  Encourage packing into bins that are already somewhat full (First-Fit Decreasing).\n    2.  Discourage placing the item into bins that would result in a very small remaining capacity\n        after the item is placed (to avoid fragmentation).\n    3. Add some stochasticity to avoid local optima.\n    \"\"\"\n    # Epsilon to avoid division by zero\n    epsilon = 1e-9\n\n    # 1. First-Fit Decreasing (but modified to fit a priority score)\n    # Prioritize bins with higher (but not excessively high) utilization if we packed the item in it.\n    potential_remain_cap = bins_remain_cap - item\n    potential_utilization = (bins_remain_cap - potential_remain_cap) / (bins_remain_cap + epsilon)\n    ffd_priority = potential_utilization\n\n    # 2. Fragmentation Avoidance\n    # Penalize bins that will have very small remaining capacity after packing\n    fragmentation_penalty = np.where(potential_remain_cap > 0, np.exp(-10*potential_remain_cap), -np.inf) # Heavily penalize negative remaining capacities\n    # Scale down penalty\n    fragmentation_penalty *= 0.5\n\n    # 3. Stochasticity\n    stochasticity = np.random.rand(len(bins_remain_cap)) * 0.1\n\n    # Combine the priorities\n    priorities = ffd_priority + fragmentation_penalty + stochasticity\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Inspired by the concept of spacetime curvature, bins with remaining capacity closer\n    to the item size will experience a stronger \"gravitational pull.\" We also add a\n    factor to avoid filling bins too greedily early on, preserving space for potentially\n    larger future items (analogous to maintaining spacetime stability). A small random\n    component is added, like Brownian motion, to explore near-optimal configurations.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero (bins with zero remaining capacity).  Give them very low priority.\n    bins_remain_cap_safe = np.where(bins_remain_cap <= 0, np.inf, bins_remain_cap)\n\n    # Calculate the \"gravitational potential\" based on how well the item fits.\n    # A value close to 0 suggests a good fit.  Add a small number to remaining\n    # capacity so item fits.\n    potential = np.abs(bins_remain_cap_safe - item)\n\n    # Use a Gaussian-like function to convert potential to \"gravitational force\" or priority.\n    # The smaller the potential (closer the fit), the higher the priority.\n    priority_base = np.exp(-(potential**2) / (2 * (item / 2)**2))  # sigma proportional to item size\n\n    # Penalize bins that are getting too full (analogy to \"spacetime distortion\").\n    # Reduce priority for bins that have been filled past some percentage, for example 80%.\n    fill_ratio = (1 - bins_remain_cap_safe / np.max(bins_remain_cap)) #Use max cap for reference\n    full_bin_penalty = np.where(fill_ratio > 0.8, 1-fill_ratio, 1) # Penalize bins filled >80%\n\n    priorities = priority_base * full_bin_penalty\n\n    # Add a small random component to encourage exploration.\n    priorities += np.random.normal(0, 0.01, size=bins_remain_cap.shape)\n\n    # Set bins with insufficient capacity to negative infinity.\n    priorities = np.where(bins_remain_cap < item, -np.inf, priorities)\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the best heuristic uses a combination of 'energy', 'potential well', and 'repulsion' inspired by physics, while the worst focuses on minimizing wasted space with a logarithmic function. There's a conceptual difference: the best uses a smoother, more nuanced approach, while the worst is more direct but potentially brittle. (2nd best) vs (second worst) - The second-best heuristic uses similar \"physics\" principles to the first, while the second-worst prioritizes filling bins to a target occupancy and includes some randomness, which seems less effective. Comparing (1st) vs (2nd), we see they are identical, suggesting redundancy in the evaluation. (3rd) vs (4th) - The 3rd heuristic employs \"Tesla's Resonance Principle\" combining proximity to item size and utilization, while the 4th simply aims to minimize wasted space. The 3rd is more sophisticated. Comparing (second worst) vs (worst), we see that the second worst added \"target occupancy\", this idea might be not helpful. Overall: Better heuristics blend multiple factors with carefully tuned weights, often inspired by physical analogies. They tend to avoid overly aggressive strategies like solely minimizing waste or targeting specific occupancy levels. Stochasticity, when applied, should be subtle and balanced. The best heuristics often include mechanisms to prevent extreme fragmentation.\n- \nOkay, I'll help you refine \"Current self-reflection\" to avoid pitfalls and design better heuristics. Here's a breakdown focusing on effective self-reflection for heuristic design:\n\n*   **Keywords:** Multifactorial, weighted combination, physical analogies, robustness, balanced stochasticity, fragmentation awareness, adaptive parameters.\n\n*   **Advice:** Actively explore combinations of relevant problem features. Experiment with weighting schemes (e.g., adaptive weights). Model heuristic behavior on real-world systems.\n\n*   **Avoid:** Premature convergence, over-reliance on randomness without control, neglecting solution structure, and \"one-size-fits-all\" approaches.\n\n*   **Explanation:** Effective heuristics often blend diverse insights. Balanced exploration and exploitation are key. Analyzing solution fragmentation helps maintain feasibility. Adaptive parameters help navigate complex landscapes.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}