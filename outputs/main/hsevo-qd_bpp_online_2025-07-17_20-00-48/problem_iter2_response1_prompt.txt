{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Tesla's Resonance Principle: Favour bins close to the item size but avoid overflow.\n            proximity = 1 - abs(cap - item) / item if item > 0 else 0 # Normalized distance to item size\n            utilization = item / cap # How well we are filling the bin.\n\n            # The Grand Unification: Combine proximity and utilization for optimal harmony.\n            # High proximity is good, and we want to increase the utilization.\n            priorities[i] = 5 * proximity + 2 * utilization  # Tuned for balanced performance.\n\n            # Introduce slight encouragement for filling up relatively empty bins\n            # if (cap > 2 * item):\n            #     priorities[i] -= 0.5 * utilization\n        else:\n            # Invalid bins get minimum priority\n            priorities[i] = -np.inf\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Employing a combination of heuristics, considering both space utilization\n    and a probabilistic element to explore different bin assignments.  This is\n    inspired by the balance between gravity (deterministic) and random molecular motion\n    (stochastic) in the physical world. We favour bins where the item fits relatively\n    well (higher utilization) and introduce a small chance of using a less-optimal\n    bin to explore the solution space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    # First, give a very low priority to bins that cannot contain the item\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf  # Ensure these bins are never chosen if possible\n\n    # For feasible bins, calculate a \"gravity\" score based on space utilization.\n    # Higher utilization (smaller remaining capacity after packing) is preferred.\n    feasible_mask = ~infeasible_mask\n    if np.any(feasible_mask):\n        utilization = item / bins_remain_cap[feasible_mask]\n        priorities[feasible_mask] = utilization\n\n        # Introduce a probabilistic element (\"Brownian motion\") to encourage exploration.\n        # This helps escape local optima. The 'temperature' parameter controls the\n        # magnitude of the random perturbation.\n\n        temperature = 0.1  # Adjust this parameter as needed\n        random_noise = np.random.normal(0, temperature, size=np.sum(feasible_mask))\n        priorities[feasible_mask] += random_noise\n\n\n        # A small bonus to using bins already somewhat full to reduce fragmentation.\n        fullness_bonus = bins_remain_cap[feasible_mask] / np.max(bins_remain_cap)\n        priorities[feasible_mask] += 0.1* (1-fullness_bonus)\n\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the best heuristic uses a combination of 'energy', 'potential well', and 'repulsion' inspired by physics, while the worst focuses on minimizing wasted space with a logarithmic function. There's a conceptual difference: the best uses a smoother, more nuanced approach, while the worst is more direct but potentially brittle. (2nd best) vs (second worst) - The second-best heuristic uses similar \"physics\" principles to the first, while the second-worst prioritizes filling bins to a target occupancy and includes some randomness, which seems less effective. Comparing (1st) vs (2nd), we see they are identical, suggesting redundancy in the evaluation. (3rd) vs (4th) - The 3rd heuristic employs \"Tesla's Resonance Principle\" combining proximity to item size and utilization, while the 4th simply aims to minimize wasted space. The 3rd is more sophisticated. Comparing (second worst) vs (worst), we see that the second worst added \"target occupancy\", this idea might be not helpful. Overall: Better heuristics blend multiple factors with carefully tuned weights, often inspired by physical analogies. They tend to avoid overly aggressive strategies like solely minimizing waste or targeting specific occupancy levels. Stochasticity, when applied, should be subtle and balanced. The best heuristics often include mechanisms to prevent extreme fragmentation.\n- \nOkay, I'll help you refine \"Current self-reflection\" to avoid pitfalls and design better heuristics. Here's a breakdown focusing on effective self-reflection for heuristic design:\n\n*   **Keywords:** Multifactorial, weighted combination, physical analogies, robustness, balanced stochasticity, fragmentation awareness, adaptive parameters.\n\n*   **Advice:** Actively explore combinations of relevant problem features. Experiment with weighting schemes (e.g., adaptive weights). Model heuristic behavior on real-world systems.\n\n*   **Avoid:** Premature convergence, over-reliance on randomness without control, neglecting solution structure, and \"one-size-fits-all\" approaches.\n\n*   **Explanation:** Effective heuristics often blend diverse insights. Balanced exploration and exploitation are key. Analyzing solution fragmentation helps maintain feasibility. Adaptive parameters help navigate complex landscapes.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}