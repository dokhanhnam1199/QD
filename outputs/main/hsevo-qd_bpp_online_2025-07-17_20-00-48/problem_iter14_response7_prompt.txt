{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function refines the priority calculation by incorporating a refined fragmentation penalty,\n    a capacity-aware best-fit bonus, a bin-emptiness gradient, and an advanced diversity measure\n    that considers both remaining capacity and the number of items already packed.  Adaptive scaling\n    is used throughout to adjust to varying item and bin sizes.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    max_cap = np.max(bins_remain_cap)\n    num_bins = len(bins_remain_cap)\n\n    # 0. Hard constraint: Item must fit. Bins that can't fit get -inf priority.\n    priorities[bins_remain_cap < item] = -np.inf\n\n    fit_mask = bins_remain_cap >= item\n\n    if not np.any(fit_mask):\n        return priorities  # No bin can fit the item\n\n    # 1. Utilization Term: Favor better utilization, but scale based on item size.\n    utilization = item / max_cap\n    remaining_capacity_after_fit = bins_remain_cap - item\n    utilization_score = (1 - remaining_capacity_after_fit / max_cap) * utilization\n    priorities[fit_mask] += utilization_score[fit_mask]\n\n    # 2. Refined Fragmentation Avoidance: Penalize bins that will result in tiny or small fragments,\n    # with adaptive penalties based on the item's relative size compared to the bin.\n    tiny_fragment_threshold = 0.05 * max_cap\n    small_fragment_threshold = 0.2 * max_cap\n\n    # Adaptive penalty based on item size: Larger items impose a heavier penalty for tiny fragments\n    tiny_fragment_penalty = -5.0 - 7.0 * utilization  # Enhanced penalty for larger items causing tiny fragments\n    small_fragment_penalty = -1.0 - 2.0 * utilization  # Enhanced penalty for larger items causing small fragments\n\n    tiny_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit <= tiny_fragment_threshold)\n    small_fragment_mask = (remaining_capacity_after_fit > tiny_fragment_threshold) & (remaining_capacity_after_fit <= small_fragment_threshold)\n\n    priorities[tiny_fragment_mask] += tiny_fragment_penalty\n    priorities[small_fragment_mask] += small_fragment_penalty\n\n    # 3. \"Pressure\" Term: Bins with higher remaining capacity exert more \"pressure\". Adjust scaling dynamically.\n    pressure = bins_remain_cap / max_cap * (1 - utilization)\n    priorities[fit_mask] += 0.5 * pressure[fit_mask]\n\n    # 4. Capacity-Aware Best Fit Bonus: Reward the bin that provides the absolute best fit (smallest waste),\n    # with a bonus that increases as the bin's capacity increases.\n    diffs = bins_remain_cap - item\n    min_diff = np.min(diffs[diffs >= 0]) if np.any(diffs >= 0) else np.inf\n    best_fit_bonus = np.where(diffs == min_diff, (1.0 + 0.5 * (1 - utilization)) * (bins_remain_cap / max_cap), 0)  # Adaptive bonus\n    priorities += best_fit_bonus\n\n    # 5. Empty Bin Preference (Adaptive Gradient): If the item is a significant fraction of bin size, strongly prefer an empty bin.\n    # Add a gradient based on how close the bin is to empty.\n    empty_bin_mask = bins_remain_cap == max_cap\n    nearly_empty_mask = (bins_remain_cap > 0.9 * max_cap) & (bins_remain_cap < max_cap)\n    empty_bin_threshold = 0.6 * max_cap\n\n    if item >= empty_bin_threshold:\n        if np.any(empty_bin_mask):\n            priorities[empty_bin_mask] += 2.5 + 1.5 * utilization  # Stronger adaptive preference\n\n        if np.any(nearly_empty_mask):\n            priorities[nearly_empty_mask] += 1.0 + 0.5 * utilization\n\n    # 6. Advanced Bin Diversity Bonus: Encourage spreading items across different bins, considering both\n    # remaining capacity and the number of items already packed in each bin.  This encourages more balanced loading.\n    if num_bins > 1:\n        # Estimate 'fullness' based on how close to the original max_cap each bin is.\n        bin_fullness = (max_cap - bins_remain_cap) / max_cap\n        diversity_metric = np.std(bin_fullness[fit_mask])  # Std dev of fullness\n        diversity_bonus = diversity_metric  # Normalize\n        priorities[fit_mask] += 0.3 * diversity_bonus  # Moderate diversity bonus\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors inspired by physics.\n    It considers the 'energy' required to place the item (smaller remaining capacity = higher energy),\n    a 'potential well' effect (bins with capacities slightly larger than the item are favored),\n    and a 'repulsion' effect (bins with capacities much larger than the item are discouraged).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 'Energy' term: Higher priority for bins that are almost full\n    energy = 1.0 / (bins_remain_cap + 1e-9)  # Avoid division by zero\n    priorities += energy\n\n    # 'Potential well' term: Favor bins with capacities slightly larger than the item\n    diff = bins_remain_cap - item\n    potential_well = np.exp(-(diff**2) / (2 * (item/3)**2)) #Gaussian centered at item. Larger variance when item size is bigger\n    priorities += potential_well\n\n    # 'Repulsion' term: Discourage bins with capacities much larger than the item\n    repulsion = np.exp(-bins_remain_cap / (item*5))  # Exponential decay with bin capacity. Higher decay if item is small\n    priorities -= 0.5 * repulsion # We don't want it to be the dominating factor\n\n    # Consider bins where item doesn't fit as non viable\n    priorities[bins_remain_cap < item] = -np.inf\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic uses a combination of utilization, fragmentation avoidance, pressure, best fit, and empty bin preference, along with a bin diversity term, using adaptive adjustments based on item size. The worst heuristic simply calculates the negative log of the ratio of item size to remaining bin capacity. (2nd) is nearly identical to (1st), suggesting stability. Comparing (1st) vs (4th), we see the best heuristic has \"pressure term\", (4th) includes pressure term.\n\nComparing (1st) vs (6th), (1st) utilizes adaptive adjustments for penalties and bonuses based on item and bin characteristics, with a bin diversity term. (6th) combines utilization, fragmentation, best fit, and empty bin considerations with fixed weights. (7th) is a simplified version of (6th), focusing on utilization and fragmentation reduction with adaptive parameter adjustment.\n\nComparing (2nd worst) vs (worst), both use ratios, but (2nd worst) also imports unused libraries, suggesting code bloat and lack of focus. Overall, the best heuristics utilize multiple factors, adaptive adjustments, and potentially a diversity term, while worse heuristics are simpler and may lack adaptive parameters or clear goals. Adding unused libraries is related to low-quality design.\n- \nOkay, let's redefine \"Current Self-Reflection\" for better heuristic design, focusing on actionable insights and avoiding common pitfalls. Here's a structured approach:\n\n*   **Keywords:** Multifaceted, Adaptive, Factor Interaction, Validation.\n\n*   **Advice:** Design heuristics by integrating multiple relevant factors (utilization, fragmentation, item characteristics) with adaptive parameters/thresholds. Emphasize understanding the *interaction* between these factors. Rigorously validate any parameter additions or changes.\n\n*   **Avoid:** Blindly adding parameters without validation. Overly simplistic approaches that ignore crucial factors. Naive physics analogies that don't translate to practical improvements.\n\n*   **Explanation:** Effective heuristics benefit from multiple inputs but must be approached systematically. Adaptation based on input properties is key, but requires careful parameter tuning and testing. Understanding factor interactions leads to superior performance and prevents counterproductive strategies.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}