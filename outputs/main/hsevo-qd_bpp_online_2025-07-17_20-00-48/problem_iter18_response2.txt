```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Returns priority with which we want to add item to each bin, enhanced with adaptive strategies and refined considerations.

    This version incorporates a more nuanced approach to bin selection, including adaptive penalties and bonuses based on item size,
    bin capacity, and overall bin utilization. It prioritizes balanced bin utilization, efficient fragmentation avoidance, and strategic
    selection of empty bins, while also considering the diversity of remaining bin capacities.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    max_cap = np.max(bins_remain_cap)
    num_bins = len(bins_remain_cap)

    # 0. Hard constraint: Item must fit.
    can_fit = bins_remain_cap >= item
    priorities[~can_fit] = -np.inf

    if not np.any(can_fit):
        return priorities

    # 1. Utilization Term:
    remaining_capacity_after_fit = bins_remain_cap - item
    utilization = (max_cap - bins_remain_cap) / max_cap # Current utilization
    potential_utilization = (max_cap - remaining_capacity_after_fit) / max_cap # Potential utilization after fit

    utilization_score = potential_utilization  # Favor higher fill levels
    priorities[can_fit] += utilization_score[can_fit]

    # 2. Fragmentation Avoidance: Penalize tiny fragments, adaptively
    tiny_fragment_threshold = 0.05 * max_cap
    small_fragment_threshold = 0.2 * max_cap

    tiny_fragment_penalty = -5.0 # Base Penalty
    small_fragment_penalty = -1.0 # Base Penalty

    # Modulate penalties based on item size and current bin utilization
    tiny_fragment_penalty -= 2 * (item / max_cap) # Bigger items create larger fragment concerns.
    tiny_fragment_penalty -= 2 * utilization # Heavily penalize creating small fragments in already full bins
    small_fragment_penalty -= (item / max_cap)
    small_fragment_penalty -= utilization

    tiny_fragment_mask = (remaining_capacity_after_fit > 0) & (remaining_capacity_after_fit <= tiny_fragment_threshold)
    small_fragment_mask = (remaining_capacity_after_fit > tiny_fragment_threshold) & (remaining_capacity_after_fit <= small_fragment_threshold)

    priorities[tiny_fragment_mask] += tiny_fragment_penalty
    priorities[small_fragment_mask] += small_fragment_penalty

    # 3. Pressure Term: Adjusted for bin size and item size.
    pressure = bins_remain_cap / max_cap
    pressure_scaling = 0.5 * (1 - item / max_cap)  # Smaller items, less pressure effect
    priorities[can_fit] += pressure[can_fit] * pressure_scaling

    # 4. Best Fit: Reward the bin that provides the absolute best fit.
    diffs = bins_remain_cap - item
    min_diff = np.min(diffs[diffs >= 0]) if np.any(diffs >= 0) else np.inf
    best_fit_bonus = np.where(diffs == min_diff, 1.5 , 0) # Enhanced reward for best fit
    priorities += best_fit_bonus

    # 5. Empty Bin Preference: Strongly prefer an empty bin for large items
    empty_bin_mask = bins_remain_cap == max_cap
    empty_bin_threshold = 0.7 * max_cap

    if item >= empty_bin_threshold and np.any(empty_bin_mask):
        empty_bin_bonus = 3.0 # Strong Preference
        priorities[empty_bin_mask] += empty_bin_bonus

    # 6. Bin Diversity Bonus: Encourages spreading items across different bins
    if num_bins > 1:
        std_dev = np.std(bins_remain_cap[can_fit])
        diversity_bonus = std_dev / max_cap
        priorities[can_fit] += 0.3 * diversity_bonus  # Moderate Diversity Bonus

    # 7. Penalize bins that are close to full but not completely full. Encourage full bins
    almost_full_threshold = 0.95 * max_cap
    almost_full_mask = (bins_remain_cap > item) & (bins_remain_cap < almost_full_threshold)

    almost_full_penalty = -0.75
    priorities[almost_full_mask] += almost_full_penalty

    return priorities
```
