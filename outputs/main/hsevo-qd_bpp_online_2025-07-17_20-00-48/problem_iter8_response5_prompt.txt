{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins based on a combination of factors inspired by physics.\n    It considers the 'energy' required to place the item (smaller remaining capacity = higher energy),\n    a 'potential well' effect (bins with capacities slightly larger than the item are favored),\n    and a 'repulsion' effect (bins with capacities much larger than the item are discouraged).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 'Energy' term: Higher priority for bins that are almost full\n    energy = 1.0 / (bins_remain_cap + 1e-9)  # Avoid division by zero\n    priorities += energy\n\n    # 'Potential well' term: Favor bins with capacities slightly larger than the item\n    diff = bins_remain_cap - item\n    potential_well = np.exp(-(diff**2) / (2 * (item/3)**2)) #Gaussian centered at item. Larger variance when item size is bigger\n    priorities += potential_well\n\n    # 'Repulsion' term: Discourage bins with capacities much larger than the item\n    repulsion = np.exp(-bins_remain_cap / (item*5))  # Exponential decay with bin capacity. Higher decay if item is small\n    priorities -= 0.5 * repulsion # We don't want it to be the dominating factor\n\n    # Consider bins where item doesn't fit as non viable\n    priorities[bins_remain_cap < item] = -np.inf\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines capacity & wasted space with physics-inspired scaling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        # Hybrid approach: capacity + inverse waste\n        priorities[valid_bins] = bins_remain_cap[valid_bins] / (1 + waste)\n    else:\n        priorities = np.full_like(bins_remain_cap, -np.inf)\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic incorporates several factors like utilization, fragmentation avoidance, pressure, best fit, and empty bin preference, whereas the worst focuses solely on the ratio of item size to remaining capacity. (2nd best) vs (second worst) are very similar, but (2nd best) already contains several factors like utilization, fragmentation avoidance, pressure, best fit, and empty bin preference. Comparing (1st) vs (2nd), we see the difference is negligible, with both implementing the same logic; (3rd) vs (4th) are identical as well. Comparing (second worst) vs (worst), we see the second worst considers both capacity and wasted space, while the worst only considers a ratio, making the second worst slightly more informed. Overall: The better heuristics consider a wider range of factors, including utilization, fragmentation, best fit, and special cases like empty bins and large items, while also using adaptive thresholds. The worse ones are simpler and focus on fewer factors, potentially leading to suboptimal packing.\n- \nOkay, let's refine \"Current Self-Reflection\" for designing better heuristics, focusing on actionable advice and avoiding pitfalls.\n\n*   **Keywords:** Multi-factor, adaptive, parameter tuning, edge cases, balance, fragmentation, practical, brittle, utilization.\n\n*   **Advice:** Design heuristics that dynamically adapt to input characteristics (size, distribution) through parameter tuning based on feedback mechanisms. Combine diverse factors (utilization, fragmentation) with adaptive weights.\n\n*   **Avoid:** Overly complex designs, premature optimization, relying solely on rigid pre-defined rules, ignoring edge cases or potential division by zero errors.\n\n*   **Explanation:** Effective heuristics are not static; they learn and adjust. Prioritize robust, adaptable designs by combining diverse factors carefully and addressing potential weaknesses proactively.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}