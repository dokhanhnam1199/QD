[
     {
          "algorithm": "This algorithm samples multiple near-optimal TSP solutions using a nearest neighbor heuristic with random restarts and edge perturbation, then aggregates edge frequencies across these samples to create a heuristic matrix indicating edge importance.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm samples multiple near-optimal TSP solutions using a nearest neighbor heuristic with random restarts and edge perturbation, then aggregates edge frequencies across these samples to create a heuristic matrix indicating edge importance.}\"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 100\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    for _ in range(num_samples):\n        start_node = np.random.randint(n)\n        current_node = start_node\n        unvisited = set(range(n))\n        unvisited.remove(start_node)\n        tour = [start_node]\n        \n        while unvisited:\n            nearest_neighbor = -1\n            min_distance = np.inf\n            for neighbor in unvisited:\n                distance = distance_matrix[current_node, neighbor]\n                if distance < min_distance:\n                    min_distance = distance\n                    nearest_neighbor = neighbor\n\n            tour.append(nearest_neighbor)\n            unvisited.remove(nearest_neighbor)\n            current_node = nearest_neighbor\n            \n        tour.append(start_node)  # Return to starting node\n        \n        #Perturb the tour with random swaps of close nodes\n        for _ in range(n):\n            i = np.random.randint(1, n+1)\n            j = np.random.randint(1, n+1)\n\n            if i != j:\n                if distance_matrix[tour[i-1], tour[j-1]] + distance_matrix[tour[i], tour[j]] < distance_matrix[tour[i-1], tour[i]] + distance_matrix[tour[j-1], tour[j]]:\n                        tour[i], tour[j] = tour[j], tour[i]\n                        \n        # Update heuristic matrix based on edge frequencies\n        for i in range(n):\n            node1 = tour[i]\n            node2 = tour[i+1]\n            heuristics_matrix[node1, node2] += 1\n            heuristics_matrix[node2, node1] += 1  # Assuming symmetric distance matrix\n\n    heuristics_matrix /= num_samples  # Normalize to get frequencies\n    return heuristics_matrix",
          "objective": 6.08597,
          "other_inf": null,
          "SLOC": 32.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 223.47971260168305
     },
     {
          "algorithm": "This algorithm samples multiple solutions using a nearest neighbor heuristic with stochastic restarts and edge acceptance probabilities based on the frequency of edge occurrences in the sampled solutions and edge distance normalized to mean edge distance.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n  \"\"\"{This algorithm samples multiple solutions using a nearest neighbor heuristic with stochastic restarts and edge acceptance probabilities based on the frequency of edge occurrences in the sampled solutions and edge distance normalized to mean edge distance.}\"\"\"\n  n = distance_matrix.shape[0]\n  num_samples = 100\n  heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n  for _ in range(num_samples):\n    start_node = np.random.randint(n)\n    current_node = start_node\n    unvisited_nodes = set(range(n))\n    unvisited_nodes.remove(current_node)\n    path = [current_node]\n\n    while unvisited_nodes:\n      nearest_neighbor = None\n      min_distance = float('inf')\n      for neighbor in unvisited_nodes:\n        distance = distance_matrix[current_node, neighbor]\n        if distance < min_distance:\n          min_distance = distance\n          nearest_neighbor = neighbor\n\n      path.append(nearest_neighbor)\n      unvisited_nodes.remove(nearest_neighbor)\n      current_node = nearest_neighbor\n\n    path.append(start_node)\n\n    for i in range(n):\n      node1 = path[i]\n      node2 = path[i+1]\n      heuristics_matrix[node1, node2] += 1\n      heuristics_matrix[node2, node1] += 1\n\n  mean_distance = np.mean(distance_matrix)\n\n  for i in range(n):\n    for j in range(n):\n      if i != j:\n        heuristics_matrix[i, j] = (heuristics_matrix[i, j] / num_samples) / (distance_matrix[i, j] / mean_distance)\n      else:\n        heuristics_matrix[i, j] = 0\n\n  return heuristics_matrix",
          "objective": 6.12212,
          "other_inf": null,
          "SLOC": 32.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 223.47971260168305
     },
     {
          "algorithm": "This algorithm samples multiple near-optimal TSP solutions using a greedy nearest neighbor heuristic with random restarts and incorporates edge frequencies into a heuristic matrix.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n  \"\"\"{This algorithm samples multiple near-optimal TSP solutions using a greedy nearest neighbor heuristic with random restarts and incorporates edge frequencies into a heuristic matrix.}\"\"\"\n  n = distance_matrix.shape[0]\n  num_samples = 100\n\n  edge_counts = np.zeros_like(distance_matrix, dtype=float)\n  \n  for _ in range(num_samples):\n    start_node = np.random.randint(n)\n    unvisited = set(range(n))\n    unvisited.remove(start_node)\n    current_node = start_node\n    tour = [start_node]\n    \n    while unvisited:\n      nearest_neighbor = min(unvisited, key=lambda node: distance_matrix[current_node, node])\n      tour.append(nearest_neighbor)\n      edge_counts[current_node, nearest_neighbor] += 1\n      edge_counts[nearest_neighbor, current_node] += 1\n      current_node = nearest_neighbor\n      unvisited.remove(nearest_neighbor)\n      \n    tour.append(start_node)\n    edge_counts[current_node, start_node] += 1\n    edge_counts[start_node, current_node] += 1\n\n  heuristics_matrix = edge_counts / num_samples\n  return heuristics_matrix",
          "objective": 6.23525,
          "other_inf": null,
          "SLOC": 32.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 223.47971260168305
     },
     {
          "algorithm": "This algorithm samples TSP solutions using a nearest neighbor heuristic, and then scores each edge based on its frequency in the sampled solutions.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm samples TSP solutions using a nearest neighbor heuristic, and then scores each edge based on its frequency in the sampled solutions.}\"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 100\n\n    edge_counts = np.zeros_like(distance_matrix, dtype=int)\n\n    for _ in range(num_samples):\n        start_node = np.random.randint(n)\n        current_node = start_node\n        unvisited_nodes = set(range(n))\n        unvisited_nodes.remove(current_node)\n        path = [current_node]\n\n        while unvisited_nodes:\n            nearest_neighbor = -1\n            min_distance = np.inf\n            for neighbor in unvisited_nodes:\n                if distance_matrix[current_node, neighbor] < min_distance:\n                    min_distance = distance_matrix[current_node, neighbor]\n                    nearest_neighbor = neighbor\n\n            path.append(nearest_neighbor)\n            unvisited_nodes.remove(nearest_neighbor)\n            current_node = nearest_neighbor\n\n        path.append(start_node)  # Return to starting node\n\n        # Update edge counts based on the sampled path\n        for i in range(n):\n            node1 = path[i]\n            node2 = path[i + 1]\n            edge_counts[node1, node2] += 1\n            edge_counts[node2, node1] += 1 #Symmetric\n\n    heuristics_matrix = edge_counts / num_samples\n    return heuristics_matrix",
          "objective": 6.24899,
          "other_inf": null,
          "SLOC": 46.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 359.4073508826329
     },
     {
          "algorithm": "This algorithm uses stochastic sampling of nearest neighbor solutions, averaging the edge inclusion frequency to create a heuristic matrix favoring edges present in many near-optimal sampled solutions.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"\n    {This algorithm uses stochastic sampling of nearest neighbor solutions, averaging the edge inclusion frequency to create a heuristic matrix favoring edges present in many near-optimal sampled solutions.}\n    \"\"\"\n    num_nodes = distance_matrix.shape[0]\n    num_samples = 100  # Number of samples to generate\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n    \n    for _ in range(num_samples):\n        start_node = np.random.randint(num_nodes)\n        current_node = start_node\n        unvisited_nodes = set(range(num_nodes))\n        unvisited_nodes.remove(current_node)\n        \n        path = [current_node]\n        \n        while unvisited_nodes:\n            nearest_neighbor = None\n            min_distance = np.inf\n            \n            for neighbor in unvisited_nodes:\n                distance = distance_matrix[current_node, neighbor]\n                if distance < min_distance:\n                    min_distance = distance\n                    nearest_neighbor = neighbor\n            \n            path.append(nearest_neighbor)\n            unvisited_nodes.remove(nearest_neighbor)\n            current_node = nearest_neighbor\n        \n        path.append(start_node)  # Return to the starting node\n        \n        # Update heuristics matrix based on edge inclusion\n        for i in range(num_nodes):\n            node1 = path[i]\n            node2 = path[i+1]\n            heuristics_matrix[node1, node2] += 1\n            heuristics_matrix[node2, node1] += 1  # Assuming symmetric distance matrix\n    \n    heuristics_matrix /= num_samples  # Normalize to get frequency\n    return heuristics_matrix",
          "objective": 6.32426,
          "other_inf": null,
          "SLOC": 32.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 223.47971260168305
     },
     {
          "algorithm": "This algorithm creates a matrix where each element represents the inverse of the corresponding distance in the distance matrix, adjusted by a scaling factor to enhance contrast between short and long distances.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"\n    {This algorithm creates a matrix where each element represents the inverse of the corresponding distance in the distance matrix, adjusted by a scaling factor to enhance contrast between short and long distances.}\n    \"\"\"\n    heuristics_matrix = 1 / (distance_matrix + 1e-9)  # Adding a small value to avoid division by zero\n    return heuristics_matrix",
          "objective": 6.51962,
          "other_inf": null,
          "SLOC": 32.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 223.47971260168305
     },
     {
          "algorithm": "This algorithm initializes heuristics based on inverse distance, then iteratively samples solutions using these heuristics, and updates the heuristics based on edge frequency in sampled solutions, enhanced with edge-closeness in top solutions.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"\n    {This algorithm initializes heuristics based on inverse distance, then iteratively samples solutions using these heuristics, and updates the heuristics based on edge frequency in sampled solutions, enhanced with edge-closeness in top solutions.}\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics_matrix = 1.0 / (distance_matrix + np.eye(n))\n    \n    num_iterations = 100\n    num_samples = 50\n    temperature = 1.0\n\n    for _ in range(num_iterations):\n        solutions = []\n        solution_costs = []\n        \n        # Sample solutions based on current heuristics\n        for _ in range(num_samples):\n            current_node = np.random.randint(n)\n            unvisited_nodes = list(range(n))\n            unvisited_nodes.remove(current_node)\n            \n            solution = [current_node]\n            solution_cost = 0\n            \n            while unvisited_nodes:\n                probabilities = heuristics_matrix[current_node, unvisited_nodes]\n                probabilities = np.exp(probabilities / temperature) / np.sum(np.exp(probabilities / temperature))\n                \n                next_node_index = np.random.choice(len(unvisited_nodes), p=probabilities)\n                next_node = unvisited_nodes[next_node_index]\n                \n                solution.append(next_node)\n                solution_cost += distance_matrix[current_node, next_node]\n                \n                current_node = next_node\n                unvisited_nodes.remove(next_node)\n            \n            solution_cost += distance_matrix[solution[-1], solution[0]]\n            solutions.append(solution)\n            solution_costs.append(solution_cost)\n        \n        # Update heuristics based on sampled solutions\n        edge_counts = np.zeros_like(distance_matrix)\n        \n        # Prioritize top solutions\n        top_solutions_indices = np.argsort(solution_costs)[:num_samples // 5]\n        for solution_index in top_solutions_indices:\n            solution = solutions[solution_index]\n            for i in range(n):\n                u = solution[i]\n                v = solution[(i + 1) % n]\n                edge_counts[u, v] += 2  # Higher weight for top solutions\n                edge_counts[v, u] += 2\n\n        # Add all sampled solutions to edge counts\n        for solution in solutions:\n            for i in range(n):\n                u = solution[i]\n                v = solution[(i + 1) % n]\n                edge_counts[u, v] += 1\n                edge_counts[v, u] += 1\n                \n        # Normalize edge counts\n        edge_counts /= np.max(edge_counts) if np.max(edge_counts) > 0 else 1\n\n        heuristics_matrix = 0.9 * heuristics_matrix + 0.1 * edge_counts\n        temperature *= 0.95 \n\n    return heuristics_matrix",
          "objective": 6.56805,
          "other_inf": null,
          "SLOC": 46.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 359.4073508826329
     },
     {
          "algorithm": "This algorithm samples multiple TSP solutions using a nearest neighbor heuristic with stochastic restarts and biased edge selection, then aggregates the edge frequencies to create a heuristics matrix.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm samples multiple TSP solutions using a nearest neighbor heuristic with stochastic restarts and biased edge selection, then aggregates the edge frequencies to create a heuristics matrix.}\"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 100\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    for _ in range(num_samples):\n        start_node = np.random.randint(n)\n        current_node = start_node\n        unvisited_nodes = set(range(n))\n        unvisited_nodes.remove(current_node)\n        path = [current_node]\n\n        while unvisited_nodes:\n            distances = distance_matrix[current_node, :]\n            \n            # Bias towards shorter distances with some randomness\n            probabilities = 1.0 / (distances + 1e-6)  # Avoid division by zero\n            probabilities[list(path)] = 0  # Avoid revisiting nodes\n            probabilities = probabilities / np.sum(probabilities)\n            \n            next_node = np.random.choice(n, p=probabilities)\n            \n            if next_node not in unvisited_nodes: #safety check\n               available_nodes = list(unvisited_nodes)\n               if available_nodes:\n                   next_node = available_nodes[0] #take the first one\n               else:\n                   break\n            \n            path.append(next_node)\n            unvisited_nodes.remove(next_node)\n            current_node = next_node\n\n        path.append(start_node)  # Return to starting node\n        \n        for i in range(len(path) - 1):\n            u = path[i]\n            v = path[i+1]\n            heuristics_matrix[u, v] += 1\n            heuristics_matrix[v, u] += 1  # Ensure symmetry\n\n    heuristics_matrix = heuristics_matrix / num_samples\n    return heuristics_matrix",
          "objective": 7.92228,
          "other_inf": null,
          "SLOC": 46.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 359.4073508826329
     },
     {
          "algorithm": "This algorithm samples TSP solutions using a nearest neighbor heuristic with random restarts and biases the edge selection probabilities based on the frequency of edges appearing in good solutions.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"\n    {This algorithm samples TSP solutions using a nearest neighbor heuristic with random restarts and biases the edge selection probabilities based on the frequency of edges appearing in good solutions.}\n    \"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = n * 10  # Number of sample solutions to generate\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n    \n    for _ in range(num_samples):\n        start_node = np.random.randint(n)\n        current_node = start_node\n        unvisited = set(range(n))\n        unvisited.remove(start_node)\n        path = [start_node]\n        \n        while unvisited:\n            distances = distance_matrix[current_node, :]\n            \n            # Prioritize nearest neighbors\n            nearest_neighbors = np.argsort(distances)\n            \n            # Filter unvisited nodes\n            valid_neighbors = [node for node in nearest_neighbors if node in unvisited]\n\n            # Add randomness: Bias towards nearest, but also consider other nodes\n            probabilities = np.exp(-np.array([distance_matrix[current_node,neighbor] for neighbor in valid_neighbors]))\n            probabilities /= probabilities.sum() # Normalize\n            next_node = np.random.choice(valid_neighbors, p=probabilities)\n            \n            path.append(next_node)\n            unvisited.remove(next_node)\n            current_node = next_node\n        \n        path.append(start_node)  # Return to start\n\n        # Calculate the tour length:\n        tour_length = 0\n        for i in range(n):\n            tour_length += distance_matrix[path[i], path[i+1]]\n\n        # Favor edges that are in the 'best' (shortest) tours.  Consider the 'best' 1/3:\n        \n        # Update heuristics matrix: encourage edges in the tour\n        for i in range(n):\n           heuristics_matrix[path[i], path[i+1]] += 1.0 / tour_length\n           heuristics_matrix[path[i+1], path[i]] += 1.0 / tour_length\n\n\n    # Normalize the matrix\n    heuristics_matrix = (heuristics_matrix + heuristics_matrix.T) / 2\n    total = np.sum(heuristics_matrix)\n    if total>0:\n      heuristics_matrix /= total\n\n    return heuristics_matrix",
          "objective": 12.624,
          "other_inf": null,
          "SLOC": 32.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 223.47971260168305
     },
     {
          "algorithm": "This algorithm generates multiple random tours, evaluates their lengths, and uses the frequency with which each edge appears in good tours to create a heuristic matrix.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm generates multiple random tours, evaluates their lengths, and uses the frequency with which each edge appears in good tours to create a heuristic matrix.}\"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 1000\n    top_k = 100 \n\n    all_tours = []\n    all_tour_lengths = []\n\n    for _ in range(num_samples):\n        tour = np.random.permutation(n)\n        tour_length = 0\n        for i in range(n - 1):\n            tour_length += distance_matrix[tour[i], tour[i+1]]\n        tour_length += distance_matrix[tour[-1], tour[0]]\n        all_tours.append(tour)\n        all_tour_lengths.append(tour_length)\n\n    ranked_tours_indices = np.argsort(all_tour_lengths)\n    top_tours = [all_tours[i] for i in ranked_tours_indices[:top_k]]\n\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n    for tour in top_tours:\n        for i in range(n - 1):\n            heuristics_matrix[tour[i], tour[i+1]] += 1\n            heuristics_matrix[tour[i+1], tour[i]] += 1\n        heuristics_matrix[tour[-1], tour[0]] += 1\n        heuristics_matrix[tour[0], tour[-1]] += 1\n\n    heuristics_matrix = heuristics_matrix / top_k\n    return heuristics_matrix",
          "objective": 13.81351,
          "other_inf": null,
          "SLOC": 46.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 359.4073508826329
     },
     {
          "algorithm": "This algorithm samples multiple random tours, scores edges based on their frequency in short tours, and returns a matrix indicating the likelihood of each edge being in a good TSP solution.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n  \"\"\"{This algorithm samples multiple random tours, scores edges based on their frequency in short tours, and returns a matrix indicating the likelihood of each edge being in a good TSP solution.}\"\"\"\n  n = distance_matrix.shape[0]\n  num_samples = 1000\n  heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n  tour_lengths = []\n\n  for _ in range(num_samples):\n    tour = np.random.permutation(n)\n    tour_length = 0\n    for i in range(n - 1):\n      tour_length += distance_matrix[tour[i], tour[i+1]]\n    tour_length += distance_matrix[tour[-1], tour[0]]\n    tour_lengths.append((tour, tour_length))\n  \n  tour_lengths.sort(key=lambda x: x[1])\n  \n  top_tours = tour_lengths[:int(num_samples * 0.1)]\n  \n  for tour, _ in top_tours:\n    for i in range(n - 1):\n      heuristics_matrix[tour[i], tour[i+1]] += 1\n      heuristics_matrix[tour[i+1], tour[i]] += 1\n    heuristics_matrix[tour[-1], tour[0]] += 1\n    heuristics_matrix[tour[0], tour[-1]] += 1\n\n  return heuristics_matrix",
          "objective": 14.14317,
          "other_inf": null,
          "SLOC": 46.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 359.4073508826329
     },
     {
          "algorithm": "This algorithm generates multiple random tours, calculates the average frequency of each edge appearing in the shortest tours, and returns a matrix representing these frequencies as heuristics.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm generates multiple random tours, calculates the average frequency of each edge appearing in the shortest tours, and returns a matrix representing these frequencies as heuristics.}\"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 1000\n    shortest_tours = []\n\n    for _ in range(num_samples):\n        permutation = np.random.permutation(n)\n        tour_length = 0\n        for i in range(n - 1):\n            tour_length += distance_matrix[permutation[i], permutation[i+1]]\n        tour_length += distance_matrix[permutation[-1], permutation[0]]\n        shortest_tours.append((permutation, tour_length))\n\n    shortest_tours = sorted(shortest_tours, key=lambda x: x[1])\n    \n    num_best = min(100, num_samples)\n    best_tours = shortest_tours[:num_best]\n\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    for tour, _ in best_tours:\n        for i in range(n - 1):\n            heuristics_matrix[tour[i], tour[i+1]] += 1\n            heuristics_matrix[tour[i+1], tour[i]] += 1\n        heuristics_matrix[tour[-1], tour[0]] += 1\n        heuristics_matrix[tour[0], tour[-1]] += 1\n        \n    heuristics_matrix = heuristics_matrix / num_best\n    return heuristics_matrix",
          "objective": 14.38661,
          "other_inf": null,
          "SLOC": 46.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 359.4073508826329
     },
     {
          "algorithm": "This algorithm samples many random tours, and assigns higher edge probabilities to edges that appear more frequently in shorter tours.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm samples many random tours, and assigns higher edge probabilities to edges that appear more frequently in shorter tours.}\"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 1000\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    for _ in range(num_samples):\n        # Generate a random tour\n        tour = np.random.permutation(n)\n\n        # Calculate the tour length\n        tour_length = 0\n        for i in range(n - 1):\n            tour_length += distance_matrix[tour[i], tour[i+1]]\n        tour_length += distance_matrix[tour[-1], tour[0]]\n        \n        # Update the heuristics matrix based on tour length\n        for i in range(n - 1):\n            heuristics_matrix[tour[i], tour[i+1]] += 1.0 / tour_length\n            heuristics_matrix[tour[i+1], tour[i]] += 1.0 / tour_length # Ensure symmetry\n        heuristics_matrix[tour[-1], tour[0]] += 1.0 / tour_length\n        heuristics_matrix[tour[0], tour[-1]] += 1.0 / tour_length # Ensure symmetry\n\n    return heuristics_matrix",
          "objective": 20.40848,
          "other_inf": null,
          "SLOC": 32.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 223.47971260168305
     },
     {
          "algorithm": "This algorithm samples multiple random tours, calculates the frequency of each edge appearing in those tours, and uses these frequencies as heuristics to indicate the likelihood of an edge being part of the optimal TSP solution.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"\n    {This algorithm samples multiple random tours, calculates the frequency of each edge appearing in those tours, and uses these frequencies as heuristics to indicate the likelihood of an edge being part of the optimal TSP solution.}\n    \"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 1000\n    edge_counts = np.zeros_like(distance_matrix, dtype=float)\n\n    for _ in range(num_samples):\n        # Generate a random permutation of nodes (excluding the starting node)\n        nodes = list(range(1, n))\n        np.random.shuffle(nodes)\n        tour = [0] + nodes + [0]  # Start and end at node 0\n\n        # Count the occurrences of each edge in the tour\n        for i in range(n):\n            u = tour[i]\n            v = tour[i+1]\n            edge_counts[u, v] += 1\n            edge_counts[v, u] += 1  # Assuming symmetric distance matrix\n\n    # Normalize the edge counts to get probabilities (heuristics)\n    heuristics_matrix = edge_counts / num_samples\n\n    return heuristics_matrix",
          "objective": 20.52712,
          "other_inf": null,
          "SLOC": 32.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 223.47971260168305
     },
     {
          "algorithm": "This algorithm samples multiple random tours, then aggregates the edge frequencies across all sampled tours to create a heuristic matrix, indicating the promise of each edge.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"\n    {This algorithm samples multiple random tours, then aggregates the edge frequencies across all sampled tours to create a heuristic matrix, indicating the promise of each edge.}\n    \"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 100\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    for _ in range(num_samples):\n        # Generate a random tour\n        tour = np.random.permutation(n)\n        tour = np.append(tour, tour[0])  # Return to starting node\n\n        # Update heuristics matrix based on edges in this tour\n        for i in range(n):\n            u = tour[i]\n            v = tour[i + 1]\n            heuristics_matrix[u, v] += 1\n            heuristics_matrix[v, u] += 1  # Ensure symmetry\n\n    # Normalize the heuristic matrix by the number of samples\n    heuristics_matrix /= num_samples\n\n    return heuristics_matrix",
          "objective": 20.62962,
          "other_inf": null,
          "SLOC": 46.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 359.4073508826329
     },
     {
          "algorithm": "This algorithm estimates edge importance by sampling random tours, accepting only those with lengths shorter than a threshold, and then averaging the frequency with which each edge appears in the accepted tours.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"\n    {This algorithm estimates edge importance by sampling random tours, accepting only those with lengths shorter than a threshold, and then averaging the frequency with which each edge appears in the accepted tours.}\n    \"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 1000\n    threshold_factor = 1.5\n    \n    # Calculate a rough estimate of the optimal tour length to set a threshold\n    avg_distance = np.mean(distance_matrix)\n    threshold = threshold_factor * avg_distance * n  # Adjust threshold as needed\n    \n    edge_counts = np.zeros_like(distance_matrix, dtype=float)\n    num_accepted = 0\n\n    for _ in range(num_samples):\n        # Generate a random tour\n        tour = np.random.permutation(n)\n        tour_length = 0\n        for i in range(n - 1):\n            tour_length += distance_matrix[tour[i], tour[i+1]]\n        tour_length += distance_matrix[tour[-1], tour[0]]\n\n        # Accept the tour if it's shorter than the threshold\n        if tour_length < threshold:\n            num_accepted += 1\n            for i in range(n - 1):\n                edge_counts[tour[i], tour[i+1]] += 1\n                edge_counts[tour[i+1], tour[i]] += 1  # Ensure symmetry\n            edge_counts[tour[-1], tour[0]] += 1\n            edge_counts[tour[0], tour[-1]] += 1\n            \n    # Normalize edge counts to get probabilities\n    if num_accepted > 0:\n        heuristics_matrix = edge_counts / num_accepted\n    else:\n        heuristics_matrix = np.ones_like(distance_matrix) / (n * (n - 1)) # Initialize with small values, avoiding division by zero.\n\n    return heuristics_matrix",
          "objective": 20.71105,
          "other_inf": null,
          "SLOC": 32.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 223.47971260168305
     },
     {
          "algorithm": "This algorithm iteratively samples random tours, biases the sampling towards shorter tours, and accumulates edge usage counts to estimate edge probabilities for inclusion in the final solution.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm iteratively samples random tours, biases the sampling towards shorter tours, and accumulates edge usage counts to estimate edge probabilities for inclusion in the final solution.}\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n    num_samples = 1000  # Number of tours to sample\n    \n    for _ in range(num_samples):\n        # Generate a random tour\n        tour = np.random.permutation(n)\n        \n        # Calculate the tour length\n        tour_length = 0\n        for i in range(n - 1):\n            tour_length += distance_matrix[tour[i], tour[i+1]]\n        tour_length += distance_matrix[tour[-1], tour[0]]\n        \n        # Bias the contribution based on tour length\n        weight = np.exp(-tour_length / 100)  # Adjust the divisor to control the bias strength\n\n        # Update heuristics matrix based on edges in the tour\n        for i in range(n - 1):\n            heuristics_matrix[tour[i], tour[i+1]] += weight\n            heuristics_matrix[tour[i+1], tour[i]] += weight  # Ensure symmetry\n        heuristics_matrix[tour[-1], tour[0]] += weight\n        heuristics_matrix[tour[0], tour[-1]] += weight  # Ensure symmetry\n    \n    # Normalize heuristics matrix\n    heuristics_matrix = heuristics_matrix / np.max(heuristics_matrix)\n\n    return heuristics_matrix",
          "objective": 20.81598,
          "other_inf": null,
          "SLOC": 46.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 359.4073508826329
     },
     {
          "algorithm": "This algorithm estimates the probability of including an edge in the optimal TSP tour by sampling random tours, recording edge occurrences in short tours, and normalizing the counts to obtain a heuristic matrix.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"\n    {This algorithm estimates the probability of including an edge in the optimal TSP tour by sampling random tours, recording edge occurrences in short tours, and normalizing the counts to obtain a heuristic matrix.}\n    \"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 1000\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    for _ in range(num_samples):\n        # Generate a random tour\n        tour = np.random.permutation(n)\n        \n        # Calculate the tour length\n        tour_length = 0\n        for i in range(n - 1):\n            tour_length += distance_matrix[tour[i], tour[i + 1]]\n        tour_length += distance_matrix[tour[n - 1], tour[0]]\n        \n        # Threshold for short tours based on average edge distance\n        avg_distance = np.mean(distance_matrix)\n        threshold = n * avg_distance * 1.5 # Adjust threshold as needed\n\n        if tour_length < threshold:\n            # Increment the counts for edges in the tour\n            for i in range(n - 1):\n                heuristics_matrix[tour[i], tour[i + 1]] += 1\n                heuristics_matrix[tour[i + 1], tour[i]] += 1 # Symmetry\n            heuristics_matrix[tour[n - 1], tour[0]] += 1\n            heuristics_matrix[tour[0], tour[n-1]] += 1\n            \n    # Normalize the matrix to get probabilities\n    total_occurrences = np.sum(heuristics_matrix)\n    if total_occurrences > 0:\n        heuristics_matrix /= total_occurrences\n\n    return heuristics_matrix",
          "objective": 20.90399,
          "other_inf": null,
          "SLOC": 46.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 359.4073508826329
     },
     {
          "algorithm": "This algorithm samples a multitude of random tours and for each edge counts how often it appears in the best tours, thereby constructing a heuristic matrix.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"{This algorithm samples a multitude of random tours and for each edge counts how often it appears in the best tours, thereby constructing a heuristic matrix.}\"\"\"\n    n = distance_matrix.shape[0]\n    num_samples = 1000\n    best_tour_length = np.inf\n    best_tours = []\n    edge_counts = np.zeros_like(distance_matrix, dtype=int)\n\n    for _ in range(num_samples):\n        tour = np.random.permutation(n)\n        tour_length = 0\n        for i in range(n - 1):\n            tour_length += distance_matrix[tour[i], tour[i+1]]\n        tour_length += distance_matrix[tour[-1], tour[0]]\n\n        if tour_length < best_tour_length:\n            best_tour_length = tour_length\n            best_tours = [tour]\n        elif tour_length == best_tour_length:\n            best_tours.append(tour)\n\n    for tour in best_tours:\n        for i in range(n - 1):\n            u, v = sorted((tour[i], tour[i+1]))\n            edge_counts[u, v] += 1\n            edge_counts[v, u] += 1\n        u, v = sorted((tour[-1], tour[0]))\n        edge_counts[u, v] += 1\n        edge_counts[v, u] += 1\n    \n    heuristics_matrix = edge_counts / len(best_tours)\n    return heuristics_matrix",
          "objective": 21.11381,
          "other_inf": null,
          "SLOC": 46.0,
          "cyclomatic_complexity": 9.0,
          "halstead": 359.4073508826329
     },
     {
          "algorithm": "This algorithm generates multiple random tours, iteratively improves them using 2-opt swaps, and aggregates edge frequencies across these improved tours to estimate edge desirability.",
          "code": "import numpy as np\n\ndef heuristics_v2(distance_matrix):\n    \"\"\"\n    {This algorithm generates multiple random tours, iteratively improves them using 2-opt swaps, and aggregates edge frequencies across these improved tours to estimate edge desirability.}\n    \"\"\"\n    num_nodes = distance_matrix.shape[0]\n    num_iterations = 100\n    heuristics_matrix = np.zeros_like(distance_matrix, dtype=float)\n\n    for _ in range(num_iterations):\n        # 1. Generate a random tour\n        tour = np.random.permutation(num_nodes)\n        \n        # 2. Improve the tour using 2-opt swaps\n        improved_tour = two_opt(tour, distance_matrix)\n\n        # 3. Update heuristics_matrix based on the improved tour\n        for i in range(num_nodes):\n            node1 = improved_tour[i]\n            node2 = improved_tour[(i + 1) % num_nodes]\n            heuristics_matrix[node1, node2] += 1\n            heuristics_matrix[node2, node1] += 1\n\n    # Normalize the heuristics matrix\n    heuristics_matrix = heuristics_matrix / num_iterations\n\n    return heuristics_matrix\n\ndef two_opt(route, distance_matrix):\n    \"\"\"\n    Implements 2-opt swaps to improve a given route.\n    \"\"\"\n    best_route = route.copy()\n    improved = True\n    while improved:\n        improved = False\n        for i in range(1, len(route) - 2):\n            for k in range(i + 1, len(route)):\n                if k - i == 1:\n                    continue  # Skip adjacent edges\n                new_route = route[:i] + route[i:k][::-1] + route[k:]\n                \n                current_cost = (\n                    distance_matrix[route[i - 1], route[i]] +\n                    distance_matrix[route[k - 1], route[k]]\n                )\n                new_cost = (\n                    distance_matrix[route[i - 1], route[k - 1]] +\n                    distance_matrix[route[i], route[k]]\n                )\n                \n                if new_cost < current_cost:\n                    best_route = new_route.copy()\n                    route = new_route.copy()\n                    improved = True\n    return heuristics_matrix",
          "objective": Infinity,
          "other_inf": null,
          "SLOC": null,
          "cyclomatic_complexity": null,
          "halstead": null
     }
]