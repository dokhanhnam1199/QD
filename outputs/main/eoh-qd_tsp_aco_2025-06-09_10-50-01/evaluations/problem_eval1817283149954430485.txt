import numpy as np

def heuristics_v2(distance_matrix):
    """{This algorithm combines edge frequency sampling with a reinforcement learning approach, rewarding edges present in shorter paths and penalizing those in longer paths, updating a heuristic matrix to guide future sampling.}"""
    n = distance_matrix.shape[0]
    heuristics_matrix = np.ones_like(distance_matrix)
    
    num_episodes = 100
    num_steps = n * 2
    learning_rate = 0.1
    discount_factor = 0.9

    for _ in range(num_episodes):
        start_node = np.random.randint(n)
        current_node = start_node
        unvisited_nodes = set(range(n))
        unvisited_nodes.remove(current_node)
        path = [current_node]
        
        total_reward = 0
        
        for _ in range(num_steps):
            if not unvisited_nodes:
                next_node = start_node
            else:
                probabilities = heuristics_matrix[current_node, list(unvisited_nodes)]
                probabilities = probabilities / np.sum(probabilities)
                
                next_node = np.random.choice(list(unvisited_nodes), p=probabilities)
            
            reward = -distance_matrix[current_node, next_node]
            total_reward += reward

            if next_node == start_node and len(unvisited_nodes) ==0:
                unvisited_nodes = set()
            elif next_node in unvisited_nodes:
                unvisited_nodes.remove(next_node)

            path.append(next_node)
            
            # Update heuristics for the edge (current_node, next_node)
            heuristics_matrix[current_node, next_node] += learning_rate * reward
            heuristics_matrix[next_node, current_node] += learning_rate * reward
            
            current_node = next_node

    return heuristics_matrix
