{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by the 'path integral' formulation: explore multiple possible futures.\n    In this case, a superposition of different bin assignments, weighted by\n    the \"probability\" of that assignment leading to a good overall packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 1e-9 # Prevent division by zero, very small number.\n\n    # Heuristic 1: \"First Fit Decreasing\" adaptation: Favor bins that are already somewhat full, but can still accommodate the item\n    space_utilization = (1 - bins_remain_cap / 1.0) # Assuming bins of size 1.0\n\n    # Heuristic 2: Minimize wasted space, but penalize very tight fits to encourage efficient packing later.\n    wasted_space = bins_remain_cap - item\n\n    # Heuristic 3: \"Level of Uncertainty\". Small amount of randomness will ensure that we don't end up in local optima.\n    uncertainty = np.random.rand(len(bins_remain_cap)) * 0.01\n\n    # Create a 'potential energy' function that combines these heuristics\n    potential_energy = - space_utilization + np.abs(wasted_space) + uncertainty\n\n    # Convert the potential energy into a probability-like distribution\n    # We take the exponential to map negative energies to [0, 1] range (probability).\n    probabilities = np.exp(-potential_energy)\n\n    # Zero out probabilities where the item doesn't fit\n    probabilities[bins_remain_cap < item] = 0.0\n\n    # Normalize to get probabilities (optional, but can help numerical stability).\n    total_probability = np.sum(probabilities)\n    if total_probability > 0:\n        probabilities /= total_probability\n    else: # if total probability is zero, assign a small equal probability to each of the bins that will fit item\n        eligible_bins = bins_remain_cap >= item\n        probabilities[eligible_bins] = 1.0 / np.sum(eligible_bins)\n\n    return probabilities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Inspired by black hole physics:\n    Bins nearing capacity (event horizon) have higher priority.\n    Larger items warp the \"spacetime\" (bin capacity) more.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero and negative values in log\n    epsilon = 1e-9\n    valid_bins = bins_remain_cap > epsilon\n\n    priorities = np.zeros_like(bins_remain_cap)\n\n    if np.any(valid_bins):\n        remain_cap_valid = bins_remain_cap[valid_bins]\n        # Calculate \"gravitational potential\" based on remaining capacity.\n        # Bins with capacity closer to item size have higher potential (priority).\n        potential = np.exp(-np.abs(remain_cap_valid - item) / (item + epsilon))\n\n        # Normalize the remaining capacity\n        normalized_cap = remain_cap_valid / np.max(bins_remain_cap)\n\n        # Combine potential with remaining capacity\n        priorities[valid_bins] = potential * (1 - normalized_cap) # Prefer bins that aren't already too full\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic directly calculates priorities based on remaining capacity, penalizing bins that cannot fit, and favoring bins with smaller remaining space, while the worst attempts a complex combination of perfect fit bonus, can-fit condition, used bin bonus and almost full penalty. The best is more concise and focused. Comparing (2nd best) vs (2nd worst), we see the second best introduces ideal remaining range. Comparing (1st) vs (2nd), we see (1st) uses inverse of remaining space with an epsilon to avoid division by zero, while (2nd) introduces an \"ideal remaining range\" and small randomness. (3rd) vs (4th) show that (3rd) adds a gravitational pull effect (higher priority to fuller bins) and slight preference to more empty bins to distribute load, while (4th) prioritize bins based on space utilization around 0.8 and gives priority based on how full the bins are. Comparing (second worst) vs (worst), we see (second worst) prioritizes based on waste relative to the mean waste, penalizes waste under 0.1, while (worst) is a complex combination. Overall: Simpler heuristics focusing on remaining capacity and avoiding fragmentation tend to perform better. Penalizing infeasible bins with -inf is very useful. The \"sweet spot\" for remaining capacity (not too much waste, not too little) is important. Exploration via randomness can help but should be a small factor. Overly complex combinations of bonuses and penalties might be detrimental.\n- \nOkay, here's a redefinition of \"Current Self-Reflection\" optimized for designing better heuristics, avoiding pitfalls, and maximizing usefulness, presented in a structured format:\n\n*   **Keywords:** Simplicity, Core Objectives (Space/Fragmentation), Infeasibility, Ideal Capacity, Incremental Complexity, Evaluation.\n\n*   **Advice:** Begin with simple heuristics focused on minimizing waste and fragmentation. Represent infeasibility clearly (e.g., -inf). Define and test different \"ideal remaining capacity\" metrics to guide allocation.\n\n*   **Avoid:** Overly complex bonus/penalty systems early on. Introduce complexity only after thoroughly evaluating simpler heuristics.\n\n*   **Explanation:** Prioritize a clear understanding of the basic heuristic's performance *before* layering on refinements. Measure the impact of each added element. Focus on core goals first.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}