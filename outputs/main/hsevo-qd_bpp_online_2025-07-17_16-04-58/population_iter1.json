[
  {
    "stdout_filepath": "problem_iter0_stdout0.txt",
    "code_path": "problem_iter0_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities",
    "response_id": 0,
    "obj": 149.30195452732352,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 11.60964047443681,
    "mi": 94.04446327225541,
    "token_count": 47.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Calculate wasted space if item is added to each bin.\n    wasted_space = bins_remain_cap - item\n\n    # Give a very high priority to bins where the item fits perfectly.\n    perfect_fit = np.isclose(wasted_space, 0)\n    priorities[perfect_fit] = np.inf\n\n    # Give high priority to bins where the wasted space is minimal and the item fits.\n    fit = wasted_space >= 0\n    if np.any(fit):\n        priorities[fit] = 1.0 / (wasted_space[fit] + 1e-6)  # Avoid division by zero\n\n        # Bonus for filling the bin more completely (higher item/capacity ratio).\n        priorities[fit] += item / (bins_remain_cap[fit] + 1e-6)\n\n    # Very negative priority for bins where item doesn't fit.\n    priorities[~fit] = -np.inf\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 20, in priority_v2\n    \nOverflowError: cannot convert float infinity to integer\n11\n1\n264.97209216286\n80.41308480637692\n178\n"
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities with a base value (e.g., all zeros)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Filter bins that can actually accommodate the item\n    feasible_bins = bins_remain_cap >= item\n\n    if not np.any(feasible_bins):\n        # No bin can fit the item. Return low priorities for all. Avoid errors.\n        return priorities\n\n    # Calculate remaining capacity AFTER placing the item (if possible)\n    remaining_capacity_after_placement = bins_remain_cap - item\n    remaining_capacity_after_placement[remaining_capacity_after_placement < 0] = -1  # Handle infeasible bins without np.inf\n\n    # Prioritize bins with smaller remaining space AFTER placement.\n    # This encourages filling bins completely.\n    # Also, penalize nearly-full bins more heavily. A slight margin may be desirable to accommodate future items.\n\n    priorities[feasible_bins] = 1.0 / (remaining_capacity_after_placement[feasible_bins] + 0.00001) # Avoid division by zero\n\n    # Boost priority of bins that are close to being full, but only if feasible.\n    almost_full_threshold = 0.1  # e.g., within 10% of item's size. Fine-tune this parameter\n    almost_full_bins = feasible_bins & (bins_remain_cap < item + almost_full_threshold * item)\n    priorities[almost_full_bins] += 5.0  # A larger value to significantly increase the priority\n\n    # Very small capacity bins are penalized harshly but not excluded\n    # Penalizes fragmented fills and may create bin almost full but not full\n    small_capacity_threshold = 0.2\n    small_capacity_bins = feasible_bins & (bins_remain_cap < small_capacity_threshold)\n    priorities[small_capacity_bins] -= 2.0\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 264.97209216286,
    "mi": 80.41308480637692,
    "token_count": 178.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response2.txt_stdout.txt",
    "code_path": "problem_iter1_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # First, heavily penalize bins that cannot fit the item\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf  # Assign infinitely low priority to infeasible bins\n\n    # For feasible bins:\n\n    # 1. Calculate the wasted space (remaining capacity after adding item).\n    wasted_space = bins_remain_cap - item\n\n    # 2. Prioritize bins with less wasted space. Smaller wasted space is better.\n    # To avoid division by zero and handle the case where wasted_space is exactly zero,\n    # add a small epsilon to the wasted space.\n    epsilon = 1e-9\n    priorities[~infeasible_bins] = -wasted_space[~infeasible_bins] # Higher priority for lower wasted space\n\n    # 3. Apply a \"gravitational\" pull effect. Give higher priority to bins that are already relatively full.\n    #    The more full, the greater the gravitational force attracting the new item.\n\n    fill_ratios = (bins_remain_cap - wasted_space) / (bins_remain_cap + epsilon)  # Avoid division by zero, and use total bin capacity, if known, can change this.\n    priorities[~infeasible_bins] += fill_ratios[~infeasible_bins] # Higher priority to more full bins.\n\n    # 4. A slight preference to more empty bins to distribute load at start\n    initial_fullness = 1.0 - (bins_remain_cap / np.max(bins_remain_cap))\n    priorities[~infeasible_bins] += 0.1 * initial_fullness[~infeasible_bins]\n\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 264.97209216286,
    "mi": 80.41308480637692,
    "token_count": 178.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response3.txt_stdout.txt",
    "code_path": "problem_iter1_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins that have enough remaining capacity to fit the item,\n    favoring those with smaller remaining space (to avoid fragmentation).  Bins that cannot\n    fit the item are given a very low priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item fits.\n    fit_mask = bins_remain_cap >= item\n\n    # If no bin can fit the item, assign a small priority to all bins, and favour the fullest.\n    if not np.any(fit_mask):\n      priorities = bins_remain_cap/ np.max(bins_remain_cap) if np.max(bins_remain_cap)>0 else np.zeros_like(bins_remain_cap, dtype=float)\n      return priorities\n\n    # Calculate remaining space after placing the item in suitable bins.\n    remaining_space = bins_remain_cap[fit_mask] - item\n\n    # Prioritize bins based on the inverse of remaining space to favor small remaining space\n    # After substraction from total, to encourage larger remaining space where fragmentation could be higher.\n    priorities[fit_mask] = 1.0 / (remaining_space + 1e-9) #Add a small value to avoid division by zero.\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 264.97209216286,
    "mi": 80.41308480637692,
    "token_count": 178.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # First-Fit Decreasing heuristic-inspired priority\n            space_left = cap - item\n            priorities[i] = 1.0 / (space_left + 0.0001)  # Favor bins with less remaining space\n\n            # Improve bin usage: prioritize bins that are close to full after adding the item, but not overfull.\n\n            # Alternative approach: prioritize bins that are more than half-full, if possible\n            if cap > 2 * item / 3.0:  # If we have some space to play with before getting full...\n                 priorities[i] *= (cap / item) # Boost based on \"closeness\" to item\n        else:\n            priorities[i] = -1e9  # Very low priority for bins that can't fit the item\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.999976869999955 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response5.txt_stdout.txt",
    "code_path": "problem_iter1_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function considers several factors:\n\n    1.  Whether the item fits in the bin (otherwise, priority is -infinity).\n    2.  How much empty space would be left after adding the item.  We penalize\n        bins that would be left with very small remaining capacity, as those\n        bins are unlikely to be useful for later items.  We also penalize bins\n        with large remaining capacity, as that suggests we're not filling them\n        efficiently.  The \"sweet spot\" is somewhere in between.\n    3.  The current fill level of the bin.  We prefer to add items to bins\n        that are already relatively full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if item > cap:\n            priorities[i] = -np.inf  # Item doesn't fit.\n\n        else:\n            remaining_after_fit = cap - item\n\n            # Reward bins where adding the item leads to an OK remaining cap\n            # (not too small, not too large).  We use a Gaussian-like penalty.\n            ideal_remaining = 0.25  # Ideally, leave 25% of the bin empty.\n            penalty_width = 0.25    # Spread of the penalty.\n            remaining_penalty = -((remaining_after_fit - ideal_remaining)**2) / (2 * penalty_width**2)\n\n\n            # Prefer filling partially filled bins more than empty ones\n            current_fill_level = 1.0 - (cap / 1.0)  # Assumes bin capacity is 1.0\n            fill_level_reward = current_fill_level\n\n            priorities[i] = remaining_penalty + fill_level_reward #+ bin_index_reward\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.9999732 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response6.txt_stdout.txt",
    "code_path": "problem_iter1_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Inspired by black hole physics:\n    Bins nearing capacity (event horizon) have higher priority.\n    Larger items warp the \"spacetime\" (bin capacity) more.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero and negative values in log\n    epsilon = 1e-9\n    valid_bins = bins_remain_cap > epsilon\n\n    priorities = np.zeros_like(bins_remain_cap)\n\n    if np.any(valid_bins):\n        remain_cap_valid = bins_remain_cap[valid_bins]\n        # Calculate \"gravitational potential\" based on remaining capacity.\n        # Bins with capacity closer to item size have higher potential (priority).\n        potential = np.exp(-np.abs(remain_cap_valid - item) / (item + epsilon))\n\n        # Normalize the remaining capacity\n        normalized_cap = remain_cap_valid / np.max(bins_remain_cap)\n\n        # Combine potential with remaining capacity\n        priorities[valid_bins] = potential * (1 - normalized_cap) # Prefer bins that aren't already too full\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 264.97209216286,
    "mi": 80.41308480637692,
    "token_count": 178.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Inspired by the 'path integral' formulation: explore multiple possible futures.\n    In this case, a superposition of different bin assignments, weighted by\n    the \"probability\" of that assignment leading to a good overall packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 1e-9 # Prevent division by zero, very small number.\n\n    # Heuristic 1: \"First Fit Decreasing\" adaptation: Favor bins that are already somewhat full, but can still accommodate the item\n    space_utilization = (1 - bins_remain_cap / 1.0) # Assuming bins of size 1.0\n\n    # Heuristic 2: Minimize wasted space, but penalize very tight fits to encourage efficient packing later.\n    wasted_space = bins_remain_cap - item\n\n    # Heuristic 3: \"Level of Uncertainty\". Small amount of randomness will ensure that we don't end up in local optima.\n    uncertainty = np.random.rand(len(bins_remain_cap)) * 0.01\n\n    # Create a 'potential energy' function that combines these heuristics\n    potential_energy = - space_utilization + np.abs(wasted_space) + uncertainty\n\n    # Convert the potential energy into a probability-like distribution\n    # We take the exponential to map negative energies to [0, 1] range (probability).\n    probabilities = np.exp(-potential_energy)\n\n    # Zero out probabilities where the item doesn't fit\n    probabilities[bins_remain_cap < item] = 0.0\n\n    # Normalize to get probabilities (optional, but can help numerical stability).\n    total_probability = np.sum(probabilities)\n    if total_probability > 0:\n        probabilities /= total_probability\n    else: # if total probability is zero, assign a small equal probability to each of the bins that will fit item\n        eligible_bins = bins_remain_cap >= item\n        probabilities[eligible_bins] = 1.0 / np.sum(eligible_bins)\n\n    return probabilities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 264.97209216286,
    "mi": 80.41308480637692,
    "token_count": 178.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response8.txt_stdout.txt",
    "code_path": "problem_iter1_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins that have enough space for the item,\n    and then among those, it prefers bins where the remaining space after\n    adding the item is relatively small, but not too small (to avoid\n    excessive fragmentation). It also introduces a small random element\n    to break ties and encourage exploration of different bin configurations.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Filter out bins that don't have enough capacity.\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        #If no bins can fit the item, try to find the best fit by minimizing wasted space by creating a score based on remaining space\n        ratios = item / bins_remain_cap\n        priorities = 1 - ratios\n        return priorities\n\n    # Calculate remaining capacity after adding the item for valid bins.\n    remaining_capacity = bins_remain_cap[valid_bins] - item\n\n    # Prioritize bins where the remaining capacity is small, but not too small.\n    # The 'ideal' remaining capacity is a fraction of the original capacity,\n    # let's say between 0.1 and 0.3 of the original capacity (assuming bins have capacity 1).\n    ideal_remaining_range = (0.1, 0.3)\n    # create priority that peaks in ideal remaining range, penalizing if less than .1 and penalizing if greater than .3\n    normalized_remaining = np.clip(remaining_capacity,ideal_remaining_range[0],ideal_remaining_range[1])\n    normalized_remaining = (normalized_remaining-ideal_remaining_range[0])/(ideal_remaining_range[1]-ideal_remaining_range[0])\n\n    # Assign priority based on the normalized remaining capacity.  We invert\n    # because lower remaining cap = better, close to zero\n    priorities[valid_bins] = 1 - (remaining_capacity / bins_remain_cap[valid_bins]) # Use remaining space ration\n\n    # Adding a small randomness\n    priorities[valid_bins] += np.random.rand(np.sum(valid_bins)) * 0.01\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 264.97209216286,
    "mi": 80.41308480637692,
    "token_count": 178.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response9.txt_stdout.txt",
    "code_path": "problem_iter1_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Aims to balance bin utilization and avoid excessive fragmentation.\n    It gives high priority to bins where the item fits reasonably well,\n    but not perfectly (to avoid creating almost-empty bins).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Define constants for the ideal fit range.  These should ideally be parameters adjusted\n    # using historical information. But alas, I am only designing the priority function and not\n    # an entire learning system.\n\n    ideal_fit_lower_bound = 0.6 #60% bin utilization when item is added\n    ideal_fit_upper_bound = 0.95 # 95% bin utilization when item is added.  Less than 1 to avoid trivial best fits.\n\n\n    for i, cap in enumerate(bins_remain_cap):\n        if item <= cap:\n            # Calculate utilization after adding the item\n            utilization = (item) / cap\n            # Priority is higher if the utilization is within the ideal range.\n            # We prefer utilization that are close to the 'sweet spot'.\n            if ideal_fit_lower_bound <= (1 - (cap - item)) <= ideal_fit_upper_bound:\n                priorities[i] = 1 / (abs(1 - (cap - item) - (ideal_fit_lower_bound + ideal_fit_upper_bound) / 2) + 0.001) #closer to middle higher priority, avoids division by zero\n            else:\n                # Slightly penalize bins with excessive or very little space\n                priorities[i] = max(0, 1 - (abs(1 - (cap - item) - (ideal_fit_lower_bound + ideal_fit_upper_bound) / 2)))  # High if near acceptable\n        else:\n            priorities[i] = -np.inf  # Item does not fit\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.999975079999956 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Calculate wasted space if item is added to each bin\n    wasted_space = bins_remain_cap - item\n\n    # Give high priority to bins where the item fits and minimizes wasted space\n    feasible_bins = wasted_space >= 0\n    if np.any(feasible_bins):\n        priorities[feasible_bins] = 1 / (wasted_space[feasible_bins] + 1e-6) # Avoid division by zero\n\n        # Further prioritize bins that are close to full after adding the item\n        fullness = 1 - wasted_space[feasible_bins] / bins_remain_cap[feasible_bins]\n        priorities[feasible_bins] += fullness\n\n    # Give low priority to bins where the item doesn't fit (negative wasted space)\n    infeasible_bins = wasted_space < 0\n    priorities[infeasible_bins] = -np.abs(wasted_space[infeasible_bins]) # Strongly discourage\n\n    return priorities",
    "response_id": 10,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 25, in priority_v2\n    waste = capacity - item\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n11\n1\n264.97209216286\n80.41308480637692\n178\n"
  },
  {
    "stdout_filepath": "problem_iter1_response11.txt_stdout.txt",
    "code_path": "problem_iter1_code11.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function considers several factors:\n    1.  The amount of wasted space if the item is placed in the bin (lower waste is better).\n    2.  The absolute remaining capacity (to prioritize bins that are already somewhat full).\n    3.  Whether the item fits at all.\n    4. A bit of \"strategic fragmentation\" avoidance.  We don't want to fill nearly-full bins unless really necessary, but neither\n       do we want to fill almost-empty bins.\n    \n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, capacity in enumerate(bins_remain_cap):\n        if item <= capacity:\n            waste = capacity - item\n            # Primary factor: Minimize waste (but use reciprocal so larger values are better)\n            # Avoid division by zero by adding a small epsilon\n            waste_priority = 1 / (waste + 0.00001)  \n            \n            # Secondary factor: Reward bins that are already somewhat full\n            # to consolidate items and free up totally empty bins. However, do not\n            # over prioritize fully-filled bins\n            # This is normalized so the max contribution of cap_priority is roughly on the\n            # order of the waste_priority, but can be adjusted with some scaling\n            cap_priority = capacity # raw capacity\n\n            # Combined priority\n            priorities[i] = waste_priority + 0.1 * cap_priority \n            \n            # Minor optimization. The goal is to discourage creating highly fragmented bins.\n            # If placing the item leads to the bin being almost full (e.g. remaining capacity between 0 and item/4), penalize it somewhat\n            if 0 < waste <= item/4:\n               priorities[i] -= 0.2 * waste_priority\n    \n        else:\n            # Item doesn't fit, so priority is zero.\n            priorities[i] = 0.0\n            \n    return priorities",
    "response_id": 11,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99997429999996 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response12.txt_stdout.txt",
    "code_path": "problem_iter1_code12.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities with a small value to avoid division by zero\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate slack (remaining capacity after adding the item)\n    slack = bins_remain_cap - item\n\n    # Prioritize bins where the item fits (slack >= 0)\n    fit_mask = slack >= 0\n\n    if np.any(fit_mask):  # at least one bin fits the item\n        # Calculate a score based on remaining capacity: Prefer bins with tighter fit\n        priorities[fit_mask] = (bins_remain_cap[fit_mask] - item)**-1 # Inverted slack for tighter fit\n\n        # Optionally, apply a transformation (e.g., exponential) for greater discrimination\n        priorities[fit_mask] = np.exp(priorities[fit_mask])\n    else:\n        # If no bin fits, prioritize the bin with least wasted space if item were to be placed\n         priorities = (item - bins_remain_cap)\n         priorities = -priorities\n    return priorities",
    "response_id": 12,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 264.97209216286,
    "mi": 80.41308480637692,
    "token_count": 178.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response13.txt_stdout.txt",
    "code_path": "problem_iter1_code13.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # First consider only bins that can accommodate the item. Others get -inf\n    eligible_bins = bins_remain_cap >= item\n    priorities[~eligible_bins] = -np.inf\n\n    # Among eligible bins, prioritize those with smaller remaining capacity, but not too small\n    # Prioritize based on how much \"waste\" will be created if we place the item\n    waste = bins_remain_cap - item\n    # Penalize very small waste heavily.  Helps to avoid fragmentation. A small constant is introduced to stabilize the score calculation.\n    priorities[eligible_bins] = -np.abs(waste[eligible_bins] - np.mean(waste[eligible_bins]))/(np.std(waste[eligible_bins]) + 1e-6) - 100*(waste[eligible_bins] < 0.1)\n\n    #Prioritize the bins where remain capacity is almost same as item size to avoid small items\n    #priorities = 1 / np.abs(bins_remain_cap - item)\n\n    return priorities",
    "response_id": 13,
    "tryHS": false,
    "obj": 60.62026326286399,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 264.97209216286,
    "mi": 80.41308480637692,
    "token_count": 178.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins that have enough remaining capacity for the item,\n    and among those, it prioritizes bins where the item fills a significant\n    portion of the remaining capacity without overflowing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        # If no bin can fit the item, assign a small negative priority to all bins,\n        # with slightly higher priority for those closest to fitting. This effectively allows the worst-fit strategy.\n        priorities = -1.0 - (item - bins_remain_cap)\n        return priorities\n\n    # Prioritize bins that can fit the item\n    capacities = bins_remain_cap[eligible_bins]\n    fill_ratios = item / capacities\n\n    # Higher fill ratio (item fills the bin more completely) is better, but only if less than 1\n    priorities[eligible_bins] = fill_ratios\n\n    # Add a bonus for bins that are nearly full after adding the item, but aren't overfull\n    nearly_full = np.logical_and(item <= bins_remain_cap, bins_remain_cap - item < 0.1) # Check if remaining cap after placement is less than 0.1\n    priorities[nearly_full] += 0.5  # Adjust this value to prioritize \"nearly full\" bins more or less.\n\n    return priorities",
    "response_id": 14,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 264.97209216286,
    "mi": 80.41308480637692,
    "token_count": 178.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Uses a combination of factors to determine bin priority. It favors bins\n    where the item fits well (not too much wasted space), but also considers\n    whether the bin is already significantly full (reducing the chance of small\n    items later preventing larger items from being packed). Bins that cannot fit\n    the item receive a very low priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Eliminate bins that cannot fit the item. Assign negative infinity to these\n    cannot_fit = bins_remain_cap < item\n    priorities[cannot_fit] = -np.inf\n\n    # 2. Calculate space utilization if item were placed in each bin.\n    space_utilization = item / bins_remain_cap\n    space_utilization[cannot_fit] = 0  # Avoid division by zero after this point\n\n    # 3. Prioritize bins where item fits well.\n    # Favor bins where the item takes up a substantial portion of the remaining space,\n    # but not so much that it leaves very little space behind.\n    fit_priority = np.exp(-np.abs(space_utilization - 0.8))  # Peaks at space_utilization = 0.8\n\n    # 4. Prioritize bins that are already somewhat full.\n    # This discourages spreading items too thinly across bins, improving chance of future items filling them more fully.\n    fullness_priority = (1 - bins_remain_cap)  # Larger number indicates fuller\n    fullness_priority[cannot_fit] = 0\n\n    # Combine Priorities:\n    priorities = fit_priority + fullness_priority\n\n    return priorities",
    "response_id": 15,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 264.97209216286,
    "mi": 80.41308480637692,
    "token_count": 178.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version considers multiple factors:\n    1.  Remaining capacity: Bins with capacity close to item size are preferred (First Fit Decreasing principle).\n    2.  Penalty for exceeding bin capacity: Heavily penalizes exceeding capacity.\n    3.  Reward for perfect fit: Gives a substantial reward for perfect fit.\n    4.  Normalize priorities to avoid very large/small values.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, cap in enumerate(bins_remain_cap):\n        if cap < item:\n            # Significant penalty for exceeding capacity. Avoid this at almost all costs.\n            priorities[i] = -float('inf')\n        elif cap == item:\n            # High reward for perfect fit\n            priorities[i] = 1000.0\n        else:\n            # Prioritize bins that have remaining capacity close to item size.  Use exponential scaling.\n            capacity_utilization = item / cap  # fraction of the bin that would be used.\n            priority_score = np.exp(5 * (1 - np.abs(1 - capacity_utilization))) # Peak priority when cap == item\n\n            priorities[i] = priority_score\n\n    # Normalize the priorities to avoid extremely large or small numbers, while preserving ordering.\n    max_priority = np.max(priorities[np.isfinite(priorities)]) #ignore -inf when normalizing.\n    if np.isfinite(max_priority) and max_priority > 0: #avoid 0 division. make sure some values are not -inf.\n        priorities[np.isfinite(priorities)] /= max_priority # Only normalize those that aren't inf\n    \n    return priorities",
    "response_id": 16,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 264.97209216286,
    "mi": 80.41308480637692,
    "token_count": 178.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response17.txt_stdout.txt",
    "code_path": "problem_iter1_code17.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin. A Feynman-inspired heuristic.\n\n    This heuristic attempts to balance exploration and exploitation. We want to find a good fit quickly,\n    but also consider other bins to avoid getting stuck in local optima (a deep potential well, as I might say).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Basic Feasibility: Rule out bins that are too small. This is like applying a hard energy cutoff.\n    feasible_bins = bins_remain_cap >= item\n\n    # If there are no feasible bins, signal that by returning -inf for all priorities\n    if not np.any(feasible_bins):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # 2. Feynman Path Integral (Sort Of): Consider all possible paths (bins) but weigh them differently.\n    # The closer the item size is to the bin capacity, the better (exploitation). Think of it as minimizing the \"action\"\n    # (wasted space). We also add a small exploration bonus to avoid purely greedy approaches.\n    space_wasted = bins_remain_cap - item\n    space_wasted[space_wasted < 0] = np.inf  # Penalize infeasible bins strongly after the hard cut.\n\n    # This part is like the exponential of the negative action. smaller space wasted means higher \"amplitude\" or priority\n    fit_priority = np.exp(-space_wasted)\n\n    # 3. Encourage Balanced Bin Usage: Give a slight bonus to bins that are relatively empty.\n    #   This is kind of like trying to minimize entanglement between the bins - we don't want a few bins hogging everything.\n    #   We need to normalize it to scale the relative weights.\n\n    normalized_capacities = bins_remain_cap / np.max(bins_remain_cap)  # Range [0, 1]\n    exploration_bonus = 0.1 * normalized_capacities\n\n    # 4. Combine all aspects\n    priorities = feasible_bins * (fit_priority + exploration_bonus)\n\n    # Re-scale, since numpy complains if some of them are 0 and it cannot normalize it\n    # to have unit vector size\n    if np.sum(priorities) == 0:\n        return priorities\n    return priorities",
    "response_id": 17,
    "tryHS": false,
    "obj": 82.17989629038694,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 264.97209216286,
    "mi": 80.41308480637692,
    "token_count": 178.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response18.txt_stdout.txt",
    "code_path": "problem_iter1_code18.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Prioritize bins that can fit the item\n    can_fit = bins_remain_cap >= item\n    priorities[can_fit] += 1  # Give a base priority for being able to fit\n\n    # Prioritize bins with smaller remaining capacity after packing. Attempt \"best fit\"\n    remaining_after_pack = bins_remain_cap - item\n    remaining_after_pack[~can_fit] = np.inf # Penalize bins that cannot fit\n    priorities[can_fit] += 1.0 / (remaining_after_pack[can_fit] + 1e-6) # Add inverse remaining capacity\n\n    # Add a bonus for bins that are nearly full if the item is added. Aim for near perfect fit.\n    near_full_threshold = 0.1 # consider nearly full if remaining capacity is less than 10% of total bin size\n    total_bin_size = bins_remain_cap + (0 * bins_remain_cap)  # Assumes all bins have the same capacity to begin\n    near_full = (remaining_after_pack > 0) & (remaining_after_pack / (total_bin_size + 1e-6) < near_full_threshold) & can_fit\n    priorities[near_full] += 2 # Strong encouragement to near fill\n\n    # Avoid fragmentation, penalize usage of almost empty bins to some extent.\n    nearly_empty_threshold = 0.9 # Consider nearly empty if remaining capacity is > 90% full.\n    nearly_empty = bins_remain_cap / (total_bin_size + 1e-6) > nearly_empty_threshold\n    priorities[nearly_empty] -= 0.5 * (priorities[nearly_empty] > 0) # Reduce priority. Don't go below 0\n\n    return priorities",
    "response_id": 18,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 22, in priority_v2\n    # Give higher priority to bins with remaining capacity closest to item size (Best-Fit heuristic)\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n11\n1\n264.97209216286\n80.41308480637692\n178\n"
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Consider bins where the item fits\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        # Normalize remaining capacity of feasible bins\n        normalized_capacities = bins_remain_cap[feasible_bins] / np.max(bins_remain_cap[feasible_bins])\n\n        # Give higher priority to bins with remaining capacity closest to item size (Best-Fit heuristic)\n        # Use exponential to exaggerate differences\n        priorities[feasible_bins] = np.exp(-np.abs(bins_remain_cap[feasible_bins] - item))\n\n        # Give slight bonus to bins that are fuller (encourages filling existing bins).\n        priorities[feasible_bins] += normalized_capacities * 0.1  # Scale the bonus\n\n        #Penalize bins which have extremely high remain capacity, such as > 3 * item\n        very_large_capacity = bins_remain_cap > 3 * item\n        priorities[very_large_capacity] = 0 # force usage of bins if available\n    else:\n        # If the item doesn't fit in any bin, assign lowest possible priority to all bins.\n        priorities[:] = -1e9 # make the value very small to give zero weight\n\n    return priorities",
    "response_id": 19,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 27, in priority_v2\n    \nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n11\n1\n264.97209216286\n80.41308480637692\n178\n"
  },
  {
    "stdout_filepath": "problem_iter1_response20.txt_stdout.txt",
    "code_path": "problem_iter1_code20.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # 1. Feasibility: Filter out bins that cannot accommodate the item\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf  # Very low priority if infeasible\n\n    # 2. Remaining Capacity Consideration\n    #   - Higher priority to bins with smaller remaining capacity that *can* fit the item.\n    #   - The closer the item size is to the remaining capacity, the higher the priority\n    \n    feasible_bins = ~infeasible_bins\n    if np.any(feasible_bins):\n      priorities[feasible_bins] = (bins_remain_cap[feasible_bins] - item)\n      priorities[feasible_bins] = -np.abs(priorities[feasible_bins]) # Closer to zero is better\n\n      # Normalize the scores to some extent (optional, but can improve performance)\n      min_priority = np.min(priorities[feasible_bins])\n      max_priority = np.max(priorities[feasible_bins])\n\n      if max_priority != min_priority:\n        priorities[feasible_bins] = (priorities[feasible_bins] - min_priority) / (max_priority - min_priority)\n\n\n    return priorities",
    "response_id": 20,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 17, in priority_v2\n    Array of same size as bins_remain_cap with priority score of each bin.\nOverflowError: cannot convert float infinity to integer\n11\n1\n264.97209216286\n80.41308480637692\n178\n"
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function considers a few factors:\n\n    1.  **Capacity Fit:** How well the item fits into the remaining capacity.  Bins with a capacity slightly larger than the item are favored.\n    2.  **Bin Utilization:**  Bins that are already relatively full are favored to consolidate items and open new bins.\n    3.  **Fragmentation Penalty:**  Bins that would leave a small, almost unusable remainder are penalized.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, cap in enumerate(bins_remain_cap):\n        if cap < item:\n            priorities[i] = -np.inf  # Item doesn't fit\n            continue\n\n        # Capacity Fit - Gaussian-like peak around item size\n        capacity_fit = np.exp(-((cap - item) ** 2) / (2 * (item * 0.2) ** 2))  # Standard deviation as 20% of item size\n\n        # Bin Utilization\n        bin_utilization = 1 - (cap / 1.0) # Assume bin size of 1, otherwise scale cap\n\n        # Fragmentation Penalty - Penalize leaving small unusable remainder\n        remainder = cap - item\n        fragmentation_penalty = 0.0\n        if 0 < remainder < 0.1: # Tunable parameter based on average item size. Penalize if remainder is less than 0.1\n            fragmentation_penalty = -10 * (0.1 - remainder)  # Higher negative penalty\n\n        priorities[i] = capacity_fit + 0.5 * bin_utilization + fragmentation_penalty  # Combine the factors with some weighting.  Bin utilization is weighted down.\n\n\n    return priorities",
    "response_id": 21,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.999972119999995 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response22.txt_stdout.txt",
    "code_path": "problem_iter1_code22.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate wasted space if item is placed in each bin\n    wasted_space = bins_remain_cap - item\n\n    # High priority to bins where the item fits (positive wasted space)\n    # and lower wasted space is better (inverse relationship)\n    fit_mask = wasted_space >= 0\n    priorities[fit_mask] = 1.0 / (1.0 + wasted_space[fit_mask]) # Use 1.0 + to avoid division by zero and provide a reasonable score even when wasted_space is zero.\n\n    # Assign negative priority to bins where the item does not fit. Very large negative value ensures these are not chosen.\n    priorities[~fit_mask] = -1e9\n\n    return priorities",
    "response_id": 22,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 264.97209216286,
    "mi": 80.41308480637692,
    "token_count": 178.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response23.txt_stdout.txt",
    "code_path": "problem_iter1_code23.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins that have just enough space for the item,\n    avoiding overly large or small gaps.  It also incorporates a randomness\n    factor to explore different packing arrangements.  A small penalty is\n    added for nearly full bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Calculate remaining capacity after placing the item\n    remaining_after = bins_remain_cap - item\n\n    # Initialize priorities\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Give high priority to bins where the remaining space is small but non-negative\n    # and moderate space available\n    near_fit = (remaining_after >= 0)\n    space_factor = np.exp(-5 * np.abs(remaining_after / item - 0.2)) * near_fit #Prioritize those with a gap between 0 and 0.4 of item size.  Experiment with values\n\n    priorities = space_factor\n\n    # Penalize bins that are already nearly full (to encourage using emptier bins when possible)\n    nearly_full = (bins_remain_cap < 1.1 * item) & (bins_remain_cap >= item)  # Consider as nearly full only if there is a bit extra. Prevents placing items that barely fit if there are better option\n\n    priorities[nearly_full] -= 0.1 #Adjust this penalty, consider zero if you do not want to use it.\n    \n    # Introduce some randomness to avoid getting stuck in local optima\n    randomness = 0.01 * np.random.rand(len(bins_remain_cap))  # Small random noise\n    priorities += randomness\n    #Prioritize the bins that actually fit.\n    priorities[bins_remain_cap < item] = -np.inf\n\n    return priorities",
    "response_id": 23,
    "tryHS": false,
    "obj": 5.963302752293574,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 264.97209216286,
    "mi": 80.41308480637692,
    "token_count": 178.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response24.txt_stdout.txt",
    "code_path": "problem_iter1_code24.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins that have just enough space for the item,\n    avoiding both near-empty bins and bins that are too full. It uses a\n    combination of factors to achieve this:\n\n    1.  A \"fit score\" that is high when the remaining capacity is close to the item size.\n\n    2.  A penalty for bins that are too empty.\n\n    3.  A bonus for bins that are already relatively full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Epsilon to avoid division by zero and log of zero\n    epsilon = 1e-9\n    \n    # Calculate \"fit score\" - higher when remaining capacity is close to item size.\n    fit_score = np.exp(-np.abs(bins_remain_cap - item) / (item + epsilon))\n\n    # Calculate penalty for bins that are too empty (encourage filling nearly full bins)\n    empty_penalty = np.exp(-bins_remain_cap / (item + epsilon)) # larger penalty for larger remain_cap\n\n    # Bonus for bins that are relatively full (avoid fragmenting large bins early)\n    fullness_bonus = bins_remain_cap / (np.max(bins_remain_cap)+epsilon) #Normalized bin capacities\n\n    priorities = fit_score - empty_penalty + fullness_bonus\n    # set priority to 0 if remain_cap is smaller than item\n    priorities[bins_remain_cap < item] = 0.0\n\n    return priorities",
    "response_id": 24,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 264.97209216286,
    "mi": 80.41308480637692,
    "token_count": 178.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response25.txt_stdout.txt",
    "code_path": "problem_iter1_code25.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Calculate remaining capacity after adding the item\n    remaining_capacities = bins_remain_cap - item\n\n    # First Fit Decreasing inspired: Prefer bins where the item fits, but not too snugly\n    fit_mask = remaining_capacities >= 0\n    if np.any(fit_mask):\n        # Give higher priority to bins where remaining capacity is a good fraction of item size\n        priorities[fit_mask] = (remaining_capacities[fit_mask] / item) \n\n        # Penalize bins that are almost full after packing\n        almost_full_mask = (remaining_capacities[fit_mask] / item) < 0.2 \n        priorities[fit_mask][almost_full_mask] *= 0.5  # Reduce priority if it's becoming too full\n\n\n    # If no bin fits, penalize bins heavily based on how much they overflow, but less aggressively than version 1, allowing the placement.\n    else:\n        overflow = item - bins_remain_cap\n        priorities = -np.log(overflow + 1e-6) # Add small constant to avoid log(0)\n\n    return priorities",
    "response_id": 25,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 26, in priority_v2\n    \nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'multiply' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n11\n1\n264.97209216286\n80.41308480637692\n178\n"
  },
  {
    "stdout_filepath": "problem_iter1_response26.txt_stdout.txt",
    "code_path": "problem_iter1_code26.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Try to fill bins as much as possible, but avoid overflowing significantly.\n    # Give a higher priority to bins that can fit the item relatively tightly,\n    # encouraging efficient packing.\n    fit_mask = bins_remain_cap >= item\n    almost_fit_mask = (bins_remain_cap >= item) & (bins_remain_cap < 1.5 * item)  # Adjust 1.5 as needed\n    nearly_full_mask = bins_remain_cap < 0.1\n\n    # Give priority to bins that can fit (positive score) and punish those that can't (negative score)\n    priorities[fit_mask] = 1.0 / (bins_remain_cap[fit_mask] - item + 0.0001) #Prioritize tighter fits\n    priorities[~fit_mask] = -1000.0  # Extremely low priority if it doesn't fit (can adjust value)\n    priorities[nearly_full_mask] = -1000.0 # Never try to add to nearly full bins as they are almost wasted space\n\n    # Add small random number to break ties and avoid getting stuck. Helps exploration.\n    priorities += np.random.rand(len(bins_remain_cap)) * 0.00001\n\n    return priorities",
    "response_id": 26,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 28, in priority_v2\n    potential_waste = bins_remain_cap - item\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n11\n1\n264.97209216286\n80.41308480637692\n178\n"
  },
  {
    "stdout_filepath": "problem_iter1_response27.txt_stdout.txt",
    "code_path": "problem_iter1_code27.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function considers several factors:\n    1. Remaining capacity: Bins with remaining capacity closer to the item size are preferred (first-fit-decreasing inspired).\n    2. Waste minimization: A penalty is applied if adding the item leads to excessive waste.\n    3. Number of Items in the bin (Encourage Filling): Give bin with more items in them higher priority. Assume, this data are captured with the reciprocal of available capacity.\n    4. Prevent excessive filling(Regularization): Prevent very full bins to encourage use of multiple bins.\n\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities with a small value to avoid negative infinities later\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Capacity difference: lower difference is better. Add a tiny offset to avoid div by zero.\n    capacity_diff = np.abs(bins_remain_cap - item) + 1e-9\n    priorities += -capacity_diff  # Invert the difference, so smaller is better (higher priority). Add small negative value to all to make lowest value 0\n\n    # Waste minimization: penalize bins if adding the item leads to substantial waste.\n    potential_waste = bins_remain_cap - item\n    waste_penalty = np.where(potential_waste > 0, -potential_waste, -np.inf)  # Negative waste penalty\n    priorities += waste_penalty\n\n    # Encourage filling: prioritize bins that are already somewhat full (avoid creating many almost-empty bins). We approximate the item_number in bin with its fullness i.e., 1/remaining capacity.\n    fullness_factor = 1.0 / (bins_remain_cap + 1e-9) # Higher value if the bin is fuller\n    priorities += fullness_factor\n\n    # Regularization : if the bin is nearly full, give it some penalty\n    is_nearly_full = np.where(bins_remain_cap < 1.1 * item , -0.5, 0) # 1.1 is somewhat arbitrary here to determine nearness.\n    priorities += is_nearly_full\n\n\n    return priorities",
    "response_id": 27,
    "tryHS": false,
    "obj": 5.195452732349436,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 264.97209216286,
    "mi": 80.41308480637692,
    "token_count": 178.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response28.txt_stdout.txt",
    "code_path": "problem_iter1_code28.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate remaining capacity after placing the item\n    remaining_capacities = bins_remain_cap - item\n\n    # High priority for bins where the item fits (positive remaining capacity)\n    # and lower for bins that are too small or already full (negative or zero remaining capacity)\n    for i, rem_cap in enumerate(remaining_capacities):\n        if rem_cap >= 0:\n            #Prioritize bins with least waste: smaller rem_cap implies higher waste if unused elsewhere\n            priorities[i] = 1.0 / (rem_cap + 1e-6) #Add a small constant to avoid divide by zero\n\n            #Further prioritization: use nearly full bins before relatively empty ones\n            #This can help pack smaller items into partially filled bins first.\n            priorities[i] += bins_remain_cap[i] / (np.sum(bins_remain_cap) + 1e-6) # Normalized capacity. Avoid division by 0\n        else:\n            priorities[i] = -np.inf # Very low priority, don't use the bin.\n    # Add a random component to diversify the bin selection\n    # Adding a random component could help escape local optima by occasionally exploring bins that might not be the highest priority based on current calculations.\n    random_noise = np.random.rand(len(bins_remain_cap)) * 0.01  # Small random values\n    priorities += random_noise\n    return priorities",
    "response_id": 28,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.999979490999976 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Heuristic 1: Prefer bins where the item almost perfectly fits (minimizing wasted space)\n    waste = bins_remain_cap - item\n    perfect_fit_bonus = np.exp(-np.abs(waste) / (item + 0.0001)) # Avoid div by zero & scale the bonus\n\n    # Heuristic 2: Higher priority to bins that can fit the item, lower otherwise.  Set -inf when item cannot fit\n    can_fit = bins_remain_cap >= item\n    priorities = np.where(can_fit, perfect_fit_bonus + (bins_remain_cap - item), -np.inf)\n\n    # Heuristic 3: Slightly reward bins that have already been used. Prevents creating too many nearly empty bins at the start.\n    used_bin_bonus = np.where(bins_remain_cap < np.max(bins_remain_cap), 0.1, 0)  # Small constant bonus\n    priorities = priorities + used_bin_bonus\n    \n    #Heuristic 4: Penalize bins close to full\n    almost_full_penalty = np.where((bins_remain_cap > item) & (bins_remain_cap < 1.2 * item) , -0.05 * (1.2 * item - bins_remain_cap), 0) # small penalty for filling too much\n\n    priorities = priorities + almost_full_penalty\n\n    return priorities",
    "response_id": 29,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "halstead": 264.97209216286,
    "mi": 80.41308480637692,
    "token_count": 178.0,
    "exec_success": true
  }
]