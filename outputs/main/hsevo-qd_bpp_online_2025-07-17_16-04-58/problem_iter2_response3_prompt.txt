{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Uses a combination of factors to determine bin priority. It favors bins\n    where the item fits well (not too much wasted space), but also considers\n    whether the bin is already significantly full (reducing the chance of small\n    items later preventing larger items from being packed). Bins that cannot fit\n    the item receive a very low priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Eliminate bins that cannot fit the item. Assign negative infinity to these\n    cannot_fit = bins_remain_cap < item\n    priorities[cannot_fit] = -np.inf\n\n    # 2. Calculate space utilization if item were placed in each bin.\n    space_utilization = item / bins_remain_cap\n    space_utilization[cannot_fit] = 0  # Avoid division by zero after this point\n\n    # 3. Prioritize bins where item fits well.\n    # Favor bins where the item takes up a substantial portion of the remaining space,\n    # but not so much that it leaves very little space behind.\n    fit_priority = np.exp(-np.abs(space_utilization - 0.8))  # Peaks at space_utilization = 0.8\n\n    # 4. Prioritize bins that are already somewhat full.\n    # This discourages spreading items too thinly across bins, improving chance of future items filling them more fully.\n    fullness_priority = (1 - bins_remain_cap)  # Larger number indicates fuller\n    fullness_priority[cannot_fit] = 0\n\n    # Combine Priorities:\n    priorities = fit_priority + fullness_priority\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin. A Feynman-inspired heuristic.\n\n    This heuristic attempts to balance exploration and exploitation. We want to find a good fit quickly,\n    but also consider other bins to avoid getting stuck in local optima (a deep potential well, as I might say).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Basic Feasibility: Rule out bins that are too small. This is like applying a hard energy cutoff.\n    feasible_bins = bins_remain_cap >= item\n\n    # If there are no feasible bins, signal that by returning -inf for all priorities\n    if not np.any(feasible_bins):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # 2. Feynman Path Integral (Sort Of): Consider all possible paths (bins) but weigh them differently.\n    # The closer the item size is to the bin capacity, the better (exploitation). Think of it as minimizing the \"action\"\n    # (wasted space). We also add a small exploration bonus to avoid purely greedy approaches.\n    space_wasted = bins_remain_cap - item\n    space_wasted[space_wasted < 0] = np.inf  # Penalize infeasible bins strongly after the hard cut.\n\n    # This part is like the exponential of the negative action. smaller space wasted means higher \"amplitude\" or priority\n    fit_priority = np.exp(-space_wasted)\n\n    # 3. Encourage Balanced Bin Usage: Give a slight bonus to bins that are relatively empty.\n    #   This is kind of like trying to minimize entanglement between the bins - we don't want a few bins hogging everything.\n    #   We need to normalize it to scale the relative weights.\n\n    normalized_capacities = bins_remain_cap / np.max(bins_remain_cap)  # Range [0, 1]\n    exploration_bonus = 0.1 * normalized_capacities\n\n    # 4. Combine all aspects\n    priorities = feasible_bins * (fit_priority + exploration_bonus)\n\n    # Re-scale, since numpy complains if some of them are 0 and it cannot normalize it\n    # to have unit vector size\n    if np.sum(priorities) == 0:\n        return priorities\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic directly calculates priorities based on remaining capacity, penalizing bins that cannot fit, and favoring bins with smaller remaining space, while the worst attempts a complex combination of perfect fit bonus, can-fit condition, used bin bonus and almost full penalty. The best is more concise and focused. Comparing (2nd best) vs (2nd worst), we see the second best introduces ideal remaining range. Comparing (1st) vs (2nd), we see (1st) uses inverse of remaining space with an epsilon to avoid division by zero, while (2nd) introduces an \"ideal remaining range\" and small randomness. (3rd) vs (4th) show that (3rd) adds a gravitational pull effect (higher priority to fuller bins) and slight preference to more empty bins to distribute load, while (4th) prioritize bins based on space utilization around 0.8 and gives priority based on how full the bins are. Comparing (second worst) vs (worst), we see (second worst) prioritizes based on waste relative to the mean waste, penalizes waste under 0.1, while (worst) is a complex combination. Overall: Simpler heuristics focusing on remaining capacity and avoiding fragmentation tend to perform better. Penalizing infeasible bins with -inf is very useful. The \"sweet spot\" for remaining capacity (not too much waste, not too little) is important. Exploration via randomness can help but should be a small factor. Overly complex combinations of bonuses and penalties might be detrimental.\n- \nOkay, here's a redefinition of \"Current Self-Reflection\" optimized for designing better heuristics, avoiding pitfalls, and maximizing usefulness, presented in a structured format:\n\n*   **Keywords:** Simplicity, Core Objectives (Space/Fragmentation), Infeasibility, Ideal Capacity, Incremental Complexity, Evaluation.\n\n*   **Advice:** Begin with simple heuristics focused on minimizing waste and fragmentation. Represent infeasibility clearly (e.g., -inf). Define and test different \"ideal remaining capacity\" metrics to guide allocation.\n\n*   **Avoid:** Overly complex bonus/penalty systems early on. Introduce complexity only after thoroughly evaluating simpler heuristics.\n\n*   **Explanation:** Prioritize a clear understanding of the basic heuristic's performance *before* layering on refinements. Measure the impact of each added element. Focus on core goals first.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}