{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins that have enough remaining capacity to fit the item,\n    favoring those with smaller remaining space (to avoid fragmentation).  Bins that cannot\n    fit the item are given a very low priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item fits.\n    fit_mask = bins_remain_cap >= item\n\n    # If no bin can fit the item, assign a small priority to all bins, and favour the fullest.\n    if not np.any(fit_mask):\n      priorities = bins_remain_cap/ np.max(bins_remain_cap) if np.max(bins_remain_cap)>0 else np.zeros_like(bins_remain_cap, dtype=float)\n      return priorities\n\n    # Calculate remaining space after placing the item in suitable bins.\n    remaining_space = bins_remain_cap[fit_mask] - item\n\n    # Prioritize bins based on the inverse of remaining space to favor small remaining space\n    # After substraction from total, to encourage larger remaining space where fragmentation could be higher.\n    priorities[fit_mask] = 1.0 / (remaining_space + 1e-9) #Add a small value to avoid division by zero.\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin. A Feynman-inspired heuristic.\n\n    This heuristic attempts to balance exploration and exploitation. We want to find a good fit quickly,\n    but also consider other bins to avoid getting stuck in local optima (a deep potential well, as I might say).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Basic Feasibility: Rule out bins that are too small. This is like applying a hard energy cutoff.\n    feasible_bins = bins_remain_cap >= item\n\n    # If there are no feasible bins, signal that by returning -inf for all priorities\n    if not np.any(feasible_bins):\n        return np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # 2. Feynman Path Integral (Sort Of): Consider all possible paths (bins) but weigh them differently.\n    # The closer the item size is to the bin capacity, the better (exploitation). Think of it as minimizing the \"action\"\n    # (wasted space). We also add a small exploration bonus to avoid purely greedy approaches.\n    space_wasted = bins_remain_cap - item\n    space_wasted[space_wasted < 0] = np.inf  # Penalize infeasible bins strongly after the hard cut.\n\n    # This part is like the exponential of the negative action. smaller space wasted means higher \"amplitude\" or priority\n    fit_priority = np.exp(-space_wasted)\n\n    # 3. Encourage Balanced Bin Usage: Give a slight bonus to bins that are relatively empty.\n    #   This is kind of like trying to minimize entanglement between the bins - we don't want a few bins hogging everything.\n    #   We need to normalize it to scale the relative weights.\n\n    normalized_capacities = bins_remain_cap / np.max(bins_remain_cap)  # Range [0, 1]\n    exploration_bonus = 0.1 * normalized_capacities\n\n    # 4. Combine all aspects\n    priorities = feasible_bins * (fit_priority + exploration_bonus)\n\n    # Re-scale, since numpy complains if some of them are 0 and it cannot normalize it\n    # to have unit vector size\n    if np.sum(priorities) == 0:\n        return priorities\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic directly calculates priorities based on remaining capacity, penalizing bins that cannot fit, and favoring bins with smaller remaining space, while the worst attempts a complex combination of perfect fit bonus, can-fit condition, used bin bonus and almost full penalty. The best is more concise and focused. Comparing (2nd best) vs (2nd worst), we see the second best introduces ideal remaining range. Comparing (1st) vs (2nd), we see (1st) uses inverse of remaining space with an epsilon to avoid division by zero, while (2nd) introduces an \"ideal remaining range\" and small randomness. (3rd) vs (4th) show that (3rd) adds a gravitational pull effect (higher priority to fuller bins) and slight preference to more empty bins to distribute load, while (4th) prioritize bins based on space utilization around 0.8 and gives priority based on how full the bins are. Comparing (second worst) vs (worst), we see (second worst) prioritizes based on waste relative to the mean waste, penalizes waste under 0.1, while (worst) is a complex combination. Overall: Simpler heuristics focusing on remaining capacity and avoiding fragmentation tend to perform better. Penalizing infeasible bins with -inf is very useful. The \"sweet spot\" for remaining capacity (not too much waste, not too little) is important. Exploration via randomness can help but should be a small factor. Overly complex combinations of bonuses and penalties might be detrimental.\n- \nOkay, here's a redefinition of \"Current Self-Reflection\" optimized for designing better heuristics, avoiding pitfalls, and maximizing usefulness, presented in a structured format:\n\n*   **Keywords:** Simplicity, Core Objectives (Space/Fragmentation), Infeasibility, Ideal Capacity, Incremental Complexity, Evaluation.\n\n*   **Advice:** Begin with simple heuristics focused on minimizing waste and fragmentation. Represent infeasibility clearly (e.g., -inf). Define and test different \"ideal remaining capacity\" metrics to guide allocation.\n\n*   **Avoid:** Overly complex bonus/penalty systems early on. Introduce complexity only after thoroughly evaluating simpler heuristics.\n\n*   **Explanation:** Prioritize a clear understanding of the basic heuristic's performance *before* layering on refinements. Measure the impact of each added element. Focus on core goals first.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}