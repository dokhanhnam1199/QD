{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling. CVRP requires finding the shortest path that visits all given nodes and returns to the starting node. Each node has a demand and each vehicle has a capacity. The total demand of the nodes visited by a vehicle cannot exceed the vehicle capacity. When the total demand exceeds the vehicle capacity, the vehicle must return to the starting node.\nThe `heuristics` function takes as input a distance matrix (shape: n by n), Euclidean coordinates of nodes (shape: n by 2), a vector of customer demands (shape: n), and the integer capacity of vehicle capacity. It returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the distance_matrix. The depot node is indexed by 0.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"\n    An enhanced heuristic for the CVRP that incorporates distance, demand, angle,\n    centrality, and depot attraction, with adaptive sparsification.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix)\n\n    # Calculate the centroid of the customer nodes\n    center_x = np.mean(coordinates[1:, 0])\n    center_y = np.mean(coordinates[1:, 1])\n\n    # Total demand calculation\n    total_demand = np.sum(demands[1:])\n\n    # Average distance to depot weighted by demand\n    demand_weighted_dist_to_depot = np.sum(demands[1:] * distance_matrix[0, 1:]) / total_demand if total_demand > 0 else 1.0\n\n    # Adaptive Sparsification Threshold (dynamically adjusted based on demand and distance)\n    sparsification_threshold = np.mean(distance_matrix) * (1 + (total_demand / (capacity * n)))\n\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                continue\n\n            distance = distance_matrix[i, j]\n\n            # Sparsification: Eliminate edges that are too long or deemed unpromising early on\n            if distance > sparsification_threshold:\n                heuristic_matrix[i, j] = 0.0  # Directly set to zero to prune unpromising edges\n                continue\n\n            # Distance component: Reciprocal of distance, with a small constant to avoid division by zero\n            distance_component = 1 / (distance + 1e-6)\n\n            # Demand component: Penalize edges that would likely violate capacity constraints early\n            demand_component = 1.0\n            if i != 0 and j != 0 and demands[i] + demands[j] > capacity * 1.2:  #relaxed capacity constraint\n                demand_component = 0.05 # more aggressive penalization\n            elif i!=0 and j!=0 and demands[i] + demands[j] > capacity:\n                demand_component = 0.2 # stronger penalization if capacity will be violated\n\n            # Angle Component (Penalize sharp turns). Simplified calculation for speed.\n            angle_component = 1.0\n            if i != 0 and j != 0:\n                # Calculate angles to a subset of other nodes for efficiency\n                num_angles = min(5, n - 2) #Consider only a few angles\n                angles = []\n\n                #Sampling without replacement\n                candidates = list(range(1,n))\n                candidates.remove(i)\n                candidates.remove(j)\n                sampled_indices = np.random.choice(candidates, size=min(num_angles, len(candidates)), replace=False)\n\n                for k in sampled_indices:\n                    v1 = coordinates[i] - coordinates[j]\n                    v2 = coordinates[k] - coordinates[i]\n                    dot_product = np.dot(v1, v2)\n                    magnitudes = np.linalg.norm(v1) * np.linalg.norm(v2)\n                    if magnitudes == 0:\n                        angle = 0\n                    else:\n                        angle = np.arccos(dot_product / magnitudes)\n                    angles.append(angle)\n                if len(angles) > 0:\n                    angle_component = np.min(np.degrees(angles) / 180.0) #Normalize between 0 and 1.\n\n            # Centrality component: Favor edges closer to the center of the customer distribution.\n            center_distance = (np.sqrt((coordinates[i, 0] - center_x)**2 + (coordinates[i, 1] - center_y)**2) +\n                               np.sqrt((coordinates[j, 0] - center_x)**2 + (coordinates[j, 1] - center_y)**2)) / 2\n            centrality_component = np.exp(-center_distance / (demand_weighted_dist_to_depot + 1e-6))\n\n            # Depot attraction: Encourage edges connecting to the depot.\n            depot_component = 1.0\n            if i == 0 or j == 0:\n                depot_component = 1.0 #High priority to depot\n            else:\n                depot_component = 0.5 #Lower prioirty if not directly connected\n\n            # Context-Aware Combination: Adaptive combination of components with multiplicative interaction\n            heuristic_matrix[i, j] = (distance_component**0.8 * demand_component**1.2 * (1 - angle_component)**0.9 *\n                                      centrality_component**0.7 * depot_component**1.1) # Fine-tuned exponents\n\n    return heuristic_matrix\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"Combines adaptive distance, demand, centrality, and depot attraction with sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix)\n\n    # Adaptive distance component\n    avg_dist_to_depot = np.mean(distance_matrix[0, 1:])\n    distance_component = np.exp(-distance_matrix / avg_dist_to_depot) if avg_dist_to_depot > 0 else np.ones_like(distance_matrix)\n\n    # Demand component, penalizing capacity violations\n    demand_matrix = np.add.outer(demands, demands)\n    demand_component = np.where(demand_matrix > capacity, 0.01, 1.0)\n    for i in range(n):\n        demand_component[i,i] = 0\n\n    # Centrality component\n    center_x = np.mean(coordinates[1:, 0])\n    center_y = np.mean(coordinates[1:, 1])\n    center_distances = np.sqrt((coordinates[:, 0] - center_x)**2 + (coordinates[:, 1] - center_y)**2)\n    total_demand = np.sum(demands[1:])\n    demand_weighted_dist_to_depot = np.sum(demands[1:] * distance_matrix[0, 1:]) / total_demand if total_demand > 0 else np.mean(distance_matrix[0, 1:])\n    centrality_component = np.exp(-(center_distances[:, None] + center_distances[None, :]) / (2 * demand_weighted_dist_to_depot)) if demand_weighted_dist_to_depot > 0 else np.ones_like(distance_matrix)\n\n    # Depot attraction component\n    depot_attraction = np.exp(-distance_matrix[0, :] / avg_dist_to_depot) if avg_dist_to_depot > 0 else np.ones(n)\n    depot_component = (depot_attraction[:, None] + depot_attraction[None, :]) / 2\n\n    # Angle Component\n    depot_x, depot_y = coordinates[0]\n    angles = np.arctan2(coordinates[:, 1] - depot_y, coordinates[:, 0] - depot_x)\n    angle_diffs = np.abs(angles[:, None] - angles[None, :])\n    angle_component = np.exp(-2 * angle_diffs)\n    # Combine components multiplicatively\n    heuristic_matrix = distance_component * demand_component * centrality_component * depot_component * angle_component\n\n    # Adaptive sparsification\n    threshold = np.mean(heuristic_matrix[heuristic_matrix > 0]) * 0.2\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    return heuristic_matrix\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the best heuristic combines centrality, capacity, angle, and depot attraction, while the worst uses a combination of distance, demand, angle, and sparsification but with less effective normalization and weighting. The best heuristic also incorporates precomputed depot attraction and angle differences. The worst heuristic also does not check the feasibility of capacity, causing routes to be infeasible.\n(2nd best) vs (2nd worst) the second best approach has a more comprehensive consideration of multiple factors (distance, demand, angle, centrality, and depot attraction), combined with adaptive sparsification based on demand and distance.  The 19th ranked heuristic uses powers to tune importance.\nComparing (1st) vs (2nd), we see the 1st ranked heuristic uses simpler calculations but the 2nd ranked heuristic is a more complex formula, adaptive sparsification, relaxed capacity constraint, and sampling.\n(3rd) vs (4th) - No difference, meaning there are duplicate heuristics on the list.\nComparing (second worst) vs (worst), we see that the 19th and 20th heuristics share similar design choices, but the 19th emphasizes demand and angle more and is more likely to provide better results.\nOverall: The better heuristics incorporate more relevant factors (centrality, depot attraction, angle) and employ adaptive techniques. They are more robust in handling capacity constraints and prioritize computational efficiency through normalization or sparsification. They also often use powers to tune the various component.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, let's refine \"Current Self-Reflection\" to design better heuristics, avoiding the pitfalls of \"Ineffective Self-Reflection.\" We'll aim for actionable advice.\n\nHere's a revised self-reflection framework:\n\n*   **Keywords:** Problem context, adaptive parameters, normalization, weighted combinations, computational cost, solution quality, experimental validation.\n\n*   **Advice:** Deeply analyze the problem's structure and constraints. Construct adaptive heuristics dynamically adjusting parameters (powers, weights) based on the search progress. Rigorously test and validate heuristics across diverse problem instances.\n\n*   **Avoid:** Overly complex weighting schemes without justification. Static parameter tuning; strive for adaptivity. Ignoring computational cost implications when increasing heuristic complexity.\n\n*   **Explanation:** Effective heuristics require a solid understanding of the underlying problem. Adaptivity allows heuristics to learn and refine their search strategy during execution. Balance between solution quality and computational efficiency is crucial for real-world applications. Normalization prevents features with large magnitudes from dominating heuristic performance.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}