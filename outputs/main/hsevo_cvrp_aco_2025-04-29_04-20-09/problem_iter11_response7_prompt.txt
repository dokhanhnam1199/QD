{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling. CVRP requires finding the shortest path that visits all given nodes and returns to the starting node. Each node has a demand and each vehicle has a capacity. The total demand of the nodes visited by a vehicle cannot exceed the vehicle capacity. When the total demand exceeds the vehicle capacity, the vehicle must return to the starting node.\nThe `heuristics` function takes as input a distance matrix (shape: n by n), Euclidean coordinates of nodes (shape: n by 2), a vector of customer demands (shape: n), and the integer capacity of vehicle capacity. It returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the distance_matrix. The depot node is indexed by 0.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"Enhanced heuristics combining distance, capacity, angle, centrality, and depot attraction.\n    Sparsifies the matrix and adapts weights based on problem characteristics.\"\"\"\n\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix)\n    \n    # --- Centrality Component ---\n    center_x = np.mean(coordinates[1:, 0])\n    center_y = np.mean(coordinates[1:, 1])\n    total_demand = np.sum(demands[1:])\n    demand_weighted_dist_to_depot = np.sum(demands[1:] * distance_matrix[0, 1:]) / total_demand if total_demand > 0 else 1\n\n    # --- Sparsification Threshold (Adaptive) ---\n    # Dynamically adjust the sparsification threshold based on the average distance\n    avg_distance = np.mean(distance_matrix)\n    sparsification_threshold = 2.5 * avg_distance  # Increased factor for more aggressive sparsification\n\n\n    # --- Demand Pairings Heuristic ---\n    demand_pairs = {}\n    for i in range(1, n):\n        for j in range(i + 1, n):\n            if demands[i] + demands[j] <= capacity:\n                demand_pairs[(i, j)] = 1.0 # A value of 1.0 means the pair is feasible\n\n\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                continue\n\n            distance = distance_matrix[i, j]\n\n            # --- Sparsification ---\n            if distance > sparsification_threshold:  # More aggressive sparsification\n                continue  # Skip calculation, effectively setting heuristic_matrix[i, j] to 0\n\n\n            distance_component = 1 / (distance + 1e-6)\n\n            demand_component = 1.0\n            if i != 0 and j != 0:\n                if demands[i] + demands[j] > capacity:\n                   demand_component = 0.01 # Severe penalty\n                else:\n                    # Small bonus for making feasible pairs\n                    if (min(i,j), max(i,j)) in demand_pairs:\n                        demand_component = 1.1\n\n            angle_component = 1.0\n            if i != 0 and j != 0:\n                angles = []\n                for k in range(n):\n                    if k != i and k != j:\n                        v1 = coordinates[i] - coordinates[j]\n                        v2 = coordinates[k] - coordinates[i]\n                        dot_product = np.dot(v1, v2)\n                        magnitudes = np.linalg.norm(v1) * np.linalg.norm(v2)\n                        if magnitudes == 0:\n                            angle = 0\n                        else:\n                            angle = np.arccos(dot_product / magnitudes)\n                        angles.append(angle)\n                if len(angles) > 0:\n                    angle_component = min(np.degrees(angles) / 180.0)\n\n            center_distance = (np.sqrt((coordinates[i, 0] - center_x)**2 + (coordinates[i, 1] - center_y)**2) +\n                               np.sqrt((coordinates[j, 0] - center_x)**2 + (coordinates[j, 1] - center_y)**2)) / 2\n            centrality_component = np.exp(-center_distance / demand_weighted_dist_to_depot if demand_weighted_dist_to_depot>0 else 1)\n\n            depot_component = 1.0\n            if i!=0:\n                load_before_depot = demands[i]\n                depot_component = (1 + np.exp(load_before_depot/capacity)) / 2\n\n\n            # --- Feature Interaction & Weighting ---\n            heuristic_value = (distance_component * demand_component * (1 - angle_component) * centrality_component * depot_component)\n\n            #Adjust weighting\n            if i==0 or j == 0:\n                heuristic_value *= 1.2 #Favor connection to depot\n\n\n\n            heuristic_matrix[i, j] = heuristic_value\n\n    return heuristic_matrix\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"Combines distance, demand, angle, depot proximity, and demand density\n    using weighted average and sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix)\n    depot_coords = coordinates[0]\n    angles = np.arctan2(coordinates[:, 1] - depot_coords[1], coordinates[:, 0] - depot_coords[0])\n\n    # Demand density calculation\n    demand_density = np.zeros(n)\n    for i in range(1, n):\n        nearby_demand = 0\n        for j in range(1, n):\n            if i != j and distance_matrix[i, j] < np.mean(distance_matrix):\n                nearby_demand += demands[j]\n        demand_density[i] = nearby_demand\n    max_demand_density = np.max(demand_density) if np.max(demand_density) > 0 else 1\n\n    #Center calculation\n    center_x = np.mean(coordinates[1:, 0])\n    center_y = np.mean(coordinates[1:, 1])\n    total_demand = np.sum(demands[1:])\n    demand_weighted_dist_to_depot = np.sum(demands[1:] * distance_matrix[0, 1:]) / total_demand if total_demand > 0 else 1e-6\n\n    # Normalizing factor for distance\n    max_distance = np.max(distance_matrix)\n    if max_distance == 0:\n        max_distance = 1\n\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                continue\n\n            distance = distance_matrix[i, j]\n            normalized_distance = distance / max_distance\n            distance_component = 1 / (normalized_distance + 1e-6)\n\n            demand_penalty = 1.0 - np.clip((demands[i] + demands[j]) / (2 * capacity), 0, 0.7)\n\n            angle_diff = abs(angles[i] - angles[j])\n            angular_factor = 1 / (angle_diff + 0.1)\n\n            depot_proximity = 1.0\n            if i == 0 or j == 0:\n                depot_proximity = 1.2\n\n            density_component = 1.0\n            if i != 0 and j != 0:\n                density_component = np.sqrt((demand_density[i] / max_demand_density) * (demand_density[j] / max_demand_density))\n\n            center_distance = (np.sqrt((coordinates[i, 0] - center_x)**2 + (coordinates[i, 1] - center_y)**2) +\n                               np.sqrt((coordinates[j, 0] - center_x)**2 + (coordinates[j, 1] - center_y)**2)) / 2\n            centrality_component = np.exp(-center_distance / demand_weighted_dist_to_depot if demand_weighted_dist_to_depot>0 else 1)\n\n            # Weighted heuristic combining components.\n            alpha, beta, gamma, delta, epsilon = 0.4, 0.2, 0.15, 0.15, 0.1 #Adjustable weights\n            heuristic_matrix[i, j] = (alpha * distance_component +\n                                       beta * demand_penalty +\n                                       gamma * angular_factor +\n                                       delta * depot_proximity +\n                                       epsilon * density_component +\n                                       (1-alpha-beta-gamma-delta-epsilon) * centrality_component)\n\n            # Sparsification\n            if i!=0 and j!=0 and (demands[i] + demands[j]) > 1.5 * capacity:\n                heuristic_matrix[i, j] = 0\n            if i!=0 and j!=0 and (demands[i] > capacity or demands[j] > capacity) :\n                heuristic_matrix[i, j] = 0\n\n            heuristic_matrix[i, j] = np.clip(heuristic_matrix[i, j], 0, 1e6)\n\n    return heuristic_matrix\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the 1st one has a simpler structure using direct multiplicative combination of components, whereas the 20th uses more complex exponential and power-based weighting, and normalization. The 1st also includes angles relative to all other nodes, while the 20th is relative to the depot.\nComparing (2nd) vs (19th), we observe the introduction of sparsification thresholding in the 2nd and adaptive parameter adjustments. The 19th introduces demand density and normalizes the distances but seems to overcomplicate the calculation.\nComparing (3rd) vs (18th), the 3rd one adapts the distance component using exponential decay, calculating the mean distances and the angles relative to the depot. The 18th uses a similar idea for demand density but calculates depot proximity directly.\nComparing (4th) vs (17th), the 4th one makes not any changes compare with the 3rd, so both heuristics are equivalent. The 17th combines normalized distance, demand, depot proximity and centrality.\nComparing (5th) vs (16th), the 5th one makes not any changes compare with the 3rd and 4th, so all heuristics are equivalent. The 16th focuses on normalized distances, demand component, centrality and depot proximity.\nComparing (6th) vs (15th), the 6th heuristic includes adaptive weights and a more sophisticated angle calculation. The 15th introduces demand density calculations.\nComparing (7th) vs (14th), the 7th normalizes distances and uses weighted components with a more traditional angle calculation. The 14th emphasizes demand density and sparsification more heavily.\nComparing (8th) vs (13th), the 8th is identical to the 7th. The 13th, incorporates density component and centralizes the design around depot.\nComparing (9th) vs (12th), the 9th and 10th uses demand density, angle, centrality, and depot proximity with fixed weights. The 11th and 12th are very similar using an enhanced combination of distance, demand, angle, centrality, and depot attraction with adaptive weighting\nComparing (10th) vs (11th), 10th is very similar to 9th but 11th has adaptive weights\nComparing (second worst) vs (worst), we see that second worst uses adaptive weighting and normalized components like distance, demand, angle, centrality and depot attaction. The worst (20th) attempt to include all component in the second worst with smoother transition and gaussian penalty but failed.\nOverall: The better heuristics tend to incorporate a balance of distance, demand, angle, centrality, and depot considerations but are careful not to overcomplicate the weighting or normalization schemes. Simpler multiplicative combinations with dynamic thresholds for sparsification appear to be effective. Adaptive weights, while promising in theory, don't always lead to superior performance if not carefully tuned.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, let's redefine \"Current self-reflection\" to avoid pitfalls and design better heuristics:\n\n*   **Keywords:** Adaptive Sparsification, Context-Aware Combination, Parameter Sensitivity, Performance Tuning.\n\n*   **Advice:** Prioritize understanding *why* specific features (distance, demand, centrality, etc.) are effective. Explore multiplicative combinations initially, but consider *adaptive* weighting informed by real-time performance.\n\n*   **Avoid:** Rigid, pre-defined weighting schemes. Over-reliance on normalization without understanding feature interactions. Brute-force tuning; focus on principled parameter adjustment based on observed behavior.\n\n*   **Explanation:** Aim for a reflection process that emphasizes understanding *underlying mechanisms* driving heuristic performance, allowing for more targeted adjustments and adaptive strategies. Avoid simply throwing features together with arbitrary weights.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}