{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling. CVRP requires finding the shortest path that visits all given nodes and returns to the starting node. Each node has a demand and each vehicle has a capacity. The total demand of the nodes visited by a vehicle cannot exceed the vehicle capacity. When the total demand exceeds the vehicle capacity, the vehicle must return to the starting node.\nThe `heuristics` function takes as input a distance matrix (shape: n by n), Euclidean coordinates of nodes (shape: n by 2), a vector of customer demands (shape: n), and the integer capacity of vehicle capacity. It returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the distance_matrix. The depot node is indexed by 0.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"Enhances CVRP heuristic by combining normalized distance, capacity, angle, centrality, depot attraction, and sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros_like(distance_matrix)\n\n    # Calculate center and characteristic distance\n    center_x = np.mean(coordinates[1:, 0])\n    center_y = np.mean(coordinates[1:, 1])\n    total_demand = np.sum(demands[1:])\n    demand_weighted_dist_to_depot = np.sum(demands[1:] * distance_matrix[0, 1:]) / total_demand if total_demand > 0 else 0\n\n    # Normalization factors to ensure features are on comparable scales.\n    max_distance = np.max(distance_matrix)\n    max_demand = np.max(demands)\n    max_coord = np.max(np.abs(coordinates))  # use max absolute value for centering calculation\n\n\n    # Define weights for each component.  Tunable parameters!\n    weight_distance = 0.4\n    weight_demand = 0.2\n    weight_angle = 0.1\n    weight_centrality = 0.15\n    weight_depot = 0.15\n\n\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                continue\n\n            # 1. Distance Component (Normalized)\n            distance = distance_matrix[i, j]\n            distance_component = 1 - (distance / max_distance)  # Higher is better\n\n\n            # 2. Demand Component (Considers combined demand relative to capacity)\n            demand_component = 1.0  # default\n            if i != 0 and j != 0:\n                 combined_demand = demands[i] + demands[j]\n                 demand_component = max(0.1, 1 - (combined_demand / capacity))  # Scale linearly. Never go to 0\n            # if demands[i] + demands[j] > capacity: # replaced by above\n            #     demand_component = 0.1\n\n\n            # 3. Angle Component (Smaller angle = higher priority). More robust.\n            angle_component = 0.0\n            if i != 0 and j != 0:\n                angles = []\n                for k in range(n):\n                    if k != i and k != j:\n                        v1 = coordinates[i] - coordinates[j]\n                        v2 = coordinates[k] - coordinates[i]\n                        dot_product = np.dot(v1, v2)\n                        magnitudes = np.linalg.norm(v1) * np.linalg.norm(v2)\n                        if magnitudes == 0:\n                            angle = 0\n                        else:\n                            angle = np.arccos(dot_product / magnitudes)\n                        angles.append(angle)\n\n                if len(angles) > 0:\n                     angle_component = min(np.degrees(angles) / 180.0) # Normalize between 0 and 1\n            angle_component = 1 - angle_component # Invert, smaller angle better.\n\n            # 4. Centrality Component (Nodes closer to center are more attractive)\n            center_distance_i = np.sqrt((coordinates[i, 0] - center_x)**2 + (coordinates[i, 1] - center_y)**2)\n            center_distance_j = np.sqrt((coordinates[j, 0] - center_x)**2 + (coordinates[j, 1] - center_y)**2)\n            avg_center_distance = (center_distance_i + center_distance_j) / 2\n            centrality_component = np.exp(-avg_center_distance / (demand_weighted_dist_to_depot + 1e-6))\n\n\n            # 5. Depot Attraction (Attract nodes back to depot based on load)\n            depot_component = 1.0\n            if i != 0:  # Only penalize non-depot nodes.\n                load_before_depot = demands[i]  # Demand of node 'i'\n                depot_component = (1 + np.exp(-load_before_depot / (capacity + 1e-6))) / 2  # Inverted, higher is better to return\n                # depot_component = (1 + np.tanh(-load_before_depot / capacity)) / 2 # alternative\n\n\n            # Combine the components using weighted sum.  Crucial step.\n            heuristic_matrix[i, j] = (\n                weight_distance * distance_component +\n                weight_demand * demand_component +\n                weight_angle * angle_component +\n                weight_centrality * centrality_component +\n                weight_depot * depot_component\n            )\n\n\n    # Sparsify the matrix.  Zero out very low values, reducing the search space.\n    threshold = np.mean(heuristic_matrix) * 0.1  # Dynamic threshold\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n\n    return heuristic_matrix\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"Combines distance, demand, angle, and depot proximity with smooth weighting.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros((n, n))\n\n    # Normalize distance\n    max_distance = np.max(distance_matrix[distance_matrix != np.inf])\n    normalized_distance = distance_matrix / max_distance if max_distance > 0 else np.ones_like(distance_matrix) # Avoid division by zero\n    normalized_distance = np.where(normalized_distance == 0, 1e-6, normalized_distance)\n\n    # Calculate angles relative to depot\n    depot_x, depot_y = coordinates[0]\n    angles = np.arctan2(coordinates[:, 1] - depot_y, coordinates[:, 0] - depot_x)\n\n    # Demand density component\n    total_demand = np.sum(demands[1:])\n    demand_weighted_dist_to_depot = np.sum(demands[1:] * distance_matrix[0, 1:]) / total_demand if total_demand > 0 else np.mean(distance_matrix[0,1:])  # Avoid division by zero\n\n    demand_density = np.zeros(n)\n    for i in range(1, n):  # Skip depot\n        nearby_demand = 0\n        for j in range(1, n):\n            if i != j and distance_matrix[i, j] < demand_weighted_dist_to_depot:  # Check reasonable distance\n                nearby_demand += demands[j]\n        demand_density[i] = nearby_demand\n\n    max_demand_density = np.max(demand_density) if np.max(demand_density) > 0 else 1 # Avoid division by zero\n\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                heuristic_value = 1 / normalized_distance[i, j]\n\n                # Demand penalty with smooth weighting\n                demand_penalty = 1.0\n                if i != 0 and j != 0:\n                    excess_demand = max(0, demands[i] + demands[j] - capacity)\n                    demand_penalty = np.exp(-excess_demand / capacity) #Smooth penalty\n\n                heuristic_value *= demand_penalty\n\n                # Depot proximity with smooth weighting\n                depot_distance_i = distance_matrix[0, i] / max_distance\n                depot_distance_j = distance_matrix[0, j] / max_distance\n                depot_proximity = np.exp(-5 * (depot_distance_i + depot_distance_j)) #Smooth\n\n                if i != 0 and j != 0:\n                    heuristic_value *= depot_proximity\n\n                # Angle difference penalty\n                angle_diff = abs(angles[i] - angles[j])\n                heuristic_value *= np.exp(-2 * angle_diff)\n\n                # Demand density component\n\n                density_component = 1.0\n                if i != 0 and j != 0:\n                    density_component = np.sqrt((demand_density[i] / max_demand_density) * (demand_density[j] / max_demand_density))\n\n                heuristic_value*= density_component\n                heuristic_matrix[i, j] = heuristic_value\n\n    return heuristic_matrix\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), we see that the 2nd heuristic uses Gaussian penalty for demand, adds depot attraction based on distance to the depot and demand balance component; and applies sparsification with a dynamic threshold; (1st) uses hard threshold of capacity.\n\nComparing (2nd) vs (3rd), the 2nd calculates centrality and depot attraction, and demand balance, and applies sparsification with a dynamic threshold. 3rd normalizes distance, calculates angles relative to the depot, and applies a depot proximity weighting. 2nd includes a more comprehensive set of factors, including demand balance and centrality, and the use of dynamic sparsification. 3rd focuses primarily on distance, demand, depot proximity, and angle to the depot.\n\nComparing (3rd) vs (4th), 3rd normalizes distances, calculates angles to the depot, and weights components more simply. 4th introduces the concept of demand density, as well as a center calculation and component. 4th also includes sparsification based on capacity constraints and clips the heuristic matrix values.\n\nComparing (4th) vs (5th), 4th and 5th are identical.\n\nComparing (5th) vs (6th), 5th uses demand density and centrality components. 6th normalizes distances and demands explicitly and uses weighted averages for distance, demand, and centrality, multiplied by a depot component. Sparsification in 6th is based on a percentile of distances.\n\nComparing (6th) vs (7th), 6th and 7th are identical.\n\nComparing (7th) vs (8th), 7th and 8th are identical.\n\nComparing (8th) vs (9th), 8th uses normalized distances, demand components, centrality, and depot attraction, with sparsification. 9th uses distance, savings, demand, and centrality. Savings heuristic is unique to 9th. 9th also ensures depot connections are preferred.\n\nComparing (9th) vs (10th), 9th combines distance, savings, demand, and centrality. 10th combines distance, demand, angle, and depot proximity with fixed weights.\n\nComparing (10th) vs (11th), 10th combines distance, demand, angle, and depot proximity with fixed weights; 11th combines distance, demand, savings, angle, depot proximity; angle is calculated using neighboring nodes; 11th has sparsification.\n\nComparing (11th) vs (12th), 11th uses savings heuristic, and the angle calculation considers other nodes; 12th use a more comprehensive set of components and normalization strategies, along with capacity penalties.\n\nComparing (12th) vs (13th), 12th uses a more comprehensive set of features, including angle calculations, centrality, depot attraction, and capacity penalties, and employs normalization. 13th focuses on distance, demand, centrality, and depot attraction without explicit angle calculations and uses exponential functions for distance and centrality components. 12th calculates penalty for exceeding capacity.\n\nComparing (13th) vs (14th), 13th and 14th are identical.\n\nComparing (14th) vs (15th), 14th combines distance, demand, centrality, and depot attraction, sparsifying based on a dynamic threshold. 15th normalizes and weights distance, demand, angle, centrality, and depot components; 15th uses more robust angle calculation and depot attraction.\n\nComparing (15th) vs (16th), 15th normalizes and weights distance, demand, angle, centrality, and depot components, sparsifying the matrix with a dynamic threshold. 16th normalizes distance, calculates angles relative to the depot, and considers demand density.\n\nComparing (16th) vs (17th), 16th and 17th are identical.\n\nComparing (17th) vs (18th), 17th and 18th are identical.\n\nComparing (18th) vs (19th), 18th and 19th are identical.\n\nComparing (19th) vs (20th), 19th uses normalized distances, demand density, depot proximity and angle difference with smooth weighting. 20th uses distance, demand, angle, centrality and depot attraction, with sparsification. 20th uses mean angle.\n\nOverall:\nThe better heuristics are characterized by normalization, weighting of components, sparsification and including more components such as centrality, demand density, savings.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, I understand. Let's redefine \"Current self-reflection\" to be more effective in designing heuristics. Here's a breakdown:\n\n*   **Keywords:** Adaptive weights, feature interaction, problem-specific context, iterative refinement.\n*   **Advice:** Focus on how features *interact* and adapt weights during the search. Analyze performance bottlenecks to guide heuristic refinement.\n*   **Avoid:** Blindly normalizing and weighting without understanding feature relationships and the problem's nuances. Static weights.\n*   **Explanation:** Move beyond simple normalization and weighting. Prioritize understanding how features influence each other in specific problem instances. Use iterative analysis of solution quality to dynamically adjust heuristic parameters, leading to more robust and effective heuristics.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}