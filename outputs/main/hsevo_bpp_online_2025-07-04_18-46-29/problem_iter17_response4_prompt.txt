{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Adaptive priority: Best-fit, target fill, fragmentation, near-empty bonus.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        # Best-fit: Minimize waste. Larger items get higher best-fit score\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] -= np.abs(waste) * (1 + item) # Item size scaling\n\n        # Target fill: Encourage around 80% fill\n        target_fill = 0.8\n        ideal_remaining = 1 - target_fill\n        distance_to_ideal = np.abs((bins_remain_cap[valid_bins] - item) - ideal_remaining)\n        priorities[valid_bins] += np.exp(-distance_to_ideal * 5)\n\n        # Fragmentation penalty: Discourage near-full bins, scaled by item size\n        near_full_threshold = 0.1\n        near_full = (bins_remain_cap[valid_bins] >= item) & (bins_remain_cap[valid_bins] < (item * (1 + near_full_threshold)))\n        priorities[valid_bins][near_full] -= 1.2 + item  # Item size scaling\n\n        # Encourage near-empty reuse with size condition\n        near_empty_threshold = 0.1\n        near_empty = bins_remain_cap > (1 - item * near_empty_threshold)\n        priorities[near_empty] -= 0.75 * (1-item)\n    else:\n        priorities[:] = -100  # Very low for invalid placements\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit, target fill, fragmentation penalty, adaptive weighting.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    num_bins = len(bins_remain_cap)\n\n    if np.any(valid_bins):\n        # Best-fit component (minimize waste)\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] -= np.abs(waste) * (1 + 0.1 * item) # Adaptive based on item size\n\n        # Target fill bonus (around 80% full)\n        target_fill = 0.8\n        ideal_remaining = 1 - target_fill\n        distance_to_ideal = np.abs((bins_remain_cap[valid_bins] - item) - ideal_remaining)\n        priorities[valid_bins] += np.exp(-distance_to_ideal * 5)\n\n        # Fragmentation penalty (discourage near-full bins)\n        fragmentation_threshold = item * 0.15\n        remaining_space = bins_remain_cap - item\n        fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)\n        fragmentation_penalty = 1.0 + 0.5 * (fragmentation_threshold - remaining_space[fragmented_bins]) / (fragmentation_threshold + 1e-9)\n        priorities[fragmented_bins] -= fragmentation_penalty * (1 + 0.05 * (num_bins / (np.sum(bins_remain_cap) + 1e-9))) # Adaptive penalty\n\n        # Encourage near-empty reuse\n        almost_empty_threshold = 0.9\n        almost_empty = bins_remain_cap > almost_empty_threshold\n        if np.any(almost_empty):\n            almost_empty_bonus = 0.5 + 0.4 * (bins_remain_cap[almost_empty] - almost_empty_threshold) / (1 - almost_empty_threshold + 1e-9)\n            priorities[almost_empty] += almost_empty_bonus\n\n    else:\n        priorities[:] = -100  # Discourage invalid placements\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the first heuristic uses carefully tuned constants and an almost-empty bonus with thresholds and weights. The 20th emphasizes fill ratio, best fit, adaptive fragmentation, reuse, and fill percentage incentive.\n(2nd) vs (19th): Heuristic 2 introduces a nonlinear best-fit encouragement and bin balancing, whereas heuristic 19 adjusts fill ratios, best fit, and fragmentation based on average bin capacity and provides fill percentage incentive, and gives stronger boost to best-fit encouragement.\n(3rd) vs (18th): Heuristic 3 uses an adaptive item size factor to adjust fill ratio, best fit, fragmentation penalty, empty bin reuse, and too-empty bin discouragement. Heuristic 18 introduces adaptive weighting based on state awareness, fill ratio priority, best-fit bonus, fragmentation penalty, and exploration randomness.\n(4th) vs (17th): Heuristic 4 adaptively balances fill, waste, and fragmentation and considers global fill levels, while Heuristic 17 uses adaptive weighting and state awareness for fill ratio, best-fit, fragmentation, almost empty reuse and exploration.\n(5th) vs (16th): Heuristic 5 is using adaptive best-fit, target fill and fragmentation penalty, near-empty bonus. The 16th does similar to 5th but without near-empty bonus scaling using remaining capacity.\nComparing (second worst) vs (worst), we see that the second worst (Heuristic 2) uses nonlinear encouragement and bin balancing, and an adaptive fragmentation penalty. The worst (Heuristic 1) relies on a fixed set of parameters.\nOverall: The better heuristics emphasize adaptivity, state awareness, and carefully combine various factors, adjusting weights and thresholds dynamically based on item size, bin availability, and global bin fill levels. The worse performing heuristics rely on static weights and less comprehensive combinations of factors. Better heuristics also appear to incorporate penalties for bins that are too full or likely to cause fragmentation.\n- \nOkay, let's refine \"Current Self-Reflection\" to build better heuristics, avoiding the pitfalls described in \"Ineffective Self-Reflection.\" Here's a focused approach:\n\n*   **Keywords:** Adaptivity, Multi-objective, Penalties/Bonuses, Global State, Parameter Tuning, Incremental Complexity.\n\n*   **Advice:** Design heuristics to adapt dynamically to item sizes, bin states (availability, fill level), and overall packing progress. Combine multiple factors (fill ratio, fragmentation) using weighted functions. Start simple and increase complexity, tracking effects.\n\n*   **Avoid:** Over-reliance on single factors. Unclear objective functions. Abrupt priority shifts. Untested complexity. Local optima traps.\n\n*   **Explanation:** Prioritize a balanced, adaptive approach to bin packing, considering both local bin states and the global packing context. Tune parameters systematically and iteratively validate the effect of new factors.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}