{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines fill optimization with adaptive penalties.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] = -np.abs(waste)\n\n        close_fit_threshold = 0.1\n        close_fit = np.abs(waste) < close_fit_threshold * item\n        priorities[valid_bins][close_fit] += 1\n\n        almost_full_threshold = 0.1\n        almost_full_penalty = 2.79\n        almost_full = bins_remain_cap[valid_bins] < (1 + almost_full_threshold) * item\n        priorities[valid_bins][almost_full] -= almost_full_penalty\n\n        remaining_after_fit_scale = 6.44\n        remaining_after_fit_weight = 0.25\n\n        remaining_after_fit = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] += np.exp(-remaining_after_fit_scale * remaining_after_fit / item) * remaining_after_fit_weight\n\n        fill_fraction = item / bins_remain_cap[valid_bins]\n        fill_fraction_weight = 0.39\n        priorities[valid_bins] += fill_fraction * fill_fraction_weight\n\n    else:\n        discourage_placement_value = 0.0008\n        priorities[:] = -discourage_placement_value\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Primary Objective: Maximize bin utilization\n    # Encourage filling bins as much as possible *without* overfilling.\n    potential_bins = bins_remain_cap >= item\n    if np.any(potential_bins):\n        # Higher score for bins that leave less waste after packing.\n        priorities[potential_bins] = 1 - (bins_remain_cap[potential_bins] - item) / bins_remain_cap[potential_bins]\n\n    # 2. Adaptive Penalty: Fragmentation Mitigation\n    # Penalize bins that, after packing, leave a remaining capacity smaller than a threshold.\n    # This threshold is dynamically adjusted based on the average item size.\n    avg_item_size = item # assuming a single item.  If multiple items were considered, this should be the average size\n    small_fragment_threshold = avg_item_size * 0.5  # Adjust this factor as needed\n\n    remaining_after_pack = bins_remain_cap - item\n    too_small_remaining = (remaining_after_pack > 0) & (remaining_after_pack < small_fragment_threshold)\n    if np.any(too_small_remaining):\n        priorities[too_small_remaining] -= 0.75  # Strong penalty for creating small fragments\n\n    # 3. Exploration Bonus: Occasionally try less-optimal bins\n    # Introduce a small probability of prioritizing a less-full bin to avoid local optima.\n    # This is done by adding a tiny random value to all priorities.  Adjust probability as needed.\n    if np.random.rand() < 0.05:\n        priorities += np.random.rand(len(bins_remain_cap)) * 0.1\n\n    # 4. Prioritize bins that are already reasonably full. Helps close them quickly\n    reasonably_full = (bins_remain_cap > item) & (bins_remain_cap < item * 2)  # Adjust as needed\n    if np.any(reasonably_full):\n        priorities[reasonably_full] += 0.25\n\n    # 5. First fit tiebreaker.\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        first_eligible_index = np.argmax(eligible_bins) # Select the index of the first true value\n        priorities[first_eligible_index] += 0.01\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), they are identical. Comparing (1st) vs (3rd), (1st) focuses on filling close-to-full bins using `(bins_remain_cap[potential_bins] - item) / bins_remain_cap[potential_bins]`, prioritizes smallest remaining capacity, introduces non-linearity and penalizes almost full bins to reduce fragmentation. (3rd) combines fullest bin, near fit bonus, and dynamic fragmentation penalty. Comparing (2nd) vs (4th), (2nd) also focuses on filling close-to-full bins, and penalizes nearly full bins. (4th) gives first fit preference, best fit encouragement and fragmentation penalty. Comparing (19th) vs (20th), they are identical. Comparing (second worst) vs (worst), they are identical. Comparing across various pairs, heuristics that combine multiple strategies like best fit, fragmentation avoidance, and target fill levels tend to perform better. Adaptive penalties and bonuses based on remaining capacity or fill ratios also seem to be beneficial. The best heuristics also often include a \"first fit\" component to encourage initial packing. The heuristics with capacity weights tend to perform better. Overall: the top heuristics combine several factors (best fit, fill ratio, fragmentation penalty, almost empty reuse) with carefully tuned weights and adaptive penalties.\n- \nOkay, let's redefine \"Current self-reflection\" to be more effective in designing heuristics, avoiding the pitfalls of the \"Ineffective self-reflection.\"\n\nHere's a focused breakdown:\n\n*   **Keywords:** Multi-objective, Adaptive, Tuning, State-dependent.\n*   **Advice:** Design heuristics considering multiple objectives concurrently and use functions that adapt based on the current problem state. Prioritize careful weight/threshold tuning.\n*   **Avoid:** Overly simplistic, single-factor approaches. Avoid abrupt changes in behavior. Avoid neglecting parameter optimization.\n*   **Explanation:** Effective heuristics benefit from balancing objectives adaptively, with responses tailored to the current state. Careful tuning ensures optimal performance.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}