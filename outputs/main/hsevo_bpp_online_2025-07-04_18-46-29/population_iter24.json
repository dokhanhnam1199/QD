[
  {
    "stdout_filepath": "problem_iter23_response0.txt_stdout.txt",
    "code_path": "problem_iter23_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive bin packing heuristic combining fill ratio, best fit, and state-aware exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    bin_size = 1.0\n\n    #Adaptive Item Size and Bin Availability\n    item_size_factor = min(1.0, item)\n    bin_availability_factor = min(1.0, np.sum(bins_remain_cap >= item) / num_bins)\n    average_fill = np.mean(1 - bins_remain_cap)\n\n    #Fill Ratio (Weighted)\n    fill_ratio_weight = 0.5 + 0.3 * item_size_factor\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + 0.0001)\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n    #Best Fit (Weighted)\n    best_fit_weight = 1.5 + 0.5 * bin_availability_factor\n    if np.any(eligible_bins):\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-2 * remaining_space)\n\n    #Fragmentation Penalty\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold_multiplier = 0.2 / np.sqrt(num_bins)\n    fragmentation_threshold = item * (0.1 + 0.1 * item_size_factor) * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    fragmentation_penalty_weight = 1.0 + 0.2 * item_size_factor\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill)\n\n    #Reuse Almost Empty Bins\n    almost_empty_threshold = 0.95 - (0.1 * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = 0.5 + average_fill * 0.5\n        reuse_weight = 0.6 + 0.4 * bin_availability_factor\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus\n\n    #Bin Utilization\n    utilization = (bin_size - bins_remain_cap) / bin_size\n    fully_utilized_threshold = 0.8\n    highly_utilized = utilization > fully_utilized_threshold\n    utilization_bonus = 0.5\n    priorities[highly_utilized] += utilization_bonus\n\n    #State-Aware Exploration\n    exploration_rate = 0.05 * (1.0 - average_fill)\n    if np.random.rand() < exploration_rate:\n        exploration_bonus = (bin_size - bins_remain_cap) / bin_size\n        priorities += exploration_bonus * 0.2\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-0.2))\n    priorities[too_full_bins] -= 0.8\n\n    # Underutilization Penalty: Penalize creating almost empty bins with small items\n    new_remaining_space = bins_remain_cap - item\n    underutilization_threshold = 0.1 # Penalty for bins with low utilization after placement\n    underutilization_penalty = 0.6\n    underutilized_bins = (new_remaining_space > 0) & (new_remaining_space / bin_size > (1 - underutilization_threshold)) & (item < (bin_size * 0.5)) #Only penalize if item is small\n    priorities[underutilized_bins] -= underutilization_penalty\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response1.txt_stdout.txt",
    "code_path": "problem_iter23_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive strategies, global awareness, and refined fragmentation handling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    bin_size = 1.0\n    average_fill = np.mean(1 - bins_remain_cap)\n    \n    item_size_factor = min(1.0, item)\n    bin_availability_factor = min(1.0, np.sum(bins_remain_cap >= item) / num_bins)\n    \n    fill_ratio_weight = 0.5 + 0.3 * item_size_factor\n    best_fit_weight = 1.5 + 0.5 * bin_availability_factor\n    fragmentation_penalty_weight = 1.0 + 0.2 * item_size_factor\n    reuse_weight = 0.6 + 0.4 * bin_availability_factor\n\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + 0.0001)\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-2 * remaining_space)\n\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold_multiplier = 0.2 / np.sqrt(num_bins)\n    fragmentation_threshold = item * (0.1 + 0.1 * item_size_factor) * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill)\n\n    almost_empty_threshold = 0.95 - (0.1 * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = 0.5 + average_fill * 0.5\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus\n\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-0.2))\n    priorities[too_full_bins] -= 0.8\n    \n    # Global Bin Balancing: Encourage filling emptier bins when average fill is high\n    if average_fill > 0.7:\n        empty_bin_bonus = (1-average_fill) * bins_remain_cap\n        priorities += 0.1*empty_bin_bonus # Bonus for packing into more empty bins\n\n    exploration_factor = 0.01 * item * (1-average_fill)\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    new_remaining_space = bins_remain_cap - item\n    underutilization_threshold = 0.1\n    underutilization_penalty = 0.6\n    underutilized_bins = (new_remaining_space > 0) & (new_remaining_space / bin_size > (1 - underutilization_threshold)) & (item < (bin_size * 0.5))\n    priorities[underutilized_bins] -= underutilization_penalty\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 11.547666533705621,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response2.txt_stdout.txt",
    "code_path": "problem_iter23_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fill ratio, best fit, frag. penalty with adaptive weights.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    bin_size = 1.0\n\n    # Global State Awareness\n    average_fill = np.mean(1 - bins_remain_cap)\n\n    # Adaptive Weights - based on item size and global fill level\n    item_size_factor = min(0.74, item) # 0.74\n    bin_availability_factor = min(1.27, np.sum(bins_remain_cap >= item) / num_bins) # 1.27\n\n    fill_ratio_weight = 0.07 + 0.09 * item_size_factor #0.07, 0.09\n    best_fit_weight = 2.8 + 0.68 * bin_availability_factor #2.8, 0.68\n    fragmentation_penalty_weight = 1.47 + 0.82 * item_size_factor #1.47, 0.82\n    reuse_weight = 0.79 + 0.51 * bin_availability_factor #0.79, 0.51\n\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + 0.0008)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        best_fit_priority = np.exp(-2.7 * remaining_space) #2.7\n        priorities[eligible_bins] += best_fit_weight * best_fit_priority\n\n        # Small Item Best Fit Boost\n        if item < 0.2:\n            priorities[eligible_bins] += 0.1 * (1 - remaining_space / (bins_remain_cap[eligible_bins]+0.0008))#0.1\n\n    # Fragmentation Penalty - Dynamic threshold & Item Size Aware\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold = item * (0.45 + 0.04 * item_size_factor) * (0.2 / np.sqrt(num_bins)) #0.45, 0.04, 0.2\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n\n    fragmentation_penalty = fragmentation_penalty_weight * (1-average_fill)\n\n    # Large item penalty\n    if item > 0.8:\n        fragmentation_penalty *= 2.0 #2.0\n\n    priorities[fragmented_bins] -= fragmentation_penalty\n\n    # Almost empty reuse\n    almost_empty_threshold = 0.93 - (0.2 * average_fill) #0.93, 0.2\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = 0.09 + average_fill * 0.57 #0.09, 0.57\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus\n\n    #Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-0.42))#0.42\n    priorities[too_full_bins] -= 0.08 #0.08\n\n    # Exploration: Add a small amount of randomness, scaled to the item size.\n    exploration_factor = 0.026 * item #0.026\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 2.2836059034702925,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response3.txt_stdout.txt",
    "code_path": "problem_iter23_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining fill ratio, best fit, and fragmentation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    bin_size = 1.0\n\n    # Fill Ratio Preference\n    potential_bins = bins_remain_cap >= item\n    if np.any(potential_bins):\n        fill_ratio = (bins_remain_cap[potential_bins] - item) / bin_size\n        priorities[potential_bins] += 0.2 * fill_ratio\n\n    # Best Fit Encouragement (Adaptive Weight)\n    capacity_diff = np.abs(bins_remain_cap - item)\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        min_diff = np.min(capacity_diff[eligible_bins])\n        best_fit_bins = capacity_diff == min_diff\n        average_fill = np.mean((bin_size - bins_remain_cap) / bin_size) if num_bins > 0 else 0.0\n        best_fit_weight = 0.8 + (1.0 - average_fill)\n        priorities[best_fit_bins] += best_fit_weight\n\n    # Fragmentation Penalty (Adaptive)\n    remaining_space = bins_remain_cap - item\n    average_remaining = np.mean(bins_remain_cap) if num_bins > 0 else 0.0\n    fragmentation_threshold_multiplier = 0.2 * (1.0 - average_remaining / bin_size)\n    fragmentation_threshold = item * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)\n    fragmentation_penalty = 0.5 + (item / bin_size)\n    priorities[fragmented_bins] -= 0.7 * fragmentation_penalty\n    \n    # Exploration Bonus (Adaptive probability)\n    exploration_prob = 0.01 * (1 + average_fill)\n    if np.random.rand() < exploration_prob:\n        exploration_bonus = (bin_size - bins_remain_cap) / bin_size\n        priorities += exploration_bonus * 0.05\n\n    # Target fill bonus, adaptive target\n    if np.any(potential_bins):\n        target_fill = 0.7 + 0.1 * average_fill\n        ideal_remaining = bin_size - target_fill\n        distance_to_ideal = np.abs((bins_remain_cap[potential_bins] - item) - ideal_remaining)\n        priorities[potential_bins] += 0.3 * np.exp(-distance_to_ideal * 6)\n        \n    #Encourage evening out the fill levels\n    std_fill = np.std(1 - bins_remain_cap)\n    fill_level_penalty = (1 - bins_remain_cap - average_fill) * std_fill * 0.1\n    priorities -= fill_level_penalty * 0.1\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response4.txt_stdout.txt",
    "code_path": "problem_iter23_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fill ratio, best fit, bin diversity, and adaptive exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    num_bins = len(bins_remain_cap)\n\n    if np.any(valid_bins):\n        # Fill Ratio with item size influence\n        fill_ratio = item / bins_remain_cap[valid_bins]\n        priorities[valid_bins] += fill_ratio * 0.6\n\n        # Best Fit with non-linear encouragement\n        remaining_space = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] += np.exp(-4 * remaining_space) * 0.9\n\n        # Bin Diversity Bonus\n        if num_bins > 1:\n            bin_std = np.std(bins_remain_cap)\n            if bin_std > 0.1:\n                priorities[valid_bins] += 0.2\n\n        # Large item encouragement with adaptive threshold\n        if item > 0.7:\n             min_remaining = np.min(bins_remain_cap[valid_bins]-item)\n             tight_fit = (bins_remain_cap[valid_bins] - item) == min_remaining\n             priorities[valid_bins][tight_fit] += 0.5\n\n        # Adaptive exploration\n        exploration_factor = 0.05 * item  # Scale randomness based on item size\n        priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n\n    else:\n        priorities[:] = -0.001\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.028719585161557,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response5.txt_stdout.txt",
    "code_path": "problem_iter23_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining fill ratio, best fit, and bin diversity with global awareness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    num_bins = len(bins_remain_cap)\n\n    # Global fill level calculation\n    total_bin_capacity = num_bins\n    total_items_packed = total_bin_capacity - np.sum(bins_remain_cap)\n    average_fill = total_items_packed / total_bin_capacity if total_bin_capacity > 0 else 0.0\n\n    if np.any(valid_bins):\n        # Adaptive Fill Ratio\n        fill_ratio = item / bins_remain_cap[valid_bins]\n        fill_ratio_weight = 0.6 * (1 - average_fill) # Decrease with higher fill\n        priorities[valid_bins] += fill_ratio * fill_ratio_weight\n\n        # Adaptive Best Fit\n        remaining_space = bins_remain_cap[valid_bins] - item\n        best_fit_weight = 0.9 * (1 + average_fill) # Increase with higher fill\n        priorities[valid_bins] += np.exp(-4 * remaining_space) * best_fit_weight\n\n        # Bin Diversity Bonus (adaptive)\n        if len(bins_remain_cap) > 1:\n            bin_std = np.std(bins_remain_cap)\n            if bin_std > 0.1:\n                diversity_bonus = 0.2 * (1 - average_fill) # Decrease with higher fill\n                priorities[valid_bins] += diversity_bonus\n\n        # Large item encouragement (adaptive)\n        if item > 0.7:\n            min_remaining = np.min(bins_remain_cap[valid_bins] - item)\n            tight_fit = (bins_remain_cap[valid_bins] - item) == min_remaining\n            tight_fit_bonus = 0.5 * (1 + average_fill) # Increase with higher fill\n            priorities[valid_bins][tight_fit] += tight_fit_bonus\n\n        # Fragmentation penalty\n        remaining_space_all = bins_remain_cap - item\n        fragmentation_threshold = 0.3\n        fragmented_bins = (remaining_space_all > 0) & (remaining_space_all < fragmentation_threshold)\n        fragmentation_penalty = 0.1 * average_fill  # Increase with higher fill\n        priorities[fragmented_bins] -= fragmentation_penalty\n        \n        # Over-utilization penalty\n        too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item - 0.4))\n        over_utilization_penalty = 0.05\n        priorities[too_full_bins] -= over_utilization_penalty\n\n    else:\n        priorities[:] = -0.001  # Very low priority if item doesn't fit\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 5.115676106900674,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response6.txt_stdout.txt",
    "code_path": "problem_iter23_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    bin_size = 1.0\n    average_fill = np.mean((bin_size - bins_remain_cap) / bin_size) if num_bins > 0 else 0.0\n\n    # Adaptive Fill Ratio\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + 1e-6)\n        fill_ratio_weight = 0.7 + 0.1 * item * (1 + average_fill)\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n    # Best Fit with Exponential Decay\n    capacity_diff = bins_remain_cap - item\n    if np.any(eligible_bins):\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        best_fit_weight = 1.5 + 0.5 * (1 - average_fill)\n        priorities[eligible_bins] += best_fit_weight * np.exp(-3 * remaining_space)\n\n    # Adaptive Fragmentation Penalty\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold = item * (0.1 + 0.05 * item)\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    fragmentation_penalty = 1.3 + 0.2 * average_fill\n    priorities[fragmented_bins] -= fragmentation_penalty\n\n    # Reuse Almost Empty Bins\n    almost_empty_threshold = 0.9 - 0.1 * average_fill\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = 0.2\n        priorities[almost_empty] += almost_empty_bonus\n\n    # State-Aware Exploration\n    exploration_probability = 0.05 * (1.0 - average_fill)\n    if np.random.rand() < exploration_probability:\n        exploration_bonus = (bin_size - bins_remain_cap) / bin_size\n        priorities += exploration_bonus * 0.1\n\n    # High fill incentive\n    if np.any(eligible_bins):\n        fill_percentage = item / (bin_size - bins_remain_cap[eligible_bins])\n        high_fill_bins = (fill_percentage > 0.7) & (fill_percentage <= 1.0) # Limit the value of fill_percentage to 1\n\n        if np.any(high_fill_bins):\n            eligible_bins_index = np.where(eligible_bins)[0][high_fill_bins]\n            priorities[eligible_bins_index] += 0.3 # smaller bonus than v1\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 135.02193857199842,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response7.txt_stdout.txt",
    "code_path": "problem_iter23_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive weights, best fit, fragmentation, reuse, global fill awareness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    average_fill = np.mean(1 - bins_remain_cap)\n    std_fill = np.std(1 - bins_remain_cap)\n    \n    # 1. Adaptive Fill Ratio\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        fill_ratio = item / bins_remain_cap[eligible_bins]\n        priorities[eligible_bins] += fill_ratio * (0.7 + 0.3 * (1 - average_fill))\n\n    # 2. Enhanced Best Fit with exponential decay\n    if np.any(eligible_bins):\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += 1.5 * np.exp(-2.0 * remaining_space / item)\n\n    # 3. Adaptive Fragmentation Penalty\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold = item * (0.1 + 0.03 * average_fill)\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= 1.0 * (1+ std_fill)\n\n    # 4. Almost Empty Bonus\n    almost_empty_threshold = 0.9\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        priorities[almost_empty] += 0.3\n\n    # 5. Global Fill Level Encouragement\n    global_fill_level = np.sum(1 - bins_remain_cap) / num_bins\n    if global_fill_level > 0.6:\n        exploration_bonus = 0.1 * bins_remain_cap\n        priorities += exploration_bonus\n\n    # 6. Discourage near empty early\n    if global_fill_level < 0.1:\n        near_empty_threshold = 0.95\n        near_empty = bins_remain_cap > near_empty_threshold\n        if np.any(near_empty):\n            priorities[near_empty] -= 0.2\n\n    # 7. State-aware Exploration\n    exploration_factor = 0.05 * item * (1 + std_fill)\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.2580773833266905,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter23_response8.txt_stdout.txt",
    "code_path": "problem_iter23_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_size: float = 1.0) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining fill ratio, best fit, and fragmentation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    average_fill = np.mean(1 - bins_remain_cap / bin_size) if num_bins > 0 else 0.0\n    item_size_factor = min(1.0, item)\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # 1. Adaptive Fill Ratio: Encourage higher fill\n        fill_ratio = item / bins_remain_cap[eligible_bins]\n        priorities[eligible_bins] += (0.6 + 0.2 * item_size_factor) * fill_ratio\n\n        # 2. Best Fit: Reward tighter fits\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += (0.7 + 0.1 * item_size_factor) * np.exp(-2 * remaining_space)\n\n        # 3. Fragmentation Penalty: Discourage leaving small gaps\n        fragmentation_threshold = 0.2\n        fragmented_bins = remaining_space > 0.001 &(remaining_space <= fragmentation_threshold * item_size_factor)\n        priorities[eligible_bins][fragmented_bins] -= (0.3 + 0.1 * item_size_factor) * (remaining_space[fragmented_bins] / item)\n\n        # 4. Almost Empty Reuse: Prefer near-empty bins\n        almost_empty_threshold = 0.9\n        almost_empty = bins_remain_cap > (almost_empty_threshold * bin_size)\n        priorities[almost_empty] += 0.4  #flat bonus for now.\n\n    else:\n        priorities[:] = -0.001 #small penalty.\n\n    # 5. Exploration: Introduce controlled randomness\n    exploration_factor = 0.01 * item * (1 - average_fill)\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    # 6. Encourage utilization balancing:\n    bin_utilization = 1 - bins_remain_cap / bin_size\n    utilization_std = np.std(bin_utilization)\n    priorities += (1 - utilization_std) * 0.05\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 22, in priority_v2\n    fill_ratio = item / (bins_remain_cap[eligible_bins] + 1e-6)\nTypeError: ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\n"
  },
  {
    "stdout_filepath": "problem_iter23_response9.txt_stdout.txt",
    "code_path": "problem_iter23_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty, reuse, and exploration, tuned.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    total_bin_capacity = num_bins\n    total_items_packed = total_bin_capacity - np.sum(bins_remain_cap)\n    average_fill = total_items_packed / total_bin_capacity if total_bin_capacity > 0 else 0.0\n    \n    item_size_factor = min(0.75, item)\n    bin_availability_factor = min(1.27, np.sum(bins_remain_cap >= item) / num_bins)\n    \n    fill_ratio_weight = 0.07 + 0.10 * item_size_factor * (1 + average_fill)\n    best_fit_weight = 2.81 + 0.68 * bin_availability_factor * (1 - average_fill)\n    fragmentation_penalty_weight = 1.47 + 0.82 * item_size_factor * (1 + average_fill)\n    reuse_weight = 0.79 + 0.51 * bin_availability_factor * (1 - average_fill)\n\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + 1e-6)\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-2.73 * remaining_space)\n\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold = item * (0.45 + 0.04 * item_size_factor) * (0.2 / np.sqrt(num_bins))\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill)**2\n\n    almost_empty_threshold = 0.93 - (0.20 * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = 0.09 + average_fill * 0.57\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus\n\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-0.42))\n    priorities[too_full_bins] -= 0.08\n\n    if average_fill > 0.7:\n        empty_bin_bonus = (1-average_fill) * bins_remain_cap\n        priorities += 0.1*empty_bin_bonus\n\n    exploration_factor = 0.026 * item * (1-average_fill)\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    # Stronger Best Fit Encouragement\n    capacity_diff = np.abs(bins_remain_cap - item)\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        min_diff = np.min(capacity_diff[eligible_bins])\n        best_fit_bins = capacity_diff == min_diff\n        priorities[best_fit_bins] += 1.5 # Boost best fit\n\n    # Discourage near empty for the first few items.\n    if average_fill < 0.1:\n        near_empty_threshold = 0.95\n        near_empty = bins_remain_cap > near_empty_threshold\n        if np.any(near_empty):\n            priorities[near_empty] -= 0.2 # Reduce near-empty bin priority.\n    \n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 85.3111288392501,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response0.txt_stdout.txt",
    "code_path": "problem_iter24_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_size: float = 1.0) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration with dynamic adjustments and lookahead.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n\n    # --- 1. Adaptive Weights (Item Size & Bin Availability) ---\n    item_size_factor = min(0.75, item)  # Capping item size factor\n    bin_availability_factor = min(1.27, np.sum(bins_remain_cap >= item) / (num_bins + 1e-6))  # Smooth availability factor\n\n    fill_ratio_weight = 0.07 + 0.1 * item_size_factor\n    best_fit_weight = 2.8 + 0.7 * bin_availability_factor\n    fragmentation_penalty_weight = 1.5 + 0.8 * item_size_factor\n    reuse_weight = 0.8 + 0.5 * bin_availability_factor\n\n    # --- 2. Fill Ratio (Eligible Bins) ---\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + 0.001)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-2.7 * remaining_space)\n\n    # --- 3. Fragmentation Penalty (Dynamic Threshold) ---\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold = item * (0.45 + 0.04 * item_size_factor) * (0.2 / np.sqrt(num_bins + 1e-6))\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n\n    # Scale penalty based on fill level and item size\n    bin_fill_level = (bin_size - bins_remain_cap[fragmented_bins]) / bin_size\n    fragmentation_penalty_scaling = bin_fill_level * item_size_factor\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * fragmentation_penalty_scaling\n\n    # --- 4. Almost Empty Reuse ---\n    average_fill = np.mean(1 - bins_remain_cap / bin_size)\n    almost_empty_threshold = 0.93 - (0.2 * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = 0.09 + average_fill * 0.6\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus\n\n    # --- 5. Too Full Penalty ---\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item - 0.42))\n    priorities[too_full_bins] -= 0.08\n\n    # --- 6. Exploration (Scaled Randomness) ---\n    exploration_factor = 0.026 * item\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    # --- 7. Encourage Even Utilization (with stronger weighting) ---\n    bin_utilization = 1 - bins_remain_cap / bin_size\n    utilization_std = np.std(bin_utilization)\n    priorities += (1 - utilization_std) * 0.2  # Doubled the bonus\n\n    # --- 8. Lookahead (Simulated Placement) ---\n    # Penalize bins that, after placing the current item, would become difficult to fill later.\n    simulated_remaining_caps = bins_remain_cap - item\n    simulated_remaining_caps[simulated_remaining_caps < 0] = -1 # Mark that the item can't be added\n\n    small_space_penalty_threshold = 0.15 #bins with remaining capacity less than this gets penalized\n    difficult_to_fill = (simulated_remaining_caps > 0) & (simulated_remaining_caps <= small_space_penalty_threshold)\n\n    # Scale penalty by how much space is wasted and the size of the item\n    waste_amount = small_space_penalty_threshold - simulated_remaining_caps[difficult_to_fill]\n    waste_penalty = waste_amount/ small_space_penalty_threshold\n\n    priorities[difficult_to_fill] -= 0.05 * waste_penalty * item_size_factor\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 2.0841643398484337,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response1.txt_stdout.txt",
    "code_path": "problem_iter24_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_size: float = 1.0) -> np.ndarray:\n    \"\"\"Improved priority function for online bin packing, focusing on adaptivity and multi-objective optimization.\"\"\"\n\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # --- Adaptive Parameters ---\n    average_fill = np.mean(1 - bins_remain_cap / bin_size)\n    item_size_relative = item / bin_size # Normalize item size.\n\n    # The smaller items are, the stronger 'best fit' should be.\n    best_fit_weight = 2.0 + (1 - item_size_relative) * 3.0\n    # Fragmentation penalty should be stronger when bins are emptier.\n    fragmentation_penalty_weight = 1.0 + average_fill * 2.0\n    # Reuse empty bins more aggressively when there are few open bins.\n    reuse_weight = 1.0 + (1 - np.sum(bins_remain_cap > 0) / num_bins) * 2.0\n\n    # --- Fill Ratio ---\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + 0.001) # Small constant to avoid division by zero\n        priorities[eligible_bins] += fill_ratio * 0.7 # Weight fill ratio.\n\n    # --- Best Fit ---\n    if np.any(eligible_bins):\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        # Exponential decay favors bins with the least remaining space.\n        priorities[eligible_bins] += best_fit_weight * np.exp(-5 * remaining_space / bin_size)\n\n    # --- Fragmentation Penalty ---\n    # Penalize bins that, after placing the item, will have a small remaining space.\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold = 0.2 * item_size_relative  # Threshold as a fraction of item size.\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1 - average_fill)\n\n    # --- Reuse Almost Empty Bins ---\n    almost_empty_threshold = 0.9 # Define \"almost empty\" as a fraction of bin size.\n    almost_empty = bins_remain_cap > almost_empty_threshold * bin_size\n    if np.any(almost_empty):\n        priorities[almost_empty] += reuse_weight * 0.5\n\n    # --- Penalize Too-Full Bins ---\n    too_full_threshold = 0.1 # Penalize bins with insufficient space\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (bins_remain_cap.max() - too_full_threshold))\n    priorities[too_full_bins] -= 0.3\n\n    # --- Exploration ---\n    # Add a small amount of randomness to encourage exploration of different solutions.\n    exploration_factor = 0.01 * item  # Scale randomness based on item size.\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    # --- Bin Utilization Balance ---\n    bin_utilization = 1 - bins_remain_cap / bin_size\n    utilization_std = np.std(bin_utilization)\n    priorities += (1 - utilization_std) * 0.1\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 5.285201435979258,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response2.txt_stdout.txt",
    "code_path": "problem_iter24_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_size: float = 1.0) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration, and bin diversity. Enhanced for adaptivity and state-awareness.\"\"\"\n\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # --- Adaptive Parameters (learned or hand-tuned) ---\n    fill_ratio_weight_base: float = 0.1\n    fill_ratio_weight_item_factor: float = 0.15\n    best_fit_weight_base: float = 3.0\n    best_fit_weight_availability_factor: float = 0.7\n    fragmentation_penalty_weight_base: float = 1.5\n    fragmentation_penalty_weight_item_factor: float = 0.9\n    reuse_weight_base: float = 0.8\n    reuse_weight_availability_factor: float = 0.55\n    best_fit_decay_rate: float = 2.5\n    fragmentation_threshold_base: float = 0.4\n    fragmentation_threshold_item_factor: float = 0.04\n    almost_empty_threshold_base: float = 0.9\n    almost_empty_threshold_average_fill_factor: float = 0.2\n    almost_empty_bonus_base: float = 0.1\n    almost_empty_bonus_average_fill_factor: float = 0.6\n    too_full_threshold: float = 0.4\n    too_full_penalty: float = 0.1\n    exploration_factor_scale: float = 0.03\n    min_item_size_factor: float = 0.7\n    min_bin_availability_factor: float = 1.3\n    division_epsilon: float = 0.001\n\n    # --- Global State Awareness ---\n    average_fill = np.mean(1 - bins_remain_cap / bin_size)\n    bin_utilization = 1 - bins_remain_cap / bin_size\n    utilization_std = np.std(bin_utilization)\n\n    # --- Adaptive Weights ---\n    item_size_factor = min(min_item_size_factor, item)\n    bin_availability_factor = min(min_bin_availability_factor, np.sum(bins_remain_cap >= item) / num_bins)\n\n    fill_ratio_weight = fill_ratio_weight_base + fill_ratio_weight_item_factor * item_size_factor\n    best_fit_weight = best_fit_weight_base + best_fit_weight_availability_factor * bin_availability_factor\n    fragmentation_penalty_weight = fragmentation_penalty_weight_base + fragmentation_penalty_weight_item_factor * item_size_factor\n    reuse_weight = reuse_weight_base + reuse_weight_availability_factor * bin_availability_factor\n\n    # --- Eligible Bins ---\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + division_epsilon)\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-best_fit_decay_rate * remaining_space)\n\n    # Fragmentation Penalty\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold = item * (fragmentation_threshold_base + fragmentation_threshold_item_factor * item_size_factor)\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    fragmentation_penalty_scaling = (bin_size - bins_remain_cap[fragmented_bins]) / bin_size  # Scale based on fill\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1 - average_fill) * fragmentation_penalty_scaling\n\n    # Almost Empty Reuse\n    almost_empty_threshold = almost_empty_threshold_base - (almost_empty_threshold_average_fill_factor * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = almost_empty_bonus_base + average_fill * almost_empty_bonus_average_fill_factor\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus\n\n    # Too Full Penalty\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item - too_full_threshold))\n    priorities[too_full_bins] -= too_full_penalty\n\n    # Exploration (scaled randomness)\n    exploration_factor = exploration_factor_scale * item\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    # Bin Diversity Bonus (Encourage evening out utilization) - More robust to outliers\n    priorities += (1 - utilization_std) * 0.1\n\n    # Sort the bins by remaining capacity, add a small bonus for more full bins (but below item size)\n    potentially_good_bins = (bins_remain_cap < item)\n    if np.any(potentially_good_bins):\n      priorities[potentially_good_bins] += (bin_size - bins_remain_cap[potentially_good_bins]) / bin_size * 0.05\n\n    # Dynamic adjustment of best fit weight. If there are very few eligible bins, increase best fit weight.\n    if np.sum(eligible_bins) < num_bins * 0.1:\n        priorities[eligible_bins] += best_fit_weight * 0.5  # Boost best fit\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 10.600319106501791,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response3.txt_stdout.txt",
    "code_path": "problem_iter24_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_size: float = 1.0) -> np.ndarray:\n    \"\"\"\n    Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration with added adaptivity and global awareness.\n    \"\"\"\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins)\n\n    # --- Adaptive Parameters (Dynamically Adjusted) ---\n    average_fill = np.mean(1 - bins_remain_cap / bin_size)\n    bin_std = np.std(bins_remain_cap / bin_size)\n    item_relative_size = item / bin_size\n\n    # Weights (Adaptive based on average fill and item size)\n    fill_ratio_weight = 0.2 + 0.1 * item_relative_size + 0.1 * average_fill\n    best_fit_weight = 0.6 + 0.2 * (1 - average_fill)\n    fragmentation_penalty_weight = 0.4 + 0.2 * item_relative_size\n    reuse_weight = 0.3 + 0.1 * (1 - item_relative_size)\n\n    # Thresholds (Adaptive)\n    fragmentation_threshold = 0.2 * bin_size * (1 + 0.5 * item_relative_size)\n    almost_empty_threshold = 0.9 * bin_size * (1 - 0.3 * average_fill)\n\n    # --- Feature: Bin Eligibility ---\n    eligible_bins = bins_remain_cap >= item\n    num_eligible_bins = np.sum(eligible_bins)\n\n    if num_eligible_bins == 0:\n        # No bin can fit, so prioritize the least full bin that is still closest to fitting\n        closest_bin_index = np.argmin(bins_remain_cap)  # Find bin with smallest remaining capacity\n        priorities[closest_bin_index] = -1.0  # Strongly discourage, but allow if necessary\n        return priorities  # Return immediately if no bin fits\n    \n    # --- Fill Ratio Priority ---\n    fill_ratio = item / (bins_remain_cap[eligible_bins] + 1e-6)\n    priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n    # --- Best Fit Priority ---\n    remaining_space = bins_remain_cap[eligible_bins] - item\n    priorities[eligible_bins] += best_fit_weight * np.exp(-5 * remaining_space / bin_size)  # Exponential decay\n\n    # --- Fragmentation Penalty ---\n    remaining_space_all = bins_remain_cap - item\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1 - average_fill) * (fragmentation_threshold - remaining_space_all[fragmented_bins]) / fragmentation_threshold\n\n    # --- Reuse Almost Empty Bins ---\n    almost_empty_bins = bins_remain_cap > almost_empty_threshold\n    priorities[almost_empty_bins] += reuse_weight * (bins_remain_cap[almost_empty_bins] / bin_size)\n    \n    # --- Balance Bin Utilization ---\n    bin_utilization = 1 - bins_remain_cap / bin_size\n    priorities += 0.1 * (1 - bin_std)  # Encourage even utilization\n\n    # --- Global Bin Balancing (New Feature) ---\n    # Penalize bins that are outliers in terms of remaining capacity.\n    capacity_median = np.median(bins_remain_cap)\n    capacity_deviation = np.abs(bins_remain_cap - capacity_median)\n    priorities -= 0.05 * capacity_deviation / bin_size\n    \n    # --- Exploration (Adaptive) ---\n    exploration_factor = 0.01 * item_relative_size * (1 + bin_std)  # Adaptive exploration\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 5.295173514160364,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response4.txt_stdout.txt",
    "code_path": "problem_iter24_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_size: float = 1.0) -> np.ndarray:\n    \"\"\"Enhanced priority function for online bin packing, building upon priority_v1.\"\"\"\n\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # --- Adaptive Parameters (dynamically adjusted based on item and bin states) ---\n    avg_capacity = np.mean(bins_remain_cap)\n    capacity_std = np.std(bins_remain_cap)\n    num_eligible = np.sum(bins_remain_cap >= item)\n    eligibility_ratio = num_eligible / num_bins if num_bins > 0 else 0.0\n    avg_fill = np.mean(1 - bins_remain_cap / bin_size)\n\n    # Fill Ratio: Prioritize bins that will be filled well. Adapt weight based on item size and bin availability.\n    fill_ratio_weight = 0.2 + 0.3 * item + 0.5 * eligibility_ratio  # Increased impact\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        fill_ratio = item / bins_remain_cap[eligible_bins]\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n    # Best Fit: Reward bins with minimal remaining space after packing.  Adaptive weight and decay.\n    best_fit_weight = 0.5 + 0.4 * eligibility_ratio + 0.1 * (1 - avg_fill)\n    best_fit_decay_rate = 3.0 - 1.5 * item # Larger items require less fine-grained best fit.\n    if np.any(eligible_bins):\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-best_fit_decay_rate * remaining_space)\n\n    # Fragmentation Penalty: Discourage creating small, unusable fragments.  Adapt based on item size and bin diversity.\n    fragmentation_penalty_weight = 0.3 + 0.2 * item + 0.5 * (capacity_std / avg_capacity if avg_capacity > 0 else 0.0)\n    fragmentation_threshold = item * (0.3 + 0.1 * item)  # Dynamic fragmentation threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1 - avg_fill)  # Scale by fill\n\n    # Reuse Almost Empty Bins: Incentivize reusing bins close to empty. Adaptive bonus.\n    almost_empty_threshold = 0.9 - 0.2 * avg_fill\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    almost_empty_bonus = 0.2 + 0.3 * avg_fill\n    priorities[almost_empty] += almost_empty_bonus\n\n    # Penalize Too Full Bins: Strongly discourage bins that are almost full but cannot fit the current item.\n    too_full_threshold = 0.2\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item - too_full_threshold))\n    priorities[too_full_bins] -= 0.4  # Strong penalty\n\n    #Bin balancing.\n    bin_utilization = 1 - bins_remain_cap / bin_size\n    utilization_std = np.std(bin_utilization)\n    priorities += (1 - utilization_std) * 0.2 # Give a small bonus to solutions with similar utilizations\n\n    # Exploration: Introduce randomness to escape local optima. Adaptive scale based on remaining capacity variance.\n    exploration_factor = 0.05 * item * (capacity_std / avg_capacity if avg_capacity > 0 else 0.0)\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n\n   #Prioritize bins with higher remaining capacity if there is no eligible bins.\n    if not np.any(eligible_bins):\n        priorities += bins_remain_cap * 0.01\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 38.432389309932205,
    "exec_success": true
  }
]