```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Adaptive bin packing heuristic combining fill ratio, best fit, and state-aware exploration."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    num_bins = len(bins_remain_cap)
    bin_size = 1.0

    #Adaptive Item Size and Bin Availability
    item_size_factor = min(1.0, item)
    bin_availability_factor = min(1.0, np.sum(bins_remain_cap >= item) / num_bins)
    average_fill = np.mean(1 - bins_remain_cap)

    #Fill Ratio (Weighted)
    fill_ratio_weight = 0.5 + 0.3 * item_size_factor
    eligible_bins = bins_remain_cap >= item
    if np.any(eligible_bins):
        fill_ratio = item / (bins_remain_cap[eligible_bins] + 0.0001)
        priorities[eligible_bins] += fill_ratio_weight * fill_ratio

    #Best Fit (Weighted)
    best_fit_weight = 1.5 + 0.5 * bin_availability_factor
    if np.any(eligible_bins):
        remaining_space = bins_remain_cap[eligible_bins] - item
        priorities[eligible_bins] += best_fit_weight * np.exp(-2 * remaining_space)

    #Fragmentation Penalty
    remaining_space_all = bins_remain_cap - item
    fragmentation_threshold_multiplier = 0.2 / np.sqrt(num_bins)
    fragmentation_threshold = item * (0.1 + 0.1 * item_size_factor) * fragmentation_threshold_multiplier
    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)
    fragmentation_penalty_weight = 1.0 + 0.2 * item_size_factor
    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill)

    #Reuse Almost Empty Bins
    almost_empty_threshold = 0.95 - (0.1 * average_fill)
    almost_empty = bins_remain_cap > almost_empty_threshold
    if np.any(almost_empty):
        almost_empty_bonus = 0.5 + average_fill * 0.5
        reuse_weight = 0.6 + 0.4 * bin_availability_factor
        priorities[almost_empty] += reuse_weight * almost_empty_bonus

    #Bin Utilization
    utilization = (bin_size - bins_remain_cap) / bin_size
    fully_utilized_threshold = 0.8
    highly_utilized = utilization > fully_utilized_threshold
    utilization_bonus = 0.5
    priorities[highly_utilized] += utilization_bonus

    #State-Aware Exploration
    exploration_rate = 0.05 * (1.0 - average_fill)
    if np.random.rand() < exploration_rate:
        exploration_bonus = (bin_size - bins_remain_cap) / bin_size
        priorities += exploration_bonus * 0.2

    # Penalize bins that are close to full but can't fit the item
    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-0.2))
    priorities[too_full_bins] -= 0.8

    # Underutilization Penalty: Penalize creating almost empty bins with small items
    new_remaining_space = bins_remain_cap - item
    underutilization_threshold = 0.1 # Penalty for bins with low utilization after placement
    underutilization_penalty = 0.6
    underutilized_bins = (new_remaining_space > 0) & (new_remaining_space / bin_size > (1 - underutilization_threshold)) & (item < (bin_size * 0.5)) #Only penalize if item is small
    priorities[underutilized_bins] -= underutilization_penalty

    return priorities
```
