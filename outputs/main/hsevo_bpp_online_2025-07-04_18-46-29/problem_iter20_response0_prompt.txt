{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines fill-ratio, best-fit, adaptive fragmentation penalty, and bin balancing.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n    item_size_factor = min(1.0, item)\n\n    if np.any(eligible_bins):\n        # 1. Fill Ratio Preference (adaptive)\n        fill_ratio = item / bins_remain_cap[eligible_bins]\n        priorities[eligible_bins] += (0.6 + 0.2 * item_size_factor) * fill_ratio\n\n        # 2. Best Fit Encouragement (Nonlinear + adaptive)\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += (0.7 + 0.1 * item_size_factor) * np.exp(-remaining_space)\n\n        # 3. Adaptive Fragmentation Penalty\n        max_bin_cap = np.max(bins_remain_cap) if np.any(bins_remain_cap) else 1.0\n        fragmentation_penalty = 0.2 * (remaining_space / max_bin_cap) * (1 + item_size_factor)\n        priorities[eligible_bins] -= fragmentation_penalty\n\n    # 4. Bin Balancing (Encourage use of emptier bins)\n    bin_capacity_normalized = bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap)>0 else np.zeros_like(bins_remain_cap)\n    priorities += 0.15 * (1-bin_capacity_normalized)\n\n    # 5. Encourage re-use of almost empty bins (adaptive threshold)\n    almost_empty_threshold = 0.9 + 0.05 * item_size_factor\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        priorities[almost_empty] += 0.6 + 0.1 * item_size_factor\n\n    #6. Add small bonus to bins that can accommodate the item (tie breaker).\n    if np.any(eligible_bins):\n      priorities[eligible_bins] += 0.01\n\n    else:\n       priorities[:] = -0.001 # Discourage if no suitable bin\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Adaptive priority function combining best-fit, target fill, and fragmentation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    average_fill = np.mean(1 - bins_remain_cap)\n\n    if np.any(valid_bins):\n        # Best-fit with adaptive item size impact\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] -= np.abs(waste) * (1 + 0.2 * item)\n\n        # Target fill bonus, adaptive target\n        target_fill = 0.7 + 0.1 * average_fill\n        ideal_remaining = 1 - target_fill\n        distance_to_ideal = np.abs((bins_remain_cap[valid_bins] - item) - ideal_remaining)\n        priorities[valid_bins] += np.exp(-distance_to_ideal * 6)\n\n        # Fragmentation penalty with adaptive threshold\n        fragmentation_threshold = item * (0.1 + 0.05 * average_fill)\n        remaining_space = bins_remain_cap - item\n        fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)\n        fragmentation_penalty = 1.0 + 0.5 * (fragmentation_threshold - remaining_space[fragmented_bins]) / (fragmentation_threshold + 1e-9)\n        priorities[fragmented_bins] -= fragmentation_penalty * (1 + 0.1 * average_fill)\n\n        # Almost-empty bonus\n        almost_empty_threshold = 0.9 - 0.05 * average_fill\n        almost_empty = bins_remain_cap > almost_empty_threshold\n        if np.any(almost_empty):\n            almost_empty_bonus = 0.5 + 0.4 * (bins_remain_cap[almost_empty] - almost_empty_threshold) / (1 - almost_empty_threshold + 1e-9)\n            priorities[almost_empty] += almost_empty_bonus\n\n        # Exploration: Add a small amount of randomness\n        exploration_factor = 0.005 * item * (1-average_fill)\n        priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    else:\n        priorities[:] = -100\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the 1st uses much more sophisticated adaptive weighting and introduces exploration with randomness scaled by item size. It dynamically adjusts weights based on item size, bin availability, and average fill level. The 20th heuristic uses fixed weights and lacks fine-grained control. (2nd best) vs (second worst) shows a similar trend, with more complex adaptive parameters in the better heuristic. Comparing (1st) vs (2nd), we see the 1st introduces a large amount of parameter to finetune the algorithm and uses many thresholds to have a finer control of the output while the 2nd uses only a few parameters to define. (3rd) vs (4th) shows that the third heuristic gives bonus to bin with high utilization. Comparing (second worst) vs (worst), we see little to no difference. Overall: better heuristics utilize adaptive weighting, state-aware adjustments, and exploration strategies. They dynamically adjust parameters based on item size, bin availability, average fill level, and other relevant factors, offering finer control and better performance. The best heuristic uses a large amount of parameters.\n- \nHere's a redefined approach to \"Current Self-Reflection\" designed to build better heuristics, incorporating your feedback and aiming for clear, actionable advice:\n\n*   **Keywords:** Adaptive, Multi-Objective, State-Aware, Exploration-Exploitation.\n\n*   **Advice:** Design heuristics that dynamically adjust their behavior (weights, exploration) based on the *global* state of the bin packing problem, considering factors like item sizes, bin availability, and fill levels. Prioritize multi-objective optimization that explicitly balances competing goals, such as minimizing waste and maximizing bin utilization.\n\n*   **Avoid:** Over-reliance on purely local information or premature focus on fine-tuning a fixed set of parameters. Avoid getting stuck in local optima.\n\n*   **Explanation:** Effective heuristics are not rigid; they adapt. They use a combination of factors to choose the best action at any given time. Penalties and bonuses should react to the global state to guide the heuristic toward the best overall packing. Think of the global state as a summary of the entire packing problem (e.g., average fill level, distribution of item sizes, number of almost-full bins).\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}