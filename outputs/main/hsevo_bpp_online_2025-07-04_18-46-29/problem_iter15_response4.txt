```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray, bin_size: float = 1.0) -> np.ndarray:
    """
    A more advanced priority function for online bin packing, incorporating:
    - Fill ratio
    - Best fit with adaptive weighting based on bin fill levels
    - Fragmentation penalty, also adaptive
    - Encouragement of almost-empty bins, adaptive too
    - Global bin state awareness to balance exploration and exploitation

    Args:
        item (float): The size of the item to be packed.
        bins_remain_cap (np.ndarray): Remaining capacity of each bin.
        bin_size (float): The capacity of each bin (default 1.0).

    Returns:
        np.ndarray: Priority score for each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    num_bins = len(bins_remain_cap)

    # 1. Fill Ratio Preference
    potential_bins = bins_remain_cap >= item
    if np.any(potential_bins):
        fill_ratio = (bins_remain_cap[potential_bins] - item) / bin_size  # Use bin size for consistent ratio calculation
        priorities[potential_bins] += fill_ratio

    # 2. Best Fit Encouragement (Adaptive Weight)
    capacity_diff = np.abs(bins_remain_cap - item)
    eligible_bins = bins_remain_cap >= item

    if np.any(eligible_bins):
        min_diff = np.min(capacity_diff[eligible_bins])
        best_fit_bins = capacity_diff == min_diff
        
        # Adaptive best-fit weight:  Higher weight when bins are relatively empty.
        # This encourages filling up emptier bins more aggressively.
        average_fill = np.mean((bin_size - bins_remain_cap) / bin_size) if num_bins > 0 else 0.0 #Global bin state
        best_fit_weight = 1.0 + (1.0 - average_fill)  # Weight increases as bins are emptier.

        priorities[best_fit_bins] += best_fit_weight
        

    # 3. Fragmentation Penalty (Adaptive)
    remaining_space = bins_remain_cap - item
    
    #Adaptive fragmentation threshold based on global state.
    average_remaining = np.mean(bins_remain_cap) if num_bins > 0 else 0.0 #Global bin state
    fragmentation_threshold_multiplier = 0.2 * (1.0 - average_remaining/bin_size) #Higher penality when bins are full
    fragmentation_threshold = item * fragmentation_threshold_multiplier
    fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)

    # Adaptive fragmentation penalty. Higher when items are small relative to bin size.
    fragmentation_penalty = 0.5 + (item / bin_size)
    priorities[fragmented_bins] -= fragmentation_penalty
    

    # 4. Encourage re-use of almost empty bins (Adaptive Bonus)
    almost_empty_threshold = 0.1
    almost_empty = bins_remain_cap > (bin_size * (1 - almost_empty_threshold))
    if np.any(almost_empty):
        #Adaptive bonus depends on how many bins are already almost empty
        almost_empty_count = np.sum(bins_remain_cap > (bin_size * (1 - almost_empty_threshold)))
        almost_empty_bonus = 0.8 / (1 + almost_empty_count) #Fewer bonus when there are many almost empty bins
        priorities[almost_empty] += almost_empty_bonus

    # 5. Exploration Bonus:  Occasionally select less-filled bins. (Controlled Randomness)
    if np.random.rand() < 0.05:  # 5% chance of exploration
        exploration_bonus = (bin_size - bins_remain_cap) / bin_size # Prefer bins that are less filled
        priorities += exploration_bonus * 0.2 #Reduce bonus influence

    return priorities
```
