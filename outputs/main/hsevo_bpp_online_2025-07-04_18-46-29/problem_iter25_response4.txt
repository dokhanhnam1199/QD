import numpy as np

def priority_v2(item: float,
                bins_remain_cap: np.ndarray,
                bin_size: float = 1.0,
                item_size_factor_cap: float = 0.9844102629276291,
                bin_availability_factor_cap: float = 1.198827020930713,
                fill_ratio_weight_base: float = 0.08786366984614481,
                fill_ratio_weight_item_factor: float = 0.09566986934788443,
                best_fit_weight_base: float = 2.9599394553214466,
                best_fit_weight_availability_factor: float = 0.5790628905998325,
                fragmentation_penalty_weight_base: float = 1.503912482931551,
                fragmentation_penalty_weight_item_factor: float = 0.953119525151401,
                reuse_weight_base: float = 0.5211098372913584,
                reuse_weight_availability_factor: float = 0.5000580806745439,
                fill_ratio_add: float = 0.0006388181485995405,
                best_fit_exp_decay: float = -2.3679455787902692,
                fragmentation_threshold_base: float = 0.4674262283622451,
                fragmentation_threshold_item_factor: float = 0.0295666311934161,
                fragmentation_threshold_num_bins_factor: float = 0.15755122469198302,
                almost_empty_threshold_base: float = 0.9458070917123214,
                almost_empty_threshold_fill_factor: float = 0.14782033646401027,
                almost_empty_bonus_base: float = 0.1321631949919208,
                almost_empty_bonus_fill_factor: float = 0.5793802337670592,
                too_full_threshold: float = 0.4944399882771907,
                too_full_penalty: float = -0.06349607698790108,
                exploration_factor_base: float = 0.022508124058499637,
                utilization_bonus: float = 0.11675038256222972,
                small_space_penalty_threshold: float = 0.19445307209173213,
                difficult_to_fill_penalty: float = 0.0332105465896363) -> np.ndarray:
    """Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration with dynamic adjustments and lookahead."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    num_bins = len(bins_remain_cap)

    # --- 1. Adaptive Weights (Item Size & Bin Availability) ---
    item_size_factor = min(item_size_factor_cap, item)  # Capping item size factor
    bin_availability_factor = min(bin_availability_factor_cap, np.sum(bins_remain_cap >= item) / (num_bins + 1e-6))  # Smooth availability factor

    fill_ratio_weight = fill_ratio_weight_base + fill_ratio_weight_item_factor * item_size_factor
    best_fit_weight = best_fit_weight_base + best_fit_weight_availability_factor * bin_availability_factor
    fragmentation_penalty_weight = fragmentation_penalty_weight_base + fragmentation_penalty_weight_item_factor * item_size_factor
    reuse_weight = reuse_weight_base + reuse_weight_availability_factor * bin_availability_factor

    # --- 2. Fill Ratio (Eligible Bins) ---
    eligible_bins = bins_remain_cap >= item
    if np.any(eligible_bins):
        fill_ratio = item / (bins_remain_cap[eligible_bins] + fill_ratio_add)  # Avoid division by zero
        priorities[eligible_bins] += fill_ratio_weight * fill_ratio

        # Best Fit - Exponential decay
        remaining_space = bins_remain_cap[eligible_bins] - item
        priorities[eligible_bins] += best_fit_weight * np.exp(best_fit_exp_decay * remaining_space)

    # --- 3. Fragmentation Penalty (Dynamic Threshold) ---
    remaining_space_all = bins_remain_cap - item
    fragmentation_threshold = item * (fragmentation_threshold_base + fragmentation_threshold_item_factor * item_size_factor) * (fragmentation_threshold_num_bins_factor / np.sqrt(num_bins + 1e-6))
    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)

    # Scale penalty based on fill level and item size
    bin_fill_level = (bin_size - bins_remain_cap[fragmented_bins]) / bin_size
    fragmentation_penalty_scaling = bin_fill_level * item_size_factor
    priorities[fragmented_bins] -= fragmentation_penalty_weight * fragmentation_penalty_scaling

    # --- 4. Almost Empty Reuse ---
    average_fill = np.mean(1 - bins_remain_cap / bin_size)
    almost_empty_threshold = almost_empty_threshold_base - (almost_empty_threshold_fill_factor * average_fill)
    almost_empty = bins_remain_cap > almost_empty_threshold
    if np.any(almost_empty):
        almost_empty_bonus = almost_empty_bonus_base + average_fill * almost_empty_bonus_fill_factor
        priorities[almost_empty] += reuse_weight * almost_empty_bonus

    # --- 5. Too Full Penalty ---
    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item - too_full_threshold))
    priorities[too_full_bins] += too_full_penalty

    # --- 6. Exploration (Scaled Randomness) ---
    exploration_factor = exploration_factor_base * item
    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)

    # --- 7. Encourage Even Utilization (with stronger weighting) ---
    bin_utilization = 1 - bins_remain_cap / bin_size
    utilization_std = np.std(bin_utilization)
    priorities += (1 - utilization_std) * utilization_bonus  # Doubled the bonus

    # --- 8. Lookahead (Simulated Placement) ---
    # Penalize bins that, after placing the current item, would become difficult to fill later.
    simulated_remaining_caps = bins_remain_cap - item
    simulated_remaining_caps[simulated_remaining_caps < 0] = -1 # Mark that the item can't be added

    difficult_to_fill = (simulated_remaining_caps > 0) & (simulated_remaining_caps <= small_space_penalty_threshold)

    # Scale penalty by how much space is wasted and the size of the item
    waste_amount = small_space_penalty_threshold - simulated_remaining_caps[difficult_to_fill]
    waste_penalty = waste_amount/ small_space_penalty_threshold

    priorities[difficult_to_fill] -= difficult_to_fill_penalty * waste_penalty * item_size_factor

    return priorities
