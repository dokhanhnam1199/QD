```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Adaptive heuristic combining fill ratio, best fit, and fragmentation."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    num_bins = len(bins_remain_cap)
    bin_size = 1.0

    # Fill Ratio Preference
    potential_bins = bins_remain_cap >= item
    if np.any(potential_bins):
        fill_ratio = (bins_remain_cap[potential_bins] - item) / bin_size
        priorities[potential_bins] += 0.2 * fill_ratio

    # Best Fit Encouragement (Adaptive Weight)
    capacity_diff = np.abs(bins_remain_cap - item)
    eligible_bins = bins_remain_cap >= item

    if np.any(eligible_bins):
        min_diff = np.min(capacity_diff[eligible_bins])
        best_fit_bins = capacity_diff == min_diff
        average_fill = np.mean((bin_size - bins_remain_cap) / bin_size) if num_bins > 0 else 0.0
        best_fit_weight = 0.8 + (1.0 - average_fill)
        priorities[best_fit_bins] += best_fit_weight

    # Fragmentation Penalty (Adaptive)
    remaining_space = bins_remain_cap - item
    average_remaining = np.mean(bins_remain_cap) if num_bins > 0 else 0.0
    fragmentation_threshold_multiplier = 0.2 * (1.0 - average_remaining / bin_size)
    fragmentation_threshold = item * fragmentation_threshold_multiplier
    fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)
    fragmentation_penalty = 0.5 + (item / bin_size)
    priorities[fragmented_bins] -= 0.7 * fragmentation_penalty
    
    # Exploration Bonus (Adaptive probability)
    exploration_prob = 0.01 * (1 + average_fill)
    if np.random.rand() < exploration_prob:
        exploration_bonus = (bin_size - bins_remain_cap) / bin_size
        priorities += exploration_bonus * 0.05

    # Target fill bonus, adaptive target
    if np.any(potential_bins):
        target_fill = 0.7 + 0.1 * average_fill
        ideal_remaining = bin_size - target_fill
        distance_to_ideal = np.abs((bins_remain_cap[potential_bins] - item) - ideal_remaining)
        priorities[potential_bins] += 0.3 * np.exp(-distance_to_ideal * 6)
        
    #Encourage evening out the fill levels
    std_fill = np.std(1 - bins_remain_cap)
    fill_level_penalty = (1 - bins_remain_cap - average_fill) * std_fill * 0.1
    priorities -= fill_level_penalty * 0.1

    return priorities
```
