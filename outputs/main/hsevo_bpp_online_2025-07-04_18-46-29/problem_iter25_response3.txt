import numpy as np

def priority_v2(item: float,
                bins_remain_cap: np.ndarray,
                bin_size: float = 1.0,
                item_size_factor_cap: float = 0.8775887111115989,
                bin_availability_factor_cap: float = 1.1189726204089225,
                fill_ratio_weight_base: float = 0.06261441886693744,
                fill_ratio_weight_item_factor: float = 0.11283644918457324,
                best_fit_weight_base: float = 2.639516225220801,
                best_fit_weight_availability_factor: float = 0.90348879905283,
                fragmentation_penalty_weight_base: float = 1.3939182292796826,
                fragmentation_penalty_weight_item_factor: float = 0.9430052369478841,
                reuse_weight_base: float = 0.6863878458283115,
                reuse_weight_availability_factor: float = 0.4578729962726866,
                fill_ratio_add: float = 0.0008157070715734856,
                best_fit_exp_decay: float = -2.3746516928241554,
                fragmentation_threshold_base: float = 0.46912520236991456,
                fragmentation_threshold_item_factor: float = 0.05927671247440283,
                fragmentation_threshold_num_bins_factor: float = 0.2970104418248459,
                almost_empty_threshold_base: float = 0.9091454724365622,
                almost_empty_threshold_fill_factor: float = 0.14018838810828574,
                almost_empty_bonus_base: float = 0.08453549177312596,
                almost_empty_bonus_fill_factor: float = 0.6235731433135354,
                too_full_threshold: float = 0.365384106694592,
                too_full_penalty: float = -0.06696088204856629,
                exploration_factor_base: float = 0.02852807891142095,
                utilization_bonus: float = 0.2207023524196182,
                small_space_penalty_threshold: float = 0.1809263918950793,
                difficult_to_fill_penalty: float = 0.06413402612444213) -> np.ndarray:
    """Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration with dynamic adjustments and lookahead."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    num_bins = len(bins_remain_cap)

    # --- 1. Adaptive Weights (Item Size & Bin Availability) ---
    item_size_factor = min(item_size_factor_cap, item)  # Capping item size factor
    bin_availability_factor = min(bin_availability_factor_cap, np.sum(bins_remain_cap >= item) / (num_bins + 1e-6))  # Smooth availability factor

    fill_ratio_weight = fill_ratio_weight_base + fill_ratio_weight_item_factor * item_size_factor
    best_fit_weight = best_fit_weight_base + best_fit_weight_availability_factor * bin_availability_factor
    fragmentation_penalty_weight = fragmentation_penalty_weight_base + fragmentation_penalty_weight_item_factor * item_size_factor
    reuse_weight = reuse_weight_base + reuse_weight_availability_factor * bin_availability_factor

    # --- 2. Fill Ratio (Eligible Bins) ---
    eligible_bins = bins_remain_cap >= item
    if np.any(eligible_bins):
        fill_ratio = item / (bins_remain_cap[eligible_bins] + fill_ratio_add)  # Avoid division by zero
        priorities[eligible_bins] += fill_ratio_weight * fill_ratio

        # Best Fit - Exponential decay
        remaining_space = bins_remain_cap[eligible_bins] - item
        priorities[eligible_bins] += best_fit_weight * np.exp(best_fit_exp_decay * remaining_space)

    # --- 3. Fragmentation Penalty (Dynamic Threshold) ---
    remaining_space_all = bins_remain_cap - item
    fragmentation_threshold = item * (fragmentation_threshold_base + fragmentation_threshold_item_factor * item_size_factor) * (fragmentation_threshold_num_bins_factor / np.sqrt(num_bins + 1e-6))
    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)

    # Scale penalty based on fill level and item size
    bin_fill_level = (bin_size - bins_remain_cap[fragmented_bins]) / bin_size
    fragmentation_penalty_scaling = bin_fill_level * item_size_factor
    priorities[fragmented_bins] -= fragmentation_penalty_weight * fragmentation_penalty_scaling

    # --- 4. Almost Empty Reuse ---
    average_fill = np.mean(1 - bins_remain_cap / bin_size)
    almost_empty_threshold = almost_empty_threshold_base - (almost_empty_threshold_fill_factor * average_fill)
    almost_empty = bins_remain_cap > almost_empty_threshold
    if np.any(almost_empty):
        almost_empty_bonus = almost_empty_bonus_base + average_fill * almost_empty_bonus_fill_factor
        priorities[almost_empty] += reuse_weight * almost_empty_bonus

    # --- 5. Too Full Penalty ---
    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item - too_full_threshold))
    priorities[too_full_bins] += too_full_penalty

    # --- 6. Exploration (Scaled Randomness) ---
    exploration_factor = exploration_factor_base * item
    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)

    # --- 7. Encourage Even Utilization (with stronger weighting) ---
    bin_utilization = 1 - bins_remain_cap / bin_size
    utilization_std = np.std(bin_utilization)
    priorities += (1 - utilization_std) * utilization_bonus  # Doubled the bonus

    # --- 8. Lookahead (Simulated Placement) ---
    # Penalize bins that, after placing the current item, would become difficult to fill later.
    simulated_remaining_caps = bins_remain_cap - item
    simulated_remaining_caps[simulated_remaining_caps < 0] = -1 # Mark that the item can't be added

    difficult_to_fill = (simulated_remaining_caps > 0) & (simulated_remaining_caps <= small_space_penalty_threshold)

    # Scale penalty by how much space is wasted and the size of the item
    waste_amount = small_space_penalty_threshold - simulated_remaining_caps[difficult_to_fill]
    waste_penalty = waste_amount/ small_space_penalty_threshold

    priorities[difficult_to_fill] -= difficult_to_fill_penalty * waste_penalty * item_size_factor

    return priorities
