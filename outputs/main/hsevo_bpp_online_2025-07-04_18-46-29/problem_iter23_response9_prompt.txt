{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration, and global awareness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    total_bin_capacity = num_bins  # Assuming each bin has capacity 1\n    total_items_packed = total_bin_capacity - np.sum(bins_remain_cap)\n    average_fill = total_items_packed / total_bin_capacity if total_bin_capacity > 0 else 0.0\n    \n    # Adaptive Weights - based on item size, bin availability and global fill level\n    item_size_factor = min(0.75, item)  # Capped item size factor\n    bin_availability_factor = min(1.27, np.sum(bins_remain_cap >= item) / num_bins)\n    \n    # Dynamic weight adjustments based on global fill\n    fill_ratio_weight = 0.07 + 0.10 * item_size_factor * (1 + average_fill)\n    best_fit_weight = 2.81 + 0.68 * bin_availability_factor * (1 - average_fill)\n    fragmentation_penalty_weight = 1.47 + 0.82 * item_size_factor * (1 + average_fill)\n    reuse_weight = 0.79 + 0.51 * bin_availability_factor * (1 - average_fill)\n\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + 1e-6)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-2.73 * remaining_space)\n\n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold = item * (0.45 + 0.04 * item_size_factor) * (0.2 / np.sqrt(num_bins))\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill)**2 # Squared penalty\n\n    # Almost empty reuse\n    almost_empty_threshold = 0.93 - (0.20 * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = 0.09 + average_fill * 0.57\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-0.42))\n    priorities[too_full_bins] -= 0.08\n\n    # Global Bin Balancing: Encourage filling emptier bins when average fill is high\n    if average_fill > 0.7:\n        empty_bin_bonus = (1-average_fill) * bins_remain_cap\n        priorities += 0.1*empty_bin_bonus # Bonus for packing into more empty bins\n\n    # Exploration: Adaptive exploration based on global fill level\n    exploration_factor = 0.026 * item * (1-average_fill) # Reduced exploration as bins fill up\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines adaptive fill ratio, best fit, fragmentation penalty, and global fill awareness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    potential_bins = bins_remain_cap >= item\n\n    # 1. Adaptive Fill Ratio Preference\n    if np.any(potential_bins):\n        fill_ratios = item / bins_remain_cap[potential_bins]\n        priorities[potential_bins] += fill_ratios * (0.7 + 0.3 * (1 - np.mean(bins_remain_cap))) # Adapt based on avg cap\n\n    # 2. Stronger Best Fit Encouragement\n    capacity_diff = np.abs(bins_remain_cap - item)\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        min_diff = np.min(capacity_diff[eligible_bins])\n        best_fit_bins = capacity_diff == min_diff\n        priorities[best_fit_bins] += 1.5 # Boost best fit\n\n    # 3. Adaptive Fragmentation Penalty\n    remaining_space = bins_remain_cap - item\n    fragmentation_threshold = item * (0.1 + 0.03 * np.mean(bins_remain_cap)) # Adaptive threshold\n    fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)\n    priorities[fragmented_bins] -= 1.0 #Penalize fragmented bins\n\n    # 4. Almost Empty Bonus\n    almost_empty_threshold = 0.9\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        priorities[almost_empty] += 0.3 # Reuse almost empty bin\n\n    # 5. Global Fill Level Encouragement\n    global_fill_level = np.sum(1 - bins_remain_cap) / num_bins # Global fill estimation\n    if global_fill_level > 0.6: # High fill level encouragement\n        exploration_bonus = 0.1 * bins_remain_cap # Linear bonus based on capacity\n        priorities += exploration_bonus\n\n    # 6. Discourage near empty for the first few items.\n    if global_fill_level < 0.1:\n        near_empty_threshold = 0.95\n        near_empty = bins_remain_cap > near_empty_threshold\n        if np.any(near_empty):\n            priorities[near_empty] -= 0.2 # Reduce near-empty bin priority.\n            \n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic uses heavily tuned weights with adaptive components based on item size, bin availability, average fill, and standard deviation of fill, while the worst uses fixed weights and a simpler exploration strategy. (2nd best) vs (second worst) shows that the second best includes global state awareness such as global bin utilization, small/large item thresholds and associated bonuses/penalties. Comparing (1st) vs (2nd), we see the most important improvement is fine-grained control over weights, fragmentation thresholding and exploration. (3rd) vs (4th) shows no difference. Comparing (second worst) vs (worst), we see a simplified exploration probability. Overall:\n- The best heuristics incorporate adaptive weights based on item size, bin availability, and global fill levels.\n- Fragmentation penalties and almost-empty reuse bonuses are common, but the best heuristics use adaptive thresholds and scaling for these.\n- State-aware exploration, where the exploration rate is adjusted based on the current fill level and bin utilization, is present in better heuristics.\n- The top functions penalize over-utilization, balance bin usage.\n- \nOkay, let's refine \"Current self-reflection\" into something truly actionable for designing better bin packing heuristics, drawing lessons from what to avoid in \"Ineffective self-reflection.\"\n\nHere's a breakdown:\n\n*   **Keywords:** Adaptivity, state-awareness, multi-objective, parameter tuning, incremental complexity, global perspective, exploration.\n\n*   **Advice:** Design heuristics that dynamically adapt weights and strategies based on item characteristics, bin availability (current capacity, fragmentation), and the overall bin state (fill levels, remaining bins). Prioritize incremental feature addition with performance evaluation at each step. Explore parameters with fine control.\n\n*   **Avoid:** Over-reliance on single factors, neglecting global state during decision-making, abrupt priority changes, premature addition of complex functions.\n\n*   **Explanation:** Effective heuristics balance multiple objectives. Adaptivity to the current state is key. Parameter tuning can make algorithms perform better. Avoid getting stuck in local optima by considering global perspectives and starting with simple heuristics and increasing complexity in steps.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}