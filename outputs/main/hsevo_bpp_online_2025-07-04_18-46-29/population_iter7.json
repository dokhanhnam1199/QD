[
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins considering waste, target fullness, and near-full penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    waste = bins_remain_cap - item\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        # Minimize waste\n        priorities[valid_bins] = -np.abs(waste[valid_bins])\n\n        # Fullness bonus\n        fullness = (bins_remain_cap[valid_bins] - waste[valid_bins]) / bins_remain_cap[valid_bins]\n        target_fullness = 0.8\n        fullness_bonus = (fullness > target_fullness) * 1.0\n        priorities[valid_bins] += fullness_bonus\n\n        # Near-full penalty with smoother gradient\n        full_threshold = 0.1\n        almost_full = bins_remain_cap < (1 + full_threshold) * item\n        penalty_strength = 2.0\n        priorities[almost_full] -= penalty_strength * np.exp(10 * (1 - (bins_remain_cap[almost_full] / (item * (1 + full_threshold))))) # Use np.exp to penalize almost full bins\n        \n        # Bonus for tight fit\n        min_waste = np.min(waste[valid_bins])\n        close_fit_bonus = np.where(waste[valid_bins] == min_waste, 0.5, 0.0)\n        priorities[valid_bins] += close_fit_bonus\n\n    else:\n        priorities[:] = -0.0001  # Small negative priority\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.956122856003196,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best fit, target fill, and residual capacity.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if np.any(can_fit):\n        # Best Fit component: prioritize fuller bins\n        remaining_space = bins_remain_cap[can_fit] - item\n        fit_scores = 1 / (remaining_space + 1e-9)\n\n        # Target fill ratio component (around 70%)\n        fit_ratios = item / bins_remain_cap[can_fit]\n        target_priority = np.exp(-np.abs(fit_ratios - 0.7))\n\n        # Residual Capacity Penalty: Avoid leaving tiny spaces\n        residual_penalty = np.abs(remaining_space / bins_remain_cap[can_fit])\n\n        # Combine scores\n        capacity_weights = bins_remain_cap[can_fit]/np.max(bins_remain_cap)\n        combined_priority = (capacity_weights * fit_scores + (1 - capacity_weights) * target_priority) - 0.1*residual_penalty\n        priorities[can_fit] = combined_priority\n\n    else:\n        # Prioritize larger bins when no fit exists\n        priorities = bins_remain_cap\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.0885520542481055,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response2.txt_stdout.txt",
    "code_path": "problem_iter5_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Balances waste, fullness, and fit with adaptive scaling.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] = -np.abs(waste)  # Favors minimal waste\n\n        close_fit = np.abs(waste) < 0.1 * item\n        priorities[valid_bins][close_fit] += 1  # Bonus for very good fit\n\n        almost_full = bins_remain_cap[valid_bins] < (1 + 0.1) * item\n        priorities[valid_bins][almost_full] -= 2  # Penalty for nearly full\n\n        # First Fit Decreasing component, scaled adaptively\n        remaining_after_fit = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] += np.exp(-10 * remaining_after_fit / item) * 0.5 #Scale impact\n        fill_fraction = item / bins_remain_cap[valid_bins]\n\n        priorities[valid_bins] += fill_fraction * 0.3\n    else:\n        priorities[:] = -0.0001  # Discourage random placement\n    return priorities",
    "response_id": 2,
    "tryHS": true,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response3.txt_stdout.txt",
    "code_path": "problem_iter5_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best fit, target fullness, and adaptive penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    potential_bins = bins_remain_cap >= item\n\n    if np.any(potential_bins):\n        # Best Fit Component: Prioritize bins with minimal waste.\n        waste = bins_remain_cap[potential_bins] - item\n        priorities[potential_bins] += np.exp(-waste) # Use exponential to prioritize close fits\n\n        # Target Fullness Component: Encourage bins to reach a target fullness.\n        fullness_after_packing = (bins_remain_cap[potential_bins] - waste) / np.max(bins_remain_cap)\n        target_fullness = 0.8\n        fullness_diff = np.abs(fullness_after_packing - target_fullness)\n        priorities[potential_bins] += np.exp(-fullness_diff * 5)  # Prioritize fullness near target\n\n        # Adaptive Fragmentation Penalty: Penalize bins based on remaining capacity relative to item size.\n        frag_penalty = (bins_remain_cap[potential_bins] / np.max(bins_remain_cap)) * (item / np.max(bins_remain_cap))\n        priorities[potential_bins] -= frag_penalty * 0.5  # Scale the penalty\n\n        # Introduce tiny Randomness for exploration\n        priorities += np.random.rand(len(bins_remain_cap)) * 0.001\n\n    else:\n        priorities[:] = -0.0001\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response4.txt_stdout.txt",
    "code_path": "problem_iter5_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Balances waste, fullness, and avoids near-full bins.\n    Uses a smoothed waste penalty and adaptive bonus for good fit.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        # Smoothed penalty for waste, scaled by item size\n        priorities[valid_bins] = -np.exp( -waste / item)\n\n        # Adaptive bonus for close fit, relative to item size\n        close_fit_threshold = 0.1 # Tune this\n        close_fit = waste < close_fit_threshold * item\n        priorities[valid_bins][close_fit] += 1\n\n        # Penalize near-full bins\n        almost_full_threshold = 0.1 # Tune this\n        almost_full = bins_remain_cap[valid_bins] < (1 + almost_full_threshold) * item\n        almost_full_penalty = 0.5 # Tune this\n        priorities[valid_bins][almost_full] -= almost_full_penalty\n    else:\n        priorities[:] = bins_remain_cap  # Prioritize larger bins if no fit\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 149.30195452732352,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response5.txt_stdout.txt",
    "code_path": "problem_iter5_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit and target fill ratio, adaptive penalty for near-full, bonus for very good fit.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Encourage filling bins closer to full\n    potential_bins = bins_remain_cap >= item\n    if np.any(potential_bins):\n      priorities[potential_bins] = (bins_remain_cap[potential_bins] - item) / bins_remain_cap[potential_bins]\n\n    # Prioritize bins with smallest remaining capacity that can still fit the item.\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n      min_remaining = np.min(bins_remain_cap[eligible_bins])\n      priorities[bins_remain_cap == min_remaining] += 1\n\n    # Einstein's Special Consideration\n    priorities = priorities + np.exp(-np.abs(bins_remain_cap - item))\n    \n    # Penalize near-full bins, adaptive scaling\n    near_full = (bins_remain_cap < item * 1.1) & (bins_remain_cap >= item)\n    if np.any(near_full):\n        priorities[near_full] -= 0.5 * (item/np.mean(bins_remain_cap))  #Adaptive penalty based on mean cap\n\n    # Bonus for very good fit\n    close_fit = (bins_remain_cap >= item) & (bins_remain_cap <= item * 1.05)\n    if np.any(close_fit):\n        priorities[close_fit] += 0.75\n      \n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response6.txt_stdout.txt",
    "code_path": "problem_iter5_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fullness, and adaptive penalties.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Minimize waste (smallest remaining capacity after adding the item)\n        waste = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] = -np.abs(waste)  # Initial priority\n\n        # Target fullness bonus\n        fullness = (bins_remain_cap[eligible_bins] - waste) / bins_remain_cap[eligible_bins]\n        target_fullness = 0.8\n        fullness_bonus = np.exp(-np.abs(fullness - target_fullness) * 5)  # Smoother bonus\n        priorities[eligible_bins] += fullness_bonus\n\n        # Adaptive penalty for near-full bins (scale penalty by item size)\n        near_full = (bins_remain_cap[eligible_bins] <= item * 1.2)\n        penalty_scale = item / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else 0.1\n        priorities[eligible_bins[near_full]] -= 2 * penalty_scale # Adaptive Penalty\n\n        # Bonus for good fit\n        fit_ratio = item / bins_remain_cap[eligible_bins]\n        good_fit = (fit_ratio >= 0.5) & (fit_ratio <= 0.95)\n        priorities[eligible_bins[good_fit]] += 1.0\n\n    else:\n        priorities[:] = -0.0001  # Small negative priority if no bin fits\n\n    # Exploration: Add a small random noise\n    priorities += np.random.rand(len(bins_remain_cap)) * 0.01\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 27, in priority_v2\n    return priorities\nIndexError: boolean index did not match indexed array along axis 0; size of axis is 5000 but size of corresponding boolean axis is 1\n"
  },
  {
    "stdout_filepath": "problem_iter5_response7.txt_stdout.txt",
    "code_path": "problem_iter5_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fullest bin and near fit with dynamic penalty.\n    Prioritizes fuller bins, near fits, and penalizes almost full.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fullest Bin component: Prioritize smallest remaining space\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] = 1 / (remaining_space + 1e-9)\n\n        # Near Fit adjustment: Give bonus to bins with slightly larger capacity\n        near_fit_threshold_upper = item * 1.2\n        near_fit_bins = (bins_remain_cap >= item) & (bins_remain_cap <= near_fit_threshold_upper)\n        priorities[near_fit_bins] += 0.5 * priorities[near_fit_bins]\n\n        # Penalize almost full bins to avoid fragmentation\n        full_threshold = 0.1\n        almost_full = bins_remain_cap < (1 + full_threshold) * item\n        priorities[almost_full] -= 0.75 * priorities[almost_full] # Adaptive penalty\n    else:\n        priorities[:] = -1  # Very low priority if item doesn't fit\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.228161148783416,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response8.txt_stdout.txt",
    "code_path": "problem_iter5_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit and target fill ratio with penalties.\n    Balances waste, fullness, and fit using smooth functions.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] = -np.abs(waste)\n\n        close_fit = np.abs(waste) < 0.1 * item\n        priorities[valid_bins][close_fit] += 1 # Bonus\n\n        almost_full = bins_remain_cap[valid_bins] < (1 + 0.1) * item\n        priorities[valid_bins][almost_full] -= 2 # Penalty\n\n        # Target fill ratio (around 70%)\n        fit_ratios = item / bins_remain_cap[valid_bins]\n        target_priority = np.exp(-np.abs(fit_ratios - 0.7)) * 0.5 #Scale impact.\n        priorities[valid_bins] += target_priority\n\n    else:\n        priorities[:] = -0.0001\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response9.txt_stdout.txt",
    "code_path": "problem_iter5_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid priority: balance waste, fullness, fit, and penalize almost full.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        waste = bins_remain_cap - item\n        priorities[valid_bins] = -np.abs(waste[valid_bins]) # Favors minimal waste\n\n        close_fit_threshold = 0.1\n        close_fit = np.abs(waste[valid_bins]) < close_fit_threshold * item\n        priorities[valid_bins][close_fit] += 1  # Bonus for very good fit\n\n        almost_full_threshold = 0.1\n        almost_full_penalty = 10\n        almost_full = bins_remain_cap < (1 + almost_full_threshold) * item\n        priorities[almost_full] -= almost_full_penalty # Penalty for nearly full\n\n        # First Fit Decreasing - ish component to avoid fragmentation\n        remaining_after_fit_scale = 2\n        remaining_after_fit_exponent_scale = 0.5\n        remaining_after_fit = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] += np.exp(-remaining_after_fit_scale * remaining_after_fit / item) * remaining_after_fit_exponent_scale #Scale impact.\n\n        # Sigmoid component for bin fullness\n        sigmoid = 1 / (1 + np.exp(10 * (item - bins_remain_cap)))\n        priorities += 0.5 * sigmoid # Combine sigmoid\n    else:\n        discourage_random_placement_value = 100\n        priorities[:] = -discourage_random_placement_value  # Discourage random placement\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 5.534503390506582,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # 1. Capacity Utilization: Encourage filling bins effectively\n    potential_bins = bins_remain_cap >= item\n    if np.any(potential_bins):\n        utilization_ratio = (bins_remain_cap[potential_bins] - item) / bins_remain_cap[potential_bins]\n        priorities[potential_bins] += (1 - utilization_ratio)**2  # Higher priority for better utilization\n\n    # 2. Smallest Remaining Capacity: First-Fit Decreasing concept\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        min_remaining = np.min(bins_remain_cap[eligible_bins])\n        priorities[bins_remain_cap == min_remaining] += 2  # High priority\n\n    # 3. Fragmentation Penalty: Penalize bins that might lead to fragmentation\n    fragmentation_risk = (bins_remain_cap - item)  # Remaining space after item placement\n    priorities[potential_bins] -= np.exp(-5 * fragmentation_risk[potential_bins])  # Exponential penalty\n    \n    # 4. Balancing Factor:  Prioritize bins that are neither too full nor too empty\n    bin_fullness = 1 - (bins_remain_cap / np.max(bins_remain_cap)) #scale it\n    priorities[potential_bins] += np.exp(-10 * np.abs(bin_fullness[potential_bins] - 0.5)) #middle range priority\n    \n    # 5. Item Size Consideration: Adapt based on item size\n    priorities[potential_bins] += item / np.max(bins_remain_cap)   # Larger items get more priority\n    \n    # 6. Sigmoid Smoothing:  Smooth transitions for a more gradual effect\n    priorities = 1 / (1 + np.exp(-priorities))\n    \n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response1.txt_stdout.txt",
    "code_path": "problem_iter6_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Objective Function: Combines multiple criteria for bin selection\n    \n    # 1. Fill Rate Priority: Prioritize bins that would be filled closest to a target fill rate.\n    target_fill_rate = 0.9  # Aim for 90% fill\n    potential_bins = bins_remain_cap >= item\n    if np.any(potential_bins):\n        future_fill_levels = (bins_remain_cap[potential_bins] - item) / np.max(bins_remain_cap)\n        fill_rate_diff = np.abs(future_fill_levels - (1 - target_fill_rate))\n        priorities[potential_bins] += np.exp(-fill_rate_diff * 10)  # Exponential scaling for sensitivity\n\n\n    # 2. Smallest Remaining Capacity (First Fit Decreasing Influence)\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        min_remaining = np.min(bins_remain_cap[eligible_bins])\n        priorities[bins_remain_cap == min_remaining] += 0.75  # A moderate boost\n\n    # 3. Fragmentation Penalty: Penalize bins that, after adding the item, would leave a gap too small for common future items.\n    # Define a 'small' item size as a fraction of the bin capacity\n    small_item_threshold = np.max(bins_remain_cap) * 0.25\n    remaining_after_fit = bins_remain_cap - item\n    fragmentation_risk = (remaining_after_fit > 0) & (remaining_after_fit < small_item_threshold)\n    priorities[fragmentation_risk] -= 0.5  # Moderate penalty\n\n    # 4. Balance Remaining Capacity: Encourage using bins that leave a \"useful\" amount of space.\n    useful_space_lower = np.max(bins_remain_cap) * 0.3\n    useful_space_upper = np.max(bins_remain_cap) * 0.7\n    useful_space = (remaining_after_fit >= useful_space_lower) & (remaining_after_fit <= useful_space_upper) & (remaining_after_fit > 0)\n    priorities[useful_space] += 0.4  # Reward\n\n    # 5. Smoothing using sigmoid function to promote exploration.\n\n    priorities = priorities + 0.1 * (1 / (1 + np.exp(-(bins_remain_cap - item)))) # Sigmoid smoothing for exploration\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response2.txt_stdout.txt",
    "code_path": "problem_iter6_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # 1. Objective Function Components:\n    #   - Fill Ratio: How much of the bin will be filled after adding the item.\n    #   - Waste: The remaining space after adding the item.\n    #   - Fragmentation Risk: A measure of how likely the remaining space is to be unusable.\n    \n    # 2. Calculate Fill Ratio (Sigmoid for Smoothing):\n    fill_ratio = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        fill_ratio[eligible_bins] = (item / (bins_remain_cap[eligible_bins])) #was (bins_remain_cap[eligible_bins] - item) / bins_remain_cap[eligible_bins]\n        # Sigmoid to smooth the priority based on fill ratio (higher fill ratio = higher priority)\n        fill_ratio = 1 / (1 + np.exp(-5 * (fill_ratio - 0.5)))  # Adjust 5 and 0.5 for sensitivity\n        priorities[eligible_bins] += fill_ratio[eligible_bins]\n\n    # 3. Waste Penalty (Adaptive):\n    waste = np.zeros_like(bins_remain_cap, dtype=float)\n    if np.any(eligible_bins):\n        waste[eligible_bins] = bins_remain_cap[eligible_bins] - item\n        # Adaptive penalty based on the magnitude of waste (larger waste = larger penalty)\n        waste_penalty = np.exp(waste / np.mean(bins_remain_cap[eligible_bins])) - 1 if np.mean(bins_remain_cap[eligible_bins]) > 0 else np.zeros_like(waste[eligible_bins]) #WAS -waste\n        priorities[eligible_bins] -= waste_penalty[eligible_bins]\n\n    # 4. Fragmentation Risk (Consider small items):\n    small_item_threshold = 0.2 #threshold of item size\n    fragmentation_risk = np.zeros_like(bins_remain_cap, dtype=float)\n    if np.any(eligible_bins):\n        # Estimate fragmentation risk based on the remaining capacity\n        fragmentation_risk[eligible_bins] = np.where(waste[eligible_bins] < small_item_threshold, -1, 0)\n\n        priorities[eligible_bins] += fragmentation_risk[eligible_bins]\n\n    # 5. Prioritize bins with the smallest remaining capacity (First Fit Decreasing approximation)\n    if np.any(eligible_bins):\n        min_remaining = np.min(bins_remain_cap[eligible_bins])\n        priorities[bins_remain_cap == min_remaining] += 0.2 #was 1\n\n    # 6. Bin Balancing: Reward bins with capacity far from mean capacity\n    bin_capacity_mean = np.mean(bins_remain_cap)\n    capacity_difference = np.abs(bins_remain_cap - bin_capacity_mean)\n    capacity_balance_reward = np.exp(-capacity_difference/np.std(bins_remain_cap)) if np.std(bins_remain_cap) > 0 else np.zeros_like(capacity_difference)\n    priorities += capacity_balance_reward * 0.1\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.96609493418428,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response3.txt_stdout.txt",
    "code_path": "problem_iter6_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Objective function: combination of fill-level, capacity, and adaptive penalty\n\n    # 1. Fill-Level Preference (Sigmoid to smooth the preference curve)\n    potential_bins = bins_remain_cap >= item\n    if np.any(potential_bins):\n        fill_ratio = (bins_remain_cap[potential_bins] - item) / bins_remain_cap[potential_bins]\n        priorities[potential_bins] += 1 / (1 + np.exp(-10 * (fill_ratio - 0.5))) # Sigmoid centered around 0.5 fill ratio\n\n    # 2. Capacity Consideration (Prioritize bins that are not too full or too empty after insertion)\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        remaining_after_fit = bins_remain_cap[eligible_bins] - item\n        capacity_score = np.exp(-0.5 * (remaining_after_fit - np.mean(remaining_after_fit))**2 / np.std(remaining_after_fit)**2) if np.std(remaining_after_fit) > 0 else np.ones_like(remaining_after_fit)  # Gaussian-like preference\n        priorities[eligible_bins] += capacity_score\n        \n\n    # 3. Adaptive Penalty (Dynamically adjust penalty based on how full the bins are becoming)\n    bin_utilization = 1 - bins_remain_cap / np.max(bins_remain_cap)  # or 1 - bins_remain_cap if bins have a fixed size\n    penalty = np.exp(5 * (bin_utilization - 0.9)) # High penalty as bins become >90% full\n    priorities -= penalty\n    \n    # 4. Encourage bins with space slightly greater than item\n    near_fit = (bins_remain_cap >= item) & (bins_remain_cap <= item * 1.2)\n    if np.any(near_fit):\n        priorities[near_fit] += 0.75\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 68.9270043877144,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response4.txt_stdout.txt",
    "code_path": "problem_iter6_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Objective Function: Combination of factors\n    \n    # 1. Space Utilization: Encourage filling bins closer to full but not overly full\n    potential_bins = bins_remain_cap >= item\n    if np.any(potential_bins):\n        utilization = (bins_remain_cap[potential_bins] - item) / bins_remain_cap[potential_bins]\n        priorities[potential_bins] += (1 - utilization)  # Higher priority for better utilization\n\n    # 2. Best Fit: Prioritize bins with smallest remaining capacity that can still fit the item\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += np.exp(-remaining_space) # Exponential decay gives high priority to best fit\n\n    # 3. Fragmentation Penalty: Penalize bins that would become too full after adding the item, leading to fragmentation. Sigmoid function used for smooth penalty.\n    near_full_threshold = 0.95\n    near_full = (bins_remain_cap >= item) & (bins_remain_cap - item <= (1 - near_full_threshold) * bins_remain_cap)\n\n    if np.any(near_full):\n        priorities[near_full] -= 1 / (1 + np.exp(-100*(bins_remain_cap[near_full] - item - (1 - near_full_threshold) * bins_remain_cap[near_full]))) # Sigmoid Penalty\n\n    # 4. Bin Balancing: Encourage balancing the load across bins.\n    bin_capacity_normalized = bins_remain_cap / np.max(bins_remain_cap)\n    priorities += bin_capacity_normalized # Higher value = more remaining capacity\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 81.94056641404069,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_response0.txt_stdout.txt",
    "code_path": "problem_iter7_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, close_fit_threshold: float = 0.17498245415140987, almost_full_threshold: float = 0.07310857833025453,\n                almost_full_penalty: float = 2.7941498802019114, remaining_after_fit_scale: float = 6.442157283252587,\n                remaining_after_fit_weight: float = 0.2523588967964998, fill_fraction_weight: float = 0.39327874113209915,\n                discourage_placement_value: float = 0.0008530523401477496) -> np.ndarray:\n    \"\"\"Balances waste, fullness, and fit with adaptive scaling.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] = -np.abs(waste)  # Favors minimal waste\n\n        close_fit = np.abs(waste) < close_fit_threshold * item\n        priorities[valid_bins][close_fit] += 1  # Bonus for very good fit\n\n        almost_full = bins_remain_cap[valid_bins] < (1 + almost_full_threshold) * item\n        priorities[valid_bins][almost_full] -= almost_full_penalty  # Penalty for nearly full\n\n        # First Fit Decreasing component, scaled adaptively\n        remaining_after_fit = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] += np.exp(-remaining_after_fit_scale * remaining_after_fit / item) * remaining_after_fit_weight #Scale impact\n        fill_fraction = item / bins_remain_cap[valid_bins]\n\n        priorities[valid_bins] += fill_fraction * fill_fraction_weight\n    else:\n        priorities[:] = -discourage_placement_value  # Discourage random placement\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.048663741523748,
    "exec_success": true
  }
]