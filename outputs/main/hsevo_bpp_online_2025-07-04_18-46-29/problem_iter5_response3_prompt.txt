{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Capacity Utilization Encouragement (Similar to v1, but refined)\n    potential_bins = bins_remain_cap >= item\n    if np.any(potential_bins):\n        # Prioritize bins that result in higher utilization after packing.\n        utilization = (item / (bins_remain_cap[potential_bins]))\n        priorities[potential_bins] += utilization # Higher utilization gets higher priority\n\n\n    # 2. Best Fit with a Twist (Prioritize near-perfect fits, but avoid overfilling)\n    diff = bins_remain_cap - item\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        # Prioritize bins where the remaining space after packing is minimal.\n        priorities[eligible_bins] += 1.0 / (1e-6 + diff[eligible_bins])  #Inverted diff, small diff get larger priority\n    \n    #3. Balancing Act: Moderate fragmentation penalty\n    if np.any(potential_bins):\n        priorities[potential_bins] -= (bins_remain_cap[potential_bins]/ np.sum(bins_remain_cap)) * 0.2 # Fragmentation cost is proportional to size of bins, and divided by total capacities\n    \n    \n    #4. Empty Bin Consideration:  Use empty bin only when items are large\n    empty_bins = bins_remain_cap == np.max(bins_remain_cap) # Bins that are empty\n    if item > np.mean(bins_remain_cap) and np.any(empty_bins):\n        priorities[empty_bins] += 0.5 # Encourage to use an empty bin only if item is large enough, prevent the empty bin from always being chosen for small item\n    \n    # 5. Diversity Boost: Introduce randomness to escape local optima\n    priorities += np.random.rand(len(bins_remain_cap)) * 0.01\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines waste minimization and target fullness for bin priority.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    waste = bins_remain_cap - item\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        # Minimize waste, but also target a fullness level.\n        priorities[valid_bins] = -np.abs(waste[valid_bins])  # Initial priority\n\n        # Calculate fullness after adding item\n        fullness = (bins_remain_cap[valid_bins] - waste[valid_bins]) / bins_remain_cap[valid_bins]\n\n        # Give a bonus to bins that become sufficiently full\n        target_fullness = 0.8\n        fullness_bonus = (fullness > target_fullness) * 1.0 #bonus increased\n        priorities[valid_bins] += fullness_bonus\n\n        #Penalize almost full bins\n        full_threshold = 0.1\n        almost_full = bins_remain_cap < (1 + full_threshold) * item\n        priorities[almost_full] -= 2 #penalty increased\n\n    else:\n        priorities[:] = -0.0001 #Small negative priority\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the best heuristic prioritizes filling bins closer to full while also considering the smallest remaining capacity. The worst heuristic uses a combination of fit scores, empty bin bonuses, almost full penalties, and tight fit bonuses. The best heuristic includes `np.exp(-np.abs(bins_remain_cap - item))` which provides a smooth, non-linear adjustment to priorities, and also penalizes near-full bins. In contrast, the worst heuristic includes an `almost_full_penalty` and `tight_fit_bonus`.\n\nComparing (2nd) vs (19th), the second best uses `waste` and `close_fit`, and it has the First Fit Decreasing component. The second worst combines best-fit and target fill ratio to prioritize bins. The second best gives bonuses for very good fit. The second worst penalizes the almost full bins.\n\nComparing (1st) vs (2nd), we observe that the best heuristic uses `bins_remain_cap >= item` multiple times. The second best gives bonus for close fit and applies penalty for nearly full. The best use `potential_bins = bins_remain_cap >= item` to filter before applying calculation.\n\nComparing (3rd) vs (4th), the only difference is that the (3rd) uses default arguments for parameters, so there is no significant difference in the algorithm.\n\nComparing (second worst) vs (worst), we see that the second worst prioritizes best fit, incorporating a target fill ratio. The worst combines fit scores, bonuses, and penalties, but the specific combination is not as effective. The key difference lies in the combination of features and the underlying weighting, where the second-worst places higher emphasis on the fill ratio.\n\nOverall:\nThe best heuristics prioritize a balance between minimizing waste, encouraging fuller bins, and penalizing near-full bins to avoid fragmentation. They also incorporate smooth, non-linear adjustments. The worst heuristics tend to have less effective combinations of bonuses and penalties, or lack a clear strategy for balancing different objectives.\n- \nOkay, let's refine \"Current self-reflection\" into a more effective approach for designing heuristics. Here's a breakdown designed to avoid the pitfalls of ineffective self-reflection and guide you towards better heuristics:\n\n*   **Keywords:** Objective Function, Multi-Criteria Optimization, Smoothing, Exploration, Penalties, State Evaluation, Adaptive Strategies.\n\n*   **Advice:** Design a well-defined objective function considering multiple interacting criteria. Employ smoothing techniques (e.g., sigmoid functions) for gradual adjustments. Use adaptive penalties.\n\n*   **Avoid:** Rigid, single-factor decision-making. Static weight assignments in objective function, lack of adaptive strategies based on previous state evaluation.\n\n*   **Explanation:** Effective heuristics require a holistic view. Instead of fixating on one aspect, build an objective function that balances multiple goals. Employ adaptive strategies based on previous results to guide exploration and dynamically adjust penalties/weights.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}