{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                fill_ratio_weight_base: float = 0.07001911716215126,\n                fill_ratio_weight_item_factor: float = 0.09674577434453879,\n                best_fit_weight_base: float = 2.805747453408391,\n                best_fit_weight_availability_factor: float = 0.6848823870770047,\n                fragmentation_penalty_weight_base: float = 1.4678366072617053,\n                fragmentation_penalty_weight_item_factor: float = 0.8155589797225978,\n                reuse_weight_base: float = 0.7877195059531279,\n                reuse_weight_availability_factor: float = 0.5099151918111539,\n                best_fit_decay_rate: float = 2.7252501697954994,\n                fragmentation_threshold_base: float = 0.45443676724460597,\n                fragmentation_threshold_item_factor: float = 0.03685272815567264,\n                almost_empty_threshold_base: float = 0.9265092958240733,\n                almost_empty_threshold_average_fill_factor: float = 0.2006311693648083,\n                almost_empty_bonus_base: float = 0.09108242175329895,\n                almost_empty_bonus_average_fill_factor: float = 0.5721102621832862,\n                too_full_threshold: float = 0.4199500766768644,\n                too_full_penalty: float = 0.0826040342356067,\n                exploration_factor_scale: float = 0.02587384524922878,\n                min_item_size_factor: float = 0.7483057590114014,\n                min_bin_availability_factor: float = 1.2697180594558546,\n                division_epsilon: float = 0.0008721588230938938,\n                bin_size: float = 1.0) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    \n    # Adaptive Weights - based on item size and global fill level\n    item_size_factor = min(min_item_size_factor, item)\n    bin_availability_factor = min(min_bin_availability_factor, np.sum(bins_remain_cap >= item) / num_bins)\n    average_fill = np.mean(1 - bins_remain_cap / bin_size)\n\n    fill_ratio_weight = fill_ratio_weight_base + fill_ratio_weight_item_factor * item_size_factor\n    best_fit_weight = best_fit_weight_base + best_fit_weight_availability_factor * bin_availability_factor\n    fragmentation_penalty_weight = fragmentation_penalty_weight_base + fragmentation_penalty_weight_item_factor * item_size_factor\n    reuse_weight = reuse_weight_base + reuse_weight_availability_factor * bin_availability_factor\n    \n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + division_epsilon)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-best_fit_decay_rate * remaining_space) #Best fit bonus\n    \n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold_multiplier = 0.2 / np.sqrt(num_bins)\n    fragmentation_threshold = item * (fragmentation_threshold_base + fragmentation_threshold_item_factor * item_size_factor) * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    \n    # Scale the penalty based on how full the bin is.  More full, higher penalty\n    fragmentation_penalty_scaling = (bin_size - bins_remain_cap[fragmented_bins]) / bin_size\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill) * fragmentation_penalty_scaling\n\n     # Almost empty reuse\n    almost_empty_threshold = almost_empty_threshold_base - (almost_empty_threshold_average_fill_factor * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = almost_empty_bonus_base + average_fill * almost_empty_bonus_average_fill_factor\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus #almost empty reuse bonus.\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-too_full_threshold))\n    priorities[too_full_bins] -= too_full_penalty\n\n    # Exploration: Add a small amount of randomness, scaled to the item size.\n    exploration_factor = exploration_factor_scale * item  # Scale randomness based on the item size\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    # Encourage evening out bin utilization\n    bin_utilization = 1 - bins_remain_cap / bin_size\n    utilization_std = np.std(bin_utilization)\n    priorities += (1 - utilization_std) * 0.1 # Give a small bonus to solutions with similar utilizations\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                fill_ratio_weight_base: float = 0.07001911716215126,\n                fill_ratio_weight_item_factor: float = 0.09674577434453879,\n                best_fit_weight_base: float = 2.805747453408391,\n                best_fit_weight_availability_factor: float = 0.6848823870770047,\n                fragmentation_penalty_weight_base: float = 1.4678366072617053,\n                fragmentation_penalty_weight_item_factor: float = 0.8155589797225978,\n                reuse_weight_base: float = 0.7877195059531279,\n                reuse_weight_availability_factor: float = 0.5099151918111539,\n                best_fit_decay_rate: float = 2.7252501697954994,\n                fragmentation_threshold_base: float = 0.45443676724460597,\n                fragmentation_threshold_item_factor: float = 0.03685272815567264,\n                almost_empty_threshold_base: float = 0.9265092958240733,\n                almost_empty_threshold_average_fill_factor: float = 0.2006311693648083,\n                almost_empty_bonus_base: float = 0.09108242175329895,\n                almost_empty_bonus_average_fill_factor: float = 0.5721102621832862,\n                too_full_threshold: float = 0.4199500766768644,\n                too_full_penalty: float = 0.0826040342356067,\n                exploration_factor_scale: float = 0.02587384524922878,\n                min_item_size_factor: float = 0.7483057590114014,\n                min_bin_availability_factor: float = 1.2697180594558546,\n                division_epsilon: float = 0.0008721588230938938,\n                global_bin_utilization_threshold: float = 0.7,\n                high_utilization_fill_ratio_penalty: float = 0.15,\n                small_item_threshold: float = 0.2,\n                large_item_threshold: float = 0.8,\n                small_item_best_fit_boost: float = 0.1,\n                large_item_fragmentation_penalty_multiplier: float = 2.0) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration with state-aware adjustments.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    \n    # Global State Awareness\n    average_fill = np.mean(1 - bins_remain_cap)\n    global_bin_utilization = 1 - np.mean(bins_remain_cap)\n\n    # Adaptive Weights - based on item size and global fill level\n    item_size_factor = min(min_item_size_factor, item)\n    bin_availability_factor = min(min_bin_availability_factor, np.sum(bins_remain_cap >= item) / num_bins)\n\n    fill_ratio_weight = fill_ratio_weight_base + fill_ratio_weight_item_factor * item_size_factor\n    best_fit_weight = best_fit_weight_base + best_fit_weight_availability_factor * bin_availability_factor\n    fragmentation_penalty_weight = fragmentation_penalty_weight_base + fragmentation_penalty_weight_item_factor * item_size_factor\n    reuse_weight = reuse_weight_base + reuse_weight_availability_factor * bin_availability_factor\n    \n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + division_epsilon)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        best_fit_priority = np.exp(-best_fit_decay_rate * remaining_space)\n        priorities[eligible_bins] += best_fit_weight * best_fit_priority\n\n        # Small Item Best Fit Boost: Encourage packing small items into tightest spots\n        if item < small_item_threshold:\n            priorities[eligible_bins] += small_item_best_fit_boost * (1 - remaining_space / (bins_remain_cap[eligible_bins]+division_epsilon))\n\n    # Fragmentation Penalty - Dynamic threshold & Item Size Aware\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold_multiplier = 0.2 / np.sqrt(num_bins)\n    fragmentation_threshold = item * (fragmentation_threshold_base + fragmentation_threshold_item_factor * item_size_factor) * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n\n    fragmentation_penalty = fragmentation_penalty_weight * (1-average_fill)\n     # Large item penalty\n    if item > large_item_threshold:\n        fragmentation_penalty *= large_item_fragmentation_penalty_multiplier\n\n    priorities[fragmented_bins] -= fragmentation_penalty\n\n    # Almost empty reuse\n    almost_empty_threshold = almost_empty_threshold_base - (almost_empty_threshold_average_fill_factor * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = almost_empty_bonus_base + average_fill * almost_empty_bonus_average_fill_factor\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus #almost empty reuse bonus.\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-too_full_threshold))\n    priorities[too_full_bins] -= too_full_penalty\n\n    # Global Bin Utilization Penalty: Discourage filling bins when global utilization is high\n    if global_bin_utilization > global_bin_utilization_threshold:\n        priorities[eligible_bins] -= high_utilization_fill_ratio_penalty * fill_ratio[eligible_bins - np.where(~eligible_bins)[0].min()] if eligible_bins.sum() > 0 else 0\n\n    # Exploration: Add a small amount of randomness, scaled to the item size.\n    exploration_factor = exploration_factor_scale * item  # Scale randomness based on the item size\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fill ratio, best fit, fragmentation penalty, reuse, exploration, adaptivity based on bin utilization and item size.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    bin_size = 1.0  # Assuming bin size is 1 for normalization\n\n    # Adaptive Weights - based on item size and global fill level\n    item_size_factor = min(1.0, item)\n    bin_availability_factor = min(1.0, np.sum(bins_remain_cap >= item) / num_bins)\n    average_fill = np.mean(1 - bins_remain_cap)\n\n    fill_ratio_weight = 0.5 + 0.3 * item_size_factor\n    best_fit_weight = 1.5 + 0.5 * bin_availability_factor\n    fragmentation_penalty_weight = 1.0 + 0.2 * item_size_factor\n    reuse_weight = 0.6 + 0.4 * bin_availability_factor\n\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + 0.0001)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-2 * remaining_space) #Best fit bonus\n\n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold_multiplier = 0.2 / np.sqrt(num_bins)\n    fragmentation_threshold = item * (0.1 + 0.1 * item_size_factor) * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill)\n\n    # Almost empty reuse\n    almost_empty_threshold = 0.95 - (0.1 * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = 0.5 + average_fill * 0.5\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus #almost empty reuse bonus.\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-0.2))\n    priorities[too_full_bins] -= 0.8\n\n    # Exploration: Add a small amount of randomness, scaled to the item size.\n    exploration_factor = 0.01 * item  # Scale randomness based on the item size\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    # Underutilization Penalty: Penalize creating almost empty bins with small items\n    new_remaining_space = bins_remain_cap - item\n    underutilization_threshold = 0.1 # Penalty for bins with low utilization after placement\n    underutilization_penalty = 0.6\n    underutilized_bins = (new_remaining_space > 0) & (new_remaining_space / bin_size > (1 - underutilization_threshold)) & (item < (bin_size * 0.5)) #Only penalize if item is small\n    priorities[underutilized_bins] -= underutilization_penalty\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fill ratio, best fit, fragmentation penalty, reuse, exploration, adaptivity based on bin utilization and item size.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    bin_size = 1.0  # Assuming bin size is 1 for normalization\n\n    # Adaptive Weights - based on item size and global fill level\n    item_size_factor = min(1.0, item)\n    bin_availability_factor = min(1.0, np.sum(bins_remain_cap >= item) / num_bins)\n    average_fill = np.mean(1 - bins_remain_cap)\n\n    fill_ratio_weight = 0.5 + 0.3 * item_size_factor\n    best_fit_weight = 1.5 + 0.5 * bin_availability_factor\n    fragmentation_penalty_weight = 1.0 + 0.2 * item_size_factor\n    reuse_weight = 0.6 + 0.4 * bin_availability_factor\n\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + 0.0001)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-2 * remaining_space) #Best fit bonus\n\n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold_multiplier = 0.2 / np.sqrt(num_bins)\n    fragmentation_threshold = item * (0.1 + 0.1 * item_size_factor) * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill)\n\n    # Almost empty reuse\n    almost_empty_threshold = 0.95 - (0.1 * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = 0.5 + average_fill * 0.5\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus #almost empty reuse bonus.\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-0.2))\n    priorities[too_full_bins] -= 0.8\n\n    # Exploration: Add a small amount of randomness, scaled to the item size.\n    exploration_factor = 0.01 * item  # Scale randomness based on the item size\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    # Underutilization Penalty: Penalize creating almost empty bins with small items\n    new_remaining_space = bins_remain_cap - item\n    underutilization_threshold = 0.1 # Penalty for bins with low utilization after placement\n    underutilization_penalty = 0.6\n    underutilized_bins = (new_remaining_space > 0) & (new_remaining_space / bin_size > (1 - underutilization_threshold)) & (item < (bin_size * 0.5)) #Only penalize if item is small\n    priorities[underutilized_bins] -= underutilization_penalty\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best fit, fill ratio, adaptive fragmentation, bin utilization and adaptive exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_size = 1.0\n    num_bins = len(bins_remain_cap)\n\n    # Fill Ratio Preference\n    potential_bins = bins_remain_cap >= item\n    if np.any(potential_bins):\n        fill_ratio = (bins_remain_cap[potential_bins] - item) / bin_size\n        priorities[potential_bins] += 0.7 * fill_ratio\n\n    # Best Fit Encouragement (Adaptive Weight)\n    capacity_diff = np.abs(bins_remain_cap - item)\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        min_diff = np.min(capacity_diff[eligible_bins])\n        best_fit_bins = capacity_diff == min_diff\n        average_fill = np.mean((bin_size - bins_remain_cap) / bin_size) if num_bins > 0 else 0.0\n        best_fit_weight = 1.5 + (1.0 - average_fill)  # Increase best-fit weight\n        priorities[best_fit_bins] += best_fit_weight\n\n    # Fragmentation Penalty (Adaptive)\n    remaining_space = bins_remain_cap - item\n    average_remaining = np.mean(bins_remain_cap) if num_bins > 0 else 0.0\n    fragmentation_threshold_multiplier = 0.2 * (1.0 - average_remaining / bin_size)\n    fragmentation_threshold = item * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)\n    fragmentation_penalty = 1.3 + (item / bin_size)\n    priorities[fragmented_bins] -= fragmentation_penalty\n\n    # Encourage re-use of almost empty bins\n    almost_empty_threshold = 0.95\n    almost_empty = bins_remain_cap > (bin_size - almost_empty_threshold)\n    if np.any(almost_empty):\n        priorities[almost_empty] += 0.8  # Consistent bonus\n\n    # Bin Utilization Bonus\n    utilization = (bin_size - bins_remain_cap) / bin_size\n    fully_utilized_threshold = 0.8  # Tune this\n    highly_utilized = utilization > fully_utilized_threshold\n    utilization_bonus = 0.5\n    priorities[highly_utilized] += utilization_bonus\n\n    # Adaptive Exploration Bonus (State-Aware)\n    exploration_rate = 0.05 * (1.0 - average_fill) #Exploration rate decreases with fill level\n\n    if np.random.rand() < exploration_rate:\n        exploration_bonus = (bin_size - bins_remain_cap) / bin_size\n        priorities += exploration_bonus * 0.2\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining fill ratio, best fit, and bin diversity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        # Fill Ratio with item size influence\n        fill_ratio = item / bins_remain_cap[valid_bins]\n        priorities[valid_bins] += fill_ratio * 0.6\n\n        # Best Fit with non-linear encouragement\n        remaining_space = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] += np.exp(-4 * remaining_space) * 0.9\n\n        # Bin Diversity Bonus\n        if len(bins_remain_cap) > 1:\n            bin_std = np.std(bins_remain_cap)\n            if bin_std > 0.1:\n                priorities[valid_bins] += 0.2\n\n        # Large item encouragement\n        if item > 0.7:\n             min_remaining = np.min(bins_remain_cap[valid_bins]-item)\n             tight_fit = (bins_remain_cap[valid_bins] - item) == min_remaining\n             priorities[valid_bins][tight_fit] += 0.5\n\n    else:\n        priorities[:] = -0.001\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining fill ratio, best fit, and bin diversity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        # Fill Ratio with item size influence\n        fill_ratio = item / bins_remain_cap[valid_bins]\n        priorities[valid_bins] += fill_ratio * 0.6\n\n        # Best Fit with non-linear encouragement\n        remaining_space = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] += np.exp(-4 * remaining_space) * 0.9\n\n        # Bin Diversity Bonus\n        if len(bins_remain_cap) > 1:\n            bin_std = np.std(bins_remain_cap)\n            if bin_std > 0.1:\n                priorities[valid_bins] += 0.2\n\n        # Large item encouragement\n        if item > 0.7:\n             min_remaining = np.min(bins_remain_cap[valid_bins]-item)\n             tight_fit = (bins_remain_cap[valid_bins] - item) == min_remaining\n             priorities[valid_bins][tight_fit] += 0.5\n\n    else:\n        priorities[:] = -0.001\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fill ratio, best fit, fragmentation, and exploration with adaptive weights.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    bin_size = 1.0\n\n    # Fill Ratio Preference\n    potential_bins = bins_remain_cap >= item\n    if np.any(potential_bins):\n        fill_ratio = (bins_remain_cap[potential_bins] - item) / bin_size\n        priorities[potential_bins] += fill_ratio\n\n    # Best Fit Encouragement (Adaptive Weight)\n    capacity_diff = np.abs(bins_remain_cap - item)\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        min_diff = np.min(capacity_diff[eligible_bins])\n        best_fit_bins = capacity_diff == min_diff\n        average_fill = np.mean((bin_size - bins_remain_cap) / bin_size) if num_bins > 0 else 0.0\n        best_fit_weight = 1.0 + (1.0 - average_fill)\n        priorities[best_fit_bins] += best_fit_weight\n\n    # Fragmentation Penalty (Adaptive)\n    remaining_space = bins_remain_cap - item\n    average_remaining = np.mean(bins_remain_cap) if num_bins > 0 else 0.0\n    fragmentation_threshold_multiplier = 0.2 * (1.0 - average_remaining / bin_size)\n    fragmentation_threshold = item * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)\n    fragmentation_penalty = 0.5 + (item / bin_size)\n    priorities[fragmented_bins] -= fragmentation_penalty\n    \n    # Exploration Bonus (Adaptive probability)\n    exploration_prob = 0.05 * (1 + average_fill)\n    if np.random.rand() < exploration_prob:\n        exploration_bonus = (bin_size - bins_remain_cap) / bin_size\n        priorities += exploration_bonus * 0.2\n    \n    # Fill percentage incentive\n    if np.any(potential_bins):\n        fill_percentage = item / (bin_size - bins_remain_cap[potential_bins])\n        high_fill_bins = (fill_percentage > 0.7) & (fill_percentage <= 1.0)\n\n        if np.any(high_fill_bins):\n            eligible_bins_index = np.where(potential_bins)[0][high_fill_bins]\n            priorities[eligible_bins_index] += 0.5\n\n    # Target fill bonus, adaptive target (from v1)\n    if np.any(potential_bins):\n        target_fill = 0.7 + 0.1 * average_fill\n        ideal_remaining = bin_size - target_fill\n        distance_to_ideal = np.abs((bins_remain_cap[potential_bins] - item) - ideal_remaining)\n        priorities[potential_bins] += np.exp(-distance_to_ideal * 6)\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                fill_ratio_weight_base: float = 0.08298567341766837,\n                fill_ratio_weight_item_factor: float = 0.1918000656729426,\n                best_fit_weight_base: float = 4.786399897470084,\n                best_fit_weight_availability_factor: float = 0.8846166548355004,\n                fragmentation_penalty_weight_base: float = 2.284981010263942,\n                fragmentation_penalty_weight_item_factor: float = 0.7773265039534436,\n                reuse_weight_base: float = 1.6306355193348756,\n                reuse_weight_availability_factor: float = 0.17851856923235693,\n                best_fit_decay_rate: float = 2.2088471578138376,\n                fragmentation_threshold_base: float = 0.6258282417693154,\n                fragmentation_threshold_item_factor: float = 0.00022205528141430177,\n                almost_empty_threshold_base: float = 1.034728592594321,\n                almost_empty_threshold_average_fill_factor: float = 0.9076513753139951,\n                almost_empty_bonus_base: float = 0.33747365128330953,\n                almost_empty_bonus_average_fill_factor: float = 0.6816988338625264,\n                too_full_threshold: float = 0.6644324513202721,\n                too_full_penalty: float = 0.30019191052353134,\n                exploration_factor_scale: float = 0.04764328369868246,\n                min_item_size_factor: float = 0.3818846450044734,\n                min_bin_availability_factor: float = 0.2657999802336206,\n                division_epsilon: float = 0.0008592151247375378,\n                bin_size: float = 1.06991901400127,\n                fragmentation_threshold_multiplier: float = 0.30173114495122316,\n                utilization_bonus: float = 0.4342909331786264) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    \n    # Adaptive Weights - based on item size and global fill level\n    item_size_factor = min(min_item_size_factor, item)\n    bin_availability_factor = min(min_bin_availability_factor, np.sum(bins_remain_cap >= item) / num_bins)\n    average_fill = np.mean(1 - bins_remain_cap / bin_size)\n\n    fill_ratio_weight = fill_ratio_weight_base + fill_ratio_weight_item_factor * item_size_factor\n    best_fit_weight = best_fit_weight_base + best_fit_weight_availability_factor * bin_availability_factor\n    fragmentation_penalty_weight = fragmentation_penalty_weight_base + fragmentation_penalty_weight_item_factor * item_size_factor\n    reuse_weight = reuse_weight_base + reuse_weight_availability_factor * bin_availability_factor\n    \n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + division_epsilon)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-best_fit_decay_rate * remaining_space) #Best fit bonus\n    \n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold = item * (fragmentation_threshold_base + fragmentation_threshold_item_factor * item_size_factor) * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    \n    # Scale the penalty based on how full the bin is.  More full, higher penalty\n    fragmentation_penalty_scaling = (bin_size - bins_remain_cap[fragmented_bins]) / bin_size\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill) * fragmentation_penalty_scaling\n\n     # Almost empty reuse\n    almost_empty_threshold = almost_empty_threshold_base - (almost_empty_threshold_average_fill_factor * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = almost_empty_bonus_base + average_fill * almost_empty_bonus_average_fill_factor\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus #almost empty reuse bonus.\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-too_full_threshold))\n    priorities[too_full_bins] -= too_full_penalty\n\n    # Exploration: Add a small amount of randomness, scaled to the item size.\n    exploration_factor = exploration_factor_scale * item  # Scale randomness based on the item size\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    # Encourage evening out bin utilization\n    bin_utilization = 1 - bins_remain_cap / bin_size\n    utilization_std = np.std(bin_utilization)\n    priorities += (1 - utilization_std) * utilization_bonus # Give a small bonus to solutions with similar utilizations\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best-fit, fragmentation, and exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n    num_bins = len(bins_remain_cap)\n    average_fill = np.mean(1 - bins_remain_cap) if num_bins > 0 else 0.0\n    item_size_factor = min(1.0, item)\n\n    if np.any(eligible_bins):\n        # 1. Adaptive Fill Ratio\n        fill_ratio = item / bins_remain_cap[eligible_bins]\n        priorities[eligible_bins] += (0.6 + 0.2 * item_size_factor) * fill_ratio\n\n        # 2. Best Fit with Adaptive Item Size\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += (0.7 + 0.1 * item_size_factor) * np.exp(-remaining_space)\n\n        # 3. Adaptive Fragmentation Penalty\n        max_bin_cap = np.max(bins_remain_cap) if np.any(bins_remain_cap) else 1.0\n        fragmentation_penalty = 0.2 * (remaining_space / max_bin_cap) * (1 + item_size_factor)\n        priorities[eligible_bins] -= fragmentation_penalty\n\n        # 4. Encourage use of emptier bins\n        bin_capacity_normalized = bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap)>0 else np.zeros_like(bins_remain_cap)\n        priorities += 0.15 * (1-bin_capacity_normalized)\n\n        # 5. Encourage re-use of almost empty bins\n        almost_empty_threshold = 0.9 + 0.05 * item_size_factor\n        almost_empty = bins_remain_cap > almost_empty_threshold\n        if np.any(almost_empty):\n            priorities[almost_empty] += 0.6 + 0.1 * item_size_factor\n        \n        # 6. Small bonus to eligible bins\n        priorities[eligible_bins] += 0.01\n\n    else:\n       priorities[:] = -0.001 # Discourage if no suitable bin\n    \n    # 7. Exploration component\n    exploration_factor = 0.005 * item * (1-average_fill)\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n    \n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration, and global awareness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    total_bin_capacity = num_bins  # Assuming each bin has capacity 1\n    total_items_packed = total_bin_capacity - np.sum(bins_remain_cap)\n    average_fill = total_items_packed / total_bin_capacity if total_bin_capacity > 0 else 0.0\n    \n    # Adaptive Weights - based on item size, bin availability and global fill level\n    item_size_factor = min(0.75, item)  # Capped item size factor\n    bin_availability_factor = min(1.27, np.sum(bins_remain_cap >= item) / num_bins)\n    \n    # Dynamic weight adjustments based on global fill\n    fill_ratio_weight = 0.07 + 0.10 * item_size_factor * (1 + average_fill)\n    best_fit_weight = 2.81 + 0.68 * bin_availability_factor * (1 - average_fill)\n    fragmentation_penalty_weight = 1.47 + 0.82 * item_size_factor * (1 + average_fill)\n    reuse_weight = 0.79 + 0.51 * bin_availability_factor * (1 - average_fill)\n\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + 1e-6)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-2.73 * remaining_space)\n\n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold = item * (0.45 + 0.04 * item_size_factor) * (0.2 / np.sqrt(num_bins))\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill)**2 # Squared penalty\n\n    # Almost empty reuse\n    almost_empty_threshold = 0.93 - (0.20 * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = 0.09 + average_fill * 0.57\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-0.42))\n    priorities[too_full_bins] -= 0.08\n\n    # Global Bin Balancing: Encourage filling emptier bins when average fill is high\n    if average_fill > 0.7:\n        empty_bin_bonus = (1-average_fill) * bins_remain_cap\n        priorities += 0.1*empty_bin_bonus # Bonus for packing into more empty bins\n\n    # Exploration: Adaptive exploration based on global fill level\n    exploration_factor = 0.026 * item * (1-average_fill) # Reduced exploration as bins fill up\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration, and global awareness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    total_bin_capacity = num_bins  # Assuming each bin has capacity 1\n    total_items_packed = total_bin_capacity - np.sum(bins_remain_cap)\n    average_fill = total_items_packed / total_bin_capacity if total_bin_capacity > 0 else 0.0\n    \n    # Adaptive Weights - based on item size, bin availability and global fill level\n    item_size_factor = min(0.75, item)  # Capped item size factor\n    bin_availability_factor = min(1.27, np.sum(bins_remain_cap >= item) / num_bins)\n    \n    # Dynamic weight adjustments based on global fill\n    fill_ratio_weight = 0.07 + 0.10 * item_size_factor * (1 + average_fill)\n    best_fit_weight = 2.81 + 0.68 * bin_availability_factor * (1 - average_fill)\n    fragmentation_penalty_weight = 1.47 + 0.82 * item_size_factor * (1 + average_fill)\n    reuse_weight = 0.79 + 0.51 * bin_availability_factor * (1 - average_fill)\n\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + 1e-6)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-2.73 * remaining_space)\n\n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold = item * (0.45 + 0.04 * item_size_factor) * (0.2 / np.sqrt(num_bins))\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill)**2 # Squared penalty\n\n    # Almost empty reuse\n    almost_empty_threshold = 0.93 - (0.20 * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = 0.09 + average_fill * 0.57\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-0.42))\n    priorities[too_full_bins] -= 0.08\n\n    # Global Bin Balancing: Encourage filling emptier bins when average fill is high\n    if average_fill > 0.7:\n        empty_bin_bonus = (1-average_fill) * bins_remain_cap\n        priorities += 0.1*empty_bin_bonus # Bonus for packing into more empty bins\n\n    # Exploration: Adaptive exploration based on global fill level\n    exploration_factor = 0.026 * item * (1-average_fill) # Reduced exploration as bins fill up\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration, and global awareness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    total_bin_capacity = num_bins  # Assuming each bin has capacity 1\n    total_items_packed = total_bin_capacity - np.sum(bins_remain_cap)\n    average_fill = total_items_packed / total_bin_capacity if total_bin_capacity > 0 else 0.0\n    \n    # Adaptive Weights - based on item size, bin availability and global fill level\n    item_size_factor = min(0.75, item)  # Capped item size factor\n    bin_availability_factor = min(1.27, np.sum(bins_remain_cap >= item) / num_bins)\n    \n    # Dynamic weight adjustments based on global fill\n    fill_ratio_weight = 0.07 + 0.10 * item_size_factor * (1 + average_fill)\n    best_fit_weight = 2.81 + 0.68 * bin_availability_factor * (1 - average_fill)\n    fragmentation_penalty_weight = 1.47 + 0.82 * item_size_factor * (1 + average_fill)\n    reuse_weight = 0.79 + 0.51 * bin_availability_factor * (1 - average_fill)\n\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + 1e-6)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-2.73 * remaining_space)\n\n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold = item * (0.45 + 0.04 * item_size_factor) * (0.2 / np.sqrt(num_bins))\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill)**2 # Squared penalty\n\n    # Almost empty reuse\n    almost_empty_threshold = 0.93 - (0.20 * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = 0.09 + average_fill * 0.57\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-0.42))\n    priorities[too_full_bins] -= 0.08\n\n    # Global Bin Balancing: Encourage filling emptier bins when average fill is high\n    if average_fill > 0.7:\n        empty_bin_bonus = (1-average_fill) * bins_remain_cap\n        priorities += 0.1*empty_bin_bonus # Bonus for packing into more empty bins\n\n    # Exploration: Adaptive exploration based on global fill level\n    exploration_factor = 0.026 * item * (1-average_fill) # Reduced exploration as bins fill up\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration, and global awareness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    total_bin_capacity = num_bins  # Assuming each bin has capacity 1\n    total_items_packed = total_bin_capacity - np.sum(bins_remain_cap)\n    average_fill = total_items_packed / total_bin_capacity if total_bin_capacity > 0 else 0.0\n    \n    # Adaptive Weights - based on item size, bin availability and global fill level\n    item_size_factor = min(0.75, item)  # Capped item size factor\n    bin_availability_factor = min(1.27, np.sum(bins_remain_cap >= item) / num_bins)\n    \n    # Dynamic weight adjustments based on global fill\n    fill_ratio_weight = 0.07 + 0.10 * item_size_factor * (1 + average_fill)\n    best_fit_weight = 2.81 + 0.68 * bin_availability_factor * (1 - average_fill)\n    fragmentation_penalty_weight = 1.47 + 0.82 * item_size_factor * (1 + average_fill)\n    reuse_weight = 0.79 + 0.51 * bin_availability_factor * (1 - average_fill)\n\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + 1e-6)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-2.73 * remaining_space)\n\n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold = item * (0.45 + 0.04 * item_size_factor) * (0.2 / np.sqrt(num_bins))\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill)**2 # Squared penalty\n\n    # Almost empty reuse\n    almost_empty_threshold = 0.93 - (0.20 * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = 0.09 + average_fill * 0.57\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-0.42))\n    priorities[too_full_bins] -= 0.08\n\n    # Global Bin Balancing: Encourage filling emptier bins when average fill is high\n    if average_fill > 0.7:\n        empty_bin_bonus = (1-average_fill) * bins_remain_cap\n        priorities += 0.1*empty_bin_bonus # Bonus for packing into more empty bins\n\n    # Exploration: Adaptive exploration based on global fill level\n    exploration_factor = 0.026 * item * (1-average_fill) # Reduced exploration as bins fill up\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                fill_ratio_weight_base: float = 0.07001911716215126,\n                fill_ratio_weight_item_factor: float = 0.09674577434453879,\n                best_fit_weight_base: float = 2.805747453408391,\n                best_fit_weight_availability_factor: float = 0.6848823870770047,\n                fragmentation_penalty_weight_base: float = 1.4678366072617053,\n                fragmentation_penalty_weight_item_factor: float = 0.8155589797225978,\n                reuse_weight_base: float = 0.7877195059531279,\n                reuse_weight_availability_factor: float = 0.5099151918111539,\n                best_fit_decay_rate: float = 2.7252501697954994,\n                fragmentation_threshold_base: float = 0.45443676724460597,\n                fragmentation_threshold_item_factor: float = 0.03685272815567264,\n                almost_empty_threshold_base: float = 0.9265092958240733,\n                almost_empty_threshold_average_fill_factor: float = 0.2006311693648083,\n                almost_empty_bonus_base: float = 0.09108242175329895,\n                almost_empty_bonus_average_fill_factor: float = 0.5721102621832862,\n                too_full_threshold: float = 0.4199500766768644,\n                too_full_penalty: float = 0.0826040342356067,\n                exploration_factor_scale: float = 0.02587384524922878,\n                min_item_size_factor: float = 0.7483057590114014,\n                min_bin_availability_factor: float = 1.2697180594558546,\n                division_epsilon: float = 0.0008721588230938938) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    \n    # Adaptive Weights - based on item size and global fill level\n    item_size_factor = min(min_item_size_factor, item)\n    bin_availability_factor = min(min_bin_availability_factor, np.sum(bins_remain_cap >= item) / num_bins)\n    average_fill = np.mean(1 - bins_remain_cap)\n    std_fill = np.std(1 - bins_remain_cap)\n\n    fill_ratio_weight = fill_ratio_weight_base + fill_ratio_weight_item_factor * item_size_factor\n    best_fit_weight = best_fit_weight_base + best_fit_weight_availability_factor * bin_availability_factor\n    fragmentation_penalty_weight = fragmentation_penalty_weight_base + fragmentation_penalty_weight_item_factor * item_size_factor\n    reuse_weight = reuse_weight_base + reuse_weight_availability_factor * bin_availability_factor\n    \n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + division_epsilon)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-best_fit_decay_rate * remaining_space) #Best fit bonus\n\n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold_multiplier = 0.2 / np.sqrt(num_bins)\n    fragmentation_threshold = item * (fragmentation_threshold_base + fragmentation_threshold_item_factor * item_size_factor) * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill)\n\n     # Almost empty reuse\n    almost_empty_threshold = almost_empty_threshold_base - (almost_empty_threshold_average_fill_factor * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = almost_empty_bonus_base + average_fill * almost_empty_bonus_average_fill_factor\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus #almost empty reuse bonus.\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-too_full_threshold))\n    priorities[too_full_bins] -= too_full_penalty\n\n    # State-Aware Exploration: Dynamically adjust exploration based on fill level variance.\n    # Higher variance indicates potential imbalance, warranting more exploration.\n    exploration_factor = exploration_factor_scale * item * (1 + std_fill)\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    # Encourage evening out the fill levels\n    fill_level_penalty = (1 - bins_remain_cap - average_fill) * std_fill * 0.1\n    priorities -= fill_level_penalty\n\n    # Prioritize bins with a remaining capacity closest to the average.\n    avg_remaining = np.mean(bins_remain_cap)\n    closeness_to_average = np.abs(bins_remain_cap - avg_remaining)\n    priorities -= closeness_to_average * 0.05 # Smaller values are better (more priority)\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                fill_ratio_weight_base: float = 0.07001911716215126,\n                fill_ratio_weight_item_factor: float = 0.09674577434453879,\n                best_fit_weight_base: float = 2.805747453408391,\n                best_fit_weight_availability_factor: float = 0.6848823870770047,\n                fragmentation_penalty_weight_base: float = 1.4678366072617053,\n                fragmentation_penalty_weight_item_factor: float = 0.8155589797225978,\n                reuse_weight_base: float = 0.7877195059531279,\n                reuse_weight_availability_factor: float = 0.5099151918111539,\n                best_fit_decay_rate: float = 2.7252501697954994,\n                fragmentation_threshold_base: float = 0.45443676724460597,\n                fragmentation_threshold_item_factor: float = 0.03685272815567264,\n                almost_empty_threshold_base: float = 0.9265092958240733,\n                almost_empty_threshold_average_fill_factor: float = 0.2006311693648083,\n                almost_empty_bonus_base: float = 0.09108242175329895,\n                almost_empty_bonus_average_fill_factor: float = 0.5721102621832862,\n                too_full_threshold: float = 0.4199500766768644,\n                too_full_penalty: float = 0.0826040342356067,\n                exploration_factor_scale: float = 0.02587384524922878,\n                min_item_size_factor: float = 0.7483057590114014,\n                min_bin_availability_factor: float = 1.2697180594558546,\n                division_epsilon: float = 0.0008721588230938938) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    \n    # Adaptive Weights - based on item size and global fill level\n    item_size_factor = min(min_item_size_factor, item)\n    bin_availability_factor = min(min_bin_availability_factor, np.sum(bins_remain_cap >= item) / num_bins)\n    average_fill = np.mean(1 - bins_remain_cap)\n    std_fill = np.std(1 - bins_remain_cap)\n\n    fill_ratio_weight = fill_ratio_weight_base + fill_ratio_weight_item_factor * item_size_factor\n    best_fit_weight = best_fit_weight_base + best_fit_weight_availability_factor * bin_availability_factor\n    fragmentation_penalty_weight = fragmentation_penalty_weight_base + fragmentation_penalty_weight_item_factor * item_size_factor\n    reuse_weight = reuse_weight_base + reuse_weight_availability_factor * bin_availability_factor\n    \n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + division_epsilon)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-best_fit_decay_rate * remaining_space) #Best fit bonus\n\n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold_multiplier = 0.2 / np.sqrt(num_bins)\n    fragmentation_threshold = item * (fragmentation_threshold_base + fragmentation_threshold_item_factor * item_size_factor) * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill)\n\n     # Almost empty reuse\n    almost_empty_threshold = almost_empty_threshold_base - (almost_empty_threshold_average_fill_factor * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = almost_empty_bonus_base + average_fill * almost_empty_bonus_average_fill_factor\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus #almost empty reuse bonus.\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-too_full_threshold))\n    priorities[too_full_bins] -= too_full_penalty\n\n    # State-Aware Exploration: Dynamically adjust exploration based on fill level variance.\n    # Higher variance indicates potential imbalance, warranting more exploration.\n    exploration_factor = exploration_factor_scale * item * (1 + std_fill)\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    # Encourage evening out the fill levels\n    fill_level_penalty = (1 - bins_remain_cap - average_fill) * std_fill * 0.1\n    priorities -= fill_level_penalty\n\n    # Prioritize bins with a remaining capacity closest to the average.\n    avg_remaining = np.mean(bins_remain_cap)\n    closeness_to_average = np.abs(bins_remain_cap - avg_remaining)\n    priorities -= closeness_to_average * 0.05 # Smaller values are better (more priority)\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, fragmentation penalty, and global fill awareness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    potential_bins = bins_remain_cap >= item\n\n    # 1. Adaptive Fill Ratio Preference\n    if np.any(potential_bins):\n        fill_ratios = item / bins_remain_cap[potential_bins]\n        priorities[potential_bins] += fill_ratios * (0.7 + 0.3 * (1 - np.mean(bins_remain_cap))) # Adapt based on avg cap\n\n    # 2. Stronger Best Fit Encouragement\n    capacity_diff = np.abs(bins_remain_cap - item)\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        min_diff = np.min(capacity_diff[eligible_bins])\n        best_fit_bins = capacity_diff == min_diff\n        priorities[best_fit_bins] += 1.5 # Boost best fit\n\n    # 3. Adaptive Fragmentation Penalty\n    remaining_space = bins_remain_cap - item\n    fragmentation_threshold = item * (0.1 + 0.03 * np.mean(bins_remain_cap)) # Adaptive threshold\n    fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)\n    priorities[fragmented_bins] -= 1.0 #Penalize fragmented bins\n\n    # 4. Almost Empty Bonus\n    almost_empty_threshold = 0.9\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        priorities[almost_empty] += 0.3 # Reuse almost empty bin\n\n    # 5. Global Fill Level Encouragement\n    global_fill_level = np.sum(1 - bins_remain_cap) / num_bins # Global fill estimation\n    if global_fill_level > 0.6: # High fill level encouragement\n        exploration_bonus = 0.1 * bins_remain_cap # Linear bonus based on capacity\n        priorities += exploration_bonus\n\n    # 6. Discourage near empty for the first few items.\n    if global_fill_level < 0.1:\n        near_empty_threshold = 0.95\n        near_empty = bins_remain_cap > near_empty_threshold\n        if np.any(near_empty):\n            priorities[near_empty] -= 0.2 # Reduce near-empty bin priority.\n            \n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, fragmentation penalty, and global fill awareness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    potential_bins = bins_remain_cap >= item\n\n    # 1. Adaptive Fill Ratio Preference\n    if np.any(potential_bins):\n        fill_ratios = item / bins_remain_cap[potential_bins]\n        priorities[potential_bins] += fill_ratios * (0.7 + 0.3 * (1 - np.mean(bins_remain_cap))) # Adapt based on avg cap\n\n    # 2. Stronger Best Fit Encouragement\n    capacity_diff = np.abs(bins_remain_cap - item)\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        min_diff = np.min(capacity_diff[eligible_bins])\n        best_fit_bins = capacity_diff == min_diff\n        priorities[best_fit_bins] += 1.5 # Boost best fit\n\n    # 3. Adaptive Fragmentation Penalty\n    remaining_space = bins_remain_cap - item\n    fragmentation_threshold = item * (0.1 + 0.03 * np.mean(bins_remain_cap)) # Adaptive threshold\n    fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)\n    priorities[fragmented_bins] -= 1.0 #Penalize fragmented bins\n\n    # 4. Almost Empty Bonus\n    almost_empty_threshold = 0.9\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        priorities[almost_empty] += 0.3 # Reuse almost empty bin\n\n    # 5. Global Fill Level Encouragement\n    global_fill_level = np.sum(1 - bins_remain_cap) / num_bins # Global fill estimation\n    if global_fill_level > 0.6: # High fill level encouragement\n        exploration_bonus = 0.1 * bins_remain_cap # Linear bonus based on capacity\n        priorities += exploration_bonus\n\n    # 6. Discourage near empty for the first few items.\n    if global_fill_level < 0.1:\n        near_empty_threshold = 0.95\n        near_empty = bins_remain_cap > near_empty_threshold\n        if np.any(near_empty):\n            priorities[near_empty] -= 0.2 # Reduce near-empty bin priority.\n            \n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fill ratio, best fit, fragmentation penalty, and adaptive exploration based on global fill level.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    bin_size = 1.0\n\n    # 1. Fill Ratio Preference\n    potential_bins = bins_remain_cap >= item\n    if np.any(potential_bins):\n        fill_ratio = (bins_remain_cap[potential_bins] - item) / bin_size\n        priorities[potential_bins] += fill_ratio * 0.7  # Weighted fill ratio\n\n    # 2. Best Fit Encouragement\n    capacity_diff = np.abs(bins_remain_cap - item)\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        min_diff = np.min(capacity_diff[eligible_bins])\n        best_fit_bins = capacity_diff == min_diff\n        priorities[best_fit_bins] += 1.5 # best_fit_weight\n\n    # 3. Fragmentation Penalty (Adaptive)\n    remaining_space = bins_remain_cap - item\n    fragmentation_threshold = item * 0.2 # fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)\n    priorities[fragmented_bins] -= 1.3 # fragmentation_penalty\n\n    # 4. Adaptive Exploration\n    average_fill = np.mean((bin_size - bins_remain_cap) / bin_size) if num_bins > 0 else 0.0\n    exploration_probability = 0.05 * (1.0 - average_fill)  # Explore more when bins are empty\n    if np.random.rand() < exploration_probability:\n        exploration_bonus = (bin_size - bins_remain_cap) / bin_size\n        priorities += exploration_bonus * 0.2\n\n    # 5. High fill incentive\n    if np.any(potential_bins):\n        fill_percentage = item / (bin_size - bins_remain_cap[potential_bins])\n        high_fill_bins = (fill_percentage > 0.7) & (fill_percentage <= 1.0) # Limit the value of fill_percentage to 1\n\n        if np.any(high_fill_bins):\n            eligible_bins_index = np.where(potential_bins)[0][high_fill_bins]\n            priorities[eligible_bins_index] += 0.5\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fill ratio, best fit, fragmentation penalty, and adaptive exploration based on global fill level.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    bin_size = 1.0\n\n    # 1. Fill Ratio Preference\n    potential_bins = bins_remain_cap >= item\n    if np.any(potential_bins):\n        fill_ratio = (bins_remain_cap[potential_bins] - item) / bin_size\n        priorities[potential_bins] += fill_ratio * 0.7  # Weighted fill ratio\n\n    # 2. Best Fit Encouragement\n    capacity_diff = np.abs(bins_remain_cap - item)\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        min_diff = np.min(capacity_diff[eligible_bins])\n        best_fit_bins = capacity_diff == min_diff\n        priorities[best_fit_bins] += 1.5 # best_fit_weight\n\n    # 3. Fragmentation Penalty (Adaptive)\n    remaining_space = bins_remain_cap - item\n    fragmentation_threshold = item * 0.2 # fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)\n    priorities[fragmented_bins] -= 1.3 # fragmentation_penalty\n\n    # 4. Adaptive Exploration\n    average_fill = np.mean((bin_size - bins_remain_cap) / bin_size) if num_bins > 0 else 0.0\n    exploration_probability = 0.05 * (1.0 - average_fill)  # Explore more when bins are empty\n    if np.random.rand() < exploration_probability:\n        exploration_bonus = (bin_size - bins_remain_cap) / bin_size\n        priorities += exploration_bonus * 0.2\n\n    # 5. High fill incentive\n    if np.any(potential_bins):\n        fill_percentage = item / (bin_size - bins_remain_cap[potential_bins])\n        high_fill_bins = (fill_percentage > 0.7) & (fill_percentage <= 1.0) # Limit the value of fill_percentage to 1\n\n        if np.any(high_fill_bins):\n            eligible_bins_index = np.where(potential_bins)[0][high_fill_bins]\n            priorities[eligible_bins_index] += 0.5\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}