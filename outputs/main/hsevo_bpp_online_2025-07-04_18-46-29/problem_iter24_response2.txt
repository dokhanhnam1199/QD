```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray, bin_size: float = 1.0) -> np.ndarray:
    """Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration, and bin diversity. Enhanced for adaptivity and state-awareness."""

    num_bins = len(bins_remain_cap)
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # --- Adaptive Parameters (learned or hand-tuned) ---
    fill_ratio_weight_base: float = 0.1
    fill_ratio_weight_item_factor: float = 0.15
    best_fit_weight_base: float = 3.0
    best_fit_weight_availability_factor: float = 0.7
    fragmentation_penalty_weight_base: float = 1.5
    fragmentation_penalty_weight_item_factor: float = 0.9
    reuse_weight_base: float = 0.8
    reuse_weight_availability_factor: float = 0.55
    best_fit_decay_rate: float = 2.5
    fragmentation_threshold_base: float = 0.4
    fragmentation_threshold_item_factor: float = 0.04
    almost_empty_threshold_base: float = 0.9
    almost_empty_threshold_average_fill_factor: float = 0.2
    almost_empty_bonus_base: float = 0.1
    almost_empty_bonus_average_fill_factor: float = 0.6
    too_full_threshold: float = 0.4
    too_full_penalty: float = 0.1
    exploration_factor_scale: float = 0.03
    min_item_size_factor: float = 0.7
    min_bin_availability_factor: float = 1.3
    division_epsilon: float = 0.001

    # --- Global State Awareness ---
    average_fill = np.mean(1 - bins_remain_cap / bin_size)
    bin_utilization = 1 - bins_remain_cap / bin_size
    utilization_std = np.std(bin_utilization)

    # --- Adaptive Weights ---
    item_size_factor = min(min_item_size_factor, item)
    bin_availability_factor = min(min_bin_availability_factor, np.sum(bins_remain_cap >= item) / num_bins)

    fill_ratio_weight = fill_ratio_weight_base + fill_ratio_weight_item_factor * item_size_factor
    best_fit_weight = best_fit_weight_base + best_fit_weight_availability_factor * bin_availability_factor
    fragmentation_penalty_weight = fragmentation_penalty_weight_base + fragmentation_penalty_weight_item_factor * item_size_factor
    reuse_weight = reuse_weight_base + reuse_weight_availability_factor * bin_availability_factor

    # --- Eligible Bins ---
    eligible_bins = bins_remain_cap >= item

    if np.any(eligible_bins):
        # Fill Ratio
        fill_ratio = item / (bins_remain_cap[eligible_bins] + division_epsilon)
        priorities[eligible_bins] += fill_ratio_weight * fill_ratio

        # Best Fit
        remaining_space = bins_remain_cap[eligible_bins] - item
        priorities[eligible_bins] += best_fit_weight * np.exp(-best_fit_decay_rate * remaining_space)

    # Fragmentation Penalty
    remaining_space_all = bins_remain_cap - item
    fragmentation_threshold = item * (fragmentation_threshold_base + fragmentation_threshold_item_factor * item_size_factor)
    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)
    fragmentation_penalty_scaling = (bin_size - bins_remain_cap[fragmented_bins]) / bin_size  # Scale based on fill
    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1 - average_fill) * fragmentation_penalty_scaling

    # Almost Empty Reuse
    almost_empty_threshold = almost_empty_threshold_base - (almost_empty_threshold_average_fill_factor * average_fill)
    almost_empty = bins_remain_cap > almost_empty_threshold
    if np.any(almost_empty):
        almost_empty_bonus = almost_empty_bonus_base + average_fill * almost_empty_bonus_average_fill_factor
        priorities[almost_empty] += reuse_weight * almost_empty_bonus

    # Too Full Penalty
    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item - too_full_threshold))
    priorities[too_full_bins] -= too_full_penalty

    # Exploration (scaled randomness)
    exploration_factor = exploration_factor_scale * item
    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)

    # Bin Diversity Bonus (Encourage evening out utilization) - More robust to outliers
    priorities += (1 - utilization_std) * 0.1

    # Sort the bins by remaining capacity, add a small bonus for more full bins (but below item size)
    potentially_good_bins = (bins_remain_cap < item)
    if np.any(potentially_good_bins):
      priorities[potentially_good_bins] += (bin_size - bins_remain_cap[potentially_good_bins]) / bin_size * 0.05

    # Dynamic adjustment of best fit weight. If there are very few eligible bins, increase best fit weight.
    if np.sum(eligible_bins) < num_bins * 0.1:
        priorities[eligible_bins] += best_fit_weight * 0.5  # Boost best fit

    return priorities
```
