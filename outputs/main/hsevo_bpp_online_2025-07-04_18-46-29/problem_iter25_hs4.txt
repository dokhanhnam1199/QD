import numpy as np

def priority_v2(item: float,
                bins_remain_cap: np.ndarray,
                bin_size: float = 1.0,
                item_size_factor_cap: float = 0.9756168813969719,
                bin_availability_factor_cap: float = 1.2155123532969492,
                fill_ratio_weight_base: float = 0.07038037601483568,
                fill_ratio_weight_item_factor: float = 0.10932525925999298,
                best_fit_weight_base: float = 2.6032035600229393,
                best_fit_weight_availability_factor: float = 0.522650436810968,
                fragmentation_penalty_weight_base: float = 1.7051599465823828,
                fragmentation_penalty_weight_item_factor: float = 0.729933729279769,
                reuse_weight_base: float = 0.8704256186934587,
                reuse_weight_availability_factor: float = 0.43458147170500905,
                fill_ratio_add: float = 0.0011349528520108163,
                best_fit_exp_decay: float = -2.8809842496617195,
                fragmentation_threshold_base: float = 0.45861402677485297,
                fragmentation_threshold_item_factor: float = 0.061182124518779635,
                fragmentation_threshold_num_bins_factor: float = 0.15755122469198302,
                almost_empty_threshold_base: float = 0.9458070917123214,
                almost_empty_threshold_fill_factor: float = 0.2509267675472767,
                almost_empty_bonus_base: float = 0.1354531860526785,
                almost_empty_bonus_fill_factor: float = 0.5720620417588334,
                too_full_threshold: float = 0.4785616895797697,
                too_full_penalty: float = -0.06909764315720812,
                exploration_factor_base: float = 0.028059142573632817,
                utilization_bonus: float = 0.1553786231065855,
                small_space_penalty_threshold: float = 0.15548612344483428,
                difficult_to_fill_penalty: float = 0.0686746078356275) -> np.ndarray:
    """Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration with dynamic adjustments and lookahead."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    num_bins = len(bins_remain_cap)

    # --- 1. Adaptive Weights (Item Size & Bin Availability) ---
    item_size_factor = min(item_size_factor_cap, item)  # Capping item size factor
    bin_availability_factor = min(bin_availability_factor_cap, np.sum(bins_remain_cap >= item) / (num_bins + 1e-6))  # Smooth availability factor

    fill_ratio_weight = fill_ratio_weight_base + fill_ratio_weight_item_factor * item_size_factor
    best_fit_weight = best_fit_weight_base + best_fit_weight_availability_factor * bin_availability_factor
    fragmentation_penalty_weight = fragmentation_penalty_weight_base + fragmentation_penalty_weight_item_factor * item_size_factor
    reuse_weight = reuse_weight_base + reuse_weight_availability_factor * bin_availability_factor

    # --- 2. Fill Ratio (Eligible Bins) ---
    eligible_bins = bins_remain_cap >= item
    if np.any(eligible_bins):
        fill_ratio = item / (bins_remain_cap[eligible_bins] + fill_ratio_add)  # Avoid division by zero
        priorities[eligible_bins] += fill_ratio_weight * fill_ratio

        # Best Fit - Exponential decay
        remaining_space = bins_remain_cap[eligible_bins] - item
        priorities[eligible_bins] += best_fit_weight * np.exp(best_fit_exp_decay * remaining_space)

    # --- 3. Fragmentation Penalty (Dynamic Threshold) ---
    remaining_space_all = bins_remain_cap - item
    fragmentation_threshold = item * (fragmentation_threshold_base + fragmentation_threshold_item_factor * item_size_factor) * (fragmentation_threshold_num_bins_factor / np.sqrt(num_bins + 1e-6))
    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)

    # Scale penalty based on fill level and item size
    bin_fill_level = (bin_size - bins_remain_cap[fragmented_bins]) / bin_size
    fragmentation_penalty_scaling = bin_fill_level * item_size_factor
    priorities[fragmented_bins] -= fragmentation_penalty_weight * fragmentation_penalty_scaling

    # --- 4. Almost Empty Reuse ---
    average_fill = np.mean(1 - bins_remain_cap / bin_size)
    almost_empty_threshold = almost_empty_threshold_base - (almost_empty_threshold_fill_factor * average_fill)
    almost_empty = bins_remain_cap > almost_empty_threshold
    if np.any(almost_empty):
        almost_empty_bonus = almost_empty_bonus_base + average_fill * almost_empty_bonus_fill_factor
        priorities[almost_empty] += reuse_weight * almost_empty_bonus

    # --- 5. Too Full Penalty ---
    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item - too_full_threshold))
    priorities[too_full_bins] += too_full_penalty

    # --- 6. Exploration (Scaled Randomness) ---
    exploration_factor = exploration_factor_base * item
    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)

    # --- 7. Encourage Even Utilization (with stronger weighting) ---
    bin_utilization = 1 - bins_remain_cap / bin_size
    utilization_std = np.std(bin_utilization)
    priorities += (1 - utilization_std) * utilization_bonus  # Doubled the bonus

    # --- 8. Lookahead (Simulated Placement) ---
    # Penalize bins that, after placing the current item, would become difficult to fill later.
    simulated_remaining_caps = bins_remain_cap - item
    simulated_remaining_caps[simulated_remaining_caps < 0] = -1 # Mark that the item can't be added

    difficult_to_fill = (simulated_remaining_caps > 0) & (simulated_remaining_caps <= small_space_penalty_threshold)

    # Scale penalty by how much space is wasted and the size of the item
    waste_amount = small_space_penalty_threshold - simulated_remaining_caps[difficult_to_fill]
    waste_penalty = waste_amount/ small_space_penalty_threshold

    priorities[difficult_to_fill] -= difficult_to_fill_penalty * waste_penalty * item_size_factor

    return priorities
