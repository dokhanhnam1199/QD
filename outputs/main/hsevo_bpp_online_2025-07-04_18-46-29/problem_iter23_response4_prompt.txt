{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Adaptive heuristic combining fill ratio, best fit, and bin diversity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        # Fill Ratio with item size influence\n        fill_ratio = item / bins_remain_cap[valid_bins]\n        priorities[valid_bins] += fill_ratio * 0.6\n\n        # Best Fit with non-linear encouragement\n        remaining_space = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] += np.exp(-4 * remaining_space) * 0.9\n\n        # Bin Diversity Bonus\n        if len(bins_remain_cap) > 1:\n            bin_std = np.std(bins_remain_cap)\n            if bin_std > 0.1:\n                priorities[valid_bins] += 0.2\n\n        # Large item encouragement\n        if item > 0.7:\n             min_remaining = np.min(bins_remain_cap[valid_bins]-item)\n             tight_fit = (bins_remain_cap[valid_bins] - item) == min_remaining\n             priorities[valid_bins][tight_fit] += 0.5\n\n    else:\n        priorities[:] = -0.001\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                fill_ratio_weight_base: float = 0.08298567341766837,\n                fill_ratio_weight_item_factor: float = 0.1918000656729426,\n                best_fit_weight_base: float = 4.786399897470084,\n                best_fit_weight_availability_factor: float = 0.8846166548355004,\n                fragmentation_penalty_weight_base: float = 2.284981010263942,\n                fragmentation_penalty_weight_item_factor: float = 0.7773265039534436,\n                reuse_weight_base: float = 1.6306355193348756,\n                reuse_weight_availability_factor: float = 0.17851856923235693,\n                best_fit_decay_rate: float = 2.2088471578138376,\n                fragmentation_threshold_base: float = 0.6258282417693154,\n                fragmentation_threshold_item_factor: float = 0.00022205528141430177,\n                almost_empty_threshold_base: float = 1.034728592594321,\n                almost_empty_threshold_average_fill_factor: float = 0.9076513753139951,\n                almost_empty_bonus_base: float = 0.33747365128330953,\n                almost_empty_bonus_average_fill_factor: float = 0.6816988338625264,\n                too_full_threshold: float = 0.6644324513202721,\n                too_full_penalty: float = 0.30019191052353134,\n                exploration_factor_scale: float = 0.04764328369868246,\n                min_item_size_factor: float = 0.3818846450044734,\n                min_bin_availability_factor: float = 0.2657999802336206,\n                division_epsilon: float = 0.0008592151247375378,\n                bin_size: float = 1.06991901400127,\n                fragmentation_threshold_multiplier: float = 0.30173114495122316,\n                utilization_bonus: float = 0.4342909331786264) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    \n    # Adaptive Weights - based on item size and global fill level\n    item_size_factor = min(min_item_size_factor, item)\n    bin_availability_factor = min(min_bin_availability_factor, np.sum(bins_remain_cap >= item) / num_bins)\n    average_fill = np.mean(1 - bins_remain_cap / bin_size)\n\n    fill_ratio_weight = fill_ratio_weight_base + fill_ratio_weight_item_factor * item_size_factor\n    best_fit_weight = best_fit_weight_base + best_fit_weight_availability_factor * bin_availability_factor\n    fragmentation_penalty_weight = fragmentation_penalty_weight_base + fragmentation_penalty_weight_item_factor * item_size_factor\n    reuse_weight = reuse_weight_base + reuse_weight_availability_factor * bin_availability_factor\n    \n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + division_epsilon)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-best_fit_decay_rate * remaining_space) #Best fit bonus\n    \n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold = item * (fragmentation_threshold_base + fragmentation_threshold_item_factor * item_size_factor) * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    \n    # Scale the penalty based on how full the bin is.  More full, higher penalty\n    fragmentation_penalty_scaling = (bin_size - bins_remain_cap[fragmented_bins]) / bin_size\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill) * fragmentation_penalty_scaling\n\n     # Almost empty reuse\n    almost_empty_threshold = almost_empty_threshold_base - (almost_empty_threshold_average_fill_factor * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = almost_empty_bonus_base + average_fill * almost_empty_bonus_average_fill_factor\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus #almost empty reuse bonus.\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-too_full_threshold))\n    priorities[too_full_bins] -= too_full_penalty\n\n    # Exploration: Add a small amount of randomness, scaled to the item size.\n    exploration_factor = exploration_factor_scale * item  # Scale randomness based on the item size\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    # Encourage evening out bin utilization\n    bin_utilization = 1 - bins_remain_cap / bin_size\n    utilization_std = np.std(bin_utilization)\n    priorities += (1 - utilization_std) * utilization_bonus # Give a small bonus to solutions with similar utilizations\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic uses heavily tuned weights with adaptive components based on item size, bin availability, average fill, and standard deviation of fill, while the worst uses fixed weights and a simpler exploration strategy. (2nd best) vs (second worst) shows that the second best includes global state awareness such as global bin utilization, small/large item thresholds and associated bonuses/penalties. Comparing (1st) vs (2nd), we see the most important improvement is fine-grained control over weights, fragmentation thresholding and exploration. (3rd) vs (4th) shows no difference. Comparing (second worst) vs (worst), we see a simplified exploration probability. Overall:\n- The best heuristics incorporate adaptive weights based on item size, bin availability, and global fill levels.\n- Fragmentation penalties and almost-empty reuse bonuses are common, but the best heuristics use adaptive thresholds and scaling for these.\n- State-aware exploration, where the exploration rate is adjusted based on the current fill level and bin utilization, is present in better heuristics.\n- The top functions penalize over-utilization, balance bin usage.\n- \nOkay, let's refine \"Current self-reflection\" into something truly actionable for designing better bin packing heuristics, drawing lessons from what to avoid in \"Ineffective self-reflection.\"\n\nHere's a breakdown:\n\n*   **Keywords:** Adaptivity, state-awareness, multi-objective, parameter tuning, incremental complexity, global perspective, exploration.\n\n*   **Advice:** Design heuristics that dynamically adapt weights and strategies based on item characteristics, bin availability (current capacity, fragmentation), and the overall bin state (fill levels, remaining bins). Prioritize incremental feature addition with performance evaluation at each step. Explore parameters with fine control.\n\n*   **Avoid:** Over-reliance on single factors, neglecting global state during decision-making, abrupt priority changes, premature addition of complex functions.\n\n*   **Explanation:** Effective heuristics balance multiple objectives. Adaptivity to the current state is key. Parameter tuning can make algorithms perform better. Avoid getting stuck in local optima by considering global perspectives and starting with simple heuristics and increasing complexity in steps.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}