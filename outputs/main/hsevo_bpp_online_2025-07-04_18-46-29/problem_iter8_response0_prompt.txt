{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Hybrid priority: balance waste, fullness, fit, and penalize almost full.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        waste = bins_remain_cap - item\n        priorities[valid_bins] = -np.abs(waste[valid_bins]) # Favors minimal waste\n\n        close_fit_threshold = 0.1\n        close_fit = np.abs(waste[valid_bins]) < close_fit_threshold * item\n        priorities[valid_bins][close_fit] += 1  # Bonus for very good fit\n\n        almost_full_threshold = 0.1\n        almost_full_penalty = 10\n        almost_full = bins_remain_cap < (1 + almost_full_threshold) * item\n        priorities[almost_full] -= almost_full_penalty # Penalty for nearly full\n\n        # First Fit Decreasing - ish component to avoid fragmentation\n        remaining_after_fit_scale = 2\n        remaining_after_fit_exponent_scale = 0.5\n        remaining_after_fit = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] += np.exp(-remaining_after_fit_scale * remaining_after_fit / item) * remaining_after_fit_exponent_scale #Scale impact.\n\n        # Sigmoid component for bin fullness\n        sigmoid = 1 / (1 + np.exp(10 * (item - bins_remain_cap)))\n        priorities += 0.5 * sigmoid # Combine sigmoid\n    else:\n        discourage_random_placement_value = 100\n        priorities[:] = -discourage_random_placement_value  # Discourage random placement\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Objective Function: Combination of factors\n    \n    # 1. Space Utilization: Encourage filling bins closer to full but not overly full\n    potential_bins = bins_remain_cap >= item\n    if np.any(potential_bins):\n        utilization = (bins_remain_cap[potential_bins] - item) / bins_remain_cap[potential_bins]\n        priorities[potential_bins] += (1 - utilization)  # Higher priority for better utilization\n\n    # 2. Best Fit: Prioritize bins with smallest remaining capacity that can still fit the item\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += np.exp(-remaining_space) # Exponential decay gives high priority to best fit\n\n    # 3. Fragmentation Penalty: Penalize bins that would become too full after adding the item, leading to fragmentation. Sigmoid function used for smooth penalty.\n    near_full_threshold = 0.95\n    near_full = (bins_remain_cap >= item) & (bins_remain_cap - item <= (1 - near_full_threshold) * bins_remain_cap)\n\n    if np.any(near_full):\n        priorities[near_full] -= 1 / (1 + np.exp(-100*(bins_remain_cap[near_full] - item - (1 - near_full_threshold) * bins_remain_cap[near_full]))) # Sigmoid Penalty\n\n    # 4. Bin Balancing: Encourage balancing the load across bins.\n    bin_capacity_normalized = bins_remain_cap / np.max(bins_remain_cap)\n    priorities += bin_capacity_normalized # Higher value = more remaining capacity\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic uses a simple combination of filling bins closer to full, prioritizing bins with the smallest remaining capacity and adding a non-linearity component and penalizing near-full bins. While the worst balances waste, fullness, and avoids near-full bins by using a smoothed waste penalty and adaptive bonus for good fit.\nComparing (2nd) vs (19th), we see (2nd) considers capacity utilization, smallest remaining capacity, fragmentation penalty, bin balancing, and item size considerations and applies a sigmoid smoothing. In contrast, (19th) balances waste, fullness and avoids near-full bins by using a smoothed waste penalty and adaptive bonus for good fit.\nComparing (1st) vs (2nd), we see the best heuristic is simpler and more directly targets filling bins, while the second heuristic attempts a more complex balancing act with more features.\nComparing (3rd) vs (4th), we see (3rd) combines best fit, target fullness and adaptive penalty with a small randomness, while (4th) uses tuned parameters to balances waste, fullness, and fit.\nComparing (19th) vs (20th), we see they are identical. Overall: Simplicity and direct targeting of fill optimization might be more effective than complex, multi-faceted approaches. Adaptive penalties and bonuses seem useful. Explicit randomization may help.\n- \nOkay, let's redefine \"Current self-reflection\" into something more effective for designing better heuristics, especially in bin packing or similar optimization problems.\n\nHere's the breakdown:\n\n*   **Keywords:** Incremental refinement, objective function alignment, adaptive mechanisms, exploration-exploitation balance.\n\n*   **Advice:** Start with a simple heuristic aligned with the primary objective. Systematically introduce complexity, rigorously evaluating the impact of each addition on the *overall* objective function. Focus on designing adaptive bonuses/penalties *linked directly* to improvements (or deteriorations) in the objective function's value.\n\n*   **Avoid:** Single-factor focus, arbitrary complexity, untuned parameters, and isolated evaluations.\n\n*   **Explanation:** Effective self-reflection for heuristic design means consciously connecting new features to the overarching goal. Don't just add penalties or complexity; understand *why* they improve performance relative to the defined objective function.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}