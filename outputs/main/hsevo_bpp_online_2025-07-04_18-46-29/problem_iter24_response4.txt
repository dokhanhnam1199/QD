```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray, bin_size: float = 1.0) -> np.ndarray:
    """Enhanced priority function for online bin packing, building upon priority_v1."""

    num_bins = len(bins_remain_cap)
    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # --- Adaptive Parameters (dynamically adjusted based on item and bin states) ---
    avg_capacity = np.mean(bins_remain_cap)
    capacity_std = np.std(bins_remain_cap)
    num_eligible = np.sum(bins_remain_cap >= item)
    eligibility_ratio = num_eligible / num_bins if num_bins > 0 else 0.0
    avg_fill = np.mean(1 - bins_remain_cap / bin_size)

    # Fill Ratio: Prioritize bins that will be filled well. Adapt weight based on item size and bin availability.
    fill_ratio_weight = 0.2 + 0.3 * item + 0.5 * eligibility_ratio  # Increased impact
    eligible_bins = bins_remain_cap >= item
    if np.any(eligible_bins):
        fill_ratio = item / bins_remain_cap[eligible_bins]
        priorities[eligible_bins] += fill_ratio_weight * fill_ratio

    # Best Fit: Reward bins with minimal remaining space after packing.  Adaptive weight and decay.
    best_fit_weight = 0.5 + 0.4 * eligibility_ratio + 0.1 * (1 - avg_fill)
    best_fit_decay_rate = 3.0 - 1.5 * item # Larger items require less fine-grained best fit.
    if np.any(eligible_bins):
        remaining_space = bins_remain_cap[eligible_bins] - item
        priorities[eligible_bins] += best_fit_weight * np.exp(-best_fit_decay_rate * remaining_space)

    # Fragmentation Penalty: Discourage creating small, unusable fragments.  Adapt based on item size and bin diversity.
    fragmentation_penalty_weight = 0.3 + 0.2 * item + 0.5 * (capacity_std / avg_capacity if avg_capacity > 0 else 0.0)
    fragmentation_threshold = item * (0.3 + 0.1 * item)  # Dynamic fragmentation threshold
    remaining_space_all = bins_remain_cap - item
    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)
    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1 - avg_fill)  # Scale by fill

    # Reuse Almost Empty Bins: Incentivize reusing bins close to empty. Adaptive bonus.
    almost_empty_threshold = 0.9 - 0.2 * avg_fill
    almost_empty = bins_remain_cap > almost_empty_threshold
    almost_empty_bonus = 0.2 + 0.3 * avg_fill
    priorities[almost_empty] += almost_empty_bonus

    # Penalize Too Full Bins: Strongly discourage bins that are almost full but cannot fit the current item.
    too_full_threshold = 0.2
    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item - too_full_threshold))
    priorities[too_full_bins] -= 0.4  # Strong penalty

    #Bin balancing.
    bin_utilization = 1 - bins_remain_cap / bin_size
    utilization_std = np.std(bin_utilization)
    priorities += (1 - utilization_std) * 0.2 # Give a small bonus to solutions with similar utilizations

    # Exploration: Introduce randomness to escape local optima. Adaptive scale based on remaining capacity variance.
    exploration_factor = 0.05 * item * (capacity_std / avg_capacity if avg_capacity > 0 else 0.0)
    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)


   #Prioritize bins with higher remaining capacity if there is no eligible bins.
    if not np.any(eligible_bins):
        priorities += bins_remain_cap * 0.01

    return priorities
```
