[
  {
    "stdout_filepath": "problem_iter20_response0.txt_stdout.txt",
    "code_path": "problem_iter20_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best-fit, fragmentation, and exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n    num_bins = len(bins_remain_cap)\n    average_fill = np.mean(1 - bins_remain_cap) if num_bins > 0 else 0.0\n    item_size_factor = min(1.0, item)\n\n    if np.any(eligible_bins):\n        # 1. Adaptive Fill Ratio\n        fill_ratio = item / bins_remain_cap[eligible_bins]\n        priorities[eligible_bins] += (0.6 + 0.2 * item_size_factor) * fill_ratio\n\n        # 2. Best Fit with Adaptive Item Size\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += (0.7 + 0.1 * item_size_factor) * np.exp(-remaining_space)\n\n        # 3. Adaptive Fragmentation Penalty\n        max_bin_cap = np.max(bins_remain_cap) if np.any(bins_remain_cap) else 1.0\n        fragmentation_penalty = 0.2 * (remaining_space / max_bin_cap) * (1 + item_size_factor)\n        priorities[eligible_bins] -= fragmentation_penalty\n\n        # 4. Encourage use of emptier bins\n        bin_capacity_normalized = bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap)>0 else np.zeros_like(bins_remain_cap)\n        priorities += 0.15 * (1-bin_capacity_normalized)\n\n        # 5. Encourage re-use of almost empty bins\n        almost_empty_threshold = 0.9 + 0.05 * item_size_factor\n        almost_empty = bins_remain_cap > almost_empty_threshold\n        if np.any(almost_empty):\n            priorities[almost_empty] += 0.6 + 0.1 * item_size_factor\n        \n        # 6. Small bonus to eligible bins\n        priorities[eligible_bins] += 0.01\n\n    else:\n       priorities[:] = -0.001 # Discourage if no suitable bin\n    \n    # 7. Exploration component\n    exploration_factor = 0.005 * item * (1-average_fill)\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n    \n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 7.090147586757094,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response1.txt_stdout.txt",
    "code_path": "problem_iter20_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive heuristic combining best-fit, target fill, fragmentation,\n    and state-aware adjustments based on bin fill levels.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n    num_bins = len(bins_remain_cap)\n\n    if np.any(valid_bins):\n        # Best-fit component (minimize waste), scaled by item size\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] -= np.abs(waste) * (1 + 0.15 * item)\n\n        # Target fill bonus (around 80% full)\n        target_fill = 0.8\n        ideal_remaining = 1 - target_fill\n        distance_to_ideal = np.abs((bins_remain_cap[valid_bins] - item) - ideal_remaining)\n        priorities[valid_bins] += np.exp(-distance_to_ideal * 6)\n\n        # Fragmentation penalty, adaptive to remaining space and number of bins\n        fragmentation_threshold = item * 0.12\n        remaining_space = bins_remain_cap - item\n        fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)\n        fragmentation_penalty = 1.0 + 0.6 * (fragmentation_threshold - remaining_space[fragmented_bins]) / (fragmentation_threshold + 1e-9)\n        priorities[fragmented_bins] -= fragmentation_penalty * (1 + 0.07 * (num_bins / (np.sum(bins_remain_cap) + 1e-9)))\n\n        # Encourage near-empty reuse\n        almost_empty_threshold = 0.9\n        almost_empty = bins_remain_cap > almost_empty_threshold\n        if np.any(almost_empty):\n            almost_empty_bonus = 0.6 + 0.5 * (bins_remain_cap[almost_empty] - almost_empty_threshold) / (1 - almost_empty_threshold + 1e-9)\n            priorities[almost_empty] += almost_empty_bonus * (1 - item) # scale bonus with item size\n\n        # Bin Diversity Bonus: Encourages using bins with different fill levels\n        if num_bins > 1:  # Only apply when there is a choice\n            bin_std = np.std(bins_remain_cap)\n            if bin_std > 0.1:  # Diversity threshold, only apply if there is actual diversity\n                priorities[valid_bins] += 0.2  # Add same bonus to all potential bins to be fair\n\n    else:\n        priorities[:] = -100  # Discourage invalid placements\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response2.txt_stdout.txt",
    "code_path": "problem_iter20_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining fill ratio, best fit, and fragmentation.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n\n    # Adaptive item size factor\n    item_size_factor = min(1.0, item)\n\n    # 1. Fill Ratio Preference (Adaptive)\n    potential_bins = bins_remain_cap >= item\n    if np.any(potential_bins):\n        fill_ratios = item / bins_remain_cap[potential_bins]\n        priorities[potential_bins] += fill_ratios * (0.7 + 0.3 * item_size_factor)\n\n    # 2. Best Fit Encouragement (Adaptive)\n    capacity_diff = np.abs(bins_remain_cap - item)\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        min_diff = np.min(capacity_diff[eligible_bins])\n        best_fit_bins = capacity_diff == min_diff\n        # Adaptive best-fit weight based on remaining capacity\n        average_remaining = np.mean(bins_remain_cap) if num_bins > 0 else 0.0\n        best_fit_weight = 1.5 + 0.5 * item_size_factor * (1 - average_remaining)\n        priorities[best_fit_bins] += best_fit_weight\n\n    # 3. Fragmentation Penalty (Adaptive)\n    remaining_space = bins_remain_cap - item\n    # Adaptive threshold based on average remaining capacity\n    average_remaining = np.mean(bins_remain_cap) if num_bins > 0 else 0.0\n    fragmentation_threshold = item * (0.2 + 0.1 * item_size_factor) * (1 + average_remaining)\n\n    fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)\n    priorities[fragmented_bins] -= 1.0 + 0.2 * item_size_factor\n\n    # 4. Encourage re-use of almost empty bins (Adaptive)\n    almost_empty_threshold = 0.9\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        #Scale bonus by how many are almost empty, and item size\n        almost_empty_count = np.sum(bins_remain_cap > almost_empty_threshold)\n        bonus_scale = 0.5 / (1 + almost_empty_count)\n        priorities[almost_empty] += bonus_scale + 0.1 * item_size_factor\n\n    # 5. Discourage bins from being too empty after placing the item\n    too_empty_threshold = 0.75\n    too_empty = remaining_space > too_empty_threshold\n    if np.any(too_empty):\n        priorities[too_empty] -= 0.4 * item_size_factor\n\n    # 6. Global Bin Balancing: Add small penalty to encourage distribution\n    bin_utilization = (1.0 - bins_remain_cap) # Assuming bin size of 1\n    utilization_std = np.std(bin_utilization) if num_bins > 1 else 0 # If there's only one bin, std is 0\n    priorities -= 0.01 * utilization_std # Penalize bins with high stdev utilization\n\n    # 7. If no suitable bin, slightly discourage all bins\n    if not np.any(potential_bins):\n        priorities[:] -= 0.001\n\n    # 8. Large Item Tighter Fit Bonus\n    large_item_threshold = 0.7\n    if item > large_item_threshold and np.any(eligible_bins):\n      capacity_diff_eligible = capacity_diff[eligible_bins]\n      tight_fit_bins = (capacity_diff_eligible == np.min(capacity_diff_eligible)) & (bins_remain_cap[eligible_bins] - item < 0.1)\n      priorities[eligible_bins[tight_fit_bins]] += 0.5\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 67, in priority_v2\nIndexError: boolean index did not match indexed array along axis 0; size of axis is 5000 but size of corresponding boolean axis is 1\n"
  },
  {
    "stdout_filepath": "problem_iter20_response3.txt_stdout.txt",
    "code_path": "problem_iter20_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fill ratio, best fit, fragmentation penalty, and adaptive exploration based on global fill level.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    bin_size = 1.0\n\n    # 1. Fill Ratio Preference\n    potential_bins = bins_remain_cap >= item\n    if np.any(potential_bins):\n        fill_ratio = (bins_remain_cap[potential_bins] - item) / bin_size\n        priorities[potential_bins] += fill_ratio * 0.7  # Weighted fill ratio\n\n    # 2. Best Fit Encouragement\n    capacity_diff = np.abs(bins_remain_cap - item)\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        min_diff = np.min(capacity_diff[eligible_bins])\n        best_fit_bins = capacity_diff == min_diff\n        priorities[best_fit_bins] += 1.5 # best_fit_weight\n\n    # 3. Fragmentation Penalty (Adaptive)\n    remaining_space = bins_remain_cap - item\n    fragmentation_threshold = item * 0.2 # fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)\n    priorities[fragmented_bins] -= 1.3 # fragmentation_penalty\n\n    # 4. Adaptive Exploration\n    average_fill = np.mean((bin_size - bins_remain_cap) / bin_size) if num_bins > 0 else 0.0\n    exploration_probability = 0.05 * (1.0 - average_fill)  # Explore more when bins are empty\n    if np.random.rand() < exploration_probability:\n        exploration_bonus = (bin_size - bins_remain_cap) / bin_size\n        priorities += exploration_bonus * 0.2\n\n    # 5. High fill incentive\n    if np.any(potential_bins):\n        fill_percentage = item / (bin_size - bins_remain_cap[potential_bins])\n        high_fill_bins = (fill_percentage > 0.7) & (fill_percentage <= 1.0) # Limit the value of fill_percentage to 1\n\n        if np.any(high_fill_bins):\n            eligible_bins_index = np.where(potential_bins)[0][high_fill_bins]\n            priorities[eligible_bins_index] += 0.5\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 149.2919824491424,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response4.txt_stdout.txt",
    "code_path": "problem_iter20_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fill ratio, best fit, fragmentation, and exploration with adaptive weights.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    bin_size = 1.0\n\n    # Fill Ratio Preference\n    potential_bins = bins_remain_cap >= item\n    if np.any(potential_bins):\n        fill_ratio = (bins_remain_cap[potential_bins] - item) / bin_size\n        priorities[potential_bins] += fill_ratio\n\n    # Best Fit Encouragement (Adaptive Weight)\n    capacity_diff = np.abs(bins_remain_cap - item)\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        min_diff = np.min(capacity_diff[eligible_bins])\n        best_fit_bins = capacity_diff == min_diff\n        average_fill = np.mean((bin_size - bins_remain_cap) / bin_size) if num_bins > 0 else 0.0\n        best_fit_weight = 1.0 + (1.0 - average_fill)\n        priorities[best_fit_bins] += best_fit_weight\n\n    # Fragmentation Penalty (Adaptive)\n    remaining_space = bins_remain_cap - item\n    average_remaining = np.mean(bins_remain_cap) if num_bins > 0 else 0.0\n    fragmentation_threshold_multiplier = 0.2 * (1.0 - average_remaining / bin_size)\n    fragmentation_threshold = item * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)\n    fragmentation_penalty = 0.5 + (item / bin_size)\n    priorities[fragmented_bins] -= fragmentation_penalty\n    \n    # Exploration Bonus (Adaptive probability)\n    exploration_prob = 0.05 * (1 + average_fill)\n    if np.random.rand() < exploration_prob:\n        exploration_bonus = (bin_size - bins_remain_cap) / bin_size\n        priorities += exploration_bonus * 0.2\n    \n    # Fill percentage incentive\n    if np.any(potential_bins):\n        fill_percentage = item / (bin_size - bins_remain_cap[potential_bins])\n        high_fill_bins = (fill_percentage > 0.7) & (fill_percentage <= 1.0)\n\n        if np.any(high_fill_bins):\n            eligible_bins_index = np.where(potential_bins)[0][high_fill_bins]\n            priorities[eligible_bins_index] += 0.5\n\n    # Target fill bonus, adaptive target (from v1)\n    if np.any(potential_bins):\n        target_fill = 0.7 + 0.1 * average_fill\n        ideal_remaining = bin_size - target_fill\n        distance_to_ideal = np.abs((bins_remain_cap[potential_bins] - item) - ideal_remaining)\n        priorities[potential_bins] += np.exp(-distance_to_ideal * 6)\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.11846828879138,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response5.txt_stdout.txt",
    "code_path": "problem_iter20_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, fragmentation penalty, and global fill awareness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    potential_bins = bins_remain_cap >= item\n\n    # 1. Adaptive Fill Ratio Preference\n    if np.any(potential_bins):\n        fill_ratios = item / bins_remain_cap[potential_bins]\n        priorities[potential_bins] += fill_ratios * (0.7 + 0.3 * (1 - np.mean(bins_remain_cap))) # Adapt based on avg cap\n\n    # 2. Stronger Best Fit Encouragement\n    capacity_diff = np.abs(bins_remain_cap - item)\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        min_diff = np.min(capacity_diff[eligible_bins])\n        best_fit_bins = capacity_diff == min_diff\n        priorities[best_fit_bins] += 1.5 # Boost best fit\n\n    # 3. Adaptive Fragmentation Penalty\n    remaining_space = bins_remain_cap - item\n    fragmentation_threshold = item * (0.1 + 0.03 * np.mean(bins_remain_cap)) # Adaptive threshold\n    fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)\n    priorities[fragmented_bins] -= 1.0 #Penalize fragmented bins\n\n    # 4. Almost Empty Bonus\n    almost_empty_threshold = 0.9\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        priorities[almost_empty] += 0.3 # Reuse almost empty bin\n\n    # 5. Global Fill Level Encouragement\n    global_fill_level = np.sum(1 - bins_remain_cap) / num_bins # Global fill estimation\n    if global_fill_level > 0.6: # High fill level encouragement\n        exploration_bonus = 0.1 * bins_remain_cap # Linear bonus based on capacity\n        priorities += exploration_bonus\n\n    # 6. Discourage near empty for the first few items.\n    if global_fill_level < 0.1:\n        near_empty_threshold = 0.95\n        near_empty = bins_remain_cap > near_empty_threshold\n        if np.any(near_empty):\n            priorities[near_empty] -= 0.2 # Reduce near-empty bin priority.\n            \n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 149.22217790187474,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response6.txt_stdout.txt",
    "code_path": "problem_iter20_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, and fragmentation penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    bin_size = 1.0  # Assuming bin size is normalized to 1\n\n    # --- Parameters (Tunable) ---\n    best_fit_weight = 1.5\n    fragmentation_threshold_multiplier = 0.2\n    fragmentation_penalty = 1.3\n    almost_empty_threshold = 0.95\n    almost_empty_bonus = 0.8\n    fill_ratio_weight = 0.7\n    underutilization_threshold = 0.1\n    underutilization_penalty = 0.6\n\n    # --- 1. Fill Ratio Preference (Weighted) ---\n    potential_bins = bins_remain_cap >= item\n    if np.any(potential_bins):\n        fill_ratios = (bin_size - (bins_remain_cap[potential_bins] - item)) / bin_size\n        priorities[potential_bins] += fill_ratios * fill_ratio_weight\n\n    # --- 2. Best Fit Encouragement ---\n    capacity_diff = np.abs(bins_remain_cap - item)\n    eligible_bins = bins_remain_cap >= item\n    if np.any(eligible_bins):\n        min_diff = np.min(capacity_diff[eligible_bins])\n        best_fit_bins = capacity_diff == min_diff\n        priorities[best_fit_bins] += best_fit_weight\n\n    # --- 3. Fragmentation Penalty (Adaptive) ---\n    remaining_space = bins_remain_cap - item\n    fragmentation_threshold = item * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty\n\n    # --- 4. Encourage re-use of almost empty bins ---\n    almost_empty = bins_remain_cap >= (bin_size * almost_empty_threshold)\n    if np.any(almost_empty):\n        priorities[almost_empty] += almost_empty_bonus\n\n    # --- 5. Underutilization Penalty: Penalize creating almost empty bins with small items\n    new_remaining_space = bins_remain_cap - item\n    underutilized_bins = (new_remaining_space > 0) & (new_remaining_space / bin_size > (1 - underutilization_threshold)) & (item < (bin_size * 0.5))\n    priorities[underutilized_bins] -= underutilization_penalty\n\n    # --- Adaptive Exploration ---\n    exploration_factor = 0.01 * item # scale with item size\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response7.txt_stdout.txt",
    "code_path": "problem_iter20_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining fill ratio, best fit, and bin diversity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        # Fill Ratio with item size influence\n        fill_ratio = item / bins_remain_cap[valid_bins]\n        priorities[valid_bins] += fill_ratio * 0.6\n\n        # Best Fit with non-linear encouragement\n        remaining_space = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] += np.exp(-4 * remaining_space) * 0.9\n\n        # Bin Diversity Bonus\n        if len(bins_remain_cap) > 1:\n            bin_std = np.std(bins_remain_cap)\n            if bin_std > 0.1:\n                priorities[valid_bins] += 0.2\n\n        # Large item encouragement\n        if item > 0.7:\n             min_remaining = np.min(bins_remain_cap[valid_bins]-item)\n             tight_fit = (bins_remain_cap[valid_bins] - item) == min_remaining\n             priorities[valid_bins][tight_fit] += 0.5\n\n    else:\n        priorities[:] = -0.001\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response8.txt_stdout.txt",
    "code_path": "problem_iter20_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines fill ratio, best fit, fragmentation penalty, reuse, exploration, adaptivity based on bin utilization and item size.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    bin_size = 1.0  # Assuming bin size is 1 for normalization\n\n    # Adaptive Weights - based on item size and global fill level\n    item_size_factor = min(1.0, item)\n    bin_availability_factor = min(1.0, np.sum(bins_remain_cap >= item) / num_bins)\n    average_fill = np.mean(1 - bins_remain_cap)\n\n    fill_ratio_weight = 0.5 + 0.3 * item_size_factor\n    best_fit_weight = 1.5 + 0.5 * bin_availability_factor\n    fragmentation_penalty_weight = 1.0 + 0.2 * item_size_factor\n    reuse_weight = 0.6 + 0.4 * bin_availability_factor\n\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + 0.0001)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-2 * remaining_space) #Best fit bonus\n\n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold_multiplier = 0.2 / np.sqrt(num_bins)\n    fragmentation_threshold = item * (0.1 + 0.1 * item_size_factor) * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill)\n\n    # Almost empty reuse\n    almost_empty_threshold = 0.95 - (0.1 * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = 0.5 + average_fill * 0.5\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus #almost empty reuse bonus.\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-0.2))\n    priorities[too_full_bins] -= 0.8\n\n    # Exploration: Add a small amount of randomness, scaled to the item size.\n    exploration_factor = 0.01 * item  # Scale randomness based on the item size\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    # Underutilization Penalty: Penalize creating almost empty bins with small items\n    new_remaining_space = bins_remain_cap - item\n    underutilization_threshold = 0.1 # Penalty for bins with low utilization after placement\n    underutilization_penalty = 0.6\n    underutilized_bins = (new_remaining_space > 0) & (new_remaining_space / bin_size > (1 - underutilization_threshold)) & (item < (bin_size * 0.5)) #Only penalize if item is small\n    priorities[underutilized_bins] -= underutilization_penalty\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 3.6298364579178393,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response9.txt_stdout.txt",
    "code_path": "problem_iter20_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best fit, fill ratio, adaptive fragmentation, bin utilization and adaptive exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    bin_size = 1.0\n    num_bins = len(bins_remain_cap)\n\n    # Fill Ratio Preference\n    potential_bins = bins_remain_cap >= item\n    if np.any(potential_bins):\n        fill_ratio = (bins_remain_cap[potential_bins] - item) / bin_size\n        priorities[potential_bins] += 0.7 * fill_ratio\n\n    # Best Fit Encouragement (Adaptive Weight)\n    capacity_diff = np.abs(bins_remain_cap - item)\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        min_diff = np.min(capacity_diff[eligible_bins])\n        best_fit_bins = capacity_diff == min_diff\n        average_fill = np.mean((bin_size - bins_remain_cap) / bin_size) if num_bins > 0 else 0.0\n        best_fit_weight = 1.5 + (1.0 - average_fill)  # Increase best-fit weight\n        priorities[best_fit_bins] += best_fit_weight\n\n    # Fragmentation Penalty (Adaptive)\n    remaining_space = bins_remain_cap - item\n    average_remaining = np.mean(bins_remain_cap) if num_bins > 0 else 0.0\n    fragmentation_threshold_multiplier = 0.2 * (1.0 - average_remaining / bin_size)\n    fragmentation_threshold = item * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space > 0) & (remaining_space <= fragmentation_threshold)\n    fragmentation_penalty = 1.3 + (item / bin_size)\n    priorities[fragmented_bins] -= fragmentation_penalty\n\n    # Encourage re-use of almost empty bins\n    almost_empty_threshold = 0.95\n    almost_empty = bins_remain_cap > (bin_size - almost_empty_threshold)\n    if np.any(almost_empty):\n        priorities[almost_empty] += 0.8  # Consistent bonus\n\n    # Bin Utilization Bonus\n    utilization = (bin_size - bins_remain_cap) / bin_size\n    fully_utilized_threshold = 0.8  # Tune this\n    highly_utilized = utilization > fully_utilized_threshold\n    utilization_bonus = 0.5\n    priorities[highly_utilized] += utilization_bonus\n\n    # Adaptive Exploration Bonus (State-Aware)\n    exploration_rate = 0.05 * (1.0 - average_fill) #Exploration rate decreases with fill level\n\n    if np.random.rand() < exploration_rate:\n        exploration_bonus = (bin_size - bins_remain_cap) / bin_size\n        priorities += exploration_bonus * 0.2\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response0.txt_stdout.txt",
    "code_path": "problem_iter21_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                fill_ratio_weight_base: float = 0.07001911716215126,\n                fill_ratio_weight_item_factor: float = 0.09674577434453879,\n                best_fit_weight_base: float = 2.805747453408391,\n                best_fit_weight_availability_factor: float = 0.6848823870770047,\n                fragmentation_penalty_weight_base: float = 1.4678366072617053,\n                fragmentation_penalty_weight_item_factor: float = 0.8155589797225978,\n                reuse_weight_base: float = 0.7877195059531279,\n                reuse_weight_availability_factor: float = 0.5099151918111539,\n                best_fit_decay_rate: float = 2.7252501697954994,\n                fragmentation_threshold_base: float = 0.45443676724460597,\n                fragmentation_threshold_item_factor: float = 0.03685272815567264,\n                almost_empty_threshold_base: float = 0.9265092958240733,\n                almost_empty_threshold_average_fill_factor: float = 0.2006311693648083,\n                almost_empty_bonus_base: float = 0.09108242175329895,\n                almost_empty_bonus_average_fill_factor: float = 0.5721102621832862,\n                too_full_threshold: float = 0.4199500766768644,\n                too_full_penalty: float = 0.0826040342356067,\n                exploration_factor_scale: float = 0.02587384524922878,\n                min_item_size_factor: float = 0.7483057590114014,\n                min_bin_availability_factor: float = 1.2697180594558546,\n                division_epsilon: float = 0.0008721588230938938,\n                bin_size: float = 1.0) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration.\n    v2: State-aware with dynamic exploration and bin balancing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    \n    # Global State\n    average_fill = np.mean(1 - bins_remain_cap / bin_size)\n    num_almost_full = np.sum(bins_remain_cap / bin_size < 0.2)  # Example metric\n\n    # Adaptive Weights - based on item size and global fill level\n    item_size_factor = min(min_item_size_factor, item / bin_size)\n    bin_availability_factor = min(min_bin_availability_factor, np.sum(bins_remain_cap >= item) / num_bins)\n\n    fill_ratio_weight = fill_ratio_weight_base + fill_ratio_weight_item_factor * item_size_factor\n    best_fit_weight = best_fit_weight_base + best_fit_weight_availability_factor * bin_availability_factor\n    fragmentation_penalty_weight = fragmentation_penalty_weight_base + fragmentation_penalty_weight_item_factor * item_size_factor\n    reuse_weight = reuse_weight_base + reuse_weight_availability_factor * bin_availability_factor\n    \n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + division_epsilon)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-best_fit_decay_rate * remaining_space) #Best fit bonus\n\n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold_multiplier = 0.2 / np.sqrt(num_bins)\n    fragmentation_threshold = item * (fragmentation_threshold_base + fragmentation_threshold_item_factor * item_size_factor) * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill)\n\n     # Almost empty reuse\n    almost_empty_threshold = almost_empty_threshold_base - (almost_empty_threshold_average_fill_factor * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = almost_empty_bonus_base + average_fill * almost_empty_bonus_average_fill_factor\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus #almost empty reuse bonus.\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-too_full_threshold))\n    priorities[too_full_bins] -= too_full_penalty\n    \n    # Dynamic Exploration: Reduce exploration if bins are highly unbalanced\n    exploration_factor = exploration_factor_scale * item * (1 - (num_almost_full / num_bins))\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n    \n    #Bin Balancing: Incentive to use less filled bins when average fill is high.\n    if average_fill > 0.7:\n        priorities += (1 - bins_remain_cap / bin_size) * (average_fill - 0.7) * 0.5 # Incentive to use less filled bins.\n        \n    #Heuristic to promote bin re-use:\n    non_empty_bins = bins_remain_cap < bin_size\n    priorities[non_empty_bins] += reuse_weight_base * 0.1\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 2.293577981651376,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response1.txt_stdout.txt",
    "code_path": "problem_iter21_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                fill_ratio_weight_base: float = 0.07001911716215126,\n                fill_ratio_weight_item_factor: float = 0.09674577434453879,\n                best_fit_weight_base: float = 2.805747453408391,\n                best_fit_weight_availability_factor: float = 0.6848823870770047,\n                fragmentation_penalty_weight_base: float = 1.4678366072617053,\n                fragmentation_penalty_weight_item_factor: float = 0.8155589797225978,\n                reuse_weight_base: float = 0.7877195059531279,\n                reuse_weight_availability_factor: float = 0.5099151918111539,\n                best_fit_decay_rate: float = 2.7252501697954994,\n                fragmentation_threshold_base: float = 0.45443676724460597,\n                fragmentation_threshold_item_factor: float = 0.03685272815567264,\n                almost_empty_threshold_base: float = 0.9265092958240733,\n                almost_empty_threshold_average_fill_factor: float = 0.2006311693648083,\n                almost_empty_bonus_base: float = 0.09108242175329895,\n                almost_empty_bonus_average_fill_factor: float = 0.5721102621832862,\n                too_full_threshold: float = 0.4199500766768644,\n                too_full_penalty: float = 0.0826040342356067,\n                exploration_factor_scale: float = 0.02587384524922878,\n                min_item_size_factor: float = 0.7483057590114014,\n                min_bin_availability_factor: float = 1.2697180594558546,\n                division_epsilon: float = 0.0008721588230938938,\n                global_bin_utilization_threshold: float = 0.7,\n                high_utilization_fill_ratio_penalty: float = 0.15,\n                small_item_threshold: float = 0.2,\n                large_item_threshold: float = 0.8,\n                small_item_best_fit_boost: float = 0.1,\n                large_item_fragmentation_penalty_multiplier: float = 2.0) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration with state-aware adjustments.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    \n    # Global State Awareness\n    average_fill = np.mean(1 - bins_remain_cap)\n    global_bin_utilization = 1 - np.mean(bins_remain_cap)\n\n    # Adaptive Weights - based on item size and global fill level\n    item_size_factor = min(min_item_size_factor, item)\n    bin_availability_factor = min(min_bin_availability_factor, np.sum(bins_remain_cap >= item) / num_bins)\n\n    fill_ratio_weight = fill_ratio_weight_base + fill_ratio_weight_item_factor * item_size_factor\n    best_fit_weight = best_fit_weight_base + best_fit_weight_availability_factor * bin_availability_factor\n    fragmentation_penalty_weight = fragmentation_penalty_weight_base + fragmentation_penalty_weight_item_factor * item_size_factor\n    reuse_weight = reuse_weight_base + reuse_weight_availability_factor * bin_availability_factor\n    \n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + division_epsilon)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        best_fit_priority = np.exp(-best_fit_decay_rate * remaining_space)\n        priorities[eligible_bins] += best_fit_weight * best_fit_priority\n\n        # Small Item Best Fit Boost: Encourage packing small items into tightest spots\n        if item < small_item_threshold:\n            priorities[eligible_bins] += small_item_best_fit_boost * (1 - remaining_space / (bins_remain_cap[eligible_bins]+division_epsilon))\n\n    # Fragmentation Penalty - Dynamic threshold & Item Size Aware\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold_multiplier = 0.2 / np.sqrt(num_bins)\n    fragmentation_threshold = item * (fragmentation_threshold_base + fragmentation_threshold_item_factor * item_size_factor) * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n\n    fragmentation_penalty = fragmentation_penalty_weight * (1-average_fill)\n     # Large item penalty\n    if item > large_item_threshold:\n        fragmentation_penalty *= large_item_fragmentation_penalty_multiplier\n\n    priorities[fragmented_bins] -= fragmentation_penalty\n\n    # Almost empty reuse\n    almost_empty_threshold = almost_empty_threshold_base - (almost_empty_threshold_average_fill_factor * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = almost_empty_bonus_base + average_fill * almost_empty_bonus_average_fill_factor\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus #almost empty reuse bonus.\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-too_full_threshold))\n    priorities[too_full_bins] -= too_full_penalty\n\n    # Global Bin Utilization Penalty: Discourage filling bins when global utilization is high\n    if global_bin_utilization > global_bin_utilization_threshold:\n        priorities[eligible_bins] -= high_utilization_fill_ratio_penalty * fill_ratio[eligible_bins - np.where(~eligible_bins)[0].min()] if eligible_bins.sum() > 0 else 0\n\n    # Exploration: Add a small amount of randomness, scaled to the item size.\n    exploration_factor = exploration_factor_scale * item  # Scale randomness based on the item size\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 2.153968887116089,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response2.txt_stdout.txt",
    "code_path": "problem_iter21_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration, and global awareness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    total_bin_capacity = num_bins  # Assuming each bin has capacity 1\n    total_items_packed = total_bin_capacity - np.sum(bins_remain_cap)\n    average_fill = total_items_packed / total_bin_capacity if total_bin_capacity > 0 else 0.0\n    \n    # Adaptive Weights - based on item size, bin availability and global fill level\n    item_size_factor = min(0.75, item)  # Capped item size factor\n    bin_availability_factor = min(1.27, np.sum(bins_remain_cap >= item) / num_bins)\n    \n    # Dynamic weight adjustments based on global fill\n    fill_ratio_weight = 0.07 + 0.10 * item_size_factor * (1 + average_fill)\n    best_fit_weight = 2.81 + 0.68 * bin_availability_factor * (1 - average_fill)\n    fragmentation_penalty_weight = 1.47 + 0.82 * item_size_factor * (1 + average_fill)\n    reuse_weight = 0.79 + 0.51 * bin_availability_factor * (1 - average_fill)\n\n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + 1e-6)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-2.73 * remaining_space)\n\n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold = item * (0.45 + 0.04 * item_size_factor) * (0.2 / np.sqrt(num_bins))\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill)**2 # Squared penalty\n\n    # Almost empty reuse\n    almost_empty_threshold = 0.93 - (0.20 * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = 0.09 + average_fill * 0.57\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-0.42))\n    priorities[too_full_bins] -= 0.08\n\n    # Global Bin Balancing: Encourage filling emptier bins when average fill is high\n    if average_fill > 0.7:\n        empty_bin_bonus = (1-average_fill) * bins_remain_cap\n        priorities += 0.1*empty_bin_bonus # Bonus for packing into more empty bins\n\n    # Exploration: Adaptive exploration based on global fill level\n    exploration_factor = 0.026 * item * (1-average_fill) # Reduced exploration as bins fill up\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 85.77981651376147,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response3.txt_stdout.txt",
    "code_path": "problem_iter21_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                fill_ratio_weight_base: float = 0.07001911716215126,\n                fill_ratio_weight_item_factor: float = 0.09674577434453879,\n                best_fit_weight_base: float = 2.805747453408391,\n                best_fit_weight_availability_factor: float = 0.6848823870770047,\n                fragmentation_penalty_weight_base: float = 1.4678366072617053,\n                fragmentation_penalty_weight_item_factor: float = 0.8155589797225978,\n                reuse_weight_base: float = 0.7877195059531279,\n                reuse_weight_availability_factor: float = 0.5099151918111539,\n                best_fit_decay_rate: float = 2.7252501697954994,\n                fragmentation_threshold_base: float = 0.45443676724460597,\n                fragmentation_threshold_item_factor: float = 0.03685272815567264,\n                almost_empty_threshold_base: float = 0.9265092958240733,\n                almost_empty_threshold_average_fill_factor: float = 0.2006311693648083,\n                almost_empty_bonus_base: float = 0.09108242175329895,\n                almost_empty_bonus_average_fill_factor: float = 0.5721102621832862,\n                too_full_threshold: float = 0.4199500766768644,\n                too_full_penalty: float = 0.0826040342356067,\n                exploration_factor_scale: float = 0.02587384524922878,\n                min_item_size_factor: float = 0.7483057590114014,\n                min_bin_availability_factor: float = 1.2697180594558546,\n                division_epsilon: float = 0.0008721588230938938) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    \n    # Adaptive Weights - based on item size and global fill level\n    item_size_factor = min(min_item_size_factor, item)\n    bin_availability_factor = min(min_bin_availability_factor, np.sum(bins_remain_cap >= item) / num_bins)\n    average_fill = np.mean(1 - bins_remain_cap)\n    std_fill = np.std(1 - bins_remain_cap)\n\n    fill_ratio_weight = fill_ratio_weight_base + fill_ratio_weight_item_factor * item_size_factor\n    best_fit_weight = best_fit_weight_base + best_fit_weight_availability_factor * bin_availability_factor\n    fragmentation_penalty_weight = fragmentation_penalty_weight_base + fragmentation_penalty_weight_item_factor * item_size_factor\n    reuse_weight = reuse_weight_base + reuse_weight_availability_factor * bin_availability_factor\n    \n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + division_epsilon)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-best_fit_decay_rate * remaining_space) #Best fit bonus\n\n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold_multiplier = 0.2 / np.sqrt(num_bins)\n    fragmentation_threshold = item * (fragmentation_threshold_base + fragmentation_threshold_item_factor * item_size_factor) * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill)\n\n     # Almost empty reuse\n    almost_empty_threshold = almost_empty_threshold_base - (almost_empty_threshold_average_fill_factor * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = almost_empty_bonus_base + average_fill * almost_empty_bonus_average_fill_factor\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus #almost empty reuse bonus.\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-too_full_threshold))\n    priorities[too_full_bins] -= too_full_penalty\n\n    # State-Aware Exploration: Dynamically adjust exploration based on fill level variance.\n    # Higher variance indicates potential imbalance, warranting more exploration.\n    exploration_factor = exploration_factor_scale * item * (1 + std_fill)\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    # Encourage evening out the fill levels\n    fill_level_penalty = (1 - bins_remain_cap - average_fill) * std_fill * 0.1\n    priorities -= fill_level_penalty\n\n    # Prioritize bins with a remaining capacity closest to the average.\n    avg_remaining = np.mean(bins_remain_cap)\n    closeness_to_average = np.abs(bins_remain_cap - avg_remaining)\n    priorities -= closeness_to_average * 0.05 # Smaller values are better (more priority)\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 149.0426804946151,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response4.txt_stdout.txt",
    "code_path": "problem_iter21_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                fill_ratio_weight_base: float = 0.07001911716215126,\n                fill_ratio_weight_item_factor: float = 0.09674577434453879,\n                best_fit_weight_base: float = 2.805747453408391,\n                best_fit_weight_availability_factor: float = 0.6848823870770047,\n                fragmentation_penalty_weight_base: float = 1.4678366072617053,\n                fragmentation_penalty_weight_item_factor: float = 0.8155589797225978,\n                reuse_weight_base: float = 0.7877195059531279,\n                reuse_weight_availability_factor: float = 0.5099151918111539,\n                best_fit_decay_rate: float = 2.7252501697954994,\n                fragmentation_threshold_base: float = 0.45443676724460597,\n                fragmentation_threshold_item_factor: float = 0.03685272815567264,\n                almost_empty_threshold_base: float = 0.9265092958240733,\n                almost_empty_threshold_average_fill_factor: float = 0.2006311693648083,\n                almost_empty_bonus_base: float = 0.09108242175329895,\n                almost_empty_bonus_average_fill_factor: float = 0.5721102621832862,\n                too_full_threshold: float = 0.4199500766768644,\n                too_full_penalty: float = 0.0826040342356067,\n                exploration_factor_scale: float = 0.02587384524922878,\n                min_item_size_factor: float = 0.7483057590114014,\n                min_bin_availability_factor: float = 1.2697180594558546,\n                division_epsilon: float = 0.0008721588230938938,\n                bin_size: float = 1.0) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    \n    # Adaptive Weights - based on item size and global fill level\n    item_size_factor = min(min_item_size_factor, item)\n    bin_availability_factor = min(min_bin_availability_factor, np.sum(bins_remain_cap >= item) / num_bins)\n    average_fill = np.mean(1 - bins_remain_cap / bin_size)\n\n    fill_ratio_weight = fill_ratio_weight_base + fill_ratio_weight_item_factor * item_size_factor\n    best_fit_weight = best_fit_weight_base + best_fit_weight_availability_factor * bin_availability_factor\n    fragmentation_penalty_weight = fragmentation_penalty_weight_base + fragmentation_penalty_weight_item_factor * item_size_factor\n    reuse_weight = reuse_weight_base + reuse_weight_availability_factor * bin_availability_factor\n    \n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + division_epsilon)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-best_fit_decay_rate * remaining_space) #Best fit bonus\n    \n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold_multiplier = 0.2 / np.sqrt(num_bins)\n    fragmentation_threshold = item * (fragmentation_threshold_base + fragmentation_threshold_item_factor * item_size_factor) * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    \n    # Scale the penalty based on how full the bin is.  More full, higher penalty\n    fragmentation_penalty_scaling = (bin_size - bins_remain_cap[fragmented_bins]) / bin_size\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill) * fragmentation_penalty_scaling\n\n     # Almost empty reuse\n    almost_empty_threshold = almost_empty_threshold_base - (almost_empty_threshold_average_fill_factor * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = almost_empty_bonus_base + average_fill * almost_empty_bonus_average_fill_factor\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus #almost empty reuse bonus.\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-too_full_threshold))\n    priorities[too_full_bins] -= too_full_penalty\n\n    # Exploration: Add a small amount of randomness, scaled to the item size.\n    exploration_factor = exploration_factor_scale * item  # Scale randomness based on the item size\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    # Encourage evening out bin utilization\n    bin_utilization = 1 - bins_remain_cap / bin_size\n    utilization_std = np.std(bin_utilization)\n    priorities += (1 - utilization_std) * 0.1 # Give a small bonus to solutions with similar utilizations\n\n    return priorities",
    "response_id": 4,
    "tryHS": true,
    "obj": 2.1041084962106127,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter22_hs3.txt_stdout.txt",
    "code_path": "problem_iter22_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                fill_ratio_weight_base: float = 0.08298567341766837,\n                fill_ratio_weight_item_factor: float = 0.1918000656729426,\n                best_fit_weight_base: float = 4.786399897470084,\n                best_fit_weight_availability_factor: float = 0.8846166548355004,\n                fragmentation_penalty_weight_base: float = 2.284981010263942,\n                fragmentation_penalty_weight_item_factor: float = 0.7773265039534436,\n                reuse_weight_base: float = 1.6306355193348756,\n                reuse_weight_availability_factor: float = 0.17851856923235693,\n                best_fit_decay_rate: float = 2.2088471578138376,\n                fragmentation_threshold_base: float = 0.6258282417693154,\n                fragmentation_threshold_item_factor: float = 0.00022205528141430177,\n                almost_empty_threshold_base: float = 1.034728592594321,\n                almost_empty_threshold_average_fill_factor: float = 0.9076513753139951,\n                almost_empty_bonus_base: float = 0.33747365128330953,\n                almost_empty_bonus_average_fill_factor: float = 0.6816988338625264,\n                too_full_threshold: float = 0.6644324513202721,\n                too_full_penalty: float = 0.30019191052353134,\n                exploration_factor_scale: float = 0.04764328369868246,\n                min_item_size_factor: float = 0.3818846450044734,\n                min_bin_availability_factor: float = 0.2657999802336206,\n                division_epsilon: float = 0.0008592151247375378,\n                bin_size: float = 1.06991901400127,\n                fragmentation_threshold_multiplier: float = 0.30173114495122316,\n                utilization_bonus: float = 0.4342909331786264) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    \n    # Adaptive Weights - based on item size and global fill level\n    item_size_factor = min(min_item_size_factor, item)\n    bin_availability_factor = min(min_bin_availability_factor, np.sum(bins_remain_cap >= item) / num_bins)\n    average_fill = np.mean(1 - bins_remain_cap / bin_size)\n\n    fill_ratio_weight = fill_ratio_weight_base + fill_ratio_weight_item_factor * item_size_factor\n    best_fit_weight = best_fit_weight_base + best_fit_weight_availability_factor * bin_availability_factor\n    fragmentation_penalty_weight = fragmentation_penalty_weight_base + fragmentation_penalty_weight_item_factor * item_size_factor\n    reuse_weight = reuse_weight_base + reuse_weight_availability_factor * bin_availability_factor\n    \n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + division_epsilon)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-best_fit_decay_rate * remaining_space) #Best fit bonus\n    \n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold = item * (fragmentation_threshold_base + fragmentation_threshold_item_factor * item_size_factor) * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    \n    # Scale the penalty based on how full the bin is.  More full, higher penalty\n    fragmentation_penalty_scaling = (bin_size - bins_remain_cap[fragmented_bins]) / bin_size\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill) * fragmentation_penalty_scaling\n\n     # Almost empty reuse\n    almost_empty_threshold = almost_empty_threshold_base - (almost_empty_threshold_average_fill_factor * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = almost_empty_bonus_base + average_fill * almost_empty_bonus_average_fill_factor\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus #almost empty reuse bonus.\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-too_full_threshold))\n    priorities[too_full_bins] -= too_full_penalty\n\n    # Exploration: Add a small amount of randomness, scaled to the item size.\n    exploration_factor = exploration_factor_scale * item  # Scale randomness based on the item size\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    # Encourage evening out bin utilization\n    bin_utilization = 1 - bins_remain_cap / bin_size\n    utilization_std = np.std(bin_utilization)\n    priorities += (1 - utilization_std) * utilization_bonus # Give a small bonus to solutions with similar utilizations\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.88631830873554,
    "exec_success": true
  }
]