{"system": "You are an expert in code review. Your task extract all threshold, weight or hardcode variable of the function make it become default parameters.", "user": "[code]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                fill_ratio_weight_base: float = 0.07001911716215126,\n                fill_ratio_weight_item_factor: float = 0.09674577434453879,\n                best_fit_weight_base: float = 2.805747453408391,\n                best_fit_weight_availability_factor: float = 0.6848823870770047,\n                fragmentation_penalty_weight_base: float = 1.4678366072617053,\n                fragmentation_penalty_weight_item_factor: float = 0.8155589797225978,\n                reuse_weight_base: float = 0.7877195059531279,\n                reuse_weight_availability_factor: float = 0.5099151918111539,\n                best_fit_decay_rate: float = 2.7252501697954994,\n                fragmentation_threshold_base: float = 0.45443676724460597,\n                fragmentation_threshold_item_factor: float = 0.03685272815567264,\n                almost_empty_threshold_base: float = 0.9265092958240733,\n                almost_empty_threshold_average_fill_factor: float = 0.2006311693648083,\n                almost_empty_bonus_base: float = 0.09108242175329895,\n                almost_empty_bonus_average_fill_factor: float = 0.5721102621832862,\n                too_full_threshold: float = 0.4199500766768644,\n                too_full_penalty: float = 0.0826040342356067,\n                exploration_factor_scale: float = 0.02587384524922878,\n                min_item_size_factor: float = 0.7483057590114014,\n                min_bin_availability_factor: float = 1.2697180594558546,\n                division_epsilon: float = 0.0008721588230938938,\n                bin_size: float = 1.0) -> np.ndarray:\n    \"\"\"Combines adaptive fill ratio, best fit, frag. penalty & reuse, exploration\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    num_bins = len(bins_remain_cap)\n    \n    # Adaptive Weights - based on item size and global fill level\n    item_size_factor = min(min_item_size_factor, item)\n    bin_availability_factor = min(min_bin_availability_factor, np.sum(bins_remain_cap >= item) / num_bins)\n    average_fill = np.mean(1 - bins_remain_cap / bin_size)\n\n    fill_ratio_weight = fill_ratio_weight_base + fill_ratio_weight_item_factor * item_size_factor\n    best_fit_weight = best_fit_weight_base + best_fit_weight_availability_factor * bin_availability_factor\n    fragmentation_penalty_weight = fragmentation_penalty_weight_base + fragmentation_penalty_weight_item_factor * item_size_factor\n    reuse_weight = reuse_weight_base + reuse_weight_availability_factor * bin_availability_factor\n    \n    eligible_bins = bins_remain_cap >= item\n\n    if np.any(eligible_bins):\n        # Fill Ratio - Adaptive\n        fill_ratio = item / (bins_remain_cap[eligible_bins] + division_epsilon)  # Avoid division by zero\n        priorities[eligible_bins] += fill_ratio_weight * fill_ratio\n\n        # Best Fit - Exponential decay\n        remaining_space = bins_remain_cap[eligible_bins] - item\n        priorities[eligible_bins] += best_fit_weight * np.exp(-best_fit_decay_rate * remaining_space) #Best fit bonus\n    \n    # Fragmentation Penalty - Dynamic threshold\n    remaining_space_all = bins_remain_cap - item\n    fragmentation_threshold_multiplier = 0.2 / np.sqrt(num_bins)\n    fragmentation_threshold = item * (fragmentation_threshold_base + fragmentation_threshold_item_factor * item_size_factor) * fragmentation_threshold_multiplier\n    fragmented_bins = (remaining_space_all > 0) & (remaining_space_all <= fragmentation_threshold)\n    \n    # Scale the penalty based on how full the bin is.  More full, higher penalty\n    fragmentation_penalty_scaling = (bin_size - bins_remain_cap[fragmented_bins]) / bin_size\n    priorities[fragmented_bins] -= fragmentation_penalty_weight * (1-average_fill) * fragmentation_penalty_scaling\n\n     # Almost empty reuse\n    almost_empty_threshold = almost_empty_threshold_base - (almost_empty_threshold_average_fill_factor * average_fill)\n    almost_empty = bins_remain_cap > almost_empty_threshold\n    if np.any(almost_empty):\n        almost_empty_bonus = almost_empty_bonus_base + average_fill * almost_empty_bonus_average_fill_factor\n        priorities[almost_empty] += reuse_weight * almost_empty_bonus #almost empty reuse bonus.\n\n    # Penalize bins that are close to full but can't fit the item\n    too_full_bins = (bins_remain_cap < item) & (bins_remain_cap > (item-too_full_threshold))\n    priorities[too_full_bins] -= too_full_penalty\n\n    # Exploration: Add a small amount of randomness, scaled to the item size.\n    exploration_factor = exploration_factor_scale * item  # Scale randomness based on the item size\n    priorities += np.random.uniform(-exploration_factor, exploration_factor, size=num_bins)\n\n    # Encourage evening out bin utilization\n    bin_utilization = 1 - bins_remain_cap / bin_size\n    utilization_std = np.std(bin_utilization)\n    priorities += (1 - utilization_std) * 0.1 # Give a small bonus to solutions with similar utilizations\n\n    return priorities\n\nNow extract all threshold, weight or hardcode variable of the function make it become default parameters and give me a 'parameter_ranges' dictionary representation. Key of dict is name of variable. Value of key is a tuple in Python MUST include 2 float elements, first element is begin value, second element is end value corresponding with parameter.\n\n- Output code only and enclose your code with Python code block: ```python ... ```.\n- Output 'parameter_ranges' dictionary only and enclose your code with other Python code block: ```python ... ```."}