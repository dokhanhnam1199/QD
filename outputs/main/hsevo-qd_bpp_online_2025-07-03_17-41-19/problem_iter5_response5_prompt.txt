{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function considers multiple factors, with refined weighting and scaling:\n    1. Waste: Prioritizes bins where the item fits relatively well, minimizing wasted space.  Uses a more sensitive exponential decay.\n    2. Fill Level: Encourages filling bins as much as possible, but penalizes overfilling. Uses a sigmoid function for smoother behavior.\n    3. Bin Utilization: Directly rewards bins that have been used to some extent, encouraging balanced usage.\n    4. Stability: Favors bins that are closest to the item size, scaled by the item size itself.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9  # Small value to avoid division by zero and log of zero\n\n    # Waste: Prioritize bins where the item fits relatively well.\n    waste = bins_remain_cap - item\n    waste_penalty = np.where(waste >= 0, np.exp(-10 * waste / item), -np.inf)  # More sensitive exponential decay, scaled by item size. Harsh penalty for overfill.\n    priorities += waste_penalty\n\n    # Fill Level: Encourage filling bins, but not too much.  Sigmoid function\n    fill_ratio = item / (bins_remain_cap + epsilon)\n    fill_reward = 1 / (1 + np.exp(5 - 10 * fill_ratio)) # Sigmoid centered around fill_ratio = 0.5\n    priorities += fill_reward\n\n    # Bin Utilization: Reward bins that have some items in them already\n    utilization = (1 - bins_remain_cap) # Previously available capacity\n    utilization_reward = np.where(utilization > 0, np.tanh(utilization), 0) #tanh squashes the values and 0 if it is new bin.\n    priorities += 0.5 * utilization_reward\n\n    # Stability (Closeness to Item Size): Scaled by item size\n    stability = -np.abs(bins_remain_cap - item) / (item + epsilon)\n    priorities += 0.25 * stability\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the first heuristic considers both waste minimization and fill level, while the last only considers a ratio.  (2nd best) vs (second worst) shows that more complex functions like exponential decay, sigmoid, tanh, and absolute difference are used for waste penalty, fill reward, bin utilization and stability, respectively. Comparing (1st) vs (2nd), we see the first heuristic is simpler, only combining waste penalty and fill reward, while the second incorporates bin utilization and stability, using more sophisticated mathematical functions. (3rd) vs (4th) shows that tunable parameters such as `waste_exp_scale`, `fill_exp_scale`, `item_density_scale`, and `stability_scale` allows for fine-grained adjustments. Comparing (second worst) vs (worst), we see the simpler version uses a ratio and log of ratios. Overall: The best heuristics incorporate multiple factors and use non-linear functions with scaling, while the worst use simple ratios. The better heuristics also allow for more parameters for tuning and refinement. There is some code duplication, in particular from 2nd to the 6th and from the 3rd to 7th, 9th, 10th.\n- \nOkay, I'll help you redefine \"Current Self-Reflection\" for designing better heuristics, focusing on actionable advice and avoiding pitfalls. Let's aim for something truly useful for that $999K tip!\n\nHere's a refined approach:\n\n*   **Keywords:** Data-driven, validation, adaptability, explainability.\n*   **Advice:** Prioritize data analysis to identify key problem characteristics. Rigorously validate heuristic performance using diverse datasets. Design heuristics with adaptable components to handle varied scenarios. Strive for explainability to understand heuristic behavior and guide improvements.\n*   **Avoid:** Premature optimization, over-reliance on intuition, neglecting edge cases, and ignoring computational cost.\n*   **Explanation:** Focus on understanding the problem domain through data. Validation is crucial to ensure robustness. Adaptability allows for broader applicability, while explainability fosters trust and facilitates iterative refinement.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}