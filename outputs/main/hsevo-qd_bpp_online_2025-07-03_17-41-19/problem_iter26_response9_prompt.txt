{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit and remaining capacity considerations for bin selection.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    waste = bins_remain_cap - item\n    fit_mask = waste >= 0\n    priorities = np.where(fit_mask, np.exp(-waste / (item + epsilon)), -np.inf)\n\n    capacity_factor = bins_remain_cap / (np.max(bins_remain_cap) + epsilon)\n    priorities = np.where(fit_mask, priorities + 0.5 * capacity_factor, priorities)\n\n    normalized_item_size = item / (np.max(bins_remain_cap) + epsilon)\n    priorities = np.where(fit_mask, priorities + 0.1 * (1 - normalized_item_size), priorities)\n\n    fill_ratio = item / (bins_remain_cap + epsilon)\n    fill_reward = np.where(fit_mask & (fill_ratio <= 1), np.exp(1 - np.abs(1 - fill_ratio)), -np.inf)\n    priorities = np.where(fit_mask, priorities + 0.2 * fill_reward, priorities)\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function considers multiple factors, with adjusted weights and new considerations:\n    1. Waste: Prioritizes bins where the item fits relatively well, minimizing wasted space. Uses a more aggressive penalty for larger waste.\n    2. Fill Level: Encourages filling bins as much as possible, but penalizes overfilling. Modified to focus on bins that are close to being filled by this item.\n    3. Bin Utilization: Aims to balance the distribution of items across bins to avoid clustering.\n    4. Best Fit Heuristic Influence: Directly rewards bins that provide a very tight fit, emulating best-fit behavior.\n    5. Avoidance of Near-Empty Bins: Discourages placing items into bins that are still almost completely empty unless no other choice is available.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9  # Small value to avoid division by zero and log of zero\n\n    # Waste: Prioritize bins where the item fits relatively well.  Aggressive penalty for waste.\n    waste = bins_remain_cap - item\n    waste_penalty = np.where(waste >= 0, -waste**2, -np.inf)  # Quadratic penalty for waste, harsh penalty for overfill\n    priorities += waste_penalty\n\n    # Fill Level: Encourage filling bins, but not too much. Focus on bins that are close to being filled.\n    fill_ratio = item / (bins_remain_cap + epsilon)\n    fill_reward = np.where(fill_ratio <= 1, np.exp(1 - np.abs(1 - fill_ratio)), -np.inf) # Reward when fill ratio is close to 1\n    priorities += fill_reward\n\n    # Bin Utilization: Try to balance utilization across bins\n    utilization = 1 - bins_remain_cap  # Assuming bin capacity is normalized to 1.  Higher utilization is better.\n    utilization_reward = np.exp(utilization)\n    priorities += 0.1 * utilization_reward # scale down to balance relative to other heuristics\n\n    # Best Fit Heuristic Influence: Directly reward bins that provide a near-perfect fit.\n    best_fit_bonus = np.where(np.abs(waste) < 0.05, 10, 0) # Substantial reward for very small waste\n    priorities += best_fit_bonus\n\n    # Avoidance of Near-Empty Bins: Discourage putting items into near-empty bins unless necessary\n    near_empty_penalty = np.where(bins_remain_cap > 0.9, -1, 0) # Penalize if almost empty.\n    priorities += near_empty_penalty\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the best heuristic considers several factors like best-fit, capacity, item size normalization, and fill ratio, while the worst only considers the ratio of item size to remaining capacity and its logarithm. (2nd best) vs (19th) gives similar insights.\n\nComparing (1st) vs (2nd), they are identical. This suggests either they perform similarly, or the ranking is based on other factors not evident in the code itself.\n\n(3rd) vs (4th): The 3rd heuristic refines the weighting and introduces a bonus for bins with significantly larger capacity than the item, while the 4th heuristic introduces a capacity threshold that penalizes bins that are almost full. The 3rd uses `np.sqrt` to soften the effect of the capacity factor, and `np.exp(-np.abs(1 - fill_ratio))` to reduce the penalty for near-full bins.\n\nComparing (second worst) vs (worst), both use a simple ratio, but the worst uses a direct ratio calculation followed by a logarithm while the second-worst also calculates the log of ratios.\n\nOverall: The better heuristics incorporate more factors with carefully tuned weights and potentially non-linear transformations (e.g., exponentials, sigmoid) to better shape the priority landscape. They also exhibit an understanding of edge cases, such as avoiding near-empty or near-full bins through penalties or rewards. They normalize values to give context and allow for better comparison.\n- \nOkay, let's redefine \"Current self-reflection\" for designing better heuristics, avoiding the pitfalls of \"Ineffective self-reflection,\" and aiming for actionable advice.\n\n**Redefined \"Current Self-Reflection\":**\n\n*   **Keywords:** Multi-factor, normalization, weighting, edge-case handling, domain knowledge, rewards/penalties, scaling, clipping, constraints, feasibility.\n\n*   **Advice:** Prioritize identifying *truly* relevant factors. Design mathematical functions that realistically model factor relationships and enforce constraints. Consider both positive (rewards) and negative (penalties) impacts, and implement scaling/clipping to maintain robustness.\n\n*   **Avoid:** Overly complex, generic non-linear functions (e.g., *just* using exponentials/sigmoids without justification). Premature optimization.\n\n*   **Explanation:** The goal is to create heuristics based on a clear understanding of the problem. Keep it simple initially and build up complexity *only* as needed. Avoid using advanced math functions without a strong rationale tied to the problem domain.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}