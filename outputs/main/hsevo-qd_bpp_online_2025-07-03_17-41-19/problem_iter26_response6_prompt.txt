{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Refines bin selection by prioritizing bins that offer a good fit while also\n    considering the overall fill level and penalizing near-full bins less harshly.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    waste = bins_remain_cap - item\n    fit_mask = waste >= 0\n\n    # Best-fit component with a sharper preference for tighter fits\n    priorities = np.where(fit_mask, np.exp(-2 * waste / (item + epsilon)), -np.inf)\n\n    # Capacity-aware component, boosted for emptier bins, but softened\n    max_cap = np.max(bins_remain_cap) + epsilon\n    capacity_factor = bins_remain_cap / max_cap\n    priorities = np.where(fit_mask, priorities + 0.3 * np.sqrt(capacity_factor), priorities) # Soften with sqrt\n\n    # Item size normalization (still useful), slightly reduced weight\n    normalized_item_size = item / max_cap\n    priorities = np.where(fit_mask, priorities + 0.05 * (1 - normalized_item_size), priorities)\n\n    # Fill ratio reward, but with reduced penalty for near-full bins\n    fill_ratio = item / (bins_remain_cap + epsilon)\n    fill_reward = np.where(fit_mask & (fill_ratio <= 1), np.exp(-np.abs(1 - fill_ratio)), -np.inf) # Reduced penalty exponent\n    priorities = np.where(fit_mask, priorities + 0.15 * fill_reward, priorities) # Slightly lower weight\n\n    # Add a small bonus for bins with significantly larger capacity than the item\n    large_capacity_bonus = np.where(fit_mask & (bins_remain_cap > 2 * item), 0.05, 0)\n    priorities = np.where(fit_mask, priorities + large_capacity_bonus, priorities)\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function considers multiple factors:\n    1. Waste: Prioritizes bins where the item fits relatively well, minimizing wasted space.\n    2. Fill Level: Encourages filling bins as much as possible, but penalizes overfilling (impossible but included for completeness).\n    3. Number of Items: Accounts for how many items are already present in bins (not directly accessible in online BPP). We approximate using the amount of available space. Sparsely filled bins are encouraged, up to a point. Densely filled bins discouraged.\n    4. Stability: Favors bins that are closest to the item size.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9  # Small value to avoid division by zero and log of zero\n\n    # Waste: Prioritize bins where the item fits relatively well.\n    waste = bins_remain_cap - item\n    waste_penalty = np.where(waste >= 0, np.exp(-waste), -np.inf)  # Exponential decay for waste, harsh penalty for overfill. Negative inf indicates bin won't fit\n    priorities += waste_penalty\n\n    # Fill Level: Encourage filling bins, but not too much.\n    fill_ratio = item / (bins_remain_cap + epsilon)\n    fill_reward = np.where(fill_ratio <= 1, np.exp(fill_ratio), -np.inf)\n    priorities += fill_reward\n\n    # Number of Items (Approximated by remaining space): Encourages placing items in bins that were sparsely filled\n    item_density = np.exp(-bins_remain_cap) # Lower remaining cap equals larger item_density, less filled\n    priorities += item_density\n    # Stability (Closeness to Item Size):\n\n    stability = -np.abs(bins_remain_cap - item)\n    priorities += stability\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the best heuristic considers several factors like best-fit, capacity, item size normalization, and fill ratio, while the worst only considers the ratio of item size to remaining capacity and its logarithm. (2nd best) vs (19th) gives similar insights.\n\nComparing (1st) vs (2nd), they are identical. This suggests either they perform similarly, or the ranking is based on other factors not evident in the code itself.\n\n(3rd) vs (4th): The 3rd heuristic refines the weighting and introduces a bonus for bins with significantly larger capacity than the item, while the 4th heuristic introduces a capacity threshold that penalizes bins that are almost full. The 3rd uses `np.sqrt` to soften the effect of the capacity factor, and `np.exp(-np.abs(1 - fill_ratio))` to reduce the penalty for near-full bins.\n\nComparing (second worst) vs (worst), both use a simple ratio, but the worst uses a direct ratio calculation followed by a logarithm while the second-worst also calculates the log of ratios.\n\nOverall: The better heuristics incorporate more factors with carefully tuned weights and potentially non-linear transformations (e.g., exponentials, sigmoid) to better shape the priority landscape. They also exhibit an understanding of edge cases, such as avoiding near-empty or near-full bins through penalties or rewards. They normalize values to give context and allow for better comparison.\n- \nOkay, let's redefine \"Current self-reflection\" for designing better heuristics, avoiding the pitfalls of \"Ineffective self-reflection,\" and aiming for actionable advice.\n\n**Redefined \"Current Self-Reflection\":**\n\n*   **Keywords:** Multi-factor, normalization, weighting, edge-case handling, domain knowledge, rewards/penalties, scaling, clipping, constraints, feasibility.\n\n*   **Advice:** Prioritize identifying *truly* relevant factors. Design mathematical functions that realistically model factor relationships and enforce constraints. Consider both positive (rewards) and negative (penalties) impacts, and implement scaling/clipping to maintain robustness.\n\n*   **Avoid:** Overly complex, generic non-linear functions (e.g., *just* using exponentials/sigmoids without justification). Premature optimization.\n\n*   **Explanation:** The goal is to create heuristics based on a clear understanding of the problem. Keep it simple initially and build up complexity *only* as needed. Avoid using advanced math functions without a strong rationale tied to the problem domain.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}