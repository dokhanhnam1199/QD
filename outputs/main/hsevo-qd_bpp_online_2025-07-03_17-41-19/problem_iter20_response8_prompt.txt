{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function considers multiple factors, with refined weighting and a focus on avoiding edge-case penalties:\n    1.  Waste: Prioritizes bins where the item fits relatively well, minimizing wasted space.  Uses a more nuanced penalty.\n    2.  Fill Level: Encourages filling bins as much as possible, but penalizes overfilling. Exponential reward for fill ratio.\n    3.  Balance: Encourages a more balanced distribution of items across bins, especially when bins are similarly filled.\n    4.  Adaptability: Introduces a parameter (alpha) to adjust the relative importance of waste vs. fill level.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9  # Small value to avoid division by zero and log of zero\n    alpha = 0.5  # Adjust the weight of waste vs. fill (0 to 1)\n\n    # Waste: Prioritize bins where the item fits relatively well, minimizing wasted space.\n    waste = bins_remain_cap - item\n    waste_penalty = np.where(waste >= 0, np.exp(-waste / (item + epsilon)), -np.inf)  # Exponential decay scaled by item size\n    priorities += alpha * waste_penalty\n\n    # Fill Level: Encourage filling bins, but not too much.\n    fill_ratio = item / (bins_remain_cap + epsilon)\n    fill_reward = np.where(fill_ratio <= 1, np.exp(fill_ratio), -np.inf)\n    priorities += (1 - alpha) * fill_reward\n\n    # Balance: Encourages a more balanced distribution of items. Avoid extreme fill levels early on.\n    # This helps in scenarios where bins have similar remaining capacities.\n    bin_utilization = 1 - (bins_remain_cap / (np.max(bins_remain_cap) + epsilon)) # Relative to the fullest bin\n    balance_reward = np.exp(-np.abs(bin_utilization - 0.5)) # Target around 50% utilization.  Avoids being too greedy.\n    priorities += 0.1 * balance_reward  # Smaller weight.  Balance is secondary.\n\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                fill_sigmoid_scale: float = 9.493317672830546, fill_sigmoid_center: float = 0.7654453973055002,\n                stability_weight: float = 0.05972327746087532) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function prioritizes bins based on a combination of factors,\n    aiming for a balance between minimizing waste, maximizing fill, and maintaining\n    stability. It refines the approach in priority_v1 by using a more targeted\n    strategy for each component.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        waste_clip_min: Small value to avoid division by zero when calculating waste priority.\n        fill_sigmoid_scale: Scale of the sigmoid function used for fill priority.\n        fill_sigmoid_center: Center point of the sigmoid function.\n        stability_weight: Weight of the stability component in the overall priority.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = waste_clip_min  # Small value to avoid division by zero\n\n    # 1. Waste Minimization (Primary Goal)\n    waste = bins_remain_cap - item\n    # Only consider bins where the item fits\n    feasible_bins = waste >= 0\n    if not np.any(feasible_bins):\n        return priorities # No feasible bin, return all zeros\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the top heuristic considers waste, remaining capacity, item size normalization, and capacity threshold, using carefully weighted combinations and normalization techniques. In contrast, the bottom heuristic uses a simple log ratio of item size to remaining capacity. (2nd) is identical to (1st). Comparing (1st) vs (4th), the top heuristic uses a more sophisticated combination of waste minimization, remaining capacity and item size normalization with capacity threshold, while the (4th) heuristic combines waste minimization and fill level considerations with less nuanced penalties and rewards. (5th) considers waste, fill level, item fit, bin utilization, and number of items (approximated by remaining space). (6th) considers waste minimization and a modified fill ratio. (7th) considers waste, fill level, bin utilization, best fit heuristic influence, and avoidance of near-empty bins. (8th) considers waste, fill level, number of items, and stability and uses scaling factors. Comparing (8th) vs (9th), (8th) has scaling factors as parameters and (9th) doesn't. Comparing (7th) vs (10th), they are identical. Comparing (11th) vs (15th), (11th) considers waste minimization, fill level encouragement and stability, while (15th) is a simplified one. Comparing (13th) vs (14th), they are identical. Overall: The better heuristics incorporate multiple factors with careful weighting and normalization, and avoid edge-case penalties.\n- \nOkay, let's refine \"Current Self-Reflection\" for designing better heuristics, avoiding pitfalls of \"Ineffective Self-Reflection\":\n\n*   **Keywords:** Relevant factors, mathematical modeling, weighting, edge cases, robustness, scaling, feasibility constraints.\n\n*   **Advice:** Prioritize incorporating *all* truly relevant factors *directly* instead of approximating; use appropriate (but not necessarily complex or non-linear) mathematical models, and carefully tune weights. Ensure robustness.\n\n*   **Avoid:** Over-reliance on non-linear functions (exponential, sigmoid, etc.) *without strong justification*; Approximating missing data when direct incorporation is feasible; Premature optimization of parameters.\n\n*   **Explanation:** Focus on a solid foundation. Accurately represent the problem's core elements mathematically, handle boundary conditions gracefully, and only add complexity *after* a simple, robust heuristic exists.\n\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}