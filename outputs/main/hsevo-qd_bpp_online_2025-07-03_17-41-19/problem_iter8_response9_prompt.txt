{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function considers multiple factors, with refined weighting and scaling:\n    1. Waste: Prioritizes bins where the item fits relatively well, minimizing wasted space.  Uses a more sensitive exponential decay.\n    2. Fill Level: Encourages filling bins as much as possible, but penalizes overfilling. Uses a sigmoid function for smoother behavior.\n    3. Bin Utilization: Directly rewards bins that have been used to some extent, encouraging balanced usage.\n    4. Stability: Favors bins that are closest to the item size, scaled by the item size itself.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9  # Small value to avoid division by zero and log of zero\n\n    # Waste: Prioritize bins where the item fits relatively well.\n    waste = bins_remain_cap - item\n    waste_penalty = np.where(waste >= 0, np.exp(-10 * waste / item), -np.inf)  # More sensitive exponential decay, scaled by item size. Harsh penalty for overfill.\n    priorities += waste_penalty\n\n    # Fill Level: Encourage filling bins, but not too much.  Sigmoid function\n    fill_ratio = item / (bins_remain_cap + epsilon)\n    fill_reward = 1 / (1 + np.exp(5 - 10 * fill_ratio)) # Sigmoid centered around fill_ratio = 0.5\n    priorities += fill_reward\n\n    # Bin Utilization: Reward bins that have some items in them already\n    utilization = (1 - bins_remain_cap) # Previously available capacity\n    utilization_reward = np.where(utilization > 0, np.tanh(utilization), 0) #tanh squashes the values and 0 if it is new bin.\n    priorities += 0.5 * utilization_reward\n\n    # Stability (Closeness to Item Size): Scaled by item size\n    stability = -np.abs(bins_remain_cap - item) / (item + epsilon)\n    priorities += 0.25 * stability\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    ratios = item / bins_remain_cap\n    log_ratios = np.log(ratios)\n    priorities = -log_ratios\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic considers both waste minimization and fill level, while the worst only considers a simple ratio. (2nd best) vs (second worst), heuristic 2nd incorporates waste, fill level, bin utilization and stability. (3rd) vs (4th), both utilize waste, fill level, item density and stability, but they use different scaling factors and weights. Comparing (1st) vs (2nd), the best heuristic uses simpler linear combinations of waste and fill level, while the second best employs exponential decay, sigmoid functions, and tanh for more nuanced behavior. (3rd) vs (4th), they use exponential decay for waste, fill and density, and scaled stability with small different parameters. Comparing (second worst) vs (worst), both are identical. Overall: Better heuristics incorporate multiple factors, often with non-linear scaling or weighting, and are well-documented. Simpler heuristics focusing on a single ratio tend to perform worse. Including bin utilization and stability generally improves performance. Tunable parameters offer further refinement.\n- \nOkay, let's redefine \"Current self-reflection\" to make it more effective for designing heuristics and avoid the pitfalls of \"Ineffective self-reflection.\" Here's a breakdown:\n\n*   **Keywords:** Rigorous evaluation, explainability, adaptive parameters, modular design.\n\n*   **Advice:** Focus on rigorous evaluation of heuristic performance across diverse problem instances. Prioritize explainability by clearly articulating the rationale behind design choices. Incorporate adaptive parameters that respond to problem characteristics during runtime. Promote modularity to facilitate component replacement and refinement.\n\n*   **Avoid:** Over-reliance on single evaluation metrics. Neglecting edge cases or unforeseen scenarios. Premature optimization without clear performance benchmarks.\n\n*   **Explanation:** Effective self-reflection leads to designing heuristics that are not only performant but also robust, understandable, and easily adaptable to changing problem dynamics. Design your evaluation such that the performance is measurable and comparable to other heuristics.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}