{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Global random generator (single instance to avoid reseeding)\n_rng = np.random.default_rng()\n\n\n    \"\"\"\n    Hybrid random\u2011softmax priority for online Bin Packing.\n\n    This heuristic blends an exponential decay on the post\u2011placement waste\n    (tight\u2011fit preference) with a random perturbation and an item\u2011size weight.\n    The decay rate \u03bb adapts to the average waste of feasible bins, and the\n    score is further scaled by the fraction of the bin that the item will occupy.\n    Infeasible bins receive a priority of 0.  Scores are normalised to sum to 1\n    over feasible bins.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of each currently open bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (same shape as ``bins_remain_cap``).\n        The bin with the highest score should be selected for the item.\n    \"\"\"\n    # Ensure a NumPy float array for vectorised operations\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Edge case: no bins exist\n    if caps.size == 0:\n        return np.empty_like(caps)\n\n    # ---------- 1. Feasibility ----------\n    feasible = caps >= item\n    if not np.any(feasible):\n        # No open bin can host the item \u2013 caller may open a new bin.\n        return np.zeros_like(caps)\n\n    # ---------- 2. Waste computation ----------\n    waste = caps - item  # waste >= 0 for feasible bins\n\n    # ---------- 3. Adaptive \u03bb (based on mean waste) ----------\n    eps = 1e-12\n    mean_waste = waste[feasible].mean()\n    lam = 1.0 / (mean_waste + eps)\n\n    # ---------- 4. Base exponential decay (tight\u2011fit bias) ----------\n    raw = np.zeros_like(caps)\n    raw[feasible] = np.exp(-lam * waste[feasible])\n\n    # ---------- 5. Item\u2011size weighting ----------\n    # Prefer bins where the item occupies a larger fraction of the remaining capacity.\n    size_weight = np.zeros_like(caps)\n    size_weight[feasible] = item / caps[feasible]\n\n    # ---------- 6. Random perturbation ----------\n    # \u03b1 controls the strength of randomness (0 \u2192 deterministic, 1 \u2192 highly stochastic).\n    alpha = 0.3\n    rand_factor = np.ones_like(caps)\n    num_feasible = feasible.sum()\n    if num_feasible:\n        rand_factor[feasible] = 1.0 + alpha * _rng.random(num_feasible)\n\n    # ---------- 7. Combine components ----------\n    scores = raw * size_weight * rand_factor\n    scores[~feasible] = 0.0  # enforce zero for infeasible bins\n\n    # ---------- 8. Normalisation ----------\n    total = scores.sum()\n    if total > 0.0:\n        priorities = scores / total\n    else:\n        # Fallback: uniform distribution over feasible bins\n        priorities = np.where(feasible, 1.0 / num_feasible, 0.0)\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Global random generator (single instance)\n_rng = np.random.default_rng()\n\n# Exponential moving average parameters for item size statistics\n_alpha_ema = 0.1  # smoothing factor (0 < alpha <= 1)\n_ema_item_size = 0.0  # mean of seen items\n_ema_item_sq = 0.0    # mean of squared sizes\n_item_count = 0\n\n# Adaptive parameters\n_epsilon_factor = 0.05  # fraction of std used as exact\u2011fit tolerance\n_swap_weight = 0.05     # scaling for the swap\u2011improvement boost\n_exact_fit_offset = 1e9 # offset ensuring exact fits dominate priority\n\n\n    \"\"\"Update exponential moving averages of item size and squared size.\"\"\"\n    global _ema_item_size, _ema_item_sq, _item_count\n    _item_count += 1\n    # EMA update\n    _ema_item_size = (1 - _alpha_ema) * _ema_item_size + _alpha_ema * item\n    _ema_item_sq = (1 - _alpha_ema) * _ema_item_sq + _alpha_ema * (item * item)\n\n\n    \"\"\"Return the current estimated standard deviation of item sizes.\"\"\"\n    var = _ema_item_sq - _ema_item_size * _ema_item_size\n    if var < 0.0:\n        var = 0.0\n    return np.sqrt(var)\n\n\n    \"\"\"\n    Adaptive priority for online Bin Packing.\n\n    The priority reflects three principles:\n    1. Exact fits are always preferred (highest priority).\n    2. Among non\u2011exact feasible bins, smaller leftover capacity is better.\n    3. A small boost is added when the leftover after placement is close to\n       the average item size observed so far (swap\u2011improvement heuristic).\n    Ties are broken with a tiny random perturbation.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the existing bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority values for each bin (same shape as ``bins_remain_cap``). The\n        caller should select the bin with the maximum priority.\n    \"\"\"\n    # ---- Update global statistics with the current item ----\n    _update_item_stats(item)\n\n    # Adaptive tolerance for exact fit detection\n    std = _current_std()\n    eps = max(1e-9, _epsilon_factor * std)\n\n    # Remaining capacity after (theoretically) placing the item\n    leftover = bins_remain_cap - item\n\n    # Feasibility mask (allow a tiny negative due to eps)\n    feasible = leftover >= -eps\n\n    # Initialise all priorities to -inf (infeasible bins)\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        # No feasible bin \u2013 return all -inf\n        return priorities\n\n    # Exact\u2011fit mask (within tolerance)\n    exact_fit = feasible & (np.abs(leftover) <= eps)\n\n    # ---- Exact fits: assign a huge offset plus a tiny random tie\u2011breaker ----\n    if np.any(exact_fit):\n        tie_noise = _rng.uniform(0.0, 1e-6, size=exact_fit.sum())\n        priorities[exact_fit] = _exact_fit_offset + tie_noise\n\n    # ---- Non\u2011exact feasible bins ----\n    non_exact = feasible & ~exact_fit\n    if np.any(non_exact):\n        # Primary component: negative leftover (smaller leftover \u2192 larger priority)\n        primary = -leftover[non_exact]\n\n        # Swap\u2011improvement boost:\n        # leftover close to the average item size is considered promising.\n        mean_size = _ema_item_size if _item_count > 0 else 1.0\n        distance_to_mean = np.abs(leftover[non_exact] - mean_size)\n        boost = _swap_weight / (distance_to_mean + eps)\n\n        # Combine components\n        combined = primary + boost\n\n        # Random tie\u2011breaker (very small)\n        combined += _rng.uniform(0.0, 1e-6, size=combined.shape)\n\n        priorities[non_exact] = combined\n\n    return priorities\n\n[Reflection]\nPrefer exact fits, adapt decay via item stats, weight by size, add tiny random tie\u2011breakers, normalize.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}