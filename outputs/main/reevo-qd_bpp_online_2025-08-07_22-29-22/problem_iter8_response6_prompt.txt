{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Global random generator (single instance)\n_rng = np.random.default_rng()\n\n# Exponential moving average parameters for item size statistics\n_alpha_ema = 0.1  # smoothing factor (0 < alpha <= 1)\n_ema_item_size = 0.0  # mean of seen items\n_ema_item_sq = 0.0    # mean of squared sizes\n_item_count = 0\n\n# Adaptive parameters\n_epsilon_factor = 0.05  # fraction of std used as exact\u2011fit tolerance\n_swap_weight = 0.05     # scaling for the swap\u2011improvement boost\n_exact_fit_offset = 1e9 # offset ensuring exact fits dominate priority\n\n\n    \"\"\"Update exponential moving averages of item size and squared size.\"\"\"\n    global _ema_item_size, _ema_item_sq, _item_count\n    _item_count += 1\n    # EMA update\n    _ema_item_size = (1 - _alpha_ema) * _ema_item_size + _alpha_ema * item\n    _ema_item_sq = (1 - _alpha_ema) * _ema_item_sq + _alpha_ema * (item * item)\n\n\n    \"\"\"Return the current estimated standard deviation of item sizes.\"\"\"\n    var = _ema_item_sq - _ema_item_size * _ema_item_size\n    if var < 0.0:\n        var = 0.0\n    return np.sqrt(var)\n\n\n    \"\"\"\n    Adaptive priority for online Bin Packing.\n\n    The priority reflects three principles:\n    1. Exact fits are always preferred (highest priority).\n    2. Among non\u2011exact feasible bins, smaller leftover capacity is better.\n    3. A small boost is added when the leftover after placement is close to\n       the average item size observed so far (swap\u2011improvement heuristic).\n    Ties are broken with a tiny random perturbation.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the existing bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority values for each bin (same shape as ``bins_remain_cap``). The\n        caller should select the bin with the maximum priority.\n    \"\"\"\n    # ---- Update global statistics with the current item ----\n    _update_item_stats(item)\n\n    # Adaptive tolerance for exact fit detection\n    std = _current_std()\n    eps = max(1e-9, _epsilon_factor * std)\n\n    # Remaining capacity after (theoretically) placing the item\n    leftover = bins_remain_cap - item\n\n    # Feasibility mask (allow a tiny negative due to eps)\n    feasible = leftover >= -eps\n\n    # Initialise all priorities to -inf (infeasible bins)\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        # No feasible bin \u2013 return all -inf\n        return priorities\n\n    # Exact\u2011fit mask (within tolerance)\n    exact_fit = feasible & (np.abs(leftover) <= eps)\n\n    # ---- Exact fits: assign a huge offset plus a tiny random tie\u2011breaker ----\n    if np.any(exact_fit):\n        tie_noise = _rng.uniform(0.0, 1e-6, size=exact_fit.sum())\n        priorities[exact_fit] = _exact_fit_offset + tie_noise\n\n    # ---- Non\u2011exact feasible bins ----\n    non_exact = feasible & ~exact_fit\n    if np.any(non_exact):\n        # Primary component: negative leftover (smaller leftover \u2192 larger priority)\n        primary = -leftover[non_exact]\n\n        # Swap\u2011improvement boost:\n        # leftover close to the average item size is considered promising.\n        mean_size = _ema_item_size if _item_count > 0 else 1.0\n        distance_to_mean = np.abs(leftover[non_exact] - mean_size)\n        boost = _swap_weight / (distance_to_mean + eps)\n\n        # Combine components\n        combined = primary + boost\n\n        # Random tie\u2011breaker (very small)\n        combined += _rng.uniform(0.0, 1e-6, size=combined.shape)\n\n        priorities[non_exact] = combined\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Global random generator for optional tie\u2011breaking noise\n_rng = np.random.default_rng()\n\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    temperature: float = 0.1,\n    random_noise: bool = False,\n    noise_scale: float = 1e-12,\n) -> np.ndarray:\n    \"\"\"\n    Compute a softmax\u2011based priority vector for an online Bin Packing item.\n\n    The function prefers bins where the item fits tightly (small slack).\n    For each feasible bin we compute a logit proportional to the negative slack,\n    scaled by ``temperature``.  The logits are turned into a probability\u2011like\n    priority distribution via a numerically\u2011stable softmax.  Infeasible bins\n    receive a priority of 0.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    temperature : float, optional (default=0.1)\n        Controls the sharpness of the softmax.  Lower values make the decision\n        more deterministic (closer to a greedy Best\u2011Fit), while higher values\n        spread the probability mass more uniformly.\n    random_noise : bool, optional (default=False)\n        If True, a tiny uniform noise (\u00b1``noise_scale``) is added to the logits\n        of feasible bins to break ties in a reproducible stochastic way.\n    noise_scale : float, optional (default=1e-12)\n        Magnitude of the optional tie\u2011breaking noise.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (same shape as ``bins_remain_cap``).  The\n        scores sum to 1 across all feasible bins; infeasible bins have a score\n        of 0.  The bin with the highest priority should be selected for the item.\n    \"\"\"\n    if temperature <= 0.0:\n        raise ValueError(\"temperature must be a positive float\")\n\n    # Ensure we work with a NumPy array of float64 for numerical stability\n    caps = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # Feasibility mask: only bins with enough remaining capacity can hold the item\n    feasible = caps >= item\n\n    # Initialise priority vector with zeros (infeasible bins stay zero)\n    priorities = np.zeros_like(caps, dtype=np.float64)\n\n    # If no bin can accommodate the item, return the zero vector\n    if not np.any(feasible):\n        return priorities\n\n    # Compute slack (unused capacity after placing the item) for feasible bins\n    slack = caps[feasible] - item  # non\u2011negative by construction\n\n    # Logits: tighter fit (smaller slack) gets larger logit\n    logits = np.full_like(caps, -np.inf, dtype=np.float64)\n    logits[feasible] = -slack / temperature\n\n    # Optional tiny noise for stochastic tie\u2011breaking (deterministic otherwise)\n    if random_noise:\n        noise = _rng.uniform(-noise_scale, noise_scale, size=logits.shape)\n        logits[feasible] += noise[feasible]\n\n    # Numerically stable softmax\n    max_logit = np.max(logits[feasible])          # safe because feasible is non\u2011empty\n    exp_shifted = np.exp(logits - max_logit)     # exp(-inf) = 0 for infeasible bins\n    sum_exp = np.sum(exp_shifted)                # >0 because at least one entry is 1\n\n    # Normalise to obtain a probability\u2011like priority distribution\n    priorities = exp_shifted / sum_exp\n\n    return priorities\n\n[Reflection]\nPrefer softmax over slack with tunable temperature; minimal EMA; small noise; avoid huge offsets.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}