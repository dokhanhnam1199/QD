{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Global random generator reused across calls\n_rng = np.random.default_rng()\n\n# Running statistics of observed item sizes (simple sum/count)\n_item_count = 0\n_item_sum = 0.0\n\n\n    \"\"\"\n    Priority function for the online Bin Packing Problem.\n\n    Higher scores indicate more desirable bins. The scoring combines:\n      \u2022 Best\u2011fit (smaller leftover \u2192 higher score)\n      \u2022 Controlled random perturbation (more for small items)\n      \u2022 A look\u2011ahead boost based on the running average item size\n      \u2022 A deterministic tie\u2011breaker favouring lower\u2011index bins\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the existing bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (same shape as ``bins_remain_cap``).\n        Infeasible bins receive ``-np.inf``.\n    \"\"\"\n    global _item_count, _item_sum\n\n    # Ensure we are working with a NumPy array of floats\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # No bins yet \u2013 just record statistics and return empty array\n    if bins_remain_cap.size == 0:\n        _item_count += 1\n        _item_sum += item\n        return np.array([], dtype=float)\n\n    # Compute leftover capacity if the item were placed in each bin\n    leftover = bins_remain_cap - item\n\n    # Small epsilon to guard against floating\u2011point round\u2011off\n    eps = 1e-12\n    feasible = leftover >= -eps\n\n    # Initialise priority vector with -inf for infeasible bins\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # If nothing fits, update stats and return\n    if not np.any(feasible):\n        _item_count += 1\n        _item_sum += item\n        return priorities\n\n    # ------------------------------------------------------------------\n    # 1. Base best\u2011fit score (smaller leftover \u2192 larger score)\n    # ------------------------------------------------------------------\n    base_score = -leftover[feasible]\n\n    # ------------------------------------------------------------------\n    # 2. Controlled randomness (more for small items)\n    # ------------------------------------------------------------------\n    # Approximate bin capacity (max remaining + current item) \u2013 fallback 1.0\n    approx_capacity = max(bins_remain_cap.max() + item, 1.0)\n    item_ratio = item / approx_capacity                     # \u2208 [0, 1]\n\n    # Spread of leftover among feasible bins\n    leftover_feas = leftover[feasible]\n    if leftover_feas.size > 1:\n        leftover_range = leftover_feas.max() - leftover_feas.min()\n    else:\n        leftover_range = 0.0\n\n    # Noise scale grows when the item is small (item_ratio low) and when\n    # there is a larger spread of leftover capacities.\n    noise_scale = leftover_range * 0.05 * (1.0 - item_ratio)\n    noise_scale = max(noise_scale, 0.0)\n    random_noise = _rng.random(leftover_feas.shape) * noise_scale\n\n    # ------------------------------------------------------------------\n    # 3. Look\u2011ahead boost using running average item size\n    # ------------------------------------------------------------------\n    if _item_count > 0:\n        avg_item = _item_sum / _item_count\n    else:\n        avg_item = item  # first item fallback\n\n    # Small positive boost if the bin would still have room for a typical\n    # future item; slight penalty otherwise.\n    future_weight = 0.02\n    future_adjust = (leftover_feas - avg_item) * future_weight\n\n    # ------------------------------------------------------------------\n    # 4. Deterministic tie\u2011breaker (prefer lower index bins)\n    # ------------------------------------------------------------------\n    tie_breaker = -np.arange(bins_remain_cap.size, dtype=float) * 1e-12\n\n    # ------------------------------------------------------------------\n    # 5. Combine components\n    # ------------------------------------------------------------------\n    combined = base_score + random_noise + future_adjust + tie_breaker[feasible]\n    priorities[feasible] = combined\n\n    # ------------------------------------------------------------------\n    # 6. Update global statistics\n    # ------------------------------------------------------------------\n    _item_count += 1\n    _item_sum += item\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Global random generator for reproducibility\n_rng = np.random.default_rng()\n\n    \"\"\"\n    Adaptive priority for online Bin Packing.\n\n    This function combines:\n      - An adaptive logistic score based on the slack after inserting the\n        current item.\n      - A blending of that score with the ratio of the item size to the\n        remaining capacity of the bin (encouraging tighter fits).\n      - A local\u2011search inspired penalty that prefers bins which, after the\n        insertion, do not become the new bin with the largest remaining\n        capacity (reducing fragmentation).\n      - A small random perturbation to break ties.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of the remaining capacity of each open bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin.  Bins that cannot accommodate the\n        item receive a priority of `-inf`.\n    \"\"\"\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # Slack after placing the item in each bin\n    slack = bins_remain_cap - item\n    feasible = slack >= 0.0\n\n    # Initialize with -inf for infeasible bins\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    if not feasible.any():\n        return priorities\n\n    # Slack values for feasible bins\n    slack_feas = slack[feasible]\n\n    # Adaptive logistic parameters\n    median_slack = np.median(slack_feas)\n    slack_range = slack_feas.max() - slack_feas.min()\n    if slack_range < 1e-12:\n        slack_range = 1e-12\n    alpha = 8.0 / slack_range  # controls steepness\n\n    # Logistic score: higher for bins that leave little slack\n    logistic_scores = 1.0 / (1.0 + np.exp(alpha * (slack_feas - median_slack)))\n\n    # Blend with item-to-remaining-capacity ratio (encourages tighter fits)\n    remaining_cap_feas = bins_remain_cap[feasible]\n    ratio = item / (remaining_cap_feas + 1e-12)  # values in (0, 1]\n    blended_scores = logistic_scores * ratio\n\n    # Local\u2011search penalty: minimize the maximum remaining capacity after\n    # insertion.  Lower penalty => better bin.\n    # Determine the global maximum remaining capacity before insertion\n    max_remaining = bins_remain_cap.max()\n    # Compute second maximum for bins that currently hold the maximum\n    sorted_cap = np.sort(bins_remain_cap)\n    second_max = sorted_cap[-2] if len(sorted_cap) >= 2 else sorted_cap[-1]\n    global_max_mask = bins_remain_cap == max_remaining\n\n    # For each feasible bin, compute the max remaining capacity after insertion\n    max_remaining_other = np.where(\n        global_max_mask[feasible], second_max, max_remaining\n    )\n    max_slack_after = np.maximum(max_remaining_other, slack_feas)\n    local_penalty = max_slack_after / max_remaining\n    local_scores = 1.0 - local_penalty  # lower penalty \u2192 higher score\n\n    # Combine the two signals with a weighted sum\n    w1, w2 = 0.6, 0.4\n    combined_scores = w1 * blended_scores + w2 * local_scores\n\n    # Add tiny random noise to break ties\n    noise = _rng.random(len(combined_scores)) * 1e-6\n    final_scores = combined_scores + noise\n\n    priorities[feasible] = final_scores\n    return priorities\n\n[Reflection]\nUse adaptive logistic slack score, blend item\u2011to\u2011capacity ratio, penalize bins raising max slack, add tiny random tie\u2011breaker.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}