```python
import numpy as np

# ----------------------- Global parameters -----------------------
_alpha_ema = 0.05          # EMA smoothing for observed item sizes
_alpha_ratio = 0.5        # Exponent for size‑to‑capacity ratio penalty
_epsilon_factor = 0.05    # Fraction of running std used as exact‑fit tolerance
_exact_fit_offset = 1e9   # Large boost for (near) exact fits

# ----------------------- Global state ----------------------------
_ema_mean = 0.0            # EMA of item sizes
_ema_sq = 0.0              # EMA of squared item sizes
_item_count = 0           # Number of items processed so far

_rng = np.random.default_rng()  # Placeholder for possible extensions


def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Compute a priority score for each bin in an online bin‑packing setting.

    Higher scores indicate more desirable bins. Infeasible bins receive
    ``-np.inf``. The score combines an adaptive waste penalty, a size‑to‑1
    capacity ratio penalty, and a large offset for (near) exact fits.
    A tiny index‑based penalty breaks ties deterministically.

    Parameters
    ----------
    item : float
        Size of the arriving item.
    bins_remain_cap : np.ndarray
        1‑D array of remaining capacities of the current bins.

    Returns
    -------
    np.ndarray
        Priority scores, same shape as ``bins_remain_cap``.
    """
    global _ema_mean, _ema_sq, _item_count

    caps = np.asarray(bins_remain_cap, dtype=float)

    # ---- No bins available -------------------------------------------------
    if caps.size == 0:
        _item_count += 1
        _ema_mean = (1 - _alpha_ema) * _ema_mean + _alpha_ema * item
        _ema_sq = (1 - _alpha_ema) * _ema_sq + _alpha_ema * (item * item)
        return np.array([], dtype=float)

    # ---- 1. Exact‑fit tolerance from past statistics -----------------------
    if _item_count > 0:
        var = _ema_sq - _ema_mean * _ema_mean
        std = np.sqrt(var) if var > 0 else 0.0
        eps_exact = max(1e-9, _epsilon_factor * std)
    else:
        eps_exact = 1e-9   # First item: very tight tolerance

    # ---- 2. Feasibility mask -----------------------------------------------
    eps_feas = 1e-12                     # Guard against floating‑point noise
    slack = caps - item                  # Remaining capacity if item placed
    feasible = slack >= -eps_feas        # Allow tiny negative slack

    # Initialise priority vector with -inf for infeasible bins
    priorities = np.full_like(caps, -np.inf, dtype=float)

    if not np.any(feasible):
        # No bin can accommodate the item – update EMA and return
        _item_count += 1
        _ema_mean = (1 - _alpha_ema) * _ema_mean + _alpha_ema * item
        _ema_sq = (1 - _alpha_ema) * _ema_sq + _alpha_ema * (item * item)
        return priorities

    # ---- 3. Exact‑fit detection --------------------------------------------
    exact_fit = feasible & (np.abs(slack) <= eps_exact)

    # ---- 1. Adaptive waste penalty -----------------------------------------
    # Waste is the positive leftover capacity (clip tiny negatives to 0)
    waste = np.maximum(slack[feasible], 0.0)
    mean_waste = np.mean(waste) if waste.size > 0 else 0.0
    lam = 1.0 / (mean_waste + 1e-6)          # Smoothing to avoid division by zero
    raw_waste = np.exp(-lam * waste)        # Larger for tighter fits

    # ---- 2. Ratio penalty ---------------------------------------------------
    ratio = item / caps[feasible]            # ≤ 1 for feasible bins
    ratio = np.clip(ratio, 0.0, 1.0)
    ratio_penalty = ratio ** _alpha_ratio

    # Combined score before normalisation
    combined = raw_waste * ratio_penalty

    # ---- 3. Soft‑max normalisation -----------------------------------------
    # Numerical stability via subtraction of max
    max_comb = combined.max()
    exp_scores = np.exp(combined - max_comb)
    prob_scores = exp_scores / exp_scores.sum()

    # Assign soft‑max probabilities to feasible bins
    priorities[feasible] = _alpha_ema) * _ema_mean + _alpha_ema * item
        _ema_sq = (1 - _alpha_ema) * _ema_sq + _alpha_ema * (item * item)

    # ---- 7. Deterministic tie‑breaker (lower index wins) -------------------
    idx = np.arange(caps.size, dtype=float)
    tie_penalty = 1e-12 * idx
    priorities[feasible] -= tie_penalty[feasible]

    # ---- 8. Exact‑fit boost (overwrites probability) -----------------------
    priorities[exact_fit] = _exact_fit_offset - tie_penalty[exact_fit]

    # ---- 9. Update EMA statistics with the current item --------------------
    _item_count += 1
    _ema_mean = (1 - _alpha_ema) * _ema_mean + _alpha_ema * item
    _ema_sq = (1 - _alpha_ema) * _ema_sq + _alpha_ema * (item * item)

    return priorities
```
