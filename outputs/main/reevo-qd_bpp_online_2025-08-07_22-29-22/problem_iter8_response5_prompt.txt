{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Global random generator (single instance)\n_rng = np.random.default_rng()\n\n# Exponential moving average parameters for item size statistics\n_alpha_ema = 0.1  # smoothing factor (0 < alpha <= 1)\n_ema_item_size = 0.0  # mean of seen items\n_ema_item_sq = 0.0    # mean of squared sizes\n_item_count = 0\n\n# Adaptive parameters\n_epsilon_factor = 0.05  # fraction of std used as exact\u2011fit tolerance\n_swap_weight = 0.05     # scaling for the swap\u2011improvement boost\n_exact_fit_offset = 1e9 # offset ensuring exact fits dominate priority\n\n\n    \"\"\"Update exponential moving averages of item size and squared size.\"\"\"\n    global _ema_item_size, _ema_item_sq, _item_count\n    _item_count += 1\n    # EMA update\n    _ema_item_size = (1 - _alpha_ema) * _ema_item_size + _alpha_ema * item\n    _ema_item_sq = (1 - _alpha_ema) * _ema_item_sq + _alpha_ema * (item * item)\n\n\n    \"\"\"Return the current estimated standard deviation of item sizes.\"\"\"\n    var = _ema_item_sq - _ema_item_size * _ema_item_size\n    if var < 0.0:\n        var = 0.0\n    return np.sqrt(var)\n\n\n    \"\"\"\n    Adaptive priority for online Bin Packing.\n\n    The priority reflects three principles:\n    1. Exact fits are always preferred (highest priority).\n    2. Among non\u2011exact feasible bins, smaller leftover capacity is better.\n    3. A small boost is added when the leftover after placement is close to\n       the average item size observed so far (swap\u2011improvement heuristic).\n    Ties are broken with a tiny random perturbation.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the existing bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority values for each bin (same shape as ``bins_remain_cap``). The\n        caller should select the bin with the maximum priority.\n    \"\"\"\n    # ---- Update global statistics with the current item ----\n    _update_item_stats(item)\n\n    # Adaptive tolerance for exact fit detection\n    std = _current_std()\n    eps = max(1e-9, _epsilon_factor * std)\n\n    # Remaining capacity after (theoretically) placing the item\n    leftover = bins_remain_cap - item\n\n    # Feasibility mask (allow a tiny negative due to eps)\n    feasible = leftover >= -eps\n\n    # Initialise all priorities to -inf (infeasible bins)\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        # No feasible bin \u2013 return all -inf\n        return priorities\n\n    # Exact\u2011fit mask (within tolerance)\n    exact_fit = feasible & (np.abs(leftover) <= eps)\n\n    # ---- Exact fits: assign a huge offset plus a tiny random tie\u2011breaker ----\n    if np.any(exact_fit):\n        tie_noise = _rng.uniform(0.0, 1e-6, size=exact_fit.sum())\n        priorities[exact_fit] = _exact_fit_offset + tie_noise\n\n    # ---- Non\u2011exact feasible bins ----\n    non_exact = feasible & ~exact_fit\n    if np.any(non_exact):\n        # Primary component: negative leftover (smaller leftover \u2192 larger priority)\n        primary = -leftover[non_exact]\n\n        # Swap\u2011improvement boost:\n        # leftover close to the average item size is considered promising.\n        mean_size = _ema_item_size if _item_count > 0 else 1.0\n        distance_to_mean = np.abs(leftover[non_exact] - mean_size)\n        boost = _swap_weight / (distance_to_mean + eps)\n\n        # Combine components\n        combined = primary + boost\n\n        # Random tie\u2011breaker (very small)\n        combined += _rng.uniform(0.0, 1e-6, size=combined.shape)\n\n        priorities[non_exact] = combined\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Single random generator \u2013 reused on every call (no reseeding)\n_rng = np.random.default_rng()\n\n# Simple running statistics of items seen so far (used for a lightweight look\u2011ahead)\n_item_count = 0\n_item_sum = 0.0\n\n\n    \"\"\"\n    Hybrid priority for the online Bin Packing Problem.\n\n    Combines a best\u2011fit score with:\n      \u2022 a controlled random perturbation (more randomness for small items),\n      \u2022 a deterministic tie\u2011breaker that favours lower\u2011index bins,\n      \u2022 a look\u2011ahead term based on the running average size of previously\n        observed items.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array with the remaining capacity of each existing bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (same shape as ``bins_remain_cap``).\n        Higher values are preferred; infeasible bins receive ``-np.inf``.\n    \"\"\"\n    global _item_count, _item_sum\n\n    # Normalise input\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # No existing bins \u2013 caller will open a new one.\n    if bins_remain_cap.size == 0:\n        _item_count += 1\n        _item_sum += item\n        return np.array([], dtype=float)\n\n    # --- 1: feasibility -------------------------------------------------\n    leftover = bins_remain_cap - item               # capacity that would remain\n    feasible = leftover >= 0                         # True for bins that can host the item\n\n    # Initialise with -inf (worst possible score)\n    priorities = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n\n    # If nothing fits, just record statistics and return.\n    if not np.any(feasible):\n        _item_count += 1\n        _item_sum += item\n        return priorities\n\n    # --- 2: best\u2011fit base score -----------------------------------------\n    # Higher score \u2194 tighter fit (smaller leftover)\n    base_score = -leftover[feasible]                # negative leftover\n\n    # --- 3: controlled randomness ----------------------------------------\n    # Rough estimate of the true bin capacity (most empty bin + current item)\n    approx_capacity = bins_remain_cap.max() + item\n    approx_capacity = max(approx_capacity, 1.0)     # guard against degenerate zero\n\n    # Item\u2011size ratio: larger items \u2192 less randomness\n    item_ratio = item / approx_capacity\n\n    # Scale random noise relative to the spread of leftover space\n    leftover_feas = leftover[feasible * 1]  # alias for readability\n    leftover_range = leftover_feas.max() - leftover_feas.min()\n    noise_scale = leftover_range * 0.05 * (1.0 - item_ratio)\n    noise_scale = max(noise_scale, 0.0)\n\n    random_noise = _rng.random(leftover_feas.shape) * noise_scale\n\n    # --- 4: look\u2011ahead using running average item size -------------------\n    if _item_count > 0:\n        avg_item = _item_sum / _item_count\n    else:\n        avg_item = item   # first item \u2013 fall back to its own size\n\n    # Small boost for bins that would still have room for a typical future item\n    # (positive if leftover > avg_item, negative otherwise)\n    future_weight = 0.02                         # tiny constant factor\n    future_adjust = (leftover_feas - avg_item) * future_weight\n\n    # --- 5: deterministic tie\u2011breaker ------------------------------------\n    # Slightly penalise higher indices to break exact ties deterministically\n    tie_breaker = -np.arange(bins_remain_cap.size, dtype=float) * 1e-12\n\n    # --- 6: combine all components ---------------------------------------\n    priorities[feasible] = (\n        base_score\n        + random_noise\n        + future_adjust\n        + tie_breaker[feasible]\n    )\n\n    # Record the current item for future look\u2011ahead calculations\n    _item_count += 1\n    _item_sum += item\n\n    return priorities\n\n[Reflection]\nUse best\u2011fit; add controlled noise; incorporate running average; deterministic tie\u2011breaker; avoid EMA.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}