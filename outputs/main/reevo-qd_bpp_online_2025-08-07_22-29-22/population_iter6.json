[
  {
    "stdout_filepath": "problem_iter1_response3.txt_stdout.txt",
    "code_path": "problem_iter1_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Almost Full Fit priority function.\n\n    Picks the bin that will be *almost* full after placing the item\n    (i.e. the smallest positive slack).  Bins that cannot accommodate\n    the item receive a very low priority of -\u221e.\n\n    Parameters\n    ----------\n    item : float\n        Size of the item to place.\n    bins_remain_cap : np.ndarray\n        Remaining capacities of each bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority score for each bin; higher scores are preferred.\n    \"\"\"\n    # Compute the remaining slack after inserting the item.\n    slack = bins_remain_cap - item\n\n    # Bins that cannot fit the item are assigned -\u221e priority.\n    invalid_mask = slack < 0\n    priorities = np.where(invalid_mask, -np.inf, -slack)  # smaller slack \u21d2 larger priority\n\n    return priorities",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Best\u2011Fit priority for the online Bin Packing Problem.\n\n    For each bin we compute the remaining capacity after (hypothetically)\n    placing the current `item`.  A feasible bin (remaining capacity \u2265 0)\n    receives a priority equal to the negative of that leftover space.\n    Since the caller selects the bin with the *highest* priority, the\n    smallest leftover (i.e., the best\u2011fit) ends up with the largest value.\n\n    Infeasible bins are given a very large negative score so they will never\n    be chosen.  A tiny index\u2011based offset is added to break ties deterministically\n    (prefer earlier bins when leftovers are equal).\n\n    Args:\n        item: Size of the incoming item.\n        bins_remain_cap: 1\u2011D array of the remaining capacity of each bin.\n\n    Returns:\n        A float array of the same shape as ``bins_remain_cap`` containing the\n        priority for each bin.\n    \"\"\"\n    # Ensure we are dealing with a float array for arithmetic\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # Compute the capacity that would remain after placing the item\n    leftover = bins_remain_cap - item\n\n    # Feasibility mask: only bins with non\u2011negative leftover can host the item\n    feasible = leftover >= 0\n\n    # Initialise priorities with -inf (worst possible score)\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # For feasible bins, priority = -leftover (higher is better, i.e., smaller leftover)\n    # Adding a tiny decreasing term based on index to break ties in favour of lower indices\n    tie_breaker = -np.arange(bins_remain_cap.size) * 1e-12\n    priorities[feasible] = -leftover[feasible] + tie_breaker[feasible]\n\n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Priority function implementing the *Exact Fit First* strategy for online Bin Packing.\n\n    Each bin receives a score; the bin with the highest score is chosen for the item.\n    - Bins that cannot accommodate the item receive `-inf` (lowest possible priority).\n    - Among feasible bins, the priority is the negative remaining slack\n      (`-(remaining_capacity - item)`).  Thus a smaller slack \u2192 a larger priority,\n      with a perfect (exact) fit yielding the highest possible score (zero).\n\n    A tiny random perturbation is added to break ties deterministically without\n    affecting the ordering of distinct slack values.\n\n    Args:\n        item: Size of the incoming item.\n        bins_remain_cap: 1\u2011D array of remaining capacities of existing bins.\n\n    Returns:\n        A 1\u2011D `np.ndarray` of priority scores, same shape as `bins_remain_cap`.\n    \"\"\"\n    # Compute how much free space would remain after placing the item in each bin.\n    slack = bins_remain_cap - item\n\n    # Initialise all priorities to -inf (i.e., bins that cannot host the item).\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # Identify feasible bins (enough remaining capacity).\n    feasible = slack >= 0\n\n    # For feasible bins, priority = -slack (higher for tighter fits).\n    priorities[feasible] = -slack[feasible]\n\n    # Optional tie\u2011breaker: add infinitesimal random noise to differentiate exact ties.\n    if feasible.any():\n        # Noise magnitude is far below any meaningful slack difference.\n        noise = np.random.rand(feasible.sum()) * 1e-9\n        priorities[feasible] += noise\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response6.txt_stdout.txt",
    "code_path": "problem_iter1_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Sigmoid Fit Score priority for online bin packing.\n\n    The score favours bins where the item leaves *little* slack after insertion.\n    For each feasible bin (remaining capacity \u2265 item) we compute the slack:\n        slack = remaining_capacity - item\n    A logistic (sigmoid) function is applied to the slack values:\n        \u2022 Small slack \u2192 high priority (close to 1)\n        \u2022 Large slack \u2192 low priority (close to 0)\n    The inflection point of the sigmoid is placed at the median slack of the\n    feasible bins, making the scoring adaptive to the current distribution of\n    free space. Infeasible bins receive a priority of 0.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        Remaining capacities of the currently open bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores with the same shape as ``bins_remain_cap``. The bin\n        with the highest score should be chosen for the item.\n    \"\"\"\n    # Ensure we work with a float NumPy array\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # Slack after placing the item in every bin (negative = infeasible)\n    slack = bins_remain_cap - item\n\n    # Feasibility mask (only bins that can actually accommodate the item)\n    feasible = slack >= 0.0\n\n    # Initialise all priorities to 0 (infeasible bins stay at 0)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # If nothing fits, simply return the zero vector\n    if not feasible.any():\n        return priorities\n\n    # Slack values for feasible bins only\n    slack_feas = slack[feasible]   # \u2265 0\n\n    # Adaptive sigmoid parameters:\n    #   \u03b2 (beta)  \u2013 median slack (inflection point of the logistic)\n    #   \u03b1 (alpha) \u2013 slope, scaled so the curve spans roughly 8 units in the\n    #               normalized slack range.\n    beta = np.median(slack_feas)\n\n    # Prevent division by zero when all feasible slacks are identical\n    slack_range = slack_feas.max() - slack_feas.min() + 1e-12\n    alpha = 8.0 / slack_range\n\n    # Logistic (sigmoid) decreasing in slack:\n    #   score = 1 / (1 + exp(\u03b1 * (slack \u2013 \u03b2)))\n    #   \u2192 slack < \u03b2  \u21d2 exponent negative \u21d2 score > 0.5 (high priority)\n    #   \u2192 slack > \u03b2  \u21d2 exponent positive \u21d2 score < 0.5 (low priority)\n    sigmoid_scores = 1.0 / (1.0 + np.exp(alpha * (slack_feas - beta)))\n\n    # Fill the scores back into the full priority vector\n    priorities[feasible] = sigmoid_scores\n\n    return priorities",
    "response_id": 6,
    "obj": 4.048663741523748,
    "SLOC": 14.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\n\n# Global random generator to avoid reseeding on every call\n_rng = np.random.default_rng()\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Random\u2011Fit priority for online Bin Packing.\n\n    For each bin that can accommodate the incoming `item` (i.e. its remaining\n    capacity \u2265 item size), we assign an independent random number drawn from a\n    uniform distribution on (0, 1). Bins that cannot accommodate the item receive\n    a priority of -inf, ensuring they are never selected. The bin with the\n    maximum priority (the highest random draw) will be chosen, which implements\n    the classic Random Fit strategy.\n\n    Args:\n        item: Size of the incoming item.\n        bins_remain_cap: 1\u2011D array with the remaining capacity of each existing bin.\n\n    Returns:\n        A NumPy array of the same shape as `bins_remain_cap` containing priority\n        scores for each bin.\n    \"\"\"\n    # Initialise all priorities to -inf (infeasible by default)\n    priorities = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n\n    # Identify bins that can fit the item\n    feasible_mask = bins_remain_cap >= item\n    num_feasible = np.count_nonzero(feasible_mask)\n\n    # Assign random priorities only to feasible bins\n    if num_feasible:\n        priorities[feasible_mask] = _rng.random(num_feasible)\n\n    return priorities",
    "response_id": 7,
    "obj": 73.55404866374154,
    "SLOC": 7.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Exact Fit First priority for the online Bin Packing Problem.\n\n    The function assigns:\n      * A very low score (negative infinity) to bins that cannot accommodate the item.\n      * A neutral/highest score (zero) to bins where the item fits *exactly* (within a tiny tolerance).\n      * For all other feasible bins, a score proportional to the *negative* leftover capacity,\n        i.e., the less space that will be wasted, the higher (less negative) the score.\n\n    By returning the array of scores, the caller can simply select the bin with the\n    maximum priority, which yields the \"Exact\u2011Fit\u2011First\" behaviour: any exact fit\n    beats any non\u2011exact fit, and among non\u2011exact fits the one leaving the smallest\n    waste is chosen.\n\n    Args:\n        item: Size of the incoming item.\n        bins_remain_cap: 1\u2011D array with the remaining capacity of each existing bin.\n\n    Returns:\n        np.ndarray of the same shape as ``bins_remain_cap`` containing priority scores.\n    \"\"\"\n    # Remaining capacity after (theoretically) placing the item in each bin\n    leftover = bins_remain_cap - item\n\n    # Tolerance for floating\u2011point comparisons (treat very small leftovers as exact fits)\n    eps = 1e-9\n\n    # If the item does not fit, assign -inf (worst possible priority)\n    # If it fits exactly (|leftover| <= eps), assign 0 (highest finite priority)\n    # Otherwise assign -leftover (larger leftover -> lower (more negative) priority)\n    priorities = np.where(\n        leftover < -eps,\n        -np.inf,\n        np.where(\n            np.abs(leftover) <= eps,\n            0.0,\n            -leftover\n        )\n    )\n\n    # Ensure floating\u2011point dtype\n    return priorities.astype(float)",
    "response_id": 14,
    "obj": 4.048663741523748,
    "SLOC": 13.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute a sigmoid\u2011based priority score for placing ``item`` into each bin.\n\n    The score favours bins that will have a small residual capacity after\n    packing the item (tight fit).  The relationship between residual capacity\n    and priority is shaped by a logistic (sigmoid) function:\n\n        score = 1 / (1 + exp(-k * (\u03c4 - r\u0302)))\n\n    where:\n        r\u0302 = (remaining_capacity - item) / C\u0302  is the normalized residual,\n        C\u0302 = max(bins_remain_cap) + item         an estimate of the true bin\n                                                   capacity,\n        \u03c4  = tolerance (fraction of capacity we consider \u201ctight\u201d),\n        k  = steepness controlling how sharply the score drops when\n             residual exceeds the tolerance.\n\n    Infeasible bins (where the item does not fit) receive a very low priority\n    (\u2011inf) so they are never selected.\n\n    Parameters\n    ----------\n    item : float\n        Size of the item to be placed.\n    bins_remain_cap : np.ndarray\n        1\u2011D array containing the remaining free capacity of each bin.\n\n    Returns\n    -------\n    np.ndarray\n        Array of priority scores of the same shape as ``bins_remain_cap``.\n    \"\"\"\n    # Ensure proper dtype for vectorised arithmetic.\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # Compute remaining capacity after the candidate placement.\n    residual = bins_remain_cap - item\n\n    # Feasibility mask \u2013 bins where the item fits.\n    feasible = residual >= 0.0\n\n    # Estimate the original bin capacity.\n    # Adding ``item`` guarantees that an empty bin (full capacity) yields C\u0302 \u2248 bin_capacity.\n    est_capacity = np.max(bins_remain_cap) + item\n\n    # Normalised residual (fraction of estimated capacity left after placement).\n    # Clip to [0, 1] for numerical stability.\n    norm_residual = np.clip(residual / est_capacity, 0.0, 1.0)\n\n    # Sigmoid hyper\u2011parameters.\n    steepness = 12.0   # Controls the sharpness of the transition.\n    tolerance = 0.10   # Desired maximal leftover fraction (10\u202f% of capacity).\n\n    # Compute sigmoid\u2011based scores.\n    # High score when normalized residual \u2264 tolerance, low otherwise.\n    scores = np.full_like(bins_remain_cap, fill_value=-np.inf, dtype=float)\n    scores[feasible] = 1.0 / (1.0 + np.exp(-steepness * (tolerance - norm_residual[feasible])))\n\n    return scores",
    "response_id": 16,
    "obj": 4.048663741523748,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray,\n                temperature: float = 0.1) -> np.ndarray:\n    \"\"\"\n    Softmax\u2011Based Fit priority for online Bin Packing.\n\n    The idea is to assign a high priority to bins where the item fits tightly\n    (i.e., leaves little remaining capacity).  For each feasible bin we compute\n    a \u201clogit\u201d proportional to the negative slack (remaining capacity after\n    placement).  These logits are transformed with a softmax so that the best\n    fit gets the largest probability while still keeping a smooth preference\n    distribution.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins.\n    temperature : float, optional (default=0.1)\n        Smoothing parameter > 0.  Lower values make the priority more\n        deterministic (closer to a greedy best\u2011fit), while higher values spread\n        the priority more uniformly.\n\n    Returns\n    # --------\n    np.ndarray\n        Priority scores for each bin.  The vector sums to 1 across all feasible\n        bins (infeasible bins receive a priority of 0).  The bin with the\n        highest priority should be selected for the item.\n    \"\"\"\n    if temperature <= 0:\n        raise ValueError(\"temperature must be positive\")\n    # Ensure float dtype for calculations\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # Feasibility mask: item can only go into bins with enough remaining capacity\n    feasible = bins_remain_cap >= item\n\n    # Initialise priorities with zeros\n    priorities = np.zeros_like(bins_remain_cap, dtype=np.float64)\n\n    # If no bin can accommodate the item, return all zeros (the caller may open a new bin)\n    if not np.any(feasible):\n        return priorities\n\n    # Compute slack (unused capacity after placing the item) for feasible bins\n    slack = np.empty_like(bins_remain_cap, dtype=np.float64)\n    slack.fill(np.inf)                      # non\u2011feasible bins get infinite slack\n    slack[feasible] = bins_remain_cap[feasible] - item\n\n    # Logits: higher when slack is smaller (tighter fit)\n    #   logits = -slack / temperature   (more negative for larger slack)\n    logits = -slack / temperature\n\n    # Stabilize the softmax: subtract the maximum logit (ignoring -inf)\n    max_logit = np.max(logits[feasible])   # safe because we have at least one feasible bin\n    exp_logits = np.exp(logits - max_logit)  # infeasible entries become exp(-inf)=0\n\n    # Normalise to obtain a probability\u2011like priority vector\n    sum_exp = np.sum(exp_logits[feasible])\n    if sum_exp > 0:\n        priorities[feasible] = exp_logits[feasible] / sum_exp\n    # Infeasible bins already have priority 0\n\n    return priorities",
    "response_id": 19,
    "obj": 4.048663741523748,
    "SLOC": 19.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Return priority scores for bin placement using a Best\u2011Fit rule.\n\n    The strategy gives higher priority to bins that will have the smallest\n    remaining capacity after the item is inserted.  Bins that cannot\n    accommodate the item receive a very low score.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array holding the remaining capacity of each open bin.\n\n    Returns\n    -------\n    priorities : np.ndarray\n        An array of the same shape as ``bins_remain_cap`` with a numeric\n        priority for each bin.  The bin with the maximum priority will\n        be chosen by the caller.  Bins that cannot take the item will\n        get a score of ``-np.inf``.\n    \"\"\"\n    # Ensure the input is a float array (in case the caller passes ints)\n    bins = np.asarray(bins_remain_cap, dtype=float)\n    n = bins.size\n\n    # Fast path for an empty bin list \u2013 typical for the very first item.\n    if n == 0:\n        return np.empty(0, dtype=float)\n\n    # Initialise all priorities to a very low value.\n    priorities = np.full(n, -np.inf, dtype=float)\n\n    # Identify bins that can accommodate the item\n    can_place = bins >= item\n    if not np.any(can_place):\n        return priorities  # nothing can take the item\n\n    # Remaining capacity after the item would be inserted\n    leftover = bins[can_place] - item\n\n    # Small deterministic bias \u2013 earlier bins get slightly higher priority\n    # for bins with exactly the same leftover.  This keeps the behaviour\n    # reproducible across runs.\n    indices = np.arange(n)[can_place]\n    priorities[can_place] = -leftover - 1e-7 * indices\n\n    return priorities",
    "response_id": 21,
    "obj": 4.048663741523748,
    "SLOC": 13.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Softmax\u2011Based Fit priority function for online Bin Packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of each currently open bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin. Scores sum to 1 across bins that can host the\n        item (softmax probabilities). Infeasible bins receive a score of 0.\n    \n    Strategy\n    --------\n    1. Determine which bins can accommodate the item.\n    2. Compute the *waste* that would remain after inserting the item:\n          waste_i = bins_remain_cap[i] - item.\n    3. Transform waste into a fitness score with exponential decay:\n          score_i = exp(-\u03bb * waste_i)\n       where \u03bb controls the steepness of the softmax. \u03bb is set adaptively as\n       the inverse of the average waste among feasible bins.\n    4. Apply a softmax normalisation so tighter fits (smaller waste) obtain\n       higher priority.\n    \"\"\"\n    # Ensure a NumPy array of float for vectorised operations\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # ---------- 1. Feasibility ----------\n    feasible = caps >= item\n    if not np.any(feasible):\n        # No open bin can host the item \u2192 caller should open a new bin.\n        return np.zeros_like(caps)\n\n    # ---------- 2. Compute waste ----------\n    # waste for feasible bins, np.inf for infeasible (will be ignored later)\n    waste = np.where(feasible, caps - item, np.inf)\n\n    # ---------- 3. Adaptive \u03bb (softmax temperature) ----------\n    # Small epsilon avoids division by zero if waste is exactly zero.\n    eps = 1e-12\n    mean_waste = waste[feasible].mean()\n    lam = 1.0 / (mean_waste + eps)\n\n    # ---------- 4. Raw scores via exponential decay ----------\n    raw = np.exp(-lam * waste)\n    raw[~feasible] = 0.0  # enforce zero for infeasible bins\n\n    # ---------- 5. Softmax normalisation ----------\n    total = raw.sum()\n    if total > 0:\n        priorities = raw / total\n    else:\n        # Numerically unlikely fallback: uniform over feasible bins\n        priorities = np.where(feasible, 1.0 / feasible.sum(), 0.0)\n\n    return priorities",
    "response_id": 29,
    "obj": 4.048663741523748,
    "SLOC": 17.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\n# Single random generator \u2013 reused on every call (no reseeding)\n_rng = np.random.default_rng()\n\n# Simple running statistics of items seen so far (used for a lightweight look\u2011ahead)\n_item_count = 0\n_item_sum = 0.0\n\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid priority for the online Bin Packing Problem.\n\n    Combines a best\u2011fit score with:\n      \u2022 a controlled random perturbation (more randomness for small items),\n      \u2022 a deterministic tie\u2011breaker that favours lower\u2011index bins,\n      \u2022 a look\u2011ahead term based on the running average size of previously\n        observed items.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array with the remaining capacity of each existing bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (same shape as ``bins_remain_cap``).\n        Higher values are preferred; infeasible bins receive ``-np.inf``.\n    \"\"\"\n    global _item_count, _item_sum\n\n    # Normalise input\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # No existing bins \u2013 caller will open a new one.\n    if bins_remain_cap.size == 0:\n        _item_count += 1\n        _item_sum += item\n        return np.array([], dtype=float)\n\n    # --- 1: feasibility -------------------------------------------------\n    leftover = bins_remain_cap - item               # capacity that would remain\n    feasible = leftover >= 0                         # True for bins that can host the item\n\n    # Initialise with -inf (worst possible score)\n    priorities = np.full(bins_remain_cap.shape, -np.inf, dtype=float)\n\n    # If nothing fits, just record statistics and return.\n    if not np.any(feasible):\n        _item_count += 1\n        _item_sum += item\n        return priorities\n\n    # --- 2: best\u2011fit base score -----------------------------------------\n    # Higher score \u2194 tighter fit (smaller leftover)\n    base_score = -leftover[feasible]                # negative leftover\n\n    # --- 3: controlled randomness ----------------------------------------\n    # Rough estimate of the true bin capacity (most empty bin + current item)\n    approx_capacity = bins_remain_cap.max() + item\n    approx_capacity = max(approx_capacity, 1.0)     # guard against degenerate zero\n\n    # Item\u2011size ratio: larger items \u2192 less randomness\n    item_ratio = item / approx_capacity\n\n    # Scale random noise relative to the spread of leftover space\n    leftover_feas = leftover[feasible * 1]  # alias for readability\n    leftover_range = leftover_feas.max() - leftover_feas.min()\n    noise_scale = leftover_range * 0.05 * (1.0 - item_ratio)\n    noise_scale = max(noise_scale, 0.0)\n\n    random_noise = _rng.random(leftover_feas.shape) * noise_scale\n\n    # --- 4: look\u2011ahead using running average item size -------------------\n    if _item_count > 0:\n        avg_item = _item_sum / _item_count\n    else:\n        avg_item = item   # first item \u2013 fall back to its own size\n\n    # Small boost for bins that would still have room for a typical future item\n    # (positive if leftover > avg_item, negative otherwise)\n    future_weight = 0.02                         # tiny constant factor\n    future_adjust = (leftover_feas - avg_item) * future_weight\n\n    # --- 5: deterministic tie\u2011breaker ------------------------------------\n    # Slightly penalise higher indices to break exact ties deterministically\n    tie_breaker = -np.arange(bins_remain_cap.size, dtype=float) * 1e-12\n\n    # --- 6: combine all components ---------------------------------------\n    priorities[feasible] = (\n        base_score\n        + random_noise\n        + future_adjust\n        + tie_breaker[feasible]\n    )\n\n    # Record the current item for future look\u2011ahead calculations\n    _item_count += 1\n    _item_sum += item\n\n    return priorities",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 39.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response1.txt_stdout.txt",
    "code_path": "problem_iter2_code1.py",
    "code": "import numpy as np\n\n# Global random generator for optional tie\u2011breaking noise\n_rng = np.random.default_rng()\n\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    temperature: float = 0.1,\n    random_noise: bool = False,\n    noise_scale: float = 1e-12,\n) -> np.ndarray:\n    \"\"\"\n    Compute a softmax\u2011based priority vector for an online Bin Packing item.\n\n    The function prefers bins where the item fits tightly (small slack).\n    For each feasible bin we compute a logit proportional to the negative slack,\n    scaled by ``temperature``.  The logits are turned into a probability\u2011like\n    priority distribution via a numerically\u2011stable softmax.  Infeasible bins\n    receive a priority of 0.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    temperature : float, optional (default=0.1)\n        Controls the sharpness of the softmax.  Lower values make the decision\n        more deterministic (closer to a greedy Best\u2011Fit), while higher values\n        spread the probability mass more uniformly.\n    random_noise : bool, optional (default=False)\n        If True, a tiny uniform noise (\u00b1``noise_scale``) is added to the logits\n        of feasible bins to break ties in a reproducible stochastic way.\n    noise_scale : float, optional (default=1e-12)\n        Magnitude of the optional tie\u2011breaking noise.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (same shape as ``bins_remain_cap``).  The\n        scores sum to 1 across all feasible bins; infeasible bins have a score\n        of 0.  The bin with the highest priority should be selected for the item.\n    \"\"\"\n    if temperature <= 0.0:\n        raise ValueError(\"temperature must be a positive float\")\n\n    # Ensure we work with a NumPy array of float64 for numerical stability\n    caps = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # Feasibility mask: only bins with enough remaining capacity can hold the item\n    feasible = caps >= item\n\n    # Initialise priority vector with zeros (infeasible bins stay zero)\n    priorities = np.zeros_like(caps, dtype=np.float64)\n\n    # If no bin can accommodate the item, return the zero vector\n    if not np.any(feasible):\n        return priorities\n\n    # Compute slack (unused capacity after placing the item) for feasible bins\n    slack = caps[feasible] - item  # non\u2011negative by construction\n\n    # Logits: tighter fit (smaller slack) gets larger logit\n    logits = np.full_like(caps, -np.inf, dtype=np.float64)\n    logits[feasible] = -slack / temperature\n\n    # Optional tiny noise for stochastic tie\u2011breaking (deterministic otherwise)\n    if random_noise:\n        noise = _rng.uniform(-noise_scale, noise_scale, size=logits.shape)\n        logits[feasible] += noise[feasible]\n\n    # Numerically stable softmax\n    max_logit = np.max(logits[feasible])          # safe because feasible is non\u2011empty\n    exp_shifted = np.exp(logits - max_logit)     # exp(-inf) = 0 for infeasible bins\n    sum_exp = np.sum(exp_shifted)                # >0 because at least one entry is 1\n\n    # Normalise to obtain a probability\u2011like priority distribution\n    priorities = exp_shifted / sum_exp\n\n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 26.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response3.txt_stdout.txt",
    "code_path": "problem_iter2_code3.py",
    "code": "import numpy as np\n\n# Global random generator for reproducibility (used only for optional tie\u2011breaking noise)\n_rng = np.random.default_rng()\n\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    base_temperature: float = 0.1,\n    min_temperature: float = 1e-4,\n    eps: float = 1e-12,\n) -> np.ndarray:\n    \"\"\"\n    Adaptive Softmax\u2011Based priority for online Bin Packing.\n\n    The function scores each existing bin by how tightly the incoming ``item``\n    would fit (negative slack).  These scores are transformed by a softmax\n    whose temperature is *adaptively* tuned based on the spread of the slack\n    values:\n\n    * When the slack distribution is highly variable, the temperature stays\n      close to ``base_temperature`` \u2192 the algorithm behaves almost greedily,\n      favouring the tightest fit.\n    * When the slacks are similar (low variability), the temperature is raised\n      (up to roughly ``2 * base_temperature``) \u2192 the selection becomes more\n      stochastic, helping to avoid deterministic tie\u2011breaking.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins.\n    base_temperature : float, optional\n        Base temperature for the softmax (must be > 0). Default = 0.1.\n    min_temperature : float, optional\n        Lower bound for the adaptive temperature to avoid division by zero.\n        Default = 1e\u20114.\n    eps : float, optional\n        Small constant to avoid division by zero in coefficient\u2011of\u2011variation\n        calculation. Default = 1e\u201112.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin.  Infeasible bins receive a priority of 0.\n        The vector sums to 1 across all feasible bins (or to 0 if none are\n        feasible).\n    \"\"\"\n    if base_temperature <= 0:\n        raise ValueError(\"base_temperature must be positive\")\n\n    # Ensure input is a NumPy array of float64 for safe arithmetic\n    caps = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # No bins at all \u2192 return empty array\n    if caps.size == 0:\n        return caps\n\n    # Feasibility mask: bins that can accommodate the item\n    feasible = caps >= item\n\n    # Initialise priorities (0 for infeasible bins)\n    priorities = np.zeros_like(caps, dtype=np.float64)\n\n    # If nothing fits, simply return the zero vector (caller may open a new bin)\n    if not np.any(feasible):\n        return priorities\n\n    # Slack = unused capacity after placing the item (only for feasible bins)\n    slack = caps[feasible] - item  # shape = (num_feasible,)\n\n    # --- Adaptive temperature -------------------------------------------------\n    # Coefficient of variation (std / mean) measures spread of slack values\n    slack_mean = np.mean(slack)\n    slack_std = np.std(slack)\n\n    # Prevent division by zero when mean slack is (near) zero\n    cv = slack_std / (slack_mean + eps)\n\n    # Scale temperature: larger when CV is small (slacks similar),\n    # smaller when CV is large (slacks diverse).  Clamp cv to [0, 1] for stability.\n    cv_clamped = min(cv, 1.0)\n    # Scaling factor lies in [1, 2]; temperature in [base, 2*base]\n    scaling = 2.0 - cv_clamped\n    temperature = max(min_temperature, base_temperature * scaling)\n\n    # --- Softmax computation --------------------------------------------------\n    # Logits are higher for tighter fits (smaller slack)\n    logits = -slack / temperature  # shape = (num_feasible,)\n\n    # Optional tiny random perturbation to break exact ties without adding\n    # noticeable randomness (especially when slacks are identical)\n    if np.any(logits == logits.max()):\n        # Add uniform noise in a very small range to the maximal logits only\n        tie_mask = logits == logits.max()\n        logits[tie_mask] += _rng.uniform(-eps, eps, size=tie_mask.sum())\n\n    # Stabilize softmax by subtracting max logit (numerical stability)\n    max_logit = np.max(logits)\n    exp_logits = np.exp(logits - max_logit)\n\n    # Normalise to obtain a probability\u2011like priority distribution\n    sum_exp = np.sum(exp_logits)\n    if sum_exp > 0:\n        probs = exp_logits / sum_exp\n    else:\n        # Degenerate case (should not happen), fall back to uniform distribution\n        probs = np.full_like(exp_logits, 1.0 / exp_logits.size)\n\n    # Fill the priority vector for feasible bins\n    priorities[feasible] = probs\n\n    return priorities",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 36.0,
    "cyclomatic_complexity": 6.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response4.txt_stdout.txt",
    "code_path": "problem_iter2_code4.py",
    "code": "import numpy as np\n\n# Global RNG for tie\u2011breaking jitter (initialized once)\n_rng = np.random.default_rng()\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive sigmoid priority for online bin packing.\n\n    This function scores each existing bin based on the slack that would\n    remain after placing the incoming item. Bins with smaller slack (i.e.\n    tighter fit) receive higher scores. The scoring uses a logistic (sigmoid)\n    function whose inflection point is the median slack of all feasible bins\n    and whose slope adapts to the observed slack range. Infeasible bins\n    (remaining capacity < item) receive ``-np.inf`` to guarantee they are never\n    selected.\n\n    A tiny random jitter is added to break ties in a deterministic way.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (higher is better). The caller should\n        select the bin with the maximum priority.\n    \"\"\"\n    # Ensure input is a NumPy float array\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # Slack after placing the item (negative = infeasible)\n    slack = bins_remain_cap - item\n\n    # Feasibility mask: bins that can accommodate the item\n    feasible = slack >= 0.0\n\n    # Initialise priorities to -inf (infeasible by default)\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # If no bin can accommodate the item, return early\n    if not feasible.any():\n        return priorities\n\n    # Slack values for feasible bins only (non\u2011negative)\n    slack_feas = slack[feasible]\n\n    # Adaptive sigmoid parameters\n    median_slack = np.median(slack_feas)\n\n    # Slack range; avoid division by zero for near\u2011identical slacks\n    slack_range = slack_feas.max() - slack_feas.min()\n    if slack_range < 1e-12:\n        # All feasible bins have (almost) identical slack \u2192 flat sigmoid\n        alpha = 1.0\n    else:\n        # Scale alpha so the sigmoid transition spans roughly 8 slack units\n        alpha = 8.0 / slack_range\n\n    # Logistic function decreasing with slack; clamp exponent for stability\n    exp_arg = np.clip(alpha * (slack_feas - median_slack), -50.0, 50.0)\n    sigmoid_scores = 1.0 / (1.0 + np.exp(exp_arg))\n\n    # Add a tiny random jitter (\u22641e\u20119) for deterministic tie\u2011breaking\n    jitter = _rng.random(sigmoid_scores.shape) * 1e-9\n    sigmoid_scores = sigmoid_scores + jitter\n\n    # Populate the full priority vector\n    priorities[feasible] = sigmoid_scores\n\n    return priorities",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response7.txt_stdout.txt",
    "code_path": "problem_iter2_code7.py",
    "code": "import numpy as np\n\n# Global random generator (currently unused, kept for potential extensions)\n_rng = np.random.default_rng()\n\n# Hyperparameter controlling the influence of the item/remaining\u2011capacity ratio.\n# It can be tuned by an external reinforcement learning loop if desired.\n_alpha = 0.5\n\ndef set_alpha(alpha: float) -> None:\n    \"\"\"\n    Update the global weight `_alpha` that balances waste minimisation against\n    efficient utilisation of the remaining bin capacity.\n\n    Parameters\n    ----------\n    alpha : float\n        New value for `_alpha`. 0\u202f\u2264\u202falpha\u202f\u2264\u202f1, where 0 relies only on waste\n        and 1 relies only on the item-to-remaining-capacity ratio.\n    \"\"\"\n    global _alpha\n    _alpha = float(alpha)\n\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive\u2011\u03bb softmax priority with item\u2011size ratio weighting for online\n    bin packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of each currently open bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (probabilities) for each bin.  Bins that cannot\n        accommodate the item receive a score of -inf, which signals that a\n        new bin must be opened by the caller.  The global variable `_alpha`\n        controls the trade\u2011off between waste minimisation (softmax of waste)\n        and efficient utilisation (item\u2011to\u2011capacity ratio).  It can be tuned\n        externally, e.g. via a reinforcement learning loop.\n    \"\"\"\n    # Ensure a float array for vectorised operations\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Feasibility mask\n    feasible = caps >= item\n    if not np.any(feasible):\n        # No open bin can fit the item\n        return np.full_like(caps, -np.inf, dtype=float)\n\n    # Waste after placing the item\n    waste = caps - item\n    eps = 1e-12\n\n    # Adaptive \u03bb (inverse of mean waste)\n    mean_waste = waste[feasible].mean()\n    lam = 1.0 / (mean_waste + eps)\n\n    # Raw exponential decay based on waste\n    raw = np.exp(-lam * waste)\n    raw[~feasible] = 0.0\n\n    # Ratio of item size to remaining capacity\n    ratio = np.where(feasible, item / caps, 0.0)\n\n    # Combine raw waste\u2011based score with ratio weighting\n    combined = raw * (ratio ** _alpha)\n\n    # Softmax normalisation over feasible bins\n    max_val = combined[feasible].max()\n    exp_scores = np.exp(combined - max_val)\n    exp_scores[~feasible] = 0.0\n\n    total = exp_scores.sum()\n    if total > 0:\n        priorities = exp_scores / total\n    else:\n        # Fallback: uniform distribution over feasible bins\n        priorities = np.where(feasible, 1.0 / feasible.sum(), -np.inf)\n\n    return priorities",
    "response_id": 7,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response8.txt_stdout.txt",
    "code_path": "problem_iter2_code8.py",
    "code": "import numpy as np\n\n_rng = np.random.default_rng()\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Priority function for online Bin Packing that prioritizes exact fits,\n    then bins that leave the least leftover space, and breaks ties with\n    a tiny random perturbation.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array with the remaining capacity of each existing bin.\n\n    Returns\n    -------\n    np.ndarray\n        Array of priority scores for each bin.  The bin with the largest\n        score should be selected for packing the item.\n    \"\"\"\n    eps = 1e-9          # tolerance for floating\u2011point comparisons\n    eps_noise = 1e-6    # magnitude of random tie\u2011breaker\n\n    # Remaining capacity after hypothetically placing the item\n    leftover = bins_remain_cap - item\n\n    # Base priority: 0 for exact fit, otherwise negative leftover\n    base = np.where(\n        leftover < -eps,           # cannot fit\n        -np.inf,\n        np.where(\n            np.abs(leftover) <= eps,\n            0.0,\n            -leftover\n        )\n    )\n\n    # Small random noise to break ties\n    noise = _rng.uniform(-eps_noise, eps_noise, size=base.shape)\n\n    # Final priority\n    priority = base + noise\n\n    return priority.astype(float)",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response2.txt_stdout.txt",
    "code_path": "problem_iter4_code2.py",
    "code": "import numpy as np\n\n# Global random generator for reproducibility\n_rng = np.random.default_rng()\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive priority for online Bin Packing.\n\n    This function combines:\n      - An adaptive logistic score based on the slack after inserting the\n        current item.\n      - A blending of that score with the ratio of the item size to the\n        remaining capacity of the bin (encouraging tighter fits).\n      - A local\u2011search inspired penalty that prefers bins which, after the\n        insertion, do not become the new bin with the largest remaining\n        capacity (reducing fragmentation).\n      - A small random perturbation to break ties.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of the remaining capacity of each open bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin.  Bins that cannot accommodate the\n        item receive a priority of `-inf`.\n    \"\"\"\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # Slack after placing the item in each bin\n    slack = bins_remain_cap - item\n    feasible = slack >= 0.0\n\n    # Initialize with -inf for infeasible bins\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    if not feasible.any():\n        return priorities\n\n    # Slack values for feasible bins\n    slack_feas = slack[feasible]\n\n    # Adaptive logistic parameters\n    median_slack = np.median(slack_feas)\n    slack_range = slack_feas.max() - slack_feas.min()\n    if slack_range < 1e-12:\n        slack_range = 1e-12\n    alpha = 8.0 / slack_range  # controls steepness\n\n    # Logistic score: higher for bins that leave little slack\n    logistic_scores = 1.0 / (1.0 + np.exp(alpha * (slack_feas - median_slack)))\n\n    # Blend with item-to-remaining-capacity ratio (encourages tighter fits)\n    remaining_cap_feas = bins_remain_cap[feasible]\n    ratio = item / (remaining_cap_feas + 1e-12)  # values in (0, 1]\n    blended_scores = logistic_scores * ratio\n\n    # Local\u2011search penalty: minimize the maximum remaining capacity after\n    # insertion.  Lower penalty => better bin.\n    # Determine the global maximum remaining capacity before insertion\n    max_remaining = bins_remain_cap.max()\n    # Compute second maximum for bins that currently hold the maximum\n    sorted_cap = np.sort(bins_remain_cap)\n    second_max = sorted_cap[-2] if len(sorted_cap) >= 2 else sorted_cap[-1]\n    global_max_mask = bins_remain_cap == max_remaining\n\n    # For each feasible bin, compute the max remaining capacity after insertion\n    max_remaining_other = np.where(\n        global_max_mask[feasible], second_max, max_remaining\n    )\n    max_slack_after = np.maximum(max_remaining_other, slack_feas)\n    local_penalty = max_slack_after / max_remaining\n    local_scores = 1.0 - local_penalty  # lower penalty \u2192 higher score\n\n    # Combine the two signals with a weighted sum\n    w1, w2 = 0.6, 0.4\n    combined_scores = w1 * blended_scores + w2 * local_scores\n\n    # Add tiny random noise to break ties\n    noise = _rng.random(len(combined_scores)) * 1e-6\n    final_scores = combined_scores + noise\n\n    priorities[feasible] = final_scores\n    return priorities",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 33.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response3.txt_stdout.txt",
    "code_path": "problem_iter4_code3.py",
    "code": "import numpy as np\n\n# Global random generator (single instance)\n_rng = np.random.default_rng()\n\n# Exponential moving average parameters for item size statistics\n_alpha_ema = 0.1  # smoothing factor (0 < alpha <= 1)\n_ema_item_size = 0.0  # mean of seen items\n_ema_item_sq = 0.0    # mean of squared sizes\n_item_count = 0\n\n# Adaptive parameters\n_epsilon_factor = 0.05  # fraction of std used as exact\u2011fit tolerance\n_swap_weight = 0.05     # scaling for the swap\u2011improvement boost\n_exact_fit_offset = 1e9 # offset ensuring exact fits dominate priority\n\n\ndef _update_item_stats(item: float) -> None:\n    \"\"\"Update exponential moving averages of item size and squared size.\"\"\"\n    global _ema_item_size, _ema_item_sq, _item_count\n    _item_count += 1\n    # EMA update\n    _ema_item_size = (1 - _alpha_ema) * _ema_item_size + _alpha_ema * item\n    _ema_item_sq = (1 - _alpha_ema) * _ema_item_sq + _alpha_ema * (item * item)\n\n\ndef _current_std() -> float:\n    \"\"\"Return the current estimated standard deviation of item sizes.\"\"\"\n    var = _ema_item_sq - _ema_item_size * _ema_item_size\n    if var < 0.0:\n        var = 0.0\n    return np.sqrt(var)\n\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive priority for online Bin Packing.\n\n    The priority reflects three principles:\n    1. Exact fits are always preferred (highest priority).\n    2. Among non\u2011exact feasible bins, smaller leftover capacity is better.\n    3. A small boost is added when the leftover after placement is close to\n       the average item size observed so far (swap\u2011improvement heuristic).\n    Ties are broken with a tiny random perturbation.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the existing bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority values for each bin (same shape as ``bins_remain_cap``). The\n        caller should select the bin with the maximum priority.\n    \"\"\"\n    # ---- Update global statistics with the current item ----\n    _update_item_stats(item)\n\n    # Adaptive tolerance for exact fit detection\n    std = _current_std()\n    eps = max(1e-9, _epsilon_factor * std)\n\n    # Remaining capacity after (theoretically) placing the item\n    leftover = bins_remain_cap - item\n\n    # Feasibility mask (allow a tiny negative due to eps)\n    feasible = leftover >= -eps\n\n    # Initialise all priorities to -inf (infeasible bins)\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        # No feasible bin \u2013 return all -inf\n        return priorities\n\n    # Exact\u2011fit mask (within tolerance)\n    exact_fit = feasible & (np.abs(leftover) <= eps)\n\n    # ---- Exact fits: assign a huge offset plus a tiny random tie\u2011breaker ----\n    if np.any(exact_fit):\n        tie_noise = _rng.uniform(0.0, 1e-6, size=exact_fit.sum())\n        priorities[exact_fit] = _exact_fit_offset + tie_noise\n\n    # ---- Non\u2011exact feasible bins ----\n    non_exact = feasible & ~exact_fit\n    if np.any(non_exact):\n        # Primary component: negative leftover (smaller leftover \u2192 larger priority)\n        primary = -leftover[non_exact]\n\n        # Swap\u2011improvement boost:\n        # leftover close to the average item size is considered promising.\n        mean_size = _ema_item_size if _item_count > 0 else 1.0\n        distance_to_mean = np.abs(leftover[non_exact] - mean_size)\n        boost = _swap_weight / (distance_to_mean + eps)\n\n        # Combine components\n        combined = primary + boost\n\n        # Random tie\u2011breaker (very small)\n        combined += _rng.uniform(0.0, 1e-6, size=combined.shape)\n\n        priorities[non_exact] = combined\n\n    return priorities",
    "response_id": 3,
    "obj": 4.068607897885915,
    "SLOC": 23.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response5.txt_stdout.txt",
    "code_path": "problem_iter4_code5.py",
    "code": "import numpy as np\n\n_rng = np.random.default_rng()\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive Sigmoid Fit Score for online bin packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        Remaining capacities of the currently open bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores with the same shape as ``bins_remain_cap``.  Bins that\n        cannot accommodate the item receive a score of ``-inf`` so they are\n        never selected.  Feasible bins are scored by a sigmoid function that\n        favours bins leaving the smallest slack after placement.  A tiny\n        random perturbation is added to break ties in a deterministic but\n        stable way.\n    \"\"\"\n    # Ensure we work with a float array\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # Slack after placing the item in each bin (negative => infeasible)\n    slack = bins_remain_cap - item\n\n    # Feasibility mask\n    feasible = slack >= 0.0\n\n    # Default priority for infeasible bins: -inf\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # If no bin can accommodate the item, return the vector of -inf\n    if not feasible.any():\n        return priorities\n\n    # Slack values for feasible bins only\n    slack_feas = slack[feasible]\n\n    # Adaptive sigmoid parameters:\n    #   beta (median slack) sets the inflection point\n    #   alpha (slope) is chosen so that the sigmoid spans roughly 8 units\n    #   across the observed slack range\n    beta = np.median(slack_feas)\n\n    slack_range = slack_feas.max() - slack_feas.min() + 1e-12\n    alpha = 8.0 / slack_range\n\n    # Logistic decreasing in slack: smaller slack \u2192 higher score\n    scores = 1.0 / (1.0 + np.exp(alpha * (slack_feas - beta)))\n\n    # Tiny random noise to break ties (scaled by 1e-6)\n    noise = _rng.random(len(slack_feas)) * 1e-6\n    scores += noise\n\n    # Assign the scores back to the full priority array\n    priorities[feasible] = scores\n\n    return priorities",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response7.txt_stdout.txt",
    "code_path": "problem_iter4_code7.py",
    "code": "import numpy as np\n\n# Global RNG for optional random tie\u2011breaking\n_rng = np.random.default_rng()\n\n\ndef priority_v2(\n    item: float,\n    bins_remain_cap: np.ndarray,\n    temperature: float = 0.1,\n    epsilon: float = 1e-12,\n) -> np.ndarray:\n    \"\"\"\n    Compute a priority vector for the online Bin Packing problem.\n\n    Each bin receives a score proportional to how tightly the item would fit.\n    Scores are obtained by a temperature\u2011controlled softmax over the negative\n    slack (remaining capacity after placement).  Infeasible bins get a priority\n    of 0.  A small multiplicative random perturbation (controlled by ``epsilon``)\n    breaks ties and adds exploration.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the current bins.\n    temperature : float, optional\n        Softmax temperature > 0.  Smaller values make the decision more\n        deterministic (closer to classic Best\u2011Fit); larger values smooth the\n        distribution for more exploration.\n    epsilon : float, optional\n        Scale of random perturbation for tie\u2011breaking.  Set to 0 to disable.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin.  The vector sums to 1 over feasible bins,\n        while infeasible bins have priority 0.\n    \"\"\"\n    if temperature <= 0:\n        raise ValueError(\"temperature must be positive\")\n\n    # Ensure a NumPy float array for vectorised operations\n    caps = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # Feasibility mask: item can only be placed in bins with enough capacity\n    feasible = caps >= item\n\n    # Initialise priority vector with zeros (infeasible bins stay zero)\n    priorities = np.zeros_like(caps, dtype=np.float64)\n\n    # If no bin can accommodate the item, return the zero vector (caller may open a new bin)\n    if not np.any(feasible):\n        return priorities\n\n    # Slack = leftover capacity after placing the item (only for feasible bins)\n    slack = caps[feasible] - item  # non\u2011negative by construction\n\n    # Logits: tighter fits (smaller slack) get larger logits\n    logits = -slack / temperature\n\n    # Stabilise softmax: subtract max logit to avoid overflow\n    max_logit = np.max(logits)\n    stable_logits = logits - max_logit\n\n    # Softmax exponentials\n    exp_logits = np.exp(stable_logits)\n\n    # Optional random perturbation for tie\u2011breaking (multiplicative noise)\n    if epsilon > 0:\n        noise = 1.0 + epsilon * _rng.random(exp_logits.shape, dtype=np.float64)\n        exp_logits *= noise\n\n    # Normalise to obtain a probability\u2011like priority vector\n    sum_exp = exp_logits.sum()\n    if sum_exp > 0:\n        priorities[feasible] = exp_logits / sum_exp\n\n    return priorities",
    "response_id": 7,
    "obj": 4.048663741523748,
    "SLOC": 25.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response9.txt_stdout.txt",
    "code_path": "problem_iter4_code9.py",
    "code": "import numpy as np\n\n# Global random generator (single instance to avoid reseeding)\n_rng = np.random.default_rng()\n\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Hybrid random\u2011softmax priority for online Bin Packing.\n\n    This heuristic blends an exponential decay on the post\u2011placement waste\n    (tight\u2011fit preference) with a random perturbation and an item\u2011size weight.\n    The decay rate \u03bb adapts to the average waste of feasible bins, and the\n    score is further scaled by the fraction of the bin that the item will occupy.\n    Infeasible bins receive a priority of 0.  Scores are normalised to sum to 1\n    over feasible bins.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of each currently open bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (same shape as ``bins_remain_cap``).\n        The bin with the highest score should be selected for the item.\n    \"\"\"\n    # Ensure a NumPy float array for vectorised operations\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Edge case: no bins exist\n    if caps.size == 0:\n        return np.empty_like(caps)\n\n    # ---------- 1. Feasibility ----------\n    feasible = caps >= item\n    if not np.any(feasible):\n        # No open bin can host the item \u2013 caller may open a new bin.\n        return np.zeros_like(caps)\n\n    # ---------- 2. Waste computation ----------\n    waste = caps - item  # waste >= 0 for feasible bins\n\n    # ---------- 3. Adaptive \u03bb (based on mean waste) ----------\n    eps = 1e-12\n    mean_waste = waste[feasible].mean()\n    lam = 1.0 / (mean_waste + eps)\n\n    # ---------- 4. Base exponential decay (tight\u2011fit bias) ----------\n    raw = np.zeros_like(caps)\n    raw[feasible] = np.exp(-lam * waste[feasible])\n\n    # ---------- 5. Item\u2011size weighting ----------\n    # Prefer bins where the item occupies a larger fraction of the remaining capacity.\n    size_weight = np.zeros_like(caps)\n    size_weight[feasible] = item / caps[feasible]\n\n    # ---------- 6. Random perturbation ----------\n    # \u03b1 controls the strength of randomness (0 \u2192 deterministic, 1 \u2192 highly stochastic).\n    alpha = 0.3\n    rand_factor = np.ones_like(caps)\n    num_feasible = feasible.sum()\n    if num_feasible:\n        rand_factor[feasible] = 1.0 + alpha * _rng.random(num_feasible)\n\n    # ---------- 7. Combine components ----------\n    scores = raw * size_weight * rand_factor\n    scores[~feasible] = 0.0  # enforce zero for infeasible bins\n\n    # ---------- 8. Normalisation ----------\n    total = scores.sum()\n    if total > 0.0:\n        priorities = scores / total\n    else:\n        # Fallback: uniform distribution over feasible bins\n        priorities = np.where(feasible, 1.0 / num_feasible, 0.0)\n\n    return priorities",
    "response_id": 9,
    "obj": 4.108496210610296,
    "SLOC": 28.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive priority function for online Bin Packing.\n\n    Scores feasible bins (those with enough remaining capacity) using a\n    temperature\u2011controlled softmax over the negative slack (i.e., the space\n    that would remain after placing the item).  A tiny penalty is applied to\n    brand\u2011new bins (still at full capacity) to encourage reuse of older bins,\n    and a minuscule index\u2011based offset breaks ties deterministically\n    (lower index = older bin).\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities for each bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority score for each bin.  Higher values indicate a more preferred\n        bin; infeasible bins receive ``-np.inf``.\n    \"\"\"\n    # Compute remaining slack after placing the item\n    slack = bins_remain_cap - item\n\n    # Feasible bins have non\u2011negative slack\n    feasible_mask = slack >= 0\n\n    # Initialise priority array with -inf for infeasible bins\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # If no bin can accommodate the item, return early (caller may open a new bin)\n    if not np.any(feasible_mask):\n        return priorities\n\n    # Base score: negative slack (smaller slack \u2192 larger score)\n    base_score = -slack[feasible_mask]\n\n    # Adaptive temperature \u03bb: median slack among feasible bins (avoid zero)\n    median_slack = np.median(slack[feasible_mask])\n    temperature = max(median_slack, 1e-6)\n\n    # Softmax\u2011like transformation: larger for smaller slack\n    soft_scores = np.exp(base_score / temperature)\n\n    # Assign soft scores to the priority vector\n    priorities[feasible_mask] = soft_scores\n\n    # Estimate full bin capacity (maximum remaining capacity corresponds to an empty bin)\n    bin_capacity_est = np.max(bins_remain_cap)\n\n    # Identify brand\u2011new bins (still at full capacity) among feasible bins\n    new_bin_mask = np.isclose(bins_remain_cap, bin_capacity_est) & feasible_mask\n\n    # Apply a tiny penalty to new bins to encourage reuse of older bins\n    new_bin_penalty = 1e-3  # 0.1\u202f% reduction for new bins\n    priorities[new_bin_mask] *= (1.0 - new_bin_penalty)\n\n    # Deterministic tie\u2011\n    # breaker: older bins (lower index) get a minuscule boost\n    epsilon = 1e-9\n    indices = np.arange(bins_remain_cap.shape[0], dtype=float)\n    priorities[feasible_mask] -= epsilon * indices[feasible_mask]\n\n    return priorities",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 19.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response3.txt_stdout.txt",
    "code_path": "problem_iter6_code3.py",
    "code": "import numpy as np\n\n# ----------------------------------------------------------------------\n# Global state (shared across calls)\n# ----------------------------------------------------------------------\n_rng = np.random.default_rng()               # RNG for optional tiny noise\n_alpha_ema = 0.1                               # EMA smoothing factor\n_epsilon_factor = 0.05                         # Fraction of std used as exact\u2011fit tolerance\n_exact_fit_offset = 1e9                        # Large offset to guarantee exact fits win\n\n# EMA statistics for item sizes\n_ema_mean = 0.0\n_ema_sq = 0.0\n_item_count = 0\n\ndef _update_item_stats(item: float) -> None:\n    \"\"\"Update exponential moving averages of the item size.\"\"\"\n    global _ema_mean, _ema_sq, _item_count\n    _item_count += 1\n    _ema_mean = (1 - _alpha_ema) * _ema_mean + _alpha_ema * item\n    _ema_sq   = (1 - _alpha_ema) * _ema_sq   + _alpha_ema * (item * item)\n\ndef _current_std() -> float:\n    \"\"\"Return the current estimated standard deviation of seen items.\"\"\"\n    var = _ema_sq - _ema_mean * _ema_mean\n    # Numerical safety\n    if var < 0.0:\n        var = 0.0\n    return np.sqrt(var)\n\n# ----------------------------------------------------------------------\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive priority for online bin packing.\n\n    Scoring principles\n    ------------------\n    1. Exact fits (within a tolerance derived from EMA std) receive a huge\n       offset, ensuring they are always preferred.\n    2. Among feasible non\u2011exact bins, a softmax over the negative slack\n       (remaining capacity after placement) is used.  The temperature is the\n       median slack of all feasible bins, making the scoring adaptive to the\n       current distribution of free space.\n    3. Brand\u2011new bins (still at full capacity) are penalised slightly to\n       encourage reuse of older bins.\n    4. Deterministic tie\u2011breaking: lower\u2011index bins receive a minuscule\n       boost (by subtracting a tiny epsilon * index).\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of each bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority values (same shape as ``bins_remain_cap``).  Infeasible bins\n        receive ``-np.inf``.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # 1. Update EMA statistics for the current item\n    # ------------------------------------------------------------------\n    _update_item_stats(item)\n\n    # Tolerance for exact\u2011fit detection (based on EMA std)\n    std = _current_std()\n    eps = max(1e-9, _epsilon_factor * std)\n\n    # ------------------------------------------------------------------\n    # 2. Compute slack (remaining capacity after placement)\n    # ------------------------------------------------------------------\n    slack = bins_remain_cap - item                     # may be negative\n    feasible = slack >= -eps                           # allow tiny negative due to eps\n\n    # Initialise all priorities to -inf (infeasible bins)\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        # No bin can accommodate the item \u2013 caller may open a new bin\n        return priorities\n\n    # ------------------------------------------------------------------\n    # 3. Exact\u2011fit handling\n    # ------------------------------------------------------------------\n    exact_fit = feasible & (np.abs(slack) <= eps)\n\n    if np.any(exact_fit):\n        # Deterministic tie\u2011breaker: lower index gets a tiny boost\n        idx_exact = np.nonzero(exact_fit)[0].astype(float)\n        tiny_eps = 1e-12\n        priorities[exact_fit] = _exact_fit_offset - tiny_eps * idx_exact\n\n    # ------------------------------------------------------------------\n    # 4. Scoring of non\u2011exact feasible bins\n    # ------------------------------------------------------------------\n    non_exact = feasible & ~exact_fit\n    if np.any(non_exact):\n        # Base score: negative slack (smaller slack \u2192 larger score)\n        base_score = -slack[non_exact]\n\n        # Adaptive temperature: median slack among all feasible bins\n        median_slack = np.median(slack[feasible])\n        temperature = max(median_slack, 1e-6)        # avoid division by zero\n\n        # Softmax\u2011like transformation (larger for smaller slack)\n        soft_scores = np.exp(base_score / temperature)\n\n        # Assign soft scores\n        priorities[non_exact] = soft_scores\n\n        # --------------------------------------------------------------\n        # 4a. Penalise brand\u2011new bins (still at full capacity)\n        # --------------------------------------------------------------\n        # Estimate bin capacity as the maximum remaining capacity observed.\n        # All bins are assumed to have identical capacity.\n        bin_capacity_est = np.max(bins_remain_cap)\n        new_bin_mask = np.isclose(bins_remain_cap, bin_capacity_est) & non_exact\n        if np.any(new_bin_mask):\n            new_bin_penalty = 0.001   # 0.1\u202f% reduction\n            priorities[new_bin_mask] *= (1.0 - new_bin_penalty)\n\n        # --------------------------------------------------------------\n        # 4b. Deterministic tie\u2011breaker (lower index gets a tiny boost)\n        # --------------------------------------------------------------\n        idx_non_exact = np.nonzero(non_exact)[0].astype(float)\n        tie_eps = 1e-12\n        priorities[non_exact] -= tie_eps * idx_non_exact\n\n    return priorities",
    "response_id": 3,
    "obj": 4.068607897885915,
    "SLOC": 30.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  }
]