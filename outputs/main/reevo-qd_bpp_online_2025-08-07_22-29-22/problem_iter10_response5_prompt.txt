{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# ----------------------------------------------------------------------\n# Global state (shared across calls)\n# ----------------------------------------------------------------------\n_rng = np.random.default_rng()               # RNG for optional tiny noise\n_alpha_ema = 0.1                               # EMA smoothing factor\n_epsilon_factor = 0.05                         # Fraction of std used as exact\u2011fit tolerance\n_exact_fit_offset = 1e9                        # Large offset to guarantee exact fits win\n\n# EMA statistics for item sizes\n_ema_mean = 0.0\n_ema_sq = 0.0\n_item_count = 0\n\n    \"\"\"Update exponential moving averages of the item size.\"\"\"\n    global _ema_mean, _ema_sq, _item_count\n    _item_count += 1\n    _ema_mean = (1 - _alpha_ema) * _ema_mean + _alpha_ema * item\n    _ema_sq   = (1 - _alpha_ema) * _ema_sq   + _alpha_ema * (item * item)\n\n    \"\"\"Return the current estimated standard deviation of seen items.\"\"\"\n    var = _ema_sq - _ema_mean * _ema_mean\n    # Numerical safety\n    if var < 0.0:\n        var = 0.0\n    return np.sqrt(var)\n\n# ----------------------------------------------------------------------\n    \"\"\"\n    Adaptive priority for online bin packing.\n\n    Scoring principles\n    ------------------\n    1. Exact fits (within a tolerance derived from EMA std) receive a huge\n       offset, ensuring they are always preferred.\n    2. Among feasible non\u2011exact bins, a softmax over the negative slack\n       (remaining capacity after placement) is used.  The temperature is the\n       median slack of all feasible bins, making the scoring adaptive to the\n       current distribution of free space.\n    3. Brand\u2011new bins (still at full capacity) are penalised slightly to\n       encourage reuse of older bins.\n    4. Deterministic tie\u2011breaking: lower\u2011index bins receive a minuscule\n       boost (by subtracting a tiny epsilon * index).\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of each bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority values (same shape as ``bins_remain_cap``).  Infeasible bins\n        receive ``-np.inf``.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # 1. Update EMA statistics for the current item\n    # ------------------------------------------------------------------\n    _update_item_stats(item)\n\n    # Tolerance for exact\u2011fit detection (based on EMA std)\n    std = _current_std()\n    eps = max(1e-9, _epsilon_factor * std)\n\n    # ------------------------------------------------------------------\n    # 2. Compute slack (remaining capacity after placement)\n    # ------------------------------------------------------------------\n    slack = bins_remain_cap - item                     # may be negative\n    feasible = slack >= -eps                           # allow tiny negative due to eps\n\n    # Initialise all priorities to -inf (infeasible bins)\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        # No bin can accommodate the item \u2013 caller may open a new bin\n        return priorities\n\n    # ------------------------------------------------------------------\n    # 3. Exact\u2011fit handling\n    # ------------------------------------------------------------------\n    exact_fit = feasible & (np.abs(slack) <= eps)\n\n    if np.any(exact_fit):\n        # Deterministic tie\u2011breaker: lower index gets a tiny boost\n        idx_exact = np.nonzero(exact_fit)[0].astype(float)\n        tiny_eps = 1e-12\n        priorities[exact_fit] = _exact_fit_offset - tiny_eps * idx_exact\n\n    # ------------------------------------------------------------------\n    # 4. Scoring of non\u2011exact feasible bins\n    # ------------------------------------------------------------------\n    non_exact = feasible & ~exact_fit\n    if np.any(non_exact):\n        # Base score: negative slack (smaller slack \u2192 larger score)\n        base_score = -slack[non_exact]\n\n        # Adaptive temperature: median slack among all feasible bins\n        median_slack = np.median(slack[feasible])\n        temperature = max(median_slack, 1e-6)        # avoid division by zero\n\n        # Softmax\u2011like transformation (larger for smaller slack)\n        soft_scores = np.exp(base_score / temperature)\n\n        # Assign soft scores\n        priorities[non_exact] = soft_scores\n\n        # --------------------------------------------------------------\n        # 4a. Penalise brand\u2011new bins (still at full capacity)\n        # --------------------------------------------------------------\n        # Estimate bin capacity as the maximum remaining capacity observed.\n        # All bins are assumed to have identical capacity.\n        bin_capacity_est = np.max(bins_remain_cap)\n        new_bin_mask = np.isclose(bins_remain_cap, bin_capacity_est) & non_exact\n        if np.any(new_bin_mask):\n            new_bin_penalty = 0.001   # 0.1\u202f% reduction\n            priorities[new_bin_mask] *= (1.0 - new_bin_penalty)\n\n        # --------------------------------------------------------------\n        # 4b. Deterministic tie\u2011breaker (lower index gets a tiny boost)\n        # --------------------------------------------------------------\n        idx_non_exact = np.nonzero(non_exact)[0].astype(float)\n        tie_eps = 1e-12\n        priorities[non_exact] -= tie_eps * idx_non_exact\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Global random generator for optional tie\u2011breaking noise\n_rng = np.random.default_rng()\n\n# ---------- Minimal EMA for item\u2011size statistics ----------\n_alpha_ema = 0.1          # smoothing factor\n_ema_item_size = 0.0      # exponential moving average of item size\n_ema_item_sq = 0.0        # exponential moving average of squared size\n_item_count = 0           # number of observed items\n\n\n    \"\"\"Update EMA statistics with a newly observed item.\"\"\"\n    global _ema_item_size, _ema_item_sq, _item_count\n    _item_count += 1\n    _ema_item_size = (1 - _alpha_ema) * _ema_item_size + _alpha_ema * item\n    _ema_item_sq = (1 - _alpha_ema) * _ema_item_sq + _alpha_ema * (item * item)\n\n\n    \"\"\"Return the current estimated standard deviation of item sizes.\"\"\"\n    var = _ema_item_sq - _ema_item_size ** 2\n    var = max(var, 0.0)          # guard against tiny negative due to rounding\n    return np.sqrt(var)\n\n\n    \"\"\"\n    Compute a small tolerance for feasibility checks.\n    The tolerance grows with the observed variability of item sizes.\n    \"\"\"\n    std = _current_std()\n    # 1\u202f% of the standard deviation (or a tiny absolute floor) is used as epsilon\n    return max(1e-9, 0.01 * std)\n\n\n    item: float,\n    bins_remain_cap: np.ndarray,\n    *,\n    temperature: float = 0.1,\n    random_noise: bool = False,\n    noise_scale: float = 1e-12,\n) -> np.ndarray:\n    \"\"\"\n    Softmax\u2011based priority for online Bin Packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the currently open bins.\n    temperature : float, optional (default=0.1)\n        Controls the sharpness of the softmax.  Lower values make the decision\n        more deterministic (approaching a greedy Best\u2011Fit), while higher values\n        spread the probability mass more uniformly.\n    random_noise : bool, optional (default=False)\n        If True, a tiny uniform noise (\u00b1``noise_scale``) is added to the logits\n        of feasible bins to break ties stochastically.\n    noise_scale : float, optional (default=1e-12)\n        Amplitude of the optional tie\u2011breaking noise.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (same shape as ``bins_remain_cap``).  Infeasible\n        bins receive a priority of 0, and the scores of feasible bins sum to 1.\n    \"\"\"\n    if temperature <= 0.0:\n        raise ValueError(\"temperature must be a positive float\")\n\n    # Update EMA statistics (used only for a tiny feasibility tolerance)\n    _update_item_stats(item)\n\n    # Convert input to a float64 NumPy array for stable arithmetic\n    caps = np.asarray(bins_remain_cap, dtype=np.float64)\n\n    # Feasibility mask with a small tolerance to guard against floating\u2011point errors\n    eps = _tolerance()\n    feasible = caps >= item - eps\n\n    # Initialise priority vector (zeros for infeasible bins)\n    priorities = np.zeros_like(caps, dtype=np.float64)\n\n    if not np.any(feasible):\n        # No bin can accommodate the item \u2013 return the zero vector\n        return priorities\n\n    # Slack (unused capacity) after placing the item in each feasible bin\n    slack = caps[feasible] - item  # non\u2011negative by construction\n\n    # Logits: tighter fit (smaller slack) yields a larger logit\n    logits = np.full_like(caps, -np.inf, dtype=np.float64)\n    logits[feasible] = -slack / temperature\n\n    # Optional tiny noise for stochastic tie\u2011breaking\n    if random_noise:\n        noise = _rng.uniform(-noise_scale, noise_scale, size=slack.shape)\n        logits[feasible] += noise\n\n    # Numerically stable softmax\n    max_logit = np.max(logits[feasible])          # safe: feasible is non\u2011empty\n    shifted = logits - max_logit                  # -inf stays -inf for infeasible bins\n    exp_shifted = np.exp(shifted)                 # exp(-inf) = 0\n    sum_exp = np.sum(exp_shifted)                # >0 because at least one entry is 1\n    priorities = exp_shifted / sum_exp\n\n    return priorities\n\n[Reflection]\nExact\u2011fit offset. Softmax slack with adaptive temperature. Penalize brand\u2011new bins. EMA tolerance.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}