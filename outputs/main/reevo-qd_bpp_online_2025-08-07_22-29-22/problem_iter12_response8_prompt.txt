{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# ----------------------------------------------------------------------\n# Global state (shared across calls)\n# ----------------------------------------------------------------------\n_rng = np.random.default_rng()               # RNG for optional tiny noise\n_alpha_ema = 0.1                               # EMA smoothing factor\n_epsilon_factor = 0.05                         # Fraction of std used as exact\u2011fit tolerance\n_exact_fit_offset = 1e9                        # Large offset to guarantee exact fits win\n\n# EMA statistics for item sizes\n_ema_mean = 0.0\n_ema_sq = 0.0\n_item_count = 0\n\n    \"\"\"Update exponential moving averages of the item size.\"\"\"\n    global _ema_mean, _ema_sq, _item_count\n    _item_count += 1\n    _ema_mean = (1 - _alpha_ema) * _ema_mean + _alpha_ema * item\n    _ema_sq   = (1 - _alpha_ema) * _ema_sq   + _alpha_ema * (item * item)\n\n    \"\"\"Return the current estimated standard deviation of seen items.\"\"\"\n    var = _ema_sq - _ema_mean * _ema_mean\n    # Numerical safety\n    if var < 0.0:\n        var = 0.0\n    return np.sqrt(var)\n\n# ----------------------------------------------------------------------\n    \"\"\"\n    Adaptive priority for online bin packing.\n\n    Scoring principles\n    ------------------\n    1. Exact fits (within a tolerance derived from EMA std) receive a huge\n       offset, ensuring they are always preferred.\n    2. Among feasible non\u2011exact bins, a softmax over the negative slack\n       (remaining capacity after placement) is used.  The temperature is the\n       median slack of all feasible bins, making the scoring adaptive to the\n       current distribution of free space.\n    3. Brand\u2011new bins (still at full capacity) are penalised slightly to\n       encourage reuse of older bins.\n    4. Deterministic tie\u2011breaking: lower\u2011index bins receive a minuscule\n       boost (by subtracting a tiny epsilon * index).\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of each bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority values (same shape as ``bins_remain_cap``).  Infeasible bins\n        receive ``-np.inf``.\n    \"\"\"\n    # ------------------------------------------------------------------\n    # 1. Update EMA statistics for the current item\n    # ------------------------------------------------------------------\n    _update_item_stats(item)\n\n    # Tolerance for exact\u2011fit detection (based on EMA std)\n    std = _current_std()\n    eps = max(1e-9, _epsilon_factor * std)\n\n    # ------------------------------------------------------------------\n    # 2. Compute slack (remaining capacity after placement)\n    # ------------------------------------------------------------------\n    slack = bins_remain_cap - item                     # may be negative\n    feasible = slack >= -eps                           # allow tiny negative due to eps\n\n    # Initialise all priorities to -inf (infeasible bins)\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        # No bin can accommodate the item \u2013 caller may open a new bin\n        return priorities\n\n    # ------------------------------------------------------------------\n    # 3. Exact\u2011fit handling\n    # ------------------------------------------------------------------\n    exact_fit = feasible & (np.abs(slack) <= eps)\n\n    if np.any(exact_fit):\n        # Deterministic tie\u2011breaker: lower index gets a tiny boost\n        idx_exact = np.nonzero(exact_fit)[0].astype(float)\n        tiny_eps = 1e-12\n        priorities[exact_fit] = _exact_fit_offset - tiny_eps * idx_exact\n\n    # ------------------------------------------------------------------\n    # 4. Scoring of non\u2011exact feasible bins\n    # ------------------------------------------------------------------\n    non_exact = feasible & ~exact_fit\n    if np.any(non_exact):\n        # Base score: negative slack (smaller slack \u2192 larger score)\n        base_score = -slack[non_exact]\n\n        # Adaptive temperature: median slack among all feasible bins\n        median_slack = np.median(slack[feasible])\n        temperature = max(median_slack, 1e-6)        # avoid division by zero\n\n        # Softmax\u2011like transformation (larger for smaller slack)\n        soft_scores = np.exp(base_score / temperature)\n\n        # Assign soft scores\n        priorities[non_exact] = soft_scores\n\n        # --------------------------------------------------------------\n        # 4a. Penalise brand\u2011new bins (still at full capacity)\n        # --------------------------------------------------------------\n        # Estimate bin capacity as the maximum remaining capacity observed.\n        # All bins are assumed to have identical capacity.\n        bin_capacity_est = np.max(bins_remain_cap)\n        new_bin_mask = np.isclose(bins_remain_cap, bin_capacity_est) & non_exact\n        if np.any(new_bin_mask):\n            new_bin_penalty = 0.001   # 0.1\u202f% reduction\n            priorities[new_bin_mask] *= (1.0 - new_bin_penalty)\n\n        # --------------------------------------------------------------\n        # 4b. Deterministic tie\u2011breaker (lower index gets a tiny boost)\n        # --------------------------------------------------------------\n        idx_non_exact = np.nonzero(non_exact)[0].astype(float)\n        tie_eps = 1e-12\n        priorities[non_exact] -= tie_eps * idx_non_exact\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Global random generator for tie-breaking noise\n_rng = np.random.default_rng()\n\n    \"\"\"Compute a priority vector for online bin packing using a temperature\u2011controlled softmax.\n\n    The priority vector favours bins with the smallest slack (i.e. where the item\n    fits most tightly).  A low temperature drives the distribution toward a\n    deterministic best\u2011fit selection, while a higher temperature spreads the\n    mass more evenly.  A very small uniform noise can be added to break ties\n    reproducibly.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities for the existing bins.\n    temperature : float, optional (default=0.1)\n        Softmax temperature.  Must be positive.  Very small values approximate\n        a deterministic best\u2011fit strategy.\n    noise_scale : float, optional (default=1e-12)\n        Magnitude of a tiny uniform noise added to logits for tie\u2011breaking.\n    rng : np.random.Generator, optional\n        Random number generator to use for the noise.  If omitted, a global\n        generator is used.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin.  Infeasible bins receive a score of 0.\n    \"\"\"\n    if temperature <= 0.0:\n        raise ValueError(\"temperature must be a positive float\")\n\n    caps = np.asarray(bins_remain_cap, dtype=np.float64)\n    feasible = caps >= item\n    priorities = np.zeros_like(caps)\n\n    # No bin can accommodate the item\n    if not np.any(feasible):\n        return priorities\n\n    # Indices of feasible bins in flattened view\n    feasible_idx = np.flatnonzero(feasible)\n\n    # Slack for feasible bins (unused capacity after placing the item)\n    slack = caps[feasible] - item\n\n    # Deterministic best\u2011fit when temperature is negligible\n    eps = 1e-12\n    if temperature < eps:\n        best_local = np.argmin(slack)\n        best_global = feasible_idx[best_local]\n        priorities.flat[best_global] = 1.0\n        return priorities\n\n    # Logits: tighter fit gets a higher logit (negative slack scaled by temperature)\n    logits = np.full_like(caps, -np.inf, dtype=np.float64)\n    logits[feasible] = -slack / temperature\n\n    # Optional tie\u2011breaking noise\n    if rng is None:\n        rng = _rng\n    if noise_scale > 0.0:\n        noise = rng.uniform(-noise_scale, noise_scale, size=caps.shape)\n        logits[feasible] += noise[feasible]\n\n    # Numerically stable softmax\n    max_logit = np.max(logits[feasible])\n    exp_shifted = np.exp(logits - max_logit)\n    sum_exp = np.sum(exp_shifted)\n\n    # Fallback to best\u2011fit if numerical issues arise\n    if sum_exp <= 0.0:\n        best_local = np.argmin(slack)\n        best_global = feasible_idx[best_local]\n        priorities.flat[best_global] = 1.0\n        return priorities\n\n    priorities = exp_shifted / sum_exp\n    return priorities\n\n[Reflection]\nUse temperature\u2011controlled softmax, minimal state, stable softmax, tiny random tie\u2011break; avoid EMA, large offsets, extra penalties.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}