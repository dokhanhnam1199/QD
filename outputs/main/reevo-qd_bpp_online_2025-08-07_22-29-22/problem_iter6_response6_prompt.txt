{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Global random generator (single instance)\n_rng = np.random.default_rng()\n\n# Exponential moving average parameters for item size statistics\n_alpha_ema = 0.1  # smoothing factor (0 < alpha <= 1)\n_ema_item_size = 0.0  # mean of seen items\n_ema_item_sq = 0.0    # mean of squared sizes\n_item_count = 0\n\n# Adaptive parameters\n_epsilon_factor = 0.05  # fraction of std used as exact\u2011fit tolerance\n_swap_weight = 0.05     # scaling for the swap\u2011improvement boost\n_exact_fit_offset = 1e9 # offset ensuring exact fits dominate priority\n\n\n    \"\"\"Update exponential moving averages of item size and squared size.\"\"\"\n    global _ema_item_size, _ema_item_sq, _item_count\n    _item_count += 1\n    # EMA update\n    _ema_item_size = (1 - _alpha_ema) * _ema_item_size + _alpha_ema * item\n    _ema_item_sq = (1 - _alpha_ema) * _ema_item_sq + _alpha_ema * (item * item)\n\n\n    \"\"\"Return the current estimated standard deviation of item sizes.\"\"\"\n    var = _ema_item_sq - _ema_item_size * _ema_item_size\n    if var < 0.0:\n        var = 0.0\n    return np.sqrt(var)\n\n\n    \"\"\"\n    Adaptive priority for online Bin Packing.\n\n    The priority reflects three principles:\n    1. Exact fits are always preferred (highest priority).\n    2. Among non\u2011exact feasible bins, smaller leftover capacity is better.\n    3. A small boost is added when the leftover after placement is close to\n       the average item size observed so far (swap\u2011improvement heuristic).\n    Ties are broken with a tiny random perturbation.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the existing bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority values for each bin (same shape as ``bins_remain_cap``). The\n        caller should select the bin with the maximum priority.\n    \"\"\"\n    # ---- Update global statistics with the current item ----\n    _update_item_stats(item)\n\n    # Adaptive tolerance for exact fit detection\n    std = _current_std()\n    eps = max(1e-9, _epsilon_factor * std)\n\n    # Remaining capacity after (theoretically) placing the item\n    leftover = bins_remain_cap - item\n\n    # Feasibility mask (allow a tiny negative due to eps)\n    feasible = leftover >= -eps\n\n    # Initialise all priorities to -inf (infeasible bins)\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        # No feasible bin \u2013 return all -inf\n        return priorities\n\n    # Exact\u2011fit mask (within tolerance)\n    exact_fit = feasible & (np.abs(leftover) <= eps)\n\n    # ---- Exact fits: assign a huge offset plus a tiny random tie\u2011breaker ----\n    if np.any(exact_fit):\n        tie_noise = _rng.uniform(0.0, 1e-6, size=exact_fit.sum())\n        priorities[exact_fit] = _exact_fit_offset + tie_noise\n\n    # ---- Non\u2011exact feasible bins ----\n    non_exact = feasible & ~exact_fit\n    if np.any(non_exact):\n        # Primary component: negative leftover (smaller leftover \u2192 larger priority)\n        primary = -leftover[non_exact]\n\n        # Swap\u2011improvement boost:\n        # leftover close to the average item size is considered promising.\n        mean_size = _ema_item_size if _item_count > 0 else 1.0\n        distance_to_mean = np.abs(leftover[non_exact] - mean_size)\n        boost = _swap_weight / (distance_to_mean + eps)\n\n        # Combine components\n        combined = primary + boost\n\n        # Random tie\u2011breaker (very small)\n        combined += _rng.uniform(0.0, 1e-6, size=combined.shape)\n\n        priorities[non_exact] = combined\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Compute a sigmoid\u2011based priority score for placing ``item`` into each bin.\n\n    The score favours bins that will have a small residual capacity after\n    packing the item (tight fit).  The relationship between residual capacity\n    and priority is shaped by a logistic (sigmoid) function:\n\n        score = 1 / (1 + exp(-k * (\u03c4 - r\u0302)))\n\n    where:\n        r\u0302 = (remaining_capacity - item) / C\u0302  is the normalized residual,\n        C\u0302 = max(bins_remain_cap) + item         an estimate of the true bin\n                                                   capacity,\n        \u03c4  = tolerance (fraction of capacity we consider \u201ctight\u201d),\n        k  = steepness controlling how sharply the score drops when\n             residual exceeds the tolerance.\n\n    Infeasible bins (where the item does not fit) receive a very low priority\n    (\u2011inf) so they are never selected.\n\n    Parameters\n    ----------\n    item : float\n        Size of the item to be placed.\n    bins_remain_cap : np.ndarray\n        1\u2011D array containing the remaining free capacity of each bin.\n\n    Returns\n    -------\n    np.ndarray\n        Array of priority scores of the same shape as ``bins_remain_cap``.\n    \"\"\"\n    # Ensure proper dtype for vectorised arithmetic.\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # Compute remaining capacity after the candidate placement.\n    residual = bins_remain_cap - item\n\n    # Feasibility mask \u2013 bins where the item fits.\n    feasible = residual >= 0.0\n\n    # Estimate the original bin capacity.\n    # Adding ``item`` guarantees that an empty bin (full capacity) yields C\u0302 \u2248 bin_capacity.\n    est_capacity = np.max(bins_remain_cap) + item\n\n    # Normalised residual (fraction of estimated capacity left after placement).\n    # Clip to [0, 1] for numerical stability.\n    norm_residual = np.clip(residual / est_capacity, 0.0, 1.0)\n\n    # Sigmoid hyper\u2011parameters.\n    steepness = 12.0   # Controls the sharpness of the transition.\n    tolerance = 0.10   # Desired maximal leftover fraction (10\u202f% of capacity).\n\n    # Compute sigmoid\u2011based scores.\n    # High score when normalized residual \u2264 tolerance, low otherwise.\n    scores = np.full_like(bins_remain_cap, fill_value=-np.inf, dtype=float)\n    scores[feasible] = 1.0 / (1.0 + np.exp(-steepness * (tolerance - norm_residual[feasible])))\n\n    return scores\n\n[Reflection]\nNormalize leftover; apply smooth sigmoid; avoid global mutable stats; use tiny random tie\u2011breakers for deterministic ties.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}