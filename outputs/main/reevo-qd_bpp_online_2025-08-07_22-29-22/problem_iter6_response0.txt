```python
import numpy as np

# ------------------- Global state & parameters ------------------- #
_rng = np.random.default_rng()

# Exponential moving average for item size statistics
_alpha_ema = 0.1               # smoothing factor (0 < α ≤ 1)
_ema_item_size = 0.0           # mean of seen items
_ema_item_sq = 0.0             # mean of squared item sizes
_item_count = 0                # number of processed items

# Heuristic parameters
_epsilon_factor = 0.05         # tolerance for “exact” fit (fraction of std)
_alpha_random = 0.02           # strength of random tie‑breaker
_exact_fit_offset = 1e9        # huge offset to dominate exact fits


def _update_item_stats(item: float) -> None:
    """Update EMA statistics for the stream of item sizes."""
    global _ema_item_size, _ema_item_sq, _item_count
    _item_count += 1
    _ema_item_size = (1 - _alpha_ema) * _ema_item_size + _alpha_ema * item
    _ema_item_sq = (1 - _alpha_ema) = _ema_item_sq? No.

We need to correct: The line "_ema_item_sq = (1 - _alpha_ema) * _ema_item_sq + _alpha_ema * (item * item)". Let's write that.

Let's continue.

```python
def _update_item_stats(item: float) -> None:
    """Update EMA statistics for the stream of item sizes."""
    global _ema_item_size, _ema_item_sq, _item_count
    _item_count += 1
    _ema_item_size = (1 - _alpha_ema) * _ema_item_size + _alpha_ema * item
    _ema_item_sq = (1 - _alpha_ema) * _ema_item_sq + _alpha_ema * (item * item)


def _current_std() -> float:
    """Return the current estimate of the standard deviation of item sizes."""
    var = _ema_item_sq - _ema_item_size * _ema_item_size
    if var < 0.0:
        var = 0.0
    return np.sqrt(var)


def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Compute a normalized priority score for each open bin in an online
    Bin Packing setting.

    Heuristic principles:
      1. Exact fits (within a tolerance derived from the observed std) receive
         the highest priority.
      2. Among non‑exact feasible bins, a tighter fit (smaller leftover) is
         preferred via an exponential decay whose rate adapts to the average
         waste of those bins.
      3. Bins where the item occupies a larger fraction of the remaining
         capacity are favoured (size‑weight term).
      4. A tiny random perturbation breaks ties.
      5. Priorities are normalised to sum to one over all bins.

    Parameters
    ----------
    item : float
        Size of the incoming item.
    bins_remain_cap : np.ndarray
        1‑D array of remaining capacities of the currently open bins.

    Returns
    -------
    np.ndarray
        Normalised priority scores (same shape as ``bins_remain_cap``).
        The bin with the maximum priority should be selected for the item.
    """
    # ---- Update online statistics for the item stream ----
    _update_item_stats(item)

    # Convert to a NumPy float array for vectorised operations
    caps = np.asarray(bins_ remain_cap, dtype=float)  # Actually a typo; should be bins_remain_cap

```

I see there are multiple errors. Let's rewrite the entire code from scratch, ensuring correct variable names and syntax.

We'll write the code cleanly.

Plan:

- import numpy
- global RNG
- EMA parameters: _alpha_ema, _ema_item_size, _ema_item_sq, _item_count
- heuristic parameters: _epsilon_factor, _alpha_random, _exact_fit_offset

- define _update_item_stats(item)
- define _current_std()
- define priority_v2(item, bins_remain_cap)

Implement priority_v2 as described.

Let's write code:

```python
import numpy as np

# Global random generator (single instance)
_rng = np.random.default_rng()

# EMA parameters for item size statistics
_alpha_ema = 0.1
_ema_item_size = 0.0
_ema_item_sq = 0.0
_item_count = 0

# Heuristic parameters
_epsilon_factor = 0.05   # tolerance for exact fit (fraction of std)
_alpha_random = 0.02     # magnitude of random tie‑breaker
_exact_fit_offset = 1e9  # offset that ensures exact fits dominate

def _update_item_stats(item: float) -> None:
    """Update exponential moving averages for mean and second moment of item sizes."""
    global _ema_item_size, _ema_item_sq, _item_count
    _item_count += 1
    _ema_item_size = (1 - _alpha_ema) * _ema_item_size + _alpha_ema * item
    _ema_item_sq = (1 - _alpha_ema) * _ema_item_sq + _alpha_ema * (item * item)

def _current_std() -> float:
    """Return the current standard deviation estimate of item sizes."""
    var = _ema_item_sq - _ema_item_size * _ema_item_size
    if var < 0.0:
        var = 0.0
    return np.sqrt(var)

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Compute normalized priority scores for each open bin in an online
    bin packing scenario.

    The heuristic prefers exact fits, then tight fits (via adaptive exponential
    decay), weighted by the fraction of the bin occupied by the item, and finally
    adds a tiny random perturbation to break ties. The resulting scores are
    normalised to sum to one.

    Parameters
    ----------
    item : float
        Size of the incoming item.
    bins_remain_cap : np.ndarray
        1‑D array of remaining capacities of the currently open bins.

    Returns
    -------
    np.ndarray
        Normalised priority scores (same shape as ``bins_remain_cap``). The bin
        with the highest priority should be chosen for the item.
    """
    # Update online statistics with the new item
    _update_item_stats(item)

    # Ensure we are working with a NumPy float array
    caps = np.asarray(bins_remain_cap, dtype=float)

    # Edge case: no bins at all
    if caps.size == 0:
        return np.empty_like(caps)

    # Remaining capacity after (theoretically) placing the item
    leftover = caps - item

    # Tolerance for exact fit based on observed standard deviation
    std = _current_std()
    eps = max(1e-9, _epsilon_factor * std)

    # Feasibility mask (allow a tiny negative leftover within tolerance)
    feasible = leftover >= -eps

    # Initialise raw scores with zeros
```

Oops, need to fix code: raw scores array.

Continue:

```
    scores = np.zeros_like(caps, dtype=float)

    if not np.any(feasible):
        # No feasible bin – return all zeros
        return scores

    # Exact fit detection
    exact_fit = feasible & (np.abs(leftover) <= eps)

    # Assign a huge offset to exact fits and add a tiny random tie‑breaker
    if np.any(exact_fit):
        tie_noise = _rng.uniform(0.0, 1e-6, size=exact_fit.sum())
        scores[exact_fit] = _exact_fit_offset + tie_noise

    # Non‑exact feasible bins
    non_exact = feasible & ~exact_fit
    if np.any(non_exact):
        waste = leftover[non_exact]          # positive leftover (strictly > eps)
        # Adaptive decay rate λ based on mean waste of non‑exact bins
        mean_waste = waste.mean()
        lam = 1.0 / (mean_waste + 1e-12)

        # Exponential decay favouring tighter fits
        exp_decay = np.exp(-lam * waste)

        # Size weight: fraction of the bin that will be: item / caps[non_exact]
        size_weight = item / caps[non_exact]

        # Small random perturbation for tie‑breaking
        rand_factor = 1.0 + _alpha_random * _rng.random(non_exact.sum())

        # Combine components
        scores[non_exact] = exp_decay * size_weight * rand_factor

    # Normalise scores to obtain probabilities / priority values
    total = scores.sum()
    if total > 0.0:
        priorities = scores / total
    else:
        # Fallback: uniform distribution over feasible bins (should rarely happen)
        feasible_count = feasible.sum()
        priorities = np.where(feasible, 1.0 / feasible_count, 0.0)

    return priorities
```

We need to ensure that there are no syntax errors.

Let's rewrite the entire block with proper indentation and correct variable names.

I'll produce final code now.

```python
import numpy as np

# ------------------- Global state & parameters ------------------- #
_rng = np.random.default_rng()

# EMA parameters for online item size statistics
_alpha_ema = 0.1               # smoothing factor (0 < α ≤ 1)
_ema_item_size = 0.0.0         # mean of observed items
_ema_item_sq = 0.0             # mean of squared item sizes
_item_count = 0                # number of processed items

# Heuristic tuning parameters
_epsilon_factor = 0.05         # fraction of std used as exact‑fit tolerance
_alpha_random = 0.02           # strength of random tie‑breaker
_exact_fit_offset = 1e9        # offset ensuring exact fits dominate priority


def _update_item_stats(item: float) -> None:
    """Update exponential moving averages for mean and second moment of item sizes."""
    global _ema_item_size, _ema_item_sq, _item_count
    _item_count += 1
    _ema_item_size = (1 - _alpha_ema) * _ema_item_size + _alpha_ema * item
    _ema_item_sq = (1 - _alpha_ema) * _ema_item_sq + _alpha_ema * (item * item)


def _current_std() -> float:
    """Return the current estimate of the standard deviation of item sizes."""
    var = _ema_item_sq - _ema_item_size * _ema_item_size
    if var < 0.0:
        var? Let's correct.

Actually, let's correct the whole function: var = _ema_item_sq - _ema_item_size * _ema_item_size

if var < 0.0: var = 0.0

return np.sqrt(var)

Now the full function:

```python
def _current_std() -> float:
    var = _ema_item_sq - _ema_item_size * _ema_item_size
    if var < 0.0:
        var = 0.0
    return np.sqrt(var)
```

Now priority_v2 function.

```python
def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Compute normalized priority scores for each open bin in an online bin packing
    scenario.

    Heuristic principles:
      1. Exact fits (within a tolerance derived from observed item-size std) get
         the highest priority.
      2. Among non‑exact feasible bins, a tighter fit (smaller leftover) is
         preferred via an exponential decay whose rate adapts to the average waste
         of those bins.
      3. Bins where the item occupies a larger fraction of the remaining
         capacity are favoured (size‑weight term).
      4. A tiny random perturbation breaks ties.
      5. Priorities are normalised to sum to one.

    Parameters
    ----------
    item : float
        Size of the incoming item.
    bins_remain_cap : np.ndarray
        1‑D array of remaining capacities of the currently open bins.

    Returns
    -------
    np.ndarray
        Normalised priority scores (same shape as ``bins_remain_cap``). The bin
        with the maximum priority should be selected for the item.
    """
    # ---- Update online statistics with the new item ----
    _update_item_stats(item)

    # Ensure we have a NumPy float array for vectorised ops
    caps = np.asarray(bins_remain_cap, dtype=float)

    # Edge case: no bins at all
    if caps.size == 0:
        return np.empty_like(caps)

    # Remaining capacity after (theoretically) placing the item
    leftover = caps - item

    # Tolerance for exact fit based on observed standard deviation
    std = _current_std()
    eps = max(1e-9, _epsilon_factor * std)

    # Feasibility mask (allow a tiny negative leftover within tolerance)
    feasible bins
```

We see many errors. Let's restructure the entire code cleanly without mistakes.

I'll rewrite the whole module from scratch, making sure there are no syntax errors.

```python
import numpy as np

# Global random generator
_rng = np.random.default_rng()

# EMA parameters for item size statistics
_alpha_ema = 0.1
_ema_item_size = 0.0
_ema_item_sq = 0.0
_item_count = 0

# Heuristic parameters
_epsilon_factor = 0.05
_alpha_random = 0.02
_exact_fit_offset = 1e9

def _update_item_stats(item: float) -> None:
    """Update EMA for mean and second moment of observed item sizes."""
    global _ema_item_size, _ema_item_sq, _item_count
    _item_count += 1
    _ema_item_size = (1 - _alpha_ema) * _ema_item_size + _alpha_ema * item
    _ema_item_sq = (1 - _alpha_ema) * _ema_item_sq + _alpha_ema * (item * item)

def _current_std() -> float:
    """Return current estimate of the standard deviation of item sizes.**"""
    var = _ema_item_sq - _ema_item_size * _ema_item_size
    if var < 0.0:
        var = 0.0
    return np.sqrt(var)

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Compute normalized priority scores for each open bin in an online bin packing setting.

    The heuristic follows:
      1. Exact fits (within a tolerance derived from the observed std of item sizes)
         receive the highest priority.
      2. Among non‑exact feasible bins, tighter fits are preferred via an
         exponential decay whose rate adapts to the average waste of those bins.
      3. Bins where the item occupies a larger fraction of the remaining capacity
         are favoured (size‑weight term).
      4. A tiny random perturbation breaks ties.
      5. Priorities are normalised to sum to one.

    Parameters
    ----------
    item : float
        Size of the incoming item.
    bins_remain_cap : np.ndarray
        1‑D array of remaining capacities of the currently open bins.

    Returns
    -------
    np.ndarray
        Normalised priority scores (same??). The bin with the highest priority should be chosen.
    """
    # Update online item statistics
    _update_item_stats(item)

    # Convert input to NumPy array
    caps = np.asarray(bins_remain_cap, dtype=float)

    # Edge case: no bins
    if caps.size == 0:
        return np.empty_like(caps)

    # Compute leftover capacity after placing the item
    leftover = caps - item

    # Determine tolerance for exact fit based on current std estimate
    std = _current_std()
    eps = max(1e-9, _epsilon_factor * std)

    # Feasibility mask (allow a tiny negative leftover within tolerance)
    feasible = leftover >= -eps

    # Initialise raw scores with zeros
    scores = np.zeros_like(caps, dtype=float)

    if not np.any(feasible):
        # No feasible bin – return all zeros
        return scores

    # -------------------- Exact fits -------------------- #
    exact_fit = feasible & (np.abs(leftover) <= eps)
    if np.any(exact_fit):
        # Huge offset + tiny random noise to dominate priority
        tie_noise = _rng.uniform(0.0, 1e-6, size_weight? Actually we need shape equal to number of exact fits
        tie_noise = _rng.uniform(0.0, 1e-6, size=exact_fit.sum())
        scores[exact_fit] = _exact_fit_offset + tie_noise

    # ---------------- Non‑exact feasible bins ---------------- #
    non_exact = feasible & ~exact_fit
    if np.any(non_exact):
        waste = leftover[non_exact]  # positive leftover (> eps)
        # Adaptive decay rate λ based on mean waste of non‑exact bins
        mean_waste = waste.mean()
        lam = 1.0 / (mean_waste + 1e-12)

        # Exponential decay favouring tighter fits
        exp_decay = np.exp(-lam * waste)

        # Size weight: fraction of the bin that will be occupied
        size_weight = item / caps[non_exact]

        # Small random perturbation for tie‑breaking
        rand_factor = 1.0 + _alpha_random * _rng.random(non_exact.sum())

        # Combine components
        scores[non_exact] = exp_decay * size_weight * rand_factor

    # ------------------- Normalisation ------------------- #
    total = scores.sum()
    if total > 0? Actually total = scores.sum()
    if total > 0.0:
        priorities = scores / total
    else:
        # Fallback: uniform distribution over feasible bins
        feasible_count = feasible.sum()
        priorities = np.where(feasible, 1.0 / feasible_count, 0.0)

    return priorities
```

There are still many errors: incomplete docstrings, mis-placed comments, wrong variable names. Let's carefully produce the final code, line by line, ensuring syntactically correct.

We'll start over but this time write the final code cleanly, ensuring no mistakes.

### Plan

Write import and global variables. Write helper functions: _update_item_stats and _current_std. Write priority_v2.

Will also include a proper docstring for priority_v2.

Make sure there are no syntax errors: comments are fine, but docstring must be triple quotes, not broken. Ensure proper indentation.

I will now write the final code from top to bottom, verifying each line.

Let's start.

```python
import numpy as np

# Global random generator (single instance to avoid reseeding)
_rng = np.random.default_rng()

# Exponential moving average parameters for item size statistics
_alpha_ema = 0.1               # smoothing factor (0 < α ≤ 1)
_ema_item_size = 0.0
_ema_item_sq = 0.0
_item_count = 0

# Heuristic tuning parameters
_epsilon_factor = 0.05   # tolerance for exact fit as fraction of std
_alpha_random = 0.02     # magnitude of random tie‑breaker
_exact_fit_offset = 1e9  # offset ensuring exact fits dominate priority
```

But I wrote "# smoothing factor (0 < α ≤ 1)" but the line has a stray comment. Actually we need to ensure correct syntax: comment lines start with #. In the line we wrote `_alpha_ema = 0.1    # smoothing factor (0 < α ≤ 1)`. That's fine.

But we must ensure we don't leave trailing comments after variable assignment that cause syntax errors? No, that's fine.

Now define `_update_item_stats`.

```python
def _update_item_stats(item: float) -> None:
    """Update exponential moving averages for mean and second moment of item sizes."""
    global _ema_item_size, _ema_item_sq, _item_count
    _item_count += 1
    _ema_item_size = (1 - _alpha_ema? This is wrong. Use `_alpha_ema`.

    _ema_item_size = (1 - _alpha_ema) * _ema_item_size + _alpha_ema * item
    _ema_item_sq = (1 - _alpha_ema) * _ema_item_sq + _alpha_ema * (item * item)
```

Now define `_current_std`.

```python
def _current_std() -> float:
    """Return the current estimate of the standard deviation of item sizes."""
    var = _ema_item_sq - _ema_item_size * _ema_item_size
    if var < 0.0:
        var = 0.0
    return np.sqrt(var)
```

Now define `priority_v2`.

We'll write a comprehensive docstring and implement the logic.

Implementation details:

- Update EMA with current item.
- Convert bins_remain_cap to np array.
- If no bins, return empty.
- Compute leftover = caps - item.
- Compute tolerance eps = max(1e-9, _epsilon_factor * std).
- Feasibility mask: leftover >= -eps (allow small negative).
- Initialize scores = zeros.
- If no feasible bins: return scores (zeros).
- exact_fit mask: feasible & (abs(leftover) <= eps). Use np.abs.
- If any exact_fit: tie_noise = _rng.uniform(0.0, 1e-6, size=exact_fit.sum()); scores[exact_fit] = _exact_fit_offset + tie_noise.
- non_exact mask: feasible & ~exact_fit.
- If any non_exact: waste = leftover[non_exact] (positive).
    - mean_waste = waste.mean()
    - lam = 1.0 / (mean_waste + 1e-12)
    - exp_decay = np.exp(-lam * waste)
    - size_weight = item / caps[non_exact]
    - rand_factor = 1.0 + _alpha_random * _rng.random(non_exact.sum())
    - scores[non_exact] = exp_decay * size_weight * rand_factor

- Normalisation: total = scores.sum()
    - if total > 0: priorities = scores / total
    - else: fallback uniform over feasible: feasible_count = feasible.sum(); priorities = np.where(feasible, 1.0 / feasible_count, 0.0)

- Return priorities.

Make sure to import numpy as np. Already done.

Potential errors: np.abs(leftover) (we need parentheses). Ensure that leftover is a numpy array; using np.abs works.

Now produce final code.

Let's write the final code now.

```python
import numpy as np

# ------------------- Global state & parameters ------------------- #
_rng = np.random.default_rng()               # single RNG instance

# EMA parameters for online item‑size statistics
_alpha_ema = 0.1                              # smoothing factor (0 < α ≤ 1)
_ema_item_size = 0.0
_ema_item_sq = 0.0
_item_count = 0

# Heuristic tuning parameters
_epsilon_factor = 0.05    # tolerance for “exact” fit (fraction of std)
_alpha_random = 0.02      # magnitude of random tie‑breaker
_exact_fit_offset = 1e9   # offset guaranteeing exact fits dominate priority


def _update_item_stats(item: float) -> None:
    """Update exponential moving averages for mean and second moment of item sizes."""
    global _ema_item_size, _ema_item_sq, _item_count
    _item_count += 1
    _ema_item_size = (1 - _alpha_ema) * _ema_item_size + _alpha_random * item
    _ema_item_sq = (1 - _alpha_ema) * _ema_item_sq + _alpha_random * (item * item)


def _current_std() -> float:
    """Return the current estimate of the standard deviation of item sizes."""
    var = _ema_item_sq - _ema_item_size * _ema_item_size
    if var < 0.0:
        var = 0.0
    return np.sqrt(var)


def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Compute normalised priority scores for each open bin in an online
    Bin Packing scenario.

    Heuristic principles:
      1. Exact fits (within a tolerance derived from the observed std of item
         sizes) receive the highest priority.
      2. Among non‑exact feasible bins, tighter fits are favoured via an
         exponential decay whose rate adapts to the average waste of those bins.
      3. Bins where the item occupies a larger fraction of the remaining
         capacity are preferred (size‑weight term).
      4. A tiny random perturbation breaks ties.
      5. Priorities are normalised to sum to one.

    6. If no feasible bin exists, all priorities are zero.

    Parameters
    ----------
    item : float
        Size of the incoming item.
    bins_remain_cap : np.ndarray
        1‑D array of remaining capacities of the currently open bins.

    Returns
    -------
    np.ndarray
        Normalised priority scores (same shape as ``bins_remain_cap``). The bin
        with the maximum priority should be selected for the item.
    """
    # -------------------------------------------------------------
    # 1. Update online statistics with the new item
    # -------------------------------------------------------------
    _update_item_stats(item)

    # -------------------------------------------------------------
    # 2. Prepare data structures
    # -------------------------------------------------------------
    caps = np.asarray(bins_remain_cap, dtype=float)

    # Edge case: no bins at all
    if caps.size == 0:
        return np.empty_like(caps)

    # Remaining capacity after (theoretically) placing the item
    leftover = caps - item

    # Adaptive tolerance for exact‑fit detection
    std = _current_std()
    eps = max(1e-9, _epsilon_factor * std)

    # Feasibility mask (allow a tiny negative leftover within tolerance)
    feasible = leftover >= -eps

    # Initialise raw scores with zeros
    scores = np.zeros_like(caps, dtype=float)

    # If no feasible bin exists, return all zeros
    if not np.any(feasible):
        return scores

    # -------------------------------------------------------------
    # 3. Exact fits – dominate the priority landscape
    # -------------------------------------------------------------
    exact_fit = feasible & (np.abs(leftover) <= eps)
    if np.any(exact_fit):
        # Huge offset plus a minuscule random noise to break ties
        tie_noise = _rng.uniform(0.0, 1e-6, size=exact_fit.sum())
        scores[exact_fit] = _exact_fit_offset + tie_noise

    # -------------------------------------------------------------
    # 4. Non‑exact feasible bins – adaptive exponential decay + size weight
    # -------------------------------------------------------------
    non_exact = feasible & ~exact_fit
    if np.any(non_exact):
        waste = leftover[non_exact]                     # positive leftovers (> eps)

        # Adaptive decay rate λ based on mean waste of non‑exact bins
        mean_waste = waste.mean()
        lam = 1.0 / (mean_waste + 1e-12)

        # Exponential decay (tight‑fit bias and adaptation)
        exp_decay = np.exp(-lam * waste)

        # Size‑weight: fraction of the bin that will be occupied by the item
        size_weight = item / caps[non_exact]

        # Tiny random perturbation for tie‑breaking
        rand_factor = 1.0 + _alpha_random * _rng.random(non_exact.sum())

        # Combine components
        scores[non_exact] = exp_decay * size_weight * rand_factor

    # -------------------------------------------------------------
    # 5. Normalise to obtain a probability‑like priority vector
    # -------------------------------------------------------------
    total = scores.sum()
    if total > 0.0:
        priorities = scores / total
    else:
        # Fallback – uniform distribution over feasible bins (should be rare)
        feasible_cnt = feasible.sum()
        priorities = np.where(feasible, 1.0 / feasible_cnt, 0.0)

    return priorities
```
