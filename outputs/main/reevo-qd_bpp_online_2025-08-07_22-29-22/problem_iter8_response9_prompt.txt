{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Global random generator (single instance)\n_rng = np.random.default_rng()\n\n# Exponential moving average parameters for item size statistics\n_alpha_ema = 0.1  # smoothing factor (0 < alpha <= 1)\n_ema_item_size = 0.0  # mean of seen items\n_ema_item_sq = 0.0    # mean of squared sizes\n_item_count = 0\n\n# Adaptive parameters\n_epsilon_factor = 0.05  # fraction of std used as exact\u2011fit tolerance\n_swap_weight = 0.05     # scaling for the swap\u2011improvement boost\n_exact_fit_offset = 1e9 # offset ensuring exact fits dominate priority\n\n\n    \"\"\"Update exponential moving averages of item size and squared size.\"\"\"\n    global _ema_item_size, _ema_item_sq, _item_count\n    _item_count += 1\n    # EMA update\n    _ema_item_size = (1 - _alpha_ema) * _ema_item_size + _alpha_ema * item\n    _ema_item_sq = (1 - _alpha_ema) * _ema_item_sq + _alpha_ema * (item * item)\n\n\n    \"\"\"Return the current estimated standard deviation of item sizes.\"\"\"\n    var = _ema_item_sq - _ema_item_size * _ema_item_size\n    if var < 0.0:\n        var = 0.0\n    return np.sqrt(var)\n\n\n    \"\"\"\n    Adaptive priority for online Bin Packing.\n\n    The priority reflects three principles:\n    1. Exact fits are always preferred (highest priority).\n    2. Among non\u2011exact feasible bins, smaller leftover capacity is better.\n    3. A small boost is added when the leftover after placement is close to\n       the average item size observed so far (swap\u2011improvement heuristic).\n    Ties are broken with a tiny random perturbation.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the existing bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority values for each bin (same shape as ``bins_remain_cap``). The\n        caller should select the bin with the maximum priority.\n    \"\"\"\n    # ---- Update global statistics with the current item ----\n    _update_item_stats(item)\n\n    # Adaptive tolerance for exact fit detection\n    std = _current_std()\n    eps = max(1e-9, _epsilon_factor * std)\n\n    # Remaining capacity after (theoretically) placing the item\n    leftover = bins_remain_cap - item\n\n    # Feasibility mask (allow a tiny negative due to eps)\n    feasible = leftover >= -eps\n\n    # Initialise all priorities to -inf (infeasible bins)\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    if not np.any(feasible):\n        # No feasible bin \u2013 return all -inf\n        return priorities\n\n    # Exact\u2011fit mask (within tolerance)\n    exact_fit = feasible & (np.abs(leftover) <= eps)\n\n    # ---- Exact fits: assign a huge offset plus a tiny random tie\u2011breaker ----\n    if np.any(exact_fit):\n        tie_noise = _rng.uniform(0.0, 1e-6, size=exact_fit.sum())\n        priorities[exact_fit] = _exact_fit_offset + tie_noise\n\n    # ---- Non\u2011exact feasible bins ----\n    non_exact = feasible & ~exact_fit\n    if np.any(non_exact):\n        # Primary component: negative leftover (smaller leftover \u2192 larger priority)\n        primary = -leftover[non_exact]\n\n        # Swap\u2011improvement boost:\n        # leftover close to the average item size is considered promising.\n        mean_size = _ema_item_size if _item_count > 0 else 1.0\n        distance_to_mean = np.abs(leftover[non_exact] - mean_size)\n        boost = _swap_weight / (distance_to_mean + eps)\n\n        # Combine components\n        combined = primary + boost\n\n        # Random tie\u2011breaker (very small)\n        combined += _rng.uniform(0.0, 1e-6, size=combined.shape)\n\n        priorities[non_exact] = combined\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Global random generator (currently unused, kept for potential extensions)\n_rng = np.random.default_rng()\n\n# Hyperparameter controlling the influence of the item/remaining\u2011capacity ratio.\n# It can be tuned by an external reinforcement learning loop if desired.\n_alpha = 0.5\n\n    \"\"\"\n    Update the global weight `_alpha` that balances waste minimisation against\n    efficient utilisation of the remaining bin capacity.\n\n    Parameters\n    ----------\n    alpha : float\n        New value for `_alpha`. 0\u202f\u2264\u202falpha\u202f\u2264\u202f1, where 0 relies only on waste\n        and 1 relies only on the item-to-remaining-capacity ratio.\n    \"\"\"\n    global _alpha\n    _alpha = float(alpha)\n\n\n    \"\"\"\n    Adaptive\u2011\u03bb softmax priority with item\u2011size ratio weighting for online\n    bin packing.\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of each currently open bin.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores (probabilities) for each bin.  Bins that cannot\n        accommodate the item receive a score of -inf, which signals that a\n        new bin must be opened by the caller.  The global variable `_alpha`\n        controls the trade\u2011off between waste minimisation (softmax of waste)\n        and efficient utilisation (item\u2011to\u2011capacity ratio).  It can be tuned\n        externally, e.g. via a reinforcement learning loop.\n    \"\"\"\n    # Ensure a float array for vectorised operations\n    caps = np.asarray(bins_remain_cap, dtype=float)\n\n    # Feasibility mask\n    feasible = caps >= item\n    if not np.any(feasible):\n        # No open bin can fit the item\n        return np.full_like(caps, -np.inf, dtype=float)\n\n    # Waste after placing the item\n    waste = caps - item\n    eps = 1e-12\n\n    # Adaptive \u03bb (inverse of mean waste)\n    mean_waste = waste[feasible].mean()\n    lam = 1.0 / (mean_waste + eps)\n\n    # Raw exponential decay based on waste\n    raw = np.exp(-lam * waste)\n    raw[~feasible] = 0.0\n\n    # Ratio of item size to remaining capacity\n    ratio = np.where(feasible, item / caps, 0.0)\n\n    # Combine raw waste\u2011based score with ratio weighting\n    combined = raw * (ratio ** _alpha)\n\n    # Softmax normalisation over feasible bins\n    max_val = combined[feasible].max()\n    exp_scores = np.exp(combined - max_val)\n    exp_scores[~feasible] = 0.0\n\n    total = exp_scores.sum()\n    if total > 0:\n        priorities = exp_scores / total\n    else:\n        # Fallback: uniform distribution over feasible bins\n        priorities = np.where(feasible, 1.0 / feasible.sum(), -np.inf)\n\n    return priorities\n\n[Reflection]\nUse adaptive \u03bb based on mean waste, combine with item\u2011capacity ratio, softmax, minimal ad\u2011hoc heuristics.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}