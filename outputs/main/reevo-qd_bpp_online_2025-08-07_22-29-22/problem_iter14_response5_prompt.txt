{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "Write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n[Worse code]\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Global random generator reused across calls\n_rng = np.random.default_rng()\n\n# Running statistics of observed item sizes (simple sum/count)\n_item_count = 0\n_item_sum = 0.0\n\n\n    \"\"\"\n    Priority function for the online Bin Packing Problem.\n\n    Higher scores indicate more desirable bins. The scoring combines:\n      \u2022 Best\u2011fit (smaller leftover \u2192 higher score)\n      \u2022 Controlled random perturbation (more for small items)\n      \u2022 A look\u2011ahead boost based on the running average item size\n      \u2022 A deterministic tie\u2011breaker favouring lower\u2011index bins\n\n    Parameters\n    ----------\n    item : float\n        Size of the incoming item.\n    bins_remain_cap : np.ndarray\n        1\u2011D array of remaining capacities of the existing bins.\n\n    Returns\n    -------\n    np.ndarray\n        Priority scores for each bin (same shape as ``bins_remain_cap``).\n        Infeasible bins receive ``-np.inf``.\n    \"\"\"\n    global _item_count, _item_sum\n\n    # Ensure we are working with a NumPy array of floats\n    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)\n\n    # No bins yet \u2013 just record statistics and return empty array\n    if bins_remain_cap.size == 0:\n        _item_count += 1\n        _item_sum += item\n        return np.array([], dtype=float)\n\n    # Compute leftover capacity if the item were placed in each bin\n    leftover = bins_remain_cap - item\n\n    # Small epsilon to guard against floating\u2011point round\u2011off\n    eps = 1e-12\n    feasible = leftover >= -eps\n\n    # Initialise priority vector with -inf for infeasible bins\n    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)\n\n    # If nothing fits, update stats and return\n    if not np.any(feasible):\n        _item_count += 1\n        _item_sum += item\n        return priorities\n\n    # ------------------------------------------------------------------\n    # 1. Base best\u2011fit score (smaller leftover \u2192 larger score)\n    # ------------------------------------------------------------------\n    base_score = -leftover[feasible]\n\n    # ------------------------------------------------------------------\n    # 2. Controlled randomness (more for small items)\n    # ------------------------------------------------------------------\n    # Approximate bin capacity (max remaining + current item) \u2013 fallback 1.0\n    approx_capacity = max(bins_remain_cap.max() + item, 1.0)\n    item_ratio = item / approx_capacity                     # \u2208 [0, 1]\n\n    # Spread of leftover among feasible bins\n    leftover_feas = leftover[feasible]\n    if leftover_feas.size > 1:\n        leftover_range = leftover_feas.max() - leftover_feas.min()\n    else:\n        leftover_range = 0.0\n\n    # Noise scale grows when the item is small (item_ratio low) and when\n    # there is a larger spread of leftover capacities.\n    noise_scale = leftover_range * 0.05 * (1.0 - item_ratio)\n    noise_scale = max(noise_scale, 0.0)\n    random_noise = _rng.random(leftover_feas.shape) * noise_scale\n\n    # ------------------------------------------------------------------\n    # 3. Look\u2011ahead boost using running average item size\n    # ------------------------------------------------------------------\n    if _item_count > 0:\n        avg_item = _item_sum / _item_count\n    else:\n        avg_item = item  # first item fallback\n\n    # Small positive boost if the bin would still have room for a typical\n    # future item; slight penalty otherwise.\n    future_weight = 0.02\n    future_adjust = (leftover_feas - avg_item) * future_weight\n\n    # ------------------------------------------------------------------\n    # 4. Deterministic tie\u2011breaker (prefer lower index bins)\n    # ------------------------------------------------------------------\n    tie_breaker = -np.arange(bins_remain_cap.size, dtype=float) * 1e-12\n\n    # ------------------------------------------------------------------\n    # 5. Combine components\n    # ------------------------------------------------------------------\n    combined = base_score + random_noise + future_adjust + tie_breaker[feasible]\n    priorities[feasible] = combined\n\n    # ------------------------------------------------------------------\n    # 6. Update global statistics\n    # ------------------------------------------------------------------\n    _item_count += 1\n    _item_sum += item\n\n    return priorities\n\n[Better code]\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n# Global parameters and state\n_alpha_ema = 0.05           # EMA smoothing factor for item sizes\n_epsilon_factor = 0.05      # Fraction of std used for exact\u2011fit tolerance\n_exact_fit_offset = 1e9     # Large offset to guarantee exact fits win\n_alpha_ratio = 0.5          # Weight for the item\u2011to\u2011capacity ratio (0 \u2192 waste only)\n\n# EMA statistics\n_ema_mean = 0.0\n_ema_sq = 0.0\n_item_count = 0\n\n# RNG placeholder for potential extensions\n_rng = np.random.default_rng()\n\n\n    \"\"\"\n    Compute priority scores for each bin in an online bin\u2011packing scenario.\n\n    The score combines an adaptive waste penalty (via a soft\u2011max over\n    waste) and a ratio penalty that favours bins whose remaining capacity\n    is close to the item size.  An exact fit (within a small tolerance\n    based on a running EMA of item sizes) receives a huge priority offset.\n    The function returns a score array; bins that cannot accommodate the\n    item receive ``-np.inf``.\n    \"\"\"\n    global _ema_mean, _ema_sq, _item_count\n    # Update EMA statistics\n    _item_count += 1\n    _ema_mean = (1 - _alpha_ema) * _ema_mean + _alpha_ema * item\n    _ema_sq = (1 - _alpha_ema) * _ema_sq + _alpha_ema * (item * item)\n\n    var = _ema_sq - _ema_mean * _ema_mean\n    std = np.sqrt(var) if var > 0 else 0.0\n    eps = max(1e-9, _epsilon_factor * std)\n\n    caps = np.asarray(bins_remain_cap, dtype=float)\n    feasible = caps >= item\n\n    # Initialize priority array with -inf for infeasible bins\n    priorities = np.full_like(caps, -np.inf, dtype=float)\n    if not np.any(feasible):\n        return priorities\n\n    slack = caps - item\n    exact_fit = feasible & (np.abs(slack) <= eps)\n\n    # Waste penalty with adaptive \u03bb\n    waste = slack[feasible]\n    lam = 1.0 / (np.mean(waste) + 1e-6)\n    raw_waste = np.exp(-lam * waste)\n\n    # Ratio penalty\n    ratio = item / caps[feasible]\n    combined = raw_waste * (ratio ** _alpha_ratio)\n\n    # Soft\u2011max over feasible bins\n    max_val = combined.max()\n    exp_scores = np.exp(combined - max_val)\n    exp_scores /= exp_scores.sum()\n\n    idx = np.arange(len(caps), dtype=float)\n    priorities[feasible] = exp_scores\n    priorities[feasible] -= 1e-12 * idx[feasible]\n    priorities[exact_fit] = _exact_fit_offset - 1e-12 * idx[exact_fit]\n\n    return priorities\n\n[Reflection]\nUse adaptive waste penalty, softmax, exact\u2011fit offset, EMA of sizes, and ratio weighting for better online packing.\n\n[Improved code]\nPlease write an improved function `priority_v2`, according to the reflection. Output code only and enclose your code with Python code block: ```python ... ```."}