```python
import numpy as np

# Global random generator for reproducibility
_rng = np.random.default_rng()

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Adaptive priority for online Bin Packing.

    This function combines:
      - An adaptive logistic score based on the slack after inserting the
        current item.
      - A blending of that score with the ratio of the item size to the
        remaining capacity of the bin (encouraging tighter fits).
      - A local‑search inspired penalty that prefers bins which, after the
        insertion, do not become the new bin with the largest remaining
        capacity (reducing fragmentation).
      - A small random perturbation to break ties.

    Parameters
    ----------
    item : float
        Size of the incoming item.
    bins_remain_cap : np.ndarray
        1‑D array of the remaining capacity of each open bin.

    Returns
    -------
    np.ndarray
        Priority scores for each bin.  Bins that cannot accommodate the
        item receive a priority of `-inf`.
    """
    bins_remain_cap = np.asarray(bins_remain_cap, dtype=float)

    # Slack after placing the item in each bin
    slack = bins_remain_cap - item
    feasible = slack >= 0.0

    # Initialize with -inf for infeasible bins
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    if not feasible.any():
        return priorities

    # Slack values for feasible bins
    slack_feas = slack[feasible]

    # Adaptive logistic parameters
    median_slack = np.median(slack_feas)
    slack_range = slack_feas.max() - slack_feas.min()
    if slack_range < 1e-12:
        slack_range = 1e-12
    alpha = 8.0 / slack_range  # controls steepness

    # Logistic score: higher for bins that leave little slack
    logistic_scores = 1.0 / (1.0 + np.exp(alpha * (slack_feas - median_slack)))

    # Blend with item-to-remaining-capacity ratio (encourages tighter fits)
    remaining_cap_feas = bins_remain_cap[feasible]
    ratio = item / (remaining_cap_feas + 1e-12)  # values in (0, 1]
    blended_scores = logistic_scores * ratio

    # Local‑search penalty: minimize the maximum remaining capacity after
    # insertion.  Lower penalty => better bin.
    # Determine the global maximum remaining capacity before insertion
    max_remaining = bins_remain_cap.max()
    # Compute second maximum for bins that currently hold the maximum
    sorted_cap = np.sort(bins_remain_cap)
    second_max = sorted_cap[-2] if len(sorted_cap) >= 2 else sorted_cap[-1]
    global_max_mask = bins_remain_cap == max_remaining

    # For each feasible bin, compute the max remaining capacity after insertion
    max_remaining_other = np.where(
        global_max_mask[feasible], second_max, max_remaining
    )
    max_slack_after = np.maximum(max_remaining_other, slack_feas)
    local_penalty = max_slack_after / max_remaining
    local_scores = 1.0 - local_penalty  # lower penalty → higher score

    # Combine the two signals with a weighted sum
    w1, w2 = 0.6, 0.4
    combined_scores = w1 * blended_scores + w2 * local_scores

    # Add tiny random noise to break ties
    noise = _rng.random(len(combined_scores)) * 1e-6
    final_scores = combined_scores + noise

    priorities[feasible] = final_scores
    return priorities
```
