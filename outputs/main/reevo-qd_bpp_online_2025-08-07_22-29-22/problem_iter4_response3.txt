```python
import numpy as np

# Global random generator (single instance)
_rng = np.random.default_rng()

# Exponential moving average parameters for item size statistics
_alpha_ema = 0.1  # smoothing factor (0 < alpha <= 1)
_ema_item_size = 0.0  # mean of seen items
_ema_item_sq = 0.0    # mean of squared sizes
_item_count = 0

# Adaptive parameters
_epsilon_factor = 0.05  # fraction of std used as exact‑fit tolerance
_swap_weight = 0.05     # scaling for the swap‑improvement boost
_exact_fit_offset = 1e9 # offset ensuring exact fits dominate priority


def _update_item_stats(item: float) -> None:
    """Update exponential moving averages of item size and squared size."""
    global _ema_item_size, _ema_item_sq, _item_count
    _item_count += 1
    # EMA update
    _ema_item_size = (1 - _alpha_ema) * _ema_item_size + _alpha_ema * item
    _ema_item_sq = (1 - _alpha_ema) * _ema_item_sq + _alpha_ema * (item * item)


def _current_std() -> float:
    """Return the current estimated standard deviation of item sizes."""
    var = _ema_item_sq - _ema_item_size * _ema_item_size
    if var < 0.0:
        var = 0.0
    return np.sqrt(var)


def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Adaptive priority for online Bin Packing.

    The priority reflects three principles:
    1. Exact fits are always preferred (highest priority).
    2. Among non‑exact feasible bins, smaller leftover capacity is better.
    3. A small boost is added when the leftover after placement is close to
       the average item size observed so far (swap‑improvement heuristic).
    Ties are broken with a tiny random perturbation.

    Parameters
    ----------
    item : float
        Size of the incoming item.
    bins_remain_cap : np.ndarray
        1‑D array of remaining capacities of the existing bins.

    Returns
    -------
    np.ndarray
        Priority values for each bin (same shape as ``bins_remain_cap``). The
        caller should select the bin with the maximum priority.
    """
    # ---- Update global statistics with the current item ----
    _update_item_stats(item)

    # Adaptive tolerance for exact fit detection
    std = _current_std()
    eps = max(1e-9, _epsilon_factor * std)

    # Remaining capacity after (theoretically) placing the item
    leftover = bins_remain_cap - item

    # Feasibility mask (allow a tiny negative due to eps)
    feasible = leftover >= -eps

    # Initialise all priorities to -inf (infeasible bins)
    priorities = np.full_like(bins_remain_cap, -np.inf, dtype=float)

    if not np.any(feasible):
        # No feasible bin – return all -inf
        return priorities

    # Exact‑fit mask (within tolerance)
    exact_fit = feasible & (np.abs(leftover) <= eps)

    # ---- Exact fits: assign a huge offset plus a tiny random tie‑breaker ----
    if np.any(exact_fit):
        tie_noise = _rng.uniform(0.0, 1e-6, size=exact_fit.sum())
        priorities[exact_fit] = _exact_fit_offset + tie_noise

    # ---- Non‑exact feasible bins ----
    non_exact = feasible & ~exact_fit
    if np.any(non_exact):
        # Primary component: negative leftover (smaller leftover → larger priority)
        primary = -leftover[non_exact]

        # Swap‑improvement boost:
        # leftover close to the average item size is considered promising.
        mean_size = _ema_item_size if _item_count > 0 else 1.0
        distance_to_mean = np.abs(leftover[non_exact] - mean_size)
        boost = _swap_weight / (distance_to_mean + eps)

        # Combine components
        combined = primary + boost

        # Random tie‑breaker (very small)
        combined += _rng.uniform(0.0, 1e-6, size=combined.shape)

        priorities[non_exact] = combined

    return priorities
```
