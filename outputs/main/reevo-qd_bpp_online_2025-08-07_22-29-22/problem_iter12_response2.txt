```python
import numpy as np

# Global random generator for tie‑breaking
_rng = np.random.default_rng()

# Adaptive hyper‑parameters (tunable at runtime)
_alpha = 0.5   # weight for the item‑to‑capacity ratio term (0 ≤ α ≤ 1)
_beta = 0.5    # weight for the waste‑minimisation term (0 ≤ β ≤ 1)

# Running statistics of observed items (used for adaptive λ)
_item_count = 0
_item_sum = 0.0


def set_alpha(alpha: float) -> None:
    """Set the ratio‑weight α (clamped to [0, 1])."""
    global _alpha
    _alpha = float(np.clip(alpha, 0.0, 1.0))


def set_beta(beta: float) -> None:
    """Set the waste‑weight β (clamped to [0, 1])."""
    global _beta
    _beta = float(np.clip(beta, 0.0, 1.0))


def _update_item_stats(item: float) -> None:
    """Update running mean of item sizes (used for adaptive λ)."""
    global _item_count, _item_sum
    _item_count += 1
    _item_sum += float(item)


def _mean_item_size() -> float:
    """Return current mean item size (0 if no items observed yet)."""
    return _item_sum / _item_count if _item_count > 0 else 0.0


def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Adaptive priority for online Bin Packing.

    The priority blends two intuitive signals:
      * **Waste minimisation** – bins that leave little unused space after
        inserting the item receive a higher score.
      * **Tight‑fit ratio** – bins whose remaining capacity is close to the
        item size (high item‑to‑capacity ratio) are favoured.

    The blend is controlled by the global hyper‑parameters α and β.
    An adaptive λ, inversely proportional to the mean waste of feasible bins,
    scales the waste term.  A tiny random perturbation breaks exact ties.

    Parameters
    ----------
    item : float
        Size of the incoming item (0 < item ≤ bin capacity).
    bins_remain_cap : np.ndarray
        1‑D array of remaining capacities of currently open bins.

    Returns
    -------
    np.ndarray
        Priority scores for each bin. Infeasible bins receive ``-np.inf``.
        The caller should select the bin with the highest score; if all are
        ``-np.inf`` a new bin must be opened.
    """
    # Update global item statistics (enables look‑ahead‑style adaptation)
    _update_item_stats(item)

    caps = np.asarray(bins_remain_cap, dtype=float)

    # Handle the trivial case of no bins
    if caps.size == 0:
        return np.array([], dtype=float)

    # Feasibility mask: only bins that can accommodate the item
    feasible = caps >= item
    priorities = np.full_like(caps, -np.inf, dtype=float)

    if not np.any(feasible):
        # No open bin can fit the item – caller will open a new bin.
        return priorities

    # Waste left after placing the item (non‑negative for feasible bins)
    waste = caps - item

    # Adaptive λ: inverse of mean waste, dampened by typical item size
    eps = 1e-12
    mean_waste = waste[feasible].mean()
    mean_item = _mean_item_size()
    # Scale λ to keep it well‑behaved across different problem scales
    scale = max(mean_item, eps)
    lam = (1.0 / (mean_waste + eps)) * (scale / (scale + mean_waste))

    # Waste‑based score: higher when waste is small (exponential decay)
    waste_score = np.exp(-lam * waste)          # ∈ (0, 1]

    # Ratio‑based score: larger when item fills a larger fraction of the bin
    ratio = np.where(feasible, item / caps, 0.0)  # ∈ (0, 1]
    ratio_score = ratio ** _alpha                # α‑controlled emphasis

    # Blend the two scores with a weighted geometric mean controlled by β
    combined = (waste_score ** _beta) * (ratio_score ** (1.0 - _beta))

    # Add a negligible random perturbation to break ties deterministically
    combined += _rng.normal(scale=1e-12, size=combined.shape)

    # Assign combined scores to feasible bins
    priorities[feasible] = combined[feasible]

    return priorities
```
