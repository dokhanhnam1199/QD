[
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Best Fit strategy.\n\n    In the Best Fit strategy, we prioritize bins that have the least remaining capacity\n    after placing the item, but only if the item fits. A higher priority is given to\n    bins that result in a smaller remaining capacity (closer to zero).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n        Higher scores indicate a more preferred bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins where the item can actually fit\n    can_fit_mask = bins_remain_cap >= item\n    \n    # For bins where the item fits, calculate the remaining capacity after placement\n    # We want to minimize this remaining capacity, so we use a negative value\n    # to make larger negative values (meaning smaller remaining capacity) have higher priority.\n    remaining_capacities_after_fit = bins_remain_cap[can_fit_mask] - item\n    \n    # To make the priorities positive and larger for better fits, we can use\n    # a transformation. A common approach is to use the negative of the remaining capacity,\n    # or a function that maps smaller positive remaining capacities to larger priority values.\n    # Here, we'll use 1 / (remaining_capacity + epsilon) to reward smaller remaining capacities,\n    # but this can be unstable if remaining_capacity is zero.\n    # A simpler approach for Best Fit is to prioritize bins that result in the *least* waste.\n    # So, the priority should be inversely related to the remaining capacity *after* packing.\n    # Thus, a higher priority means smaller `remaining_capacities_after_fit`.\n    \n    # Let's assign priority based on the \"tightness\" of the fit.\n    # The best fit is the one that leaves the minimum remaining capacity.\n    # So, we want to maximize the negative of the remaining capacity, or\n    # minimize the remaining capacity itself and use that as the ranking.\n    \n    # A simple heuristic: prioritize bins that have *just enough* space.\n    # If a bin has remaining capacity `R` and an item of size `I` arrives,\n    # placing it results in `R - I` remaining capacity. We want to minimize `R - I`.\n    # Therefore, higher priority for smaller `R - I`.\n    # We can represent this by `- (R - I)` or by giving a high score when `R - I` is small.\n    \n    # Calculate a score that is higher for smaller remaining capacities after packing.\n    # For example, `1.0 / (remaining_capacity_after_fit + 1e-6)`\n    # or a simple inverse like `-remaining_capacity_after_fit`.\n    \n    # Using negative remaining capacity for direct comparison (higher value is better)\n    priorities[can_fit_mask] = -remaining_capacities_after_fit\n    \n    # Alternatively, for a \"tighter fit\" score:\n    # Add a small epsilon to avoid division by zero and to ensure positive scores\n    # This rewards bins that are almost full.\n    # priorities[can_fit_mask] = 1.0 / (remaining_capacities_after_fit + 1e-6)\n\n    # For Best Fit, we want to find the bin with the smallest positive remaining capacity\n    # after packing. This is equivalent to maximizing `- (remaining_capacity - item)`.\n    \n    # Another perspective: what if we prioritize bins where `bins_remain_cap` is closest to `item`?\n    # `abs(bins_remain_cap - item)` can measure the \"difference\". We want to minimize this.\n    # So, priority could be `-abs(bins_remain_cap - item)`.\n    # This is closer to the *idea* of Best Fit (finding the tightest fit), but the problem\n    # statement implies prioritizing based on the *resulting* remaining capacity.\n    \n    # Sticking to the definition: Best Fit aims to minimize the wasted space.\n    # This means choosing the bin such that `bins_remain_cap - item` is minimized (and non-negative).\n    # So, for bins that can fit the item, the priority is directly proportional to the\n    # negative of the remaining capacity after packing.\n    \n    return priorities",
    "response_id": 1,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 22.458839376460833,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response3.txt_stdout.txt",
    "code_path": "problem_iter1_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Almost Full Fit.\n\n    The Almost Full Fit strategy prioritizes bins that are close to being full,\n    but still have enough capacity for the current item. This aims to leave\n    larger capacity bins for potentially larger future items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the \"almost full\" priority.\n    # We want to prioritize bins that are \"almost full\" but can still fit the item.\n    # A good measure for \"almost full\" is the remaining capacity.\n    # We can define priority as inversely proportional to remaining capacity,\n    # but also consider that we don't want to pick a bin that is *too* full,\n    # as that might be a bad fit.\n    # A common approach for \"almost full\" is to use a function that peaks\n    # when remaining capacity is small but positive.\n    # For simplicity, we'll use the negative of remaining capacity to\n    # prioritize smaller remaining capacities (i.e., fuller bins).\n    # Adding a small constant to avoid zero division if remaining capacity is zero\n    # and ensuring positive priorities for valid fits.\n\n    # Let's use a strategy that penalizes bins that are too full or too empty.\n    # We want to find bins where `bins_remain_cap - item` is small.\n    # This means `bins_remain_cap` should be slightly larger than `item`.\n\n    # Option 1: Prioritize bins with the smallest remaining capacity that can fit the item.\n    # This is essentially the \"Best Fit\" approach. For \"Almost Full Fit\",\n    # we want to be *close* to Best Fit.\n\n    # A possible interpretation of \"Almost Full Fit\" for priority:\n    # Prioritize bins where the remaining capacity after placing the item is minimized,\n    # but we ensure that the bin is not *completely* full.\n    # We can assign a high priority to bins that have just enough space.\n\n    # Let's try a priority function that gives higher scores to bins with\n    # smaller remaining capacity, but only if they can fit the item.\n    # We want to avoid bins that are *too* empty.\n\n    # A simple way to prioritize \"almost full\" bins is to sort them by remaining capacity.\n    # The bins with the smallest remaining capacity (that can fit the item) are preferred.\n    # For a priority score, we want higher scores for preferred bins.\n\n    # Let's assign priority based on how \"tightly\" the item fits.\n    # A tighter fit means `bins_remain_cap - item` is small and non-negative.\n    # We want to maximize the priority for bins where `bins_remain_cap - item` is close to 0.\n\n    # We can map the remaining capacity (after fitting the item) to a priority.\n    # Smaller remaining capacity should get higher priority.\n    # A simple mapping could be `1 / (remaining_capacity + epsilon)`\n    # where epsilon is a small value to prevent division by zero.\n\n    # Let's filter out bins that cannot fit the item.\n    valid_bins_indices = np.where(can_fit_mask)[0]\n\n    if len(valid_bins_indices) > 0:\n        # Calculate remaining capacity for valid bins\n        remaining_capacities_for_valid = bins_remain_cap[valid_bins_indices] - item\n\n        # To prioritize \"almost full\" bins, we want to give higher scores\n        # to bins with smaller `remaining_capacities_for_valid`.\n        # We can use the negative of these values.\n        # However, to avoid very large negative numbers for empty bins and to\n        # make the heuristic more focused on being \"almost full\", we can\n        # adjust the values.\n\n        # A good heuristic for \"almost full\" could be to reward bins\n        # where the remaining capacity `bins_remain_cap` is just slightly\n        # larger than `item`.\n\n        # Let's consider the ratio `item / bins_remain_cap` for bins that can fit.\n        # Higher ratio means the item takes up more of the bin's *current* capacity.\n        # This could imply a more \"full\" bin if the current capacity is already small.\n        # However, this might not be the best for \"almost full\".\n\n        # The core idea of \"Almost Full Fit\" is to pick a bin that is \"nearly full\".\n        # So, we want bins where `bins_remain_cap` is small but sufficient.\n\n        # Let's create a priority that is inversely proportional to the\n        # `bins_remain_cap` itself, but only for bins that can fit the item.\n        # This prioritizes bins that are already closer to being full.\n        # Add a small epsilon to the denominator to avoid division by zero,\n        # and a small offset to ensure positive priorities.\n\n        epsilon = 1e-6  # Small constant to avoid division by zero\n        # We want bins with small `bins_remain_cap` (but >= item) to have high priority.\n        # So, a good priority could be `1 / bins_remain_cap`.\n        # But we only apply this to bins that can fit the item.\n\n        # Let's construct a score that emphasizes bins that are almost full.\n        # For a bin with remaining capacity `r`, after placing item `i`, the new remaining capacity is `r-i`.\n        # We want to prioritize bins where `r-i` is small.\n        # So, a good priority would be inversely related to `r-i`.\n        # `priority = 1 / (r-i + epsilon)` for bins where `r >= i`.\n\n        # Let's use the value `bins_remain_cap` directly for priority.\n        # Smaller `bins_remain_cap` should have higher priority, but only if `bins_remain_cap >= item`.\n        # We can use `1 / bins_remain_cap` but this might penalize very large bins too much.\n\n        # Alternative: Prioritize bins where `bins_remain_cap - item` is minimal.\n        # So, `priority = - (bins_remain_cap - item)` for bins that fit.\n        # We want higher values for smaller (more negative or closer to zero) differences.\n        # So, `priority = -(bins_remain_cap - item)` where `bins_remain_cap - item >= 0`.\n        # Let's shift this to be positive and emphasize small positive differences.\n\n        # A heuristic often used for \"almost full\" or \"tight fit\" is to reward bins\n        # where `bins_remain_cap` is just large enough.\n        # Consider the difference `bins_remain_cap - item`. We want this to be small and positive.\n        # A priority could be related to `-(bins_remain_cap - item)` or `1 / (bins_remain_cap - item + epsilon)`.\n\n        # Let's try `priority = - (bins_remain_cap - item)` for fitting bins.\n        # This means bins with `bins_remain_cap = item` get priority 0.\n        # Bins with `bins_remain_cap = item + 1` get priority -1.\n        # We want higher priority for bins that are *closer* to being full.\n        # So, we want bins with smaller `bins_remain_cap` to have higher priority.\n\n        # A robust \"almost full\" strategy often involves prioritizing bins\n        # that have a small remaining capacity *after* placing the item.\n        # This is equivalent to prioritizing bins that were \"most full\"\n        # among those that can accommodate the item.\n\n        # Let's use the negative of the remaining capacity for bins that can fit.\n        # This gives higher priority to bins with less remaining capacity.\n        # `priorities[valid_bins_indices] = -bins_remain_cap[valid_bins_indices]`\n        # This makes bins that are already close to full have higher (less negative) scores.\n        # However, we want *positive* priorities that can be sorted.\n\n        # Let's reconsider the objective: pick the bin that becomes \"most full\"\n        # after placing the item. This means picking the bin with the smallest\n        # remaining capacity *after* placing the item.\n        # Let `r` be the current remaining capacity. The new remaining capacity is `r - item`.\n        # We want to minimize `r - item`.\n        # So, a good priority score would be `-(r - item)` which is `item - r`.\n        # However, this gives higher priority to bins that were already more full.\n\n        # For \"Almost Full Fit\", we're looking for bins that are *close* to full,\n        # but not overfilled.\n        # We can define \"almost full\" as having a remaining capacity that is small,\n        # but greater than or equal to the item's size.\n\n        # Let's use a priority that favors bins where `bins_remain_cap` is slightly\n        # larger than `item`.\n        # We can assign a priority based on `1 / (bins_remain_cap - item + epsilon)`.\n        # This prioritizes bins where the \"gap\" is smallest.\n\n        priorities[valid_bins_indices] = 1.0 / (bins_remain_cap[valid_bins_indices] - item + epsilon)\n\n        # This assigns a very high priority to bins where `bins_remain_cap` is just\n        # barely larger than `item`. For instance, if `bins_remain_cap = item + 0.01`,\n        # priority is 100. If `bins_remain_cap = item + 1`, priority is 1.\n        # This aligns well with the \"almost full\" concept.\n\n    return priorities",
    "response_id": 3,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 70.32403072095333,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response6.txt_stdout.txt",
    "code_path": "problem_iter1_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Sigmoid Fit Score.\n\n    The Sigmoid Fit Score strategy aims to prioritize bins that are \"almost full\"\n    but can still accommodate the current item. This is achieved by applying a\n    sigmoid function to the ratio of remaining capacity to the item size.\n    Bins with a remaining capacity that is slightly larger than the item size\n    will receive a high score.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Only consider bins that can fit the item\n    valid_bins_mask = bins_remain_cap >= item\n\n    # Calculate a \"tightness\" metric. A lower value means the bin is tighter\n    # for the given item (i.e., remaining capacity is close to item size).\n    # We add a small epsilon to the denominator to avoid division by zero if\n    # an item size is 0, although in BPP item sizes are usually positive.\n    tightness = (bins_remain_cap - item) / (bins_remain_cap + 1e-9)\n\n    # Apply sigmoid function to the negative of tightness.\n    # We use negative tightness because we want higher priority for tighter bins.\n    # The sigmoid function squashes the values between 0 and 1.\n    # A common sigmoid is 1 / (1 + exp(-x)).\n    # We shift and scale the tightness to optimize the sigmoid's sensitivity\n    # to the range of \"almost full\" bins.\n    # Let's map the \"tightness\" range from [-1, 1] to a more suitable range for sigmoid.\n    # If remaining_cap = item, tightness = 0.\n    # If remaining_cap = infinity, tightness = 1.\n    # If remaining_cap = item + epsilon, tightness is close to 0.\n    # If remaining_cap = item - epsilon, the bin is invalid and we handle this with the mask.\n\n    # We want bins where remaining_cap is *just* larger than item to have high priority.\n    # This means (bins_remain_cap - item) is small and positive.\n    # The ratio (bins_remain_cap - item) / bins_remain_cap (or similar) will be small and positive.\n    # Let's try to center the sigmoid around the \"ideal\" fit.\n    # The ideal fit is when remaining_cap is just enough, i.e., remaining_cap = item.\n    # So, we want to maximize the score when remaining_cap - item is close to 0.\n\n    # Let's consider a transformed \"fit_score\" that is high when remaining_cap is\n    # slightly larger than item, and lower otherwise.\n    # A simple measure of \"how much space is left relative to the item\" could be:\n    # relative_excess_space = (bins_remain_cap - item) / item\n    # We want high priority when this is small and positive.\n\n    # Sigmoid function: S(x) = 1 / (1 + exp(-k * (x - x0)))\n    # We want high values when (bins_remain_cap - item) is small and positive.\n    # Let x = bins_remain_cap - item.\n    # We want S(x) to be high when x is near 0 and positive.\n    # Let's use a sigmoid on a transformed value related to the remaining capacity.\n\n    # A good candidate for the argument of the sigmoid:\n    # If bins_remain_cap is much larger than item, we want low priority.\n    # If bins_remain_cap is just enough (item), we want high priority.\n    # If bins_remain_cap is slightly more than item, we want high priority.\n\n    # Let's use the ratio (item / bins_remain_cap) as the input to the sigmoid,\n    # but inverted. We want high priority when this ratio is close to 1 (but less than 1).\n    # Consider ratio r = bins_remain_cap / item.\n    # We want high priority when r is close to 1.\n    # Sigmoid of (1 - r) could work, but it would give high priority when r is small.\n\n    # Let's re-evaluate the \"Sigmoid Fit Score\" concept.\n    # It's often about fitting the item as snugly as possible without overflow.\n    # A good score should be high for bins where `bins_remain_cap` is slightly GREATER than `item`.\n    # And low for bins where `bins_remain_cap` is much larger than `item` or too small.\n\n    # Consider the \"space available relative to the item size\":\n    # If bins_remain_cap = item + delta, where delta is small and positive.\n    # We want a high score.\n\n    # Let's use the ratio: `remaining_capacity / item_size`.\n    # We are interested in values of this ratio that are slightly greater than 1.\n    # Let `ratio = bins_remain_cap / item`.\n    # We can use a sigmoid centered around `ratio = 1`.\n    # The sigmoid function is `1 / (1 + exp(-k * (x - center)))`.\n    # If `x = ratio`, we want the peak when `ratio` is around `1`.\n    # So, `center = 1`.\n    # `k` controls the steepness. A larger `k` makes the score drop faster away from the center.\n\n    # We want the peak when `bins_remain_cap` is slightly GREATER than `item`.\n    # This means `bins_remain_cap - item` is a small positive number.\n    # Let's use `bins_remain_cap - item` as the input.\n    # We want high score when this difference is close to 0 (and positive).\n\n    # Let `diff = bins_remain_cap - item`.\n    # We want high score when `diff` is small and positive.\n    # Consider `sigmoid(k * -diff)`. This peaks when `diff` is small and negative. Not right.\n    # Consider `sigmoid(k * diff)`. This peaks when `diff` is large and positive. Not right.\n\n    # The common \"Best Fit\" heuristic aims for `remaining_capacity - item` to be minimized (and non-negative).\n    # The \"Worst Fit\" heuristic aims for `remaining_capacity - item` to be maximized (and non-negative).\n\n    # The prompt suggests \"prioritize bins that are 'almost full' but can still accommodate the current item\".\n    # This sounds like minimizing the remaining space *after* placing the item, as long as it's not negative.\n    # So, we want to minimize `bins_remain_cap - item` (subject to it being >= 0).\n\n    # If we apply a sigmoid to `-(bins_remain_cap - item)`, it will peak when `bins_remain_cap - item` is minimal.\n    # `score = 1 / (1 + exp(-k * -(bins_remain_cap - item)))`\n    # `score = 1 / (1 + exp(k * (bins_remain_cap - item)))`\n    # This score is high when `bins_remain_cap - item` is small (close to 0 or negative).\n    # For valid bins (`bins_remain_cap >= item`), this means `bins_remain_cap - item` is small and positive.\n    # This aligns with the \"Best Fit\" principle.\n\n    # Let's set a reasonable `k` and potentially an offset/scaling.\n    # We want to prioritize bins where `bins_remain_cap` is *just* large enough for the `item`.\n    # This means `bins_remain_cap` is close to `item`.\n    # So, `bins_remain_cap - item` is close to 0.\n\n    # Let's use the ratio: `item / bins_remain_cap`.\n    # We want bins where this ratio is close to 1 but less than 1.\n    # The argument to the sigmoid could be `-(item / bins_remain_cap)`.\n    # `score = 1 / (1 + exp(-k * -(item / bins_remain_cap)))`\n    # `score = 1 / (1 + exp(k * item / bins_remain_cap))`\n    # This peaks when `item / bins_remain_cap` is small (i.e., `bins_remain_cap` is large). This is \"Worst Fit\" like.\n\n    # Let's try to create a scenario where the \"sweet spot\" is when `bins_remain_cap` is slightly larger than `item`.\n    # Consider the normalized difference: `(bins_remain_cap - item) / item`.\n    # We want this to be small and positive.\n    # Argument for sigmoid: `-k * (bins_remain_cap - item) / item`\n    # `score = 1 / (1 + exp(-k * -(bins_remain_cap - item) / item))`\n    # `score = 1 / (1 + exp(k * (bins_remain_cap - item) / item))`\n    # This score is high when `(bins_remain_cap - item) / item` is small and positive,\n    # which means `bins_remain_cap - item` is small and positive. This aligns with Best Fit.\n\n    # Let's try to make the \"sweet spot\" specific. For example, if a bin has\n    # `bins_remain_cap = 1.2 * item`, we want a high score.\n    # If `bins_remain_cap = 1.05 * item`, we want an even higher score.\n    # If `bins_remain_cap = 2 * item`, we want a lower score.\n\n    # Let's use `x = bins_remain_cap / item`. We want to peak around `x = 1`.\n    # `score = 1 / (1 + exp(-k * (x - 1)))`\n    # This means `score = 1 / (1 + exp(-k * (bins_remain_cap / item - 1)))`\n    # `score = 1 / (1 + exp(-k * (bins_remain_cap - item) / item))`\n\n    # Let's choose a steepness factor `k`.\n    # A common sigmoid implementation might use `k=1` or a small value.\n    # We can adjust `k` to control how \"picky\" the algorithm is.\n    # A higher `k` makes the peak sharper.\n\n    k = 5.0  # Steepness factor. Higher means sharper peak around the target.\n    # We are targeting bins where remaining capacity is just slightly larger than the item.\n    # This means `bins_remain_cap / item` should be slightly greater than 1.\n\n    # We want to maximize the sigmoid's output for ratios `bins_remain_cap / item` that are close to 1,\n    # but specifically slightly *above* 1.\n\n    # Let's use `ratio = bins_remain_cap / item`.\n    # We want to evaluate `sigmoid(f(ratio))` where `f(ratio)` is maximal\n    # when `ratio` is slightly above 1.\n\n    # Consider `f(ratio) = -(ratio - 1.05)`. This peaks when `ratio` is 1.05.\n    # `score = 1 / (1 + exp(-k * -(ratio - 1.05)))`\n    # `score = 1 / (1 + exp(k * (ratio - 1.05)))`\n    # `score = 1 / (1 + exp(k * (bins_remain_cap / item - 1.05)))`\n\n    # However, the description mentions \"prioritize bins that are 'almost full'\".\n    # \"Almost full\" implies small remaining capacity.\n    # If a bin has `remaining_cap = 1.01 * item`, it's \"almost full\" and can fit the item.\n    # If a bin has `remaining_cap = 2.0 * item`, it's not \"almost full\".\n\n    # So, the condition `bins_remain_cap` is close to `item` is the key.\n    # Let's use `bins_remain_cap` directly, but scaled.\n    # The sigmoid is good for mapping a range to [0, 1].\n    # We want to map bins where `bins_remain_cap` is slightly greater than `item`\n    # to high scores.\n\n    # A common pattern for fitting is to use `sigmoid(-remaining_capacity)`.\n    # This would prioritize smaller remaining capacities.\n    # `score = 1 / (1 + exp(k * bins_remain_cap))`\n    # This gives higher priority to bins with less remaining capacity.\n\n    # But we also need to consider the item size itself.\n    # The prompt asks for a *Sigmoid Fit Score*. This usually implies\n    # fitting the item snugly.\n\n    # Let's assume `bins_remain_cap` are normalized such that the bin capacity is 1.\n    # Then item is `item_norm`. We want to find bins with `bins_remain_cap` close to `item_norm`.\n    # But here, `bins_remain_cap` are actual capacities, and `item` is the item size.\n\n    # Consider the \"slack\": `slack = bins_remain_cap - item`.\n    # We want high priority when `slack` is small and positive.\n    # Use `sigmoid(-slack)`?\n    # `score = 1 / (1 + exp(k * slack))`\n    # `score = 1 / (1 + exp(k * (bins_remain_cap - item)))`\n    # This will indeed prioritize bins where `bins_remain_cap - item` is minimal and non-negative.\n    # This is the \"Best Fit\" heuristic, but expressed via a sigmoid.\n\n    # Apply the sigmoid to valid bins. For invalid bins, the priority is 0.\n    # To make the sigmoid's response more nuanced, we can scale `bins_remain_cap - item`.\n    # If bin capacities are large, `k` might need to be smaller, or we could normalize the difference.\n    # For instance, normalize by the bin's total capacity `C`.\n    # `scaled_slack = (bins_remain_cap - item) / C`\n    # But we don't have `C` here, only remaining capacity.\n\n    # Let's use the `bins_remain_cap - item` as the argument, but carefully.\n    # We want to avoid division by zero for `item`.\n    # For valid bins (`bins_remain_cap >= item`):\n    # Calculate `slack = bins_remain_cap - item`.\n    # A sigmoid on `-slack` will give higher scores for smaller `slack`.\n    # `score = 1 / (1 + exp(-k * slack))`\n    # `score = 1 / (1 + exp(-k * (bins_remain_cap - item)))`\n\n    # Let's add a small constant `epsilon` to the denominator of the exponent for stability,\n    # and to potentially shift the peak if needed, though `bins_remain_cap - item` is often fine.\n    # A common sigmoid is `1 / (1 + exp(-x))`. If we want peak at `x=0`, this is it.\n    # Here, `x = k * (bins_remain_cap - item)`.\n    # So peak at `bins_remain_cap = item`. This is \"perfect fit\".\n    # We want peak when `bins_remain_cap` is slightly GREATER than `item`.\n    # So we want `bins_remain_cap - item` to be a small positive number.\n\n    # Let's shift the argument: `sigmoid(k * (bins_remain_cap - item - offset))`.\n    # If we want peak when `bins_remain_cap - item = ideal_slack`, then `offset = ideal_slack`.\n    # If `ideal_slack` is 0, we get the perfect fit.\n    # If `ideal_slack` is a small positive number (e.g., 5% of item size), it's better.\n\n    # For \"Sigmoid Fit Score\", often the interpretation is fitting the item as snugly as possible.\n    # This implies prioritizing bins with minimal remaining space *after* placement.\n    # This is precisely what `sigmoid(k * (bins_remain_cap - item))` achieves when `k > 0`.\n    # `sigmoid_arg = k * (bins_remain_cap - item)`\n    # As `bins_remain_cap` decreases towards `item`, `sigmoid_arg` decreases towards 0.\n    # The sigmoid function `1 / (1 + exp(-x))` increases as `x` increases.\n    # So, as `bins_remain_cap` decreases towards `item`, `bins_remain_cap - item` becomes smaller positive,\n    # `k * (bins_remain_cap - item)` becomes smaller positive, and the sigmoid value increases.\n    # This is the desired behavior for Best Fit via Sigmoid.\n\n    # However, the description mentions prioritizing bins that are \"almost full\" but can *still* accommodate.\n    # This phrasing is key. If a bin is *already full* (remaining capacity < item), it's invalid.\n    # If a bin is *just barely able to fit* (remaining capacity = item), it's a perfect fit, possibly high priority.\n    # If a bin has `remaining_capacity = item + epsilon`, where epsilon is small, it's also a good candidate.\n\n    # Let's reconsider the ratio `bins_remain_cap / item`.\n    # A bin is \"almost full\" if its remaining capacity is not much larger than the item.\n    # Let `target_ratio = 1.0`. We want to prioritize bins where `bins_remain_cap / item` is close to `target_ratio`.\n    # Specifically, slightly GREATER than `target_ratio`.\n\n    # Using `ratio = bins_remain_cap / item` (careful with item=0).\n    # `sigmoid_arg = k * (ratio - target_ratio)`\n    # For a peak at `ratio = target_ratio`.\n    # If `target_ratio = 1.0`: `sigmoid_arg = k * (bins_remain_cap / item - 1.0)`\n    # `priorities[valid_bins_mask] = 1 / (1 + np.exp(-sigmoid_arg[valid_bins_mask]))`\n\n    # To make it favor slightly *more* capacity than item:\n    # Let `target_ratio = 1.05` (meaning 5% slack).\n    # `sigmoid_arg = k * (bins_remain_cap / item - 1.05)`\n    # `priorities[valid_bins_mask] = 1 / (1 + np.exp(-sigmoid_arg[valid_bins_mask]))`\n    # This would peak when `bins_remain_cap / item = 1.05`.\n\n    # Let's try to interpret \"almost full\" as meaning the remaining capacity is small,\n    # but also that it's a good fit for the item.\n    # A common heuristic is `1 - (item / bin_capacity)` for first fit decreasing.\n    # Here it's online and priority based.\n\n    # Let's stick with the idea of fitting the item as snugly as possible without overflow,\n    # which corresponds to minimizing `bins_remain_cap - item`.\n    # The sigmoid `1 / (1 + exp(-k * (bins_remain_cap - item)))` works for this,\n    # assigning higher scores to bins where `bins_remain_cap` is closer to `item`.\n\n    # We need to handle the case where `item` is zero or very small.\n    # If `item` is 0, any bin is a valid fit, and we might want to prioritize bins\n    # that are \"more full\" (less remaining capacity), which would mean smaller `bins_remain_cap`.\n    # The current formulation `1 / (1 + exp(-k * (bins_remain_cap - item)))` would still work,\n    # but the interpretation of \"fit\" changes. Assume item > 0.\n\n    # We need to be careful about the range of `bins_remain_cap` and `item`.\n    # If `bins_remain_cap` can be very large, `bins_remain_cap - item` can be very large.\n    # The exponent `-k * (bins_remain_cap - item)` can become very negative, making the sigmoid close to 1.\n    # This means very large bins would get high priority, which is not ideal for \"almost full\".\n\n    # We might need to normalize the `bins_remain_cap - item` by something.\n    # However, without the total bin capacity `C`, it's hard.\n    # Let's try scaling the `bins_remain_cap` itself as an input.\n\n    # Consider mapping `bins_remain_cap` values to a range suitable for the sigmoid,\n    # aiming for high scores for values near `item`.\n\n    # Alternative strategy: What if we want to give a good score to bins that are\n    # \"pretty full\" but *can* take the item?\n    # If `bins_remain_cap` is very large, the bin is not \"almost full\".\n    # If `bins_remain_cap` is just slightly larger than `item`, it's \"almost full\".\n\n    # Let's use a sigmoid that penalizes large remaining capacities.\n    # `sigmoid_arg = k * (item - bins_remain_cap)`\n    # `score = 1 / (1 + exp(-sigmoid_arg))`\n    # `score = 1 / (1 + exp(-k * (item - bins_remain_cap)))`\n    # `score = 1 / (1 + exp(k * (bins_remain_cap - item)))`\n    # This is the same as before. This prioritizes bins where `bins_remain_cap` is close to `item`.\n\n    # What if we want to give a preference for bins that have a certain amount of \"slack\"?\n    # For example, prioritize bins with `bins_remain_cap / item` between 1.1 and 1.3.\n    # This could be done with a Gaussian-like function or a sigmoid difference.\n\n    # Let's use a pragmatic interpretation of \"Sigmoid Fit Score\" in BPP:\n    # Prioritize bins that have the smallest POSITIVE remaining capacity after placing the item.\n    # This means minimizing `bins_remain_cap - item` among valid bins.\n    # The sigmoid `1 / (1 + exp(-k * (bins_remain_cap - item)))` with `k > 0` achieves this.\n\n    # To make it more creative and specific to \"almost full\":\n    # We can try to center the sigmoid's effect around a value slightly larger than `item`.\n    # Let's define a target \"slack\" `S_target`. We want `bins_remain_cap - item` to be close to `S_target`.\n    # `sigmoid_arg = k * ( (bins_remain_cap - item) - S_target )`\n    # `priorities[valid_bins_mask] = 1 / (1 + np.exp(-sigmoid_arg[valid_bins_mask]))`\n\n    # Let's choose `S_target` as a small fraction of the item size, or a fixed small value if item can be 0.\n    # If item can be 0, `S_target` should not depend on item.\n    # Assume item > 0 for typical BPP.\n    # Let `S_target = 0.1 * item` or some small fixed value, e.g., `0.1 * global_bin_capacity` if known.\n    # Since `global_bin_capacity` is not provided, let's make it relative to the item.\n    # `S_target = 0.1 * item` might not be robust if item sizes vary wildly.\n    # A fixed small slack like `0.5` or `1.0` might be better if item sizes are in a known range.\n    # If item sizes are very small, `0.1 * item` might be too small.\n\n    # Let's define a \"tolerance\" or \"preferred slack\" `T`.\n    # We want to prioritize bins where `bins_remain_cap - item` is close to `T`.\n    # The argument to the sigmoid will be `-k * ( (bins_remain_cap - item) - T )`.\n    # This makes the score high when `bins_remain_cap - item` is just above `T`.\n\n    # Let's choose a reasonable `T`. If item sizes are generally around 0.5, then a bin with capacity 0.6\n    # after placing it might be \"almost full\" and fit well.\n    # A general approach without knowing item distribution is difficult.\n    # Let's make `T` a small positive constant, e.g., `0.5`.\n    # `k` controls steepness. `k=5` should be okay for moderate ranges.\n\n    # Reconsider the phrasing: \"prioritize bins that are 'almost full'\".\n    # This suggests that very empty bins (large `bins_remain_cap`) should get low scores,\n    # and bins that are very full (small `bins_remain_cap`) but still fit the item\n    # should get high scores.\n\n    # Let's use the ratio `bins_remain_cap / item`.\n    # We want `bins_remain_cap / item` to be small, but >= 1.\n    # So, `bins_remain_cap` should be slightly larger than `item`.\n\n    # Use `r = bins_remain_cap / item`.\n    # We want high scores when `r` is close to 1 (but `r >= 1`).\n    # Let's use `sigmoid_arg = k * (1 - r)`  (This peaks when r is small). Not right.\n    # Let's use `sigmoid_arg = k * (r - 1)`  (This peaks when r is large). Not right.\n\n    # We need to emphasize the \"almost full\" aspect.\n    # A bin is \"almost full\" if its `bins_remain_cap` is small relative to its original capacity.\n    # But we don't have original capacity.\n\n    # Let's map `bins_remain_cap` to a \"fullness\" score.\n    # Higher fullness = lower remaining capacity.\n    # A sigmoid function `sigmoid(-bins_remain_cap)` could give this.\n    # But we must also fit the item.\n\n    # Let's combine two ideas:\n    # 1. Can the bin fit the item? (Handled by `valid_bins_mask`)\n    # 2. How \"almost full\" is the bin, given it can fit the item?\n\n    # If `bins_remain_cap` is very large compared to `item`, the bin is NOT \"almost full\".\n    # If `bins_remain_cap` is just a little bit larger than `item`, it IS \"almost full\".\n\n    # Let `normalized_remaining_space = (bins_remain_cap - item) / item`.\n    # We want `normalized_remaining_space` to be small and positive.\n    # Let's call this `fitting_slack`.\n    # `fitting_slack` should be small for high priority.\n    # `sigmoid_arg = k * (-fitting_slack)`\n    # `sigmoid_arg = k * (-(bins_remain_cap - item) / item)`\n    # `sigmoid_arg = -k * (bins_remain_cap - item) / item`\n\n    # `score = 1 / (1 + np.exp(-sigmoid_arg))`\n    # `score = 1 / (1 + np.exp(k * (bins_remain_cap - item) / item))`\n\n    # Let's check this.\n    # If `bins_remain_cap = item` (perfect fit): `score = 1 / (1 + exp(0)) = 0.5`.\n    # If `bins_remain_cap = item + epsilon`: `score = 1 / (1 + exp(k * epsilon / item))`. If epsilon small, exp is slightly > 1, score slightly < 0.5. This is NOT right. We want high priority when `bins_remain_cap` is *slightly greater* than `item`.\n\n    # We want peak when `bins_remain_cap - item` is minimal POSITIVE value.\n    # Let's use the inverse of slack as an indicator for fullness.\n    # Consider `item / bins_remain_cap`. This ratio is high when `bins_remain_cap` is close to `item`.\n    # BUT we need `bins_remain_cap >= item`. So `item / bins_remain_cap` will be <= 1.\n    # So we want high priority when `item / bins_remain_cap` is close to 1.\n\n    # Let `r = item / bins_remain_cap`. We want to maximize `sigmoid(k * (r - 1))` -- peaks at r=1, value 0.5.\n    # We want to maximize `sigmoid(k * r)`. This peaks when `r` is large (bins_remain_cap small). This is again \"Best Fit\".\n\n    # The phrase \"Sigmoid Fit Score\" is often used for packing, meaning to fit the item\n    # such that the remaining capacity is minimized, subject to it being non-negative.\n    # This leads back to `1 / (1 + np.exp(-k * (bins_remain_cap - item)))`.\n\n    # Let's make it slightly more creative by influencing the \"center\" of the sigmoid.\n    # The interpretation could be: prioritize bins where the ratio `remaining_capacity / item_size`\n    # is as close to 1 as possible.\n    # `ratio = bins_remain_cap / item`\n    # We want peak score when `ratio = 1.0`.\n    # `sigmoid_arg = k * (ratio - 1.0)`\n    # `priorities[valid_bins_mask] = 1 / (1 + np.exp(-sigmoid_arg[valid_bins_mask]))`\n\n    # This strategy assigns priority:\n    # - 0.5 if `bins_remain_cap == item`\n    # - > 0.5 if `bins_remain_cap > item`\n    # - < 0.5 if `bins_remain_cap < item` (but these are filtered by mask)\n\n    # So higher priority is given to bins with MORE remaining capacity relative to the item.\n    # This is the opposite of \"Best Fit\" (which wants minimal remaining).\n    # This sounds more like \"Worst Fit\", but evaluated with a sigmoid.\n\n    # The description says \"prioritize bins that are 'almost full'\".\n    # This implies `bins_remain_cap` should be small.\n    # Let's use `sigmoid_arg = k * (item / bins_remain_cap)`.\n    # `score = 1 / (1 + np.exp(-k * item / bins_remain_cap))`\n    # When `item / bins_remain_cap` is high (meaning `bins_remain_cap` is small relative to `item`),\n    # the sigmoid argument is high, and the score is high.\n    # This matches \"almost full\".\n\n    # This score will be 0.5 when `item / bins_remain_cap` is 0, which implies `bins_remain_cap` is infinite.\n    # It will be high when `item / bins_remain_cap` is close to 1.\n    # It will be higher when `item / bins_remain_cap` is > 1, which happens if `bins_remain_cap < item`.\n    # BUT we only apply it to valid bins where `bins_remain_cap >= item`.\n    # So `item / bins_remain_cap <= 1`.\n    # The score will be highest (approaching 1) when `item / bins_remain_cap` is close to 1,\n    # meaning `bins_remain_cap` is just slightly larger than `item`. This IS \"almost full\".\n\n    # Let's choose parameters:\n    k = 5.0  # Steepness. Higher means score sharply increases as ratio approaches 1.\n    # We need to avoid division by zero if `bins_remain_cap` or `item` is 0.\n    # For BPP, `item` > 0. `bins_remain_cap` can be 0 if a bin is full.\n    # The `valid_bins_mask` handles `bins_remain_cap < item`.\n    # If `item` is 0, then `item / bins_remain_cap = 0`, score is 0.5 for all. That's fine.\n\n    # Let's refine the interpretation of \"Sigmoid Fit Score\" by ensuring it favors\n    # small remaining capacity among valid bins.\n    # Use `1 - (bins_remain_cap - item) / max_possible_remaining`. Not feasible without `max_possible_remaining`.\n\n    # Let's use the ratio `bins_remain_cap / item`.\n    # We want the peak score when `bins_remain_cap / item` is small (>=1).\n    # Let `x = bins_remain_cap / item`. We want to optimize `sigmoid(f(x))` where `f(x)` peaks\n    # for small `x >= 1`.\n    # Try `f(x) = -k * (x - C)` for some center `C`.\n    # If `C = 1`, then `f(x) = -k * (x - 1)`. Max value at `x=1`.\n    # This means `score = 1 / (1 + exp(k * (x - 1)))`.\n    # Score is 0.5 at `x=1`. Score decreases as `x` increases (remaining capacity grows).\n    # This is \"Best Fit\" via sigmoid.\n\n    # To favor \"almost full\": the bins should be \"fuller\".\n    # This means `bins_remain_cap` is smaller.\n    # So we want high score when `bins_remain_cap` is small but `bins_remain_cap >= item`.\n\n    # Let's map `bins_remain_cap` to a value that is low for large capacities and high for small capacities.\n    # `f(bins_remain_cap) = -bins_remain_cap`\n    # Use `sigmoid(k * (-bins_remain_cap))` which is `sigmoid(-k * bins_remain_cap)`.\n    # This will prioritize bins with smaller `bins_remain_cap`.\n\n    # Combining with the item:\n    # We only consider `bins_remain_cap >= item`.\n    # Let's use `sigmoid(k * (item - bins_remain_cap))`.\n    # For valid bins: `item - bins_remain_cap <= 0`.\n    # So `k * (item - bins_remain_cap) <= 0`.\n    # `sigmoid(negative_value)` will be < 0.5.\n    # As `bins_remain_cap` decreases (bin gets fuller), `item - bins_remain_cap` becomes more negative,\n    # `k * (item - bins_remain_cap)` becomes more negative, and sigmoid score decreases further.\n    # This is not quite right.\n\n    # The core idea of \"fitting\" is often related to minimizing wasted space.\n    # Wasted space = `bins_remain_cap - item` (for valid bins).\n    # To prioritize minimal wasted space, we want high score when `bins_remain_cap - item` is small.\n\n    # Let's define the score `S(b)` for bin `b` and item `i`:\n    # If `b.remaining_cap < i`: `S(b) = 0`\n    # If `b.remaining_cap >= i`: `S(b) = sigmoid(k * (item - b.remaining_cap))`\n    # With `k > 0`:\n    # `item - b.remaining_cap` is zero or negative.\n    # `sigmoid(0)` is 0.5.\n    # `sigmoid(negative)` is < 0.5.\n    # As `b.remaining_cap` decreases (gets fuller), `item - b.remaining_cap` becomes more negative,\n    # and sigmoid score decreases. This gives highest priority to bins that are barely able to fit.\n    # This is Best Fit.\n\n    # Let's try to align the description with the common use of sigmoid in packing heuristics.\n    # A typical \"Sigmoid Fit\" heuristic prioritizes bins that have remaining capacity\n    # closest to the item size (without going below).\n    # This is captured by `1 / (1 + exp(-k * (bins_remain_cap - item)))`.\n\n    # Let's add a slight modification to reflect \"almost full\" more explicitly.\n    # Perhaps by shaping the sigmoid argument based on some notion of \"fullness threshold\".\n    # If we assume bins are scaled to capacity 1, then `item_norm` and `rem_cap_norm`.\n    # A bin is \"almost full\" if `rem_cap_norm` is small.\n    # We want high score when `rem_cap_norm` is small AND `rem_cap_norm >= item_norm`.\n\n    # Final attempt:\n    # We want to prioritize bins where `bins_remain_cap` is just slightly larger than `item`.\n    # Let's use `score = sigmoid(k * (1 - bins_remain_cap / item))`? This peaks when `bins_remain_cap / item` is small.\n    # `score = sigmoid(k * (item / bins_remain_cap - 1))`? This peaks when `item / bins_remain_cap` is small.\n\n    # Let's focus on the \"Sigmoid Fit Score\" for packing. It aims to minimize `bins_remain_cap - item`.\n    # The function `f(x) = 1 / (1 + exp(-k * x))` is monotonically increasing.\n    # To maximize f(x) when `x = bins_remain_cap - item` is minimized, we should use `x`.\n    # Thus, `score = 1 / (1 + exp(-k * (bins_remain_cap - item)))`.\n\n    # Let's creatively tweak this for \"almost full\".\n    # We can make the sigmoid's argument dependent on the 'fullness' of the bin.\n    # A bin is \"fuller\" if `bins_remain_cap` is smaller.\n    # Let's scale the `bins_remain_cap` itself, or a normalized version.\n    # Without total bin capacity, this is tricky.\n\n    # Let's use the ratio `item / bins_remain_cap` again.\n    # It is <= 1 for valid bins.\n    # We want to prioritize bins where this ratio is close to 1.\n    # This means `bins_remain_cap` is close to `item`.\n    # High score when `item / bins_remain_cap` is close to 1.\n    # Function: `sigmoid(k * (item / bins_remain_cap))`\n    # Argument `k * item / bins_remain_cap`.\n    # This function is HIGH when `item / bins_remain_cap` is HIGH.\n    # `item / bins_remain_cap` is high when `bins_remain_cap` is low.\n    # This means we prioritize bins with LESS remaining capacity.\n    # This fits the \"almost full\" criteria.\n\n    # Let's verify `item / bins_remain_cap` for valid bins (`bins_remain_cap >= item`):\n    # If `bins_remain_cap = item`, ratio = 1.\n    # If `bins_remain_cap = item + epsilon`, ratio < 1.\n    # If `bins_remain_cap = very large`, ratio is close to 0.\n\n    # So `sigmoid(k * item / bins_remain_cap)` will:\n    # - Give score of 0.5 when `item / bins_remain_cap = 0` (very large bins).\n    # - Give score of 0.5 when `bins_remain_cap = item` if `k=0`. For `k>0`, it will be `sigmoid(k)`. Let's recheck.\n\n    # `sigmoid(x) = 1 / (1 + exp(-x))`.\n    # If `x = k * item / bins_remain_cap`.\n    # If `bins_remain_cap = item`, `x = k`. Score = `1 / (1 + exp(-k))`.\n    # If `bins_remain_cap = very large`, `x` approaches 0. Score approaches `1 / (1 + exp(0)) = 0.5`.\n    # If `bins_remain_cap = item + epsilon`, `x = k * item / (item + epsilon)`. This `x` is slightly less than `k`. Score will be slightly less than `1 / (1 + exp(-k))`.\n\n    # This still seems to prioritize larger remaining capacities amongst the valid ones.\n    # This is confusing. Let's try the opposite: `sigmoid(k * (bins_remain_cap / item))`.\n    # Argument `k * bins_remain_cap / item`.\n    # If `bins_remain_cap = item`, arg = k. Score = `1 / (1 + exp(-k))`.\n    # If `bins_remain_cap = item + epsilon`, arg = `k * (1 + epsilon/item)`. Arg > k. Score > `1/(1+exp(-k))`. Higher scores for LARGER remaining capacity.\n    # This is not \"almost full\".\n\n    # Back to `1 / (1 + exp(-k * (bins_remain_cap - item)))`. This is best fit.\n    # How to modify for \"almost full\"?\n    # \"Almost full\" means small `bins_remain_cap`, but still fitting.\n    # This means `bins_remain_cap` should be close to `item`.\n    # The current function peaks as `bins_remain_cap` approaches `item`.\n\n    # The core of the strategy is likely in the argument of the sigmoid.\n    # Let's make the argument inversely proportional to the remaining capacity,\n    # but only for valid bins.\n    # Let `arg = -bins_remain_cap`.\n    # Sigmoid `sigmoid(k * arg)` => `sigmoid(k * -bins_remain_cap)`. This favors small `bins_remain_cap`.\n\n    # We must ensure `bins_remain_cap >= item`.\n    # Let's transform `bins_remain_cap` to be a value that is high when it's small and positive.\n    # How about: `target_value = item`.\n    # We want to maximize score when `bins_remain_cap` is slightly above `item`.\n    # Let `x = bins_remain_cap`.\n    # We want peak of `sigmoid(f(x))` where `f(x)` peaks for `x` just above `item`.\n    # Let `f(x) = k * (item - x)`. Peaks at `x = item`, value 0.\n    # `sigmoid(k * (item - x))` => `sigmoid(k * (item - bins_remain_cap))`\n    # This peaks when `item - bins_remain_cap` is maximal (i.e., `bins_remain_cap` is minimal).\n    # For valid bins, this means `bins_remain_cap` is minimally larger than `item`.\n    # This interpretation of \"Sigmoid Fit Score\" sounds good for \"almost full\".\n\n    # Argument: `k * (item - bins_remain_cap)`\n    # If `bins_remain_cap = item`: arg = 0, score = 0.5\n    # If `bins_remain_cap = item + epsilon`: arg = `k * (-epsilon)`. Score < 0.5.\n    # This is still favoring bins that are *just* fitting, and penalizing slightly over-fitting ones.\n    # This seems to be the \"Best Fit\" interpretation.\n\n    # What if \"almost full\" implies a specific threshold?\n    # e.g., a bin is \"almost full\" if its remaining capacity is less than 50% of its original capacity.\n    # But we don't know original capacity.\n\n    # Let's assume the prompt intends to prioritize bins with small POSITIVE remaining capacity after fitting.\n    # This means `bins_remain_cap - item` should be minimized and positive.\n    # The function `1 / (1 + exp(-k * (bins_remain_cap - item)))` does this.\n    # Let's use this as the baseline and ensure `k` is chosen to make it sensitive.\n\n    # Consider `k=5`.\n    # `bins_remain_cap - item`\n    # If 0, exp(0)=1, score = 0.5\n    # If 0.1, exp(-0.5) ~ 0.6, score ~ 0.6\n    # If 0.2, exp(-1) ~ 0.36, score ~ 0.7\n    # If 0.5, exp(-2.5) ~ 0.08, score ~ 0.92\n    # If 1.0, exp(-5) ~ 0.006, score ~ 0.99\n\n    # This means larger `bins_remain_cap - item` gets higher priority. This is Worst Fit.\n    # The goal is \"almost full\", which implies small `bins_remain_cap - item`.\n    # So, we need the opposite sigmoid behavior.\n    # `score = 1 / (1 + exp(k * (bins_remain_cap - item)))`\n    # If `bins_remain_cap = item`: exp(0)=1, score = 0.5\n    # If `bins_remain_cap = item + 0.1`: exp(0.5) ~ 1.6, score ~ 1/2.6 ~ 0.38\n    # If `bins_remain_cap = item + 0.2`: exp(1) ~ 2.7, score ~ 1/3.7 ~ 0.27\n    # If `bins_remain_cap = item + 0.5`: exp(2.5) ~ 12, score ~ 1/13 ~ 0.07\n\n    # This means `score` DECREASES as `bins_remain_cap - item` increases.\n    # So, this prioritizes bins with minimum positive remaining capacity.\n    # This is Best Fit!\n\n    # The description says \"priority score for each bin. The bin with the highest priority score will be selected\".\n    # This heuristic (`1 / (1 + exp(k * (bins_remain_cap - item)))`) prioritizes bins with minimum `bins_remain_cap - item`.\n\n    # Is this \"creative\"? It's a standard way to express Best Fit with a sigmoid.\n    # The creativity might come from tuning `k` or shifting the argument.\n\n    # Let's make it more creative by creating a \"preferred slack\".\n    # Prioritize bins where `bins_remain_cap - item` is close to `S_pref`.\n    # `arg = -k * ( (bins_remain_cap - item) - S_pref )`\n    # `score = 1 / (1 + exp(arg))`\n    # `score = 1 / (1 + exp(k * ( (bins_remain_cap - item) - S_pref )))`\n\n    # Let's choose `S_pref` to be a small positive value, say `0.1 * item` or `0.5` as a fixed small slack.\n    # If we want to explicitly target \"almost full\", we should target small slack.\n    # Let `S_pref = 0.1` (assuming typical item sizes are > 0.1).\n\n    S_pref = 0.1  # Preferred slack (e.g., 0.1 units of capacity remaining)\n    k = 5.0     # Steepness factor\n\n    # Calculate the argument for the sigmoid\n    # We want to maximize the score when `bins_remain_cap - item` is close to `S_pref`.\n    # The sigmoid `1/(1+exp(-x))` peaks at `x=0`.\n    # So, we need `arg = -k * ( (bins_remain_cap - item) - S_pref )`\n    # This ensures the peak is when `bins_remain_cap - item = S_pref`.\n\n    sigmoid_arg = -k * (bins_remain_cap - item - S_pref)\n\n    # Calculate priorities for valid bins using the sigmoid function\n    # Handle potential overflow in `np.exp` by clipping the argument if necessary,\n    # though with reasonable `k` and `S_pref`, it's often not needed.\n    # Using a robust sigmoid:\n    # `safe_sigmoid(x)` can be `1 / (1 + np.exp(-x))`\n    # or `0.5 * (1 + np.tanh(x / 2))`\n\n    # Using the standard sigmoid:\n    priorities[valid_bins_mask] = 1 / (1 + np.exp(-sigmoid_arg[valid_bins_mask]))\n\n    # The resulting priorities will be highest for bins where `bins_remain_cap - item` is closest to `S_pref`.\n    # If `S_pref` is small and positive, this prioritizes bins that are \"almost full\" but can still fit the item.\n    # For bins that cannot fit, the priority remains 0.\n\n    return priorities",
    "response_id": 6,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 1.0,
    "halstead": 133.97977094150824,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a First Fit strategy.\n\n    The priority is higher for bins that can fit the item and that have less remaining capacity\n    after placing the item. This encourages using bins that are closer to being full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Identify bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit, calculate a priority score.\n    # Higher priority for bins with less remaining capacity *after* placing the item.\n    # This is the core of the \"best fit\" idea within a first-fit framework.\n    # We want to leave more space in bins that are already quite full if they can accommodate the item.\n    if np.any(can_fit_mask):\n        remaining_after_placement = bins_remain_cap[can_fit_mask] - item\n        # To prioritize bins with *less* remaining capacity, we can invert this.\n        # A small remaining capacity means a high priority score.\n        # We can use the negative of the remaining capacity, or 1 / (remaining + epsilon)\n        # Let's use a large number minus the remaining capacity to emphasize smaller remainders.\n        # We add a small epsilon to avoid division by zero if remaining_after_placement is 0.\n        priorities[can_fit_mask] = 1000 - remaining_after_placement\n\n    # If no bins can fit, all priorities remain 0.\n    return priorities",
    "response_id": 10,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 2.0,
    "halstead": 25.26619429851844,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response8.txt_stdout.txt",
    "code_path": "problem_iter1_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using an Epsilon-Greedy strategy.\n\n    The Epsilon-Greedy strategy balances exploration (trying less optimal bins)\n    and exploitation (choosing the best fitting bins).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.2  # Exploration rate\n\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins)\n\n    # Identify bins that can fit the item\n    suitable_bins_indices = np.where(bins_remain_cap >= item)[0]\n\n    if len(suitable_bins_indices) == 0:\n        # No bin can fit the item, return all zeros (or handle as error/new bin creation)\n        return priorities\n\n    # Calculate 'greedy' scores for suitable bins\n    # We prioritize bins that have the least remaining capacity after placing the item\n    # This is a common strategy in BPP to try and fill bins more tightly.\n    greedy_scores = -bins_remain_cap[suitable_bins_indices] + item\n\n    # Normalize greedy scores to be between 0 and 1 (optional but good for consistency)\n    # We take the maximum possible difference to scale\n    if len(suitable_bins_indices) > 1:\n        max_diff = np.max(bins_remain_cap[suitable_bins_indices]) - np.min(bins_remain_cap[suitable_bins_indices])\n        if max_diff > 0:\n            greedy_scores = greedy_scores / (max_diff + item) # Add item to avoid division by zero if all are same\n        else: # All suitable bins have the same remaining capacity\n            greedy_scores = np.zeros_like(greedy_scores) # Assign equal score\n\n    # Apply Epsilon-Greedy:\n    # With probability epsilon, choose a random suitable bin (exploration).\n    # With probability 1-epsilon, choose the bin with the highest greedy score (exploitation).\n\n    if np.random.rand() < epsilon:\n        # Exploration: pick a random suitable bin\n        chosen_bin_index = np.random.choice(suitable_bins_indices)\n        priorities[chosen_bin_index] = 1.0  # High priority for the randomly chosen bin\n    else:\n        # Exploitation: pick the best greedy bin\n        best_bin_index_in_suitable = np.argmax(greedy_scores)\n        chosen_bin_index = suitable_bins_indices[best_bin_index_in_suitable]\n        priorities[chosen_bin_index] = 1.0 # Assign highest priority to the best bin\n\n    # For bins that are not suitable, their priority remains 0.\n    # For suitable bins not chosen by the epsilon-greedy strategy, assign a lower priority.\n    # This makes the chosen bin's priority stand out.\n    for idx in suitable_bins_indices:\n        if idx != chosen_bin_index:\n            priorities[idx] = 0.1 # Lower priority for other suitable bins\n\n\n    return priorities",
    "response_id": 8,
    "obj": 4.347826086956536,
    "cyclomatic_complexity": 7.0,
    "halstead": 150.41407098051496,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response9.txt_stdout.txt",
    "code_path": "problem_iter1_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a Softmax-Based Fit strategy.\n\n    This strategy prioritizes bins that are \"almost full\" but can still accommodate the item,\n    while also giving some consideration to bins that have ample space. The Softmax function\n    is used to translate these preferences into a probability-like score for each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # We only consider bins that can fit the current item.\n    # For bins that cannot fit, assign a very low \"priority\" (effectively zero).\n    can_fit_mask = bins_remain_cap >= item\n    valid_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    if valid_bins_remain_cap.size == 0:\n        # If no bin can fit the item, return zeros.\n        return np.zeros_like(bins_remain_cap)\n\n    # Calculate a \"fit score\" for each valid bin.\n    # We want to favor bins that are nearly full but can still fit the item.\n    # A simple approach is to use the remaining capacity directly.\n    # A higher remaining capacity means it's less \"tightly packed\".\n    # To encourage \"almost full\" bins, we can invert the remaining capacity relative to the item size.\n    # This makes bins with remaining capacity just slightly larger than 'item' have higher scores.\n    # We add a small epsilon to avoid division by zero if remaining capacity is exactly 'item'.\n    fit_scores = (valid_bins_remain_cap - item + 1e-6) / (valid_bins_remain_cap + 1e-6)\n\n    # Apply a penalty for bins that have significantly more space than needed.\n    # This can be achieved by making the 'fit_scores' decrease faster for larger remaining capacities.\n    # For example, we can scale the fit_scores by a factor that reduces with remaining capacity.\n    # Or, more simply, we can add a small constant to 'item' before subtracting,\n    # which slightly penalizes bins with very large remaining capacities.\n    # Let's consider a more nuanced approach:\n    # We want to prioritize bins where (remaining_capacity - item) is small.\n    # If remaining_capacity is much larger than item, it's less desirable.\n\n    # Alternative approach: prioritize bins where remaining capacity is \"closest\" to item size.\n    # We can use the absolute difference, but then we want smaller differences to be better.\n    # Or, we can use a measure that is high when remaining capacity is just enough.\n    # Let's try a score that is high when (remaining_capacity - item) is close to zero,\n    # and decreases as (remaining_capacity - item) increases.\n\n    # Score based on how \"tightly\" the item fits:\n    # We want smaller (remaining_capacity - item) to be better.\n    # Let's try a transformation:\n    # If remaining_capacity = item, score is high.\n    # If remaining_capacity >> item, score is low.\n    # Consider score proportional to 1 / (remaining_capacity - item + epsilon) if we want tighter fits.\n    # However, this can lead to extreme values.\n\n    # Let's go back to a Softmax strategy focusing on \"almost full\" bins.\n    # We want a higher value for bins where `remaining_capacity - item` is small,\n    # but non-negative.\n    # Let's create a score that is inversely related to `remaining_capacity - item`.\n    # To prevent very large values when `remaining_capacity - item` is close to zero,\n    # we can use an exponential function.\n\n    # We want higher scores for bins where `valid_bins_remain_cap - item` is small.\n    # Let `slack = valid_bins_remain_cap - item`.\n    # We want scores to be high for small slack, and lower for large slack.\n    # Using `np.exp(-slack)` would achieve this. However, if slack is very large,\n    # the value becomes close to zero.\n\n    # Let's try to model this as a desirability score.\n    # Desirability increases as remaining capacity gets closer to item size.\n    # A potential score could be based on the \"waste\" created: waste = remaining_capacity - item.\n    # We want to minimize waste. So, high priority for low waste.\n\n    # Let's create a \"preference\" value for each valid bin.\n    # We want to prioritize bins that have a small amount of remaining capacity *after*\n    # placing the item, but not so small that it cannot accommodate the item.\n    # A score could be related to 1 / (remaining_capacity - item + epsilon).\n    # To smooth this and use with Softmax, we can use an exponential.\n    # `np.exp(-(valid_bins_remain_cap - item))` would work, higher for smaller (remaining_capacity - item).\n\n    # Let's try a score that emphasizes bins that are almost full.\n    # Consider the inverse of the available slack.\n    # `slack = valid_bins_remain_cap - item`.\n    # `score = 1.0 / (slack + 1e-9)`. This can be very sensitive.\n\n    # Let's refine: We want to give priority to bins where the remaining capacity\n    # is \"just enough\" for the item. This means `remaining_capacity - item` is small.\n    # A Gaussian-like function centered around a small slack value?\n    # Or simpler: A function that decreases as slack increases.\n\n    # Let's use a form inspired by Softmax, where we have a \"quality\" for each bin.\n    # The quality should be higher for bins with less \"waste\".\n    # `waste = valid_bins_remain_cap - item`\n    # Higher quality for smaller `waste`.\n\n    # Let's try a score that uses the reciprocal of remaining capacity to give\n    # a slight bias towards fuller bins, but also penalizes very empty bins.\n    # `1.0 / (valid_bins_remain_cap + 1e-6)` -> Higher for less remaining capacity.\n    # This would favor bins that are already somewhat full.\n\n    # To combine \"can fit\" with a \"desirability\" of being almost full:\n    # A value that is high when `valid_bins_remain_cap` is just slightly greater than `item`.\n    # Consider `remaining_capacity / bin_capacity` (if bin_capacity was known).\n    # Without bin_capacity, we can consider the ratio of item size to remaining capacity.\n    # `item / valid_bins_remain_cap`. This is high for smaller remaining capacities,\n    # which is what we want if the bin is \"almost full\".\n\n    # Let's try a score based on `remaining_capacity - item`.\n    # We want this value to be small.\n    # Score = `exp(-k * (remaining_capacity - item))` where `k` is a scaling factor.\n    # A larger `k` makes the preference for smaller slack stronger.\n\n    # Let's set a moderate `k` to balance preference for \"almost full\" vs. \"more space\".\n    # We can also make the preference sharper or flatter by adjusting the scaling.\n    # For simplicity, let's use a simple inverse relationship with a floor.\n\n    # Let's try to create scores that are high for bins where `remaining_capacity` is\n    # just above `item`.\n\n    # A simple score: the difference between the remaining capacity and the item size.\n    # We want smaller differences to be prioritized. So, we invert this or subtract from a constant.\n    # `priorities_valid = 1.0 / (valid_bins_remain_cap - item + 1e-9)`\n    # This would give very high priority to bins where `remaining_capacity - item` is tiny.\n\n    # Softmax-Based Fit: the idea is to assign probabilities.\n    # We want to put the item in a bin that results in the least \"slack\" (remaining_capacity - item).\n    # So, higher priority for smaller slack.\n    # A common transformation for Softmax is `exp(score)`.\n    # Let the score be `-(valid_bins_remain_cap - item)`. This means higher scores for smaller slack.\n    # Then, we normalize these scores using Softmax.\n\n    scores = -(valid_bins_remain_cap - item)\n\n    # Apply Softmax to the scores of valid bins.\n    # The Softmax function converts scores into probabilities.\n    # We add a small value to `valid_bins_remain_cap - item` to avoid division by zero in exp.\n    # Let's use `exp(-slack)` where `slack = valid_bins_remain_cap - item`.\n    # This gives higher values for smaller slack.\n    # We need to be careful about the scale of these scores before exp to avoid overflow/underflow.\n    # A common technique is to subtract the maximum score before exp.\n\n    # Let `value = valid_bins_remain_cap - item`\n    # We want higher priority when `value` is small.\n    # Consider `transformed_value = 1.0 / (value + 1e-9)` - this might be too extreme.\n    # Consider `transformed_value = -value` - this means smaller `value` gives larger score.\n    # Using Softmax: `exp(-value)`\n\n    # Let's try a more direct approach related to the \"goodness\" of a fit.\n    # A good fit is when `remaining_capacity` is close to `item`.\n    # We can define a \"fit quality\" for each valid bin.\n    # Let `quality = 1.0 / (valid_bins_remain_cap - item + 1e-9)`.\n    # This makes bins with very little slack have very high quality.\n\n    # Alternative: Consider a Gaussian-like function peaking at zero slack.\n    # `quality = np.exp(-(valid_bins_remain_cap - item)**2 / (2 * sigma**2))` for some sigma.\n    # However, this penalizes bins that are too full (negative slack) which are not allowed.\n\n    # Let's stick with a simpler score that emphasizes bins with small residual capacity.\n    # Score for valid bins: `1.0 / (valid_bins_remain_cap - item + 1e-6)`\n    # This gives higher scores to bins with less remaining capacity after fitting the item.\n\n    # Using Softmax:\n    # `logits = 1.0 / (valid_bins_remain_cap - item + 1e-6)`\n    # `exp_logits = np.exp(logits - np.max(logits))`\n    # `probabilities = exp_logits / np.sum(exp_logits)`\n\n    # This approach might overemphasize bins with near-zero slack.\n    # Let's try a score that is higher when the remaining capacity is just slightly larger than item.\n    # A more controlled \"almost full\" preference.\n    # Score: `np.exp(-(valid_bins_remain_cap - item))` would work well with softmax.\n    # Smaller `(valid_bins_remain_cap - item)` -> higher score.\n\n    scores_for_softmax = np.exp(-(valid_bins_remain_cap - item))\n\n    # To prevent overflow with large negative exponents, or underflow with large positive ones,\n    # it's good practice to shift the scores by subtracting the maximum score.\n    shifted_scores = scores_for_softmax - np.max(scores_for_softmax)\n\n    # Calculate the probabilities using Softmax.\n    exp_shifted_scores = np.exp(shifted_scores)\n    probabilities = exp_shifted_scores / np.sum(exp_shifted_scores)\n\n    # Create the final priorities array, filling in probabilities for valid bins\n    # and zeros for invalid bins.\n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[can_fit_mask] = probabilities\n\n    return priorities",
    "response_id": 9,
    "obj": 4.487435181491823,
    "cyclomatic_complexity": 2.0,
    "halstead": 149.33879237447786,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response11.txt_stdout.txt",
    "code_path": "problem_iter1_code11.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Best Fit strategy.\n\n    The Best Fit strategy prioritizes bins that have just enough remaining capacity\n    to fit the item. This aims to leave larger remaining capacities in other bins\n    for potentially larger future items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities to a very low value for bins that cannot fit the item\n    priorities = np.full_like(bins_remain_cap, -np.inf)\n\n    # Identify bins that have enough capacity for the item\n    fitting_bins_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, calculate the remaining capacity after placing the item\n    remaining_after_fit = bins_remain_cap[fitting_bins_mask] - item\n\n    # The \"best fit\" is the bin where the remaining capacity is minimized.\n    # We want to assign higher priority to bins with smaller remaining capacity (after fitting).\n    # A simple heuristic for priority could be the inverse of the remaining capacity,\n    # but we need to avoid division by zero and give preference to exact fits.\n    # A common approach is to penalize larger remaining capacities.\n    # We can assign a score that is inversely proportional to the remaining capacity.\n    # To make it simple and avoid division by zero, we can use something like:\n    # priority = 1 / (remaining_after_fit + epsilon) for small epsilon, or\n    # more robustly, map the remaining capacity to a priority score.\n    # A high priority should be for the smallest remaining capacity.\n\n    # Let's map the remaining capacity to a priority:\n    # If remaining_after_fit is 0, it's a perfect fit, give it highest priority.\n    # If remaining_after_fit is small and positive, give it high priority.\n    # If remaining_after_fit is large, give it lower priority.\n\n    # To achieve this, we can sort the fitting bins by their remaining capacity.\n    # The bin with the smallest remaining capacity should get the highest priority.\n    # We can assign priorities based on the rank of the remaining capacity.\n\n    # Find the indices of bins that can fit the item\n    fitting_indices = np.where(fitting_bins_mask)[0]\n\n    if len(fitting_indices) > 0:\n        # Calculate the remaining capacity for only those bins that can fit the item\n        remaining_for_fitting = bins_remain_cap[fitting_indices] - item\n\n        # Create a sorting key: smaller remaining capacity gets higher priority.\n        # We can assign priority based on the sorted order. The bin with the smallest\n        # remaining capacity (best fit) should have the highest priority value.\n        # Let's sort the fitting indices based on remaining_for_fitting in ascending order.\n        sorted_fitting_indices = fitting_indices[np.argsort(remaining_for_fitting)]\n\n        # Assign priorities: higher value means higher priority.\n        # The best fit bin (smallest remaining capacity) gets the highest priority score.\n        # We can use a decreasing sequence of numbers for priority.\n        # The number of fitting bins determines the range of priorities.\n        num_fitting_bins = len(sorted_fitting_indices)\n        for i, idx in enumerate(sorted_fitting_indices):\n            # Assign priority such that the best fit gets the highest number.\n            # E.g., if 3 bins fit, priorities could be 3, 2, 1.\n            priorities[idx] = num_fitting_bins - i\n\n    return priorities",
    "response_id": 11,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 3.0,
    "halstead": 62.907475208398566,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response20.txt_stdout.txt",
    "code_path": "problem_iter1_code20.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using a\n    First Fit Decreasing inspired heuristic for the priority function.\n\n    This heuristic prioritizes bins that have just enough space for the item,\n    followed by bins that have slightly more space. It aims to leave larger\n    bins for potentially larger future items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Find bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate the \"tightness\" of fit for bins that can accommodate the item\n    # A smaller residual capacity (tighter fit) is prioritized.\n    # We add a small epsilon to avoid division by zero if residual capacity is 0,\n    # though technically that case would be a perfect fit.\n    residual_capacities = bins_remain_cap[can_fit_mask] - item\n    \n    # Assign higher priority to bins with less remaining space after fitting the item\n    # The priority is inversely proportional to the remaining space, favoring tighter fits.\n    # We also add 1 to avoid zero priorities and ensure non-zero positive scores for fitting bins.\n    priorities[can_fit_mask] = 1.0 / (residual_capacities + 1e-6) + 1\n\n    # Among bins that can fit the item, we want to slightly favor bins that\n    # have a capacity closer to the item's size but still enough.\n    # This is an approximation of First Fit Decreasing idea: try to fill bins\n    # somewhat efficiently without leaving too much empty space, but also not\n    # using up bins that could fit larger items later.\n\n    # Let's refine the priority: bins that have slightly more space are less desirable\n    # than those that fit snugly.\n    # A simple way to achieve this is to penalize bins with much larger capacities.\n    # However, the primary driver should be fitting the item.\n    # For simplicity and to adhere to a \"priority score\", let's use the reciprocal\n    # of remaining capacity as the main score, and a penalty for excess capacity.\n\n    # Option 1 (used above): Prioritize tighter fits.\n    # Option 2 (alternative idea, could be combined or a different v3):\n    # If we wanted to prioritize bins that are \"just right\" or \"slightly over\",\n    # we could consider bins whose remaining capacity is between item and item + tolerance.\n    # However, the current v2 aims to simply prioritize fitting snugly.\n\n    # Let's ensure that bins that *cannot* fit the item get a priority of 0.\n    # The initialization handles this.\n\n    # Let's consider the \"emptiness\" of a bin if it fits. A bin that fits item perfectly\n    # has 0 remaining space. A bin that fits item with 1 unit remaining has 1 unit of space.\n    # We want to prioritize the former. So, a higher score for lower remaining space.\n    # `1.0 / (residual_capacities + epsilon)` does exactly this.\n\n    # To make it more \"priority\" like, maybe we can adjust based on how \"close\"\n    # the original bin capacity was to the item size.\n    # However, the problem asks for a priority for EACH bin. So, the `bins_remain_cap`\n    # is the direct information.\n\n    # A slightly more complex heuristic might be:\n    # score = (1 / (residual_capacity + epsilon)) + bonus_for_tight_fit\n    # where bonus_for_tight_fit is higher if residual_capacity is small.\n    # The current `1.0 / (residual_capacities + 1e-6) + 1` already captures this well.\n    # The `+ 1` ensures all fitting bins have positive priority, with higher values\n    # for tighter fits.\n\n    return priorities",
    "response_id": 20,
    "obj": 4.198244914240141,
    "cyclomatic_complexity": 1.0,
    "halstead": 53.77443751081735,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response18.txt_stdout.txt",
    "code_path": "problem_iter1_code18.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Epsilon-Greedy strategy.\n\n    This strategy balances exploration (trying less-fit bins) and exploitation\n    (choosing the best-fit bins).\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.1  # Probability of exploration\n    num_bins = len(bins_remain_cap)\n    priorities = np.zeros(num_bins)\n\n    # Identify feasible bins\n    feasible_bins_indices = np.where(bins_remain_cap >= item)[0]\n\n    if len(feasible_bins_indices) == 0:\n        return np.zeros(num_bins)  # No bin can accommodate the item\n\n    # Exploitation: Prioritize bins that leave the least remaining space after packing\n    # This is a common heuristic for Bin Packing (e.g., Best Fit)\n    remaining_space = bins_remain_cap[feasible_bins_indices] - item\n    # Invert the remaining space to make it a \"score\" where higher is better for exploitation\n    # Add a small epsilon to avoid division by zero if remaining_space can be 0\n    exploitation_scores = 1.0 / (remaining_space + 1e-9)\n\n    # Normalize exploitation scores to be between 0 and 1\n    if exploitation_scores.max() > 0:\n        exploitation_scores = exploitation_scores / exploitation_scores.max()\n    else:\n        exploitation_scores = np.zeros_like(exploitation_scores) # All feasible bins have same remaining space\n\n    # Exploration: Randomly choose some bins to give a slight boost,\n    # or assign a uniform small priority to less-fit bins.\n    # Here, we'll add a small random noise to all feasible bins to encourage exploration.\n    exploration_scores = np.random.rand(len(feasible_bins_indices)) * epsilon\n\n    # Combine exploitation and exploration\n    # We want to exploit the best bins but also give a chance to explore others.\n    # A simple way is to add exploration scores to exploitation scores,\n    # but ensuring exploration doesn't dominate exploitation completely.\n    # Here, we add random noise proportional to epsilon.\n    combined_scores = exploitation_scores + exploration_scores\n\n    # Assign the combined scores to the feasible bins\n    priorities[feasible_bins_indices] = combined_scores\n\n    # Ensure that bins that cannot fit the item have a priority of 0\n    # (already handled by initialization and only assigning to feasible bins)\n\n    return priorities",
    "response_id": 18,
    "obj": 4.058635819704831,
    "cyclomatic_complexity": 3.0,
    "halstead": 120.40465370320703,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response23.txt_stdout.txt",
    "code_path": "problem_iter1_code23.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Almost Full Fit.\n\n    Almost Full Fit prioritizes bins that are almost full and can still accommodate the item.\n    The priority is higher for bins that have less remaining capacity after placing the item,\n    but only if the item fits.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins where the item can fit\n    can_fit_mask = bins_remain_cap >= item\n\n    # Calculate remaining capacity if the item is placed\n    remaining_if_placed = bins_remain_cap - item\n\n    # For bins where the item fits, assign priority based on how \"tight\" the fit is.\n    # A smaller remaining capacity after placing the item means a higher priority.\n    # We invert the remaining capacity to make smaller values higher priority.\n    # Add a small epsilon to avoid division by zero or very small numbers if\n    # remaining_if_placed becomes zero (perfect fit).\n    epsilon = 1e-9\n    priorities[can_fit_mask] = 1.0 / (remaining_if_placed[can_fit_mask] + epsilon)\n\n    # To implement the \"Almost Full Fit\" aspect, we can slightly boost bins that\n    # are very full (i.e., have a small remaining capacity BEFORE the item is added).\n    # This encourages filling up bins that are already quite full.\n    # We can use a threshold for \"almost full\". Let's say if remaining capacity\n    # is less than some percentage of the bin's original capacity (not provided here,\n    # so we'll use a relative threshold based on the remaining capacities themselves).\n    # A simpler approach is to give a bonus to bins that have a small remaining capacity.\n\n    # Let's define \"almost full\" as having remaining capacity less than, say, 20% of the item size,\n    # or simply having a very small absolute remaining capacity.\n    # A practical way is to give a multiplier to bins with lower remaining capacity *before* adding the item.\n\n    # We can use the reciprocal of the *original* remaining capacity (if it fits) as a base priority,\n    # and then add a bonus if the original remaining capacity was small.\n    # For bins that *cannot* fit the item, their priority remains 0.\n\n    # Re-calculating priorities to incorporate the \"almost full\" aspect more directly.\n    # Higher priority for bins that are already quite full (small bins_remain_cap)\n    # AND can fit the item. The goal is to leave larger gaps in other bins for larger items.\n    # So, priority should be inversely proportional to bins_remain_cap, given the item fits.\n\n    # If a bin can fit the item:\n    # Priority = 1 / (bins_remain_cap - item)  -- this favors tighter fits\n    # We also want to favor bins that are *already* nearly full.\n    # So, let's combine these:\n    # Priority = (1 / bins_remain_cap) * (1 / (bins_remain_cap - item)) -- this might over-amplify\n\n    # A common strategy for \"almost full\" is to prioritize bins with the smallest remaining capacity that can still fit the item.\n    # This is exactly what `1.0 / (remaining_if_placed[can_fit_mask] + epsilon)` achieves.\n    # If we want to explicitly make it \"almost full fit\", we can boost bins that\n    # have a small `bins_remain_cap` *before* placing the item.\n\n    # Let's refine this:\n    # Priority = k * (1 / (bins_remain_cap - item)) for bins that fit\n    # where k is a bonus for being \"almost full\".\n    # A simple bonus could be related to the inverse of the original remaining capacity.\n    # But we need to be careful not to make bins that are *too* full (where item doesn't fit) get high priority.\n\n    # A common interpretation of \"almost full fit\" is to sort bins by remaining capacity\n    # and pick the first one that fits, but the prompt asks for a priority score.\n    # The goal of \"almost full fit\" is to leave the \"most open\" bins for potentially larger items.\n    # This means we want to fill up bins that are already somewhat full.\n\n    # So, prioritize bins that are already quite full, as long as they can fit the item.\n    # A simple heuristic:\n    # Priority = 1 / (bins_remain_cap) if item fits, otherwise 0.\n    # This would prioritize bins that are *already* closer to full.\n    # However, we still need to ensure the item *fits*.\n\n    # Let's combine: Prioritize bins where the item fits *and* which have a small remaining capacity *before* placing the item.\n    # This implies that a bin with less remaining capacity is more attractive, IF it can take the item.\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Calculate the \"tightness\" of the fit: how much capacity is left *after* placing the item.\n    # Lower remaining capacity after placing means a tighter, more desirable fit for this strategy.\n    remaining_after_fit = bins_remain_cap - item\n\n    # Create a mask for bins that can accommodate the item.\n    can_accommodate_mask = bins_remain_cap >= item\n\n    # For bins that can accommodate the item, assign a priority.\n    # A higher priority is given to bins that will have LESS remaining capacity after the item is placed.\n    # We use the reciprocal of the remaining capacity *after* placing the item.\n    # Add epsilon to avoid division by zero for perfect fits.\n    priorities[can_accommodate_mask] = 1.0 / (remaining_after_fit[can_accommodate_mask] + epsilon)\n\n    # To emphasize the \"almost full\" aspect, we can further boost bins that\n    # had a small remaining capacity *before* the item was considered.\n    # This ensures that among bins that create a tight fit, we prefer those that were already closer to full.\n    # We can multiply the existing priority by a factor related to the inverse of the original remaining capacity.\n    # Again, add epsilon to avoid division by zero for bins that were already full.\n    almost_full_boost = 1.0 / (bins_remain_cap[can_accommodate_mask] + epsilon)\n\n    # Combine the two factors: the \"tightness of fit\" and the \"already almost full\" state.\n    # We want both to contribute. Multiplying them can be effective.\n    priorities[can_accommodate_mask] *= almost_full_boost\n\n    # A simpler approach that directly maps to \"smallest remaining capacity if it fits\":\n    # If item fits, priority is proportional to 1 / (bins_remain_cap - item).\n    # To emphasize \"almost full\" specifically, we might want to penalize bins that are *too* empty,\n    # or give a bonus to bins that are *already* quite full.\n\n    # Let's go with the interpretation that we want to select bins that are ALMOST full,\n    # but still fit the item. This means we prefer bins with a SMALL `bins_remain_cap`\n    # as long as `bins_remain_cap >= item`.\n    # The \"Almost Full Fit\" often means picking the bin with the smallest `bins_remain_cap`\n    # that can fit the item. This translates to prioritizing bins with low `bins_remain_cap`\n    # among those that satisfy `bins_remain_cap >= item`.\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit_mask = bins_remain_cap >= item\n\n    # For bins that can fit the item, their priority is inversely proportional\n    # to their current remaining capacity. The smaller the remaining capacity,\n    # the higher the priority, as it indicates the bin is \"almost full\".\n    # We use the reciprocal of `bins_remain_cap` to achieve this.\n    # Add epsilon for numerical stability and to avoid division by zero.\n    priorities[can_fit_mask] = 1.0 / (bins_remain_cap[can_fit_mask] + epsilon)\n\n    return priorities",
    "response_id": 23,
    "obj": 4.048663741523748,
    "cyclomatic_complexity": 1.0,
    "halstead": 178.41295556463058,
    "exec_success": true
  }
]