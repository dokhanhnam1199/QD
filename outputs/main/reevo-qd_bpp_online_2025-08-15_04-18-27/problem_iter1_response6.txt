```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin using Sigmoid Fit Score.

    The Sigmoid Fit Score strategy aims to prioritize bins that are "almost full"
    but can still accommodate the current item. This is achieved by applying a
    sigmoid function to the ratio of remaining capacity to the item size.
    Bins with a remaining capacity that is slightly larger than the item size
    will receive a high score.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """
    priorities = np.zeros_like(bins_remain_cap)

    # Only consider bins that can fit the item
    valid_bins_mask = bins_remain_cap >= item

    # Calculate a "tightness" metric. A lower value means the bin is tighter
    # for the given item (i.e., remaining capacity is close to item size).
    # We add a small epsilon to the denominator to avoid division by zero if
    # an item size is 0, although in BPP item sizes are usually positive.
    tightness = (bins_remain_cap - item) / (bins_remain_cap + 1e-9)

    # Apply sigmoid function to the negative of tightness.
    # We use negative tightness because we want higher priority for tighter bins.
    # The sigmoid function squashes the values between 0 and 1.
    # A common sigmoid is 1 / (1 + exp(-x)).
    # We shift and scale the tightness to optimize the sigmoid's sensitivity
    # to the range of "almost full" bins.
    # Let's map the "tightness" range from [-1, 1] to a more suitable range for sigmoid.
    # If remaining_cap = item, tightness = 0.
    # If remaining_cap = infinity, tightness = 1.
    # If remaining_cap = item + epsilon, tightness is close to 0.
    # If remaining_cap = item - epsilon, the bin is invalid and we handle this with the mask.

    # We want bins where remaining_cap is *just* larger than item to have high priority.
    # This means (bins_remain_cap - item) is small and positive.
    # The ratio (bins_remain_cap - item) / bins_remain_cap (or similar) will be small and positive.
    # Let's try to center the sigmoid around the "ideal" fit.
    # The ideal fit is when remaining_cap is just enough, i.e., remaining_cap = item.
    # So, we want to maximize the score when remaining_cap - item is close to 0.

    # Let's consider a transformed "fit_score" that is high when remaining_cap is
    # slightly larger than item, and lower otherwise.
    # A simple measure of "how much space is left relative to the item" could be:
    # relative_excess_space = (bins_remain_cap - item) / item
    # We want high priority when this is small and positive.

    # Sigmoid function: S(x) = 1 / (1 + exp(-k * (x - x0)))
    # We want high values when (bins_remain_cap - item) is small and positive.
    # Let x = bins_remain_cap - item.
    # We want S(x) to be high when x is near 0 and positive.
    # Let's use a sigmoid on a transformed value related to the remaining capacity.

    # A good candidate for the argument of the sigmoid:
    # If bins_remain_cap is much larger than item, we want low priority.
    # If bins_remain_cap is just enough (item), we want high priority.
    # If bins_remain_cap is slightly more than item, we want high priority.

    # Let's use the ratio (item / bins_remain_cap) as the input to the sigmoid,
    # but inverted. We want high priority when this ratio is close to 1 (but less than 1).
    # Consider ratio r = bins_remain_cap / item.
    # We want high priority when r is close to 1.
    # Sigmoid of (1 - r) could work, but it would give high priority when r is small.

    # Let's re-evaluate the "Sigmoid Fit Score" concept.
    # It's often about fitting the item as snugly as possible without overflow.
    # A good score should be high for bins where `bins_remain_cap` is slightly GREATER than `item`.
    # And low for bins where `bins_remain_cap` is much larger than `item` or too small.

    # Consider the "space available relative to the item size":
    # If bins_remain_cap = item + delta, where delta is small and positive.
    # We want a high score.

    # Let's use the ratio: `remaining_capacity / item_size`.
    # We are interested in values of this ratio that are slightly greater than 1.
    # Let `ratio = bins_remain_cap / item`.
    # We can use a sigmoid centered around `ratio = 1`.
    # The sigmoid function is `1 / (1 + exp(-k * (x - center)))`.
    # If `x = ratio`, we want the peak when `ratio` is around `1`.
    # So, `center = 1`.
    # `k` controls the steepness. A larger `k` makes the score drop faster away from the center.

    # We want the peak when `bins_remain_cap` is slightly GREATER than `item`.
    # This means `bins_remain_cap - item` is a small positive number.
    # Let's use `bins_remain_cap - item` as the input.
    # We want high score when this difference is close to 0 (and positive).

    # Let `diff = bins_remain_cap - item`.
    # We want high score when `diff` is small and positive.
    # Consider `sigmoid(k * -diff)`. This peaks when `diff` is small and negative. Not right.
    # Consider `sigmoid(k * diff)`. This peaks when `diff` is large and positive. Not right.

    # The common "Best Fit" heuristic aims for `remaining_capacity - item` to be minimized (and non-negative).
    # The "Worst Fit" heuristic aims for `remaining_capacity - item` to be maximized (and non-negative).

    # The prompt suggests "prioritize bins that are 'almost full' but can still accommodate the current item".
    # This sounds like minimizing the remaining space *after* placing the item, as long as it's not negative.
    # So, we want to minimize `bins_remain_cap - item` (subject to it being >= 0).

    # If we apply a sigmoid to `-(bins_remain_cap - item)`, it will peak when `bins_remain_cap - item` is minimal.
    # `score = 1 / (1 + exp(-k * -(bins_remain_cap - item)))`
    # `score = 1 / (1 + exp(k * (bins_remain_cap - item)))`
    # This score is high when `bins_remain_cap - item` is small (close to 0 or negative).
    # For valid bins (`bins_remain_cap >= item`), this means `bins_remain_cap - item` is small and positive.
    # This aligns with the "Best Fit" principle.

    # Let's set a reasonable `k` and potentially an offset/scaling.
    # We want to prioritize bins where `bins_remain_cap` is *just* large enough for the `item`.
    # This means `bins_remain_cap` is close to `item`.
    # So, `bins_remain_cap - item` is close to 0.

    # Let's use the ratio: `item / bins_remain_cap`.
    # We want bins where this ratio is close to 1 but less than 1.
    # The argument to the sigmoid could be `-(item / bins_remain_cap)`.
    # `score = 1 / (1 + exp(-k * -(item / bins_remain_cap)))`
    # `score = 1 / (1 + exp(k * item / bins_remain_cap))`
    # This peaks when `item / bins_remain_cap` is small (i.e., `bins_remain_cap` is large). This is "Worst Fit" like.

    # Let's try to create a scenario where the "sweet spot" is when `bins_remain_cap` is slightly larger than `item`.
    # Consider the normalized difference: `(bins_remain_cap - item) / item`.
    # We want this to be small and positive.
    # Argument for sigmoid: `-k * (bins_remain_cap - item) / item`
    # `score = 1 / (1 + exp(-k * -(bins_remain_cap - item) / item))`
    # `score = 1 / (1 + exp(k * (bins_remain_cap - item) / item))`
    # This score is high when `(bins_remain_cap - item) / item` is small and positive,
    # which means `bins_remain_cap - item` is small and positive. This aligns with Best Fit.

    # Let's try to make the "sweet spot" specific. For example, if a bin has
    # `bins_remain_cap = 1.2 * item`, we want a high score.
    # If `bins_remain_cap = 1.05 * item`, we want an even higher score.
    # If `bins_remain_cap = 2 * item`, we want a lower score.

    # Let's use `x = bins_remain_cap / item`. We want to peak around `x = 1`.
    # `score = 1 / (1 + exp(-k * (x - 1)))`
    # This means `score = 1 / (1 + exp(-k * (bins_remain_cap / item - 1)))`
    # `score = 1 / (1 + exp(-k * (bins_remain_cap - item) / item))`

    # Let's choose a steepness factor `k`.
    # A common sigmoid implementation might use `k=1` or a small value.
    # We can adjust `k` to control how "picky" the algorithm is.
    # A higher `k` makes the peak sharper.

    k = 5.0  # Steepness factor. Higher means sharper peak around the target.
    # We are targeting bins where remaining capacity is just slightly larger than the item.
    # This means `bins_remain_cap / item` should be slightly greater than 1.

    # We want to maximize the sigmoid's output for ratios `bins_remain_cap / item` that are close to 1,
    # but specifically slightly *above* 1.

    # Let's use `ratio = bins_remain_cap / item`.
    # We want to evaluate `sigmoid(f(ratio))` where `f(ratio)` is maximal
    # when `ratio` is slightly above 1.

    # Consider `f(ratio) = -(ratio - 1.05)`. This peaks when `ratio` is 1.05.
    # `score = 1 / (1 + exp(-k * -(ratio - 1.05)))`
    # `score = 1 / (1 + exp(k * (ratio - 1.05)))`
    # `score = 1 / (1 + exp(k * (bins_remain_cap / item - 1.05)))`

    # However, the description mentions "prioritize bins that are 'almost full'".
    # "Almost full" implies small remaining capacity.
    # If a bin has `remaining_cap = 1.01 * item`, it's "almost full" and can fit the item.
    # If a bin has `remaining_cap = 2.0 * item`, it's not "almost full".

    # So, the condition `bins_remain_cap` is close to `item` is the key.
    # Let's use `bins_remain_cap` directly, but scaled.
    # The sigmoid is good for mapping a range to [0, 1].
    # We want to map bins where `bins_remain_cap` is slightly greater than `item`
    # to high scores.

    # A common pattern for fitting is to use `sigmoid(-remaining_capacity)`.
    # This would prioritize smaller remaining capacities.
    # `score = 1 / (1 + exp(k * bins_remain_cap))`
    # This gives higher priority to bins with less remaining capacity.

    # But we also need to consider the item size itself.
    # The prompt asks for a *Sigmoid Fit Score*. This usually implies
    # fitting the item snugly.

    # Let's assume `bins_remain_cap` are normalized such that the bin capacity is 1.
    # Then item is `item_norm`. We want to find bins with `bins_remain_cap` close to `item_norm`.
    # But here, `bins_remain_cap` are actual capacities, and `item` is the item size.

    # Consider the "slack": `slack = bins_remain_cap - item`.
    # We want high priority when `slack` is small and positive.
    # Use `sigmoid(-slack)`?
    # `score = 1 / (1 + exp(k * slack))`
    # `score = 1 / (1 + exp(k * (bins_remain_cap - item)))`
    # This will indeed prioritize bins where `bins_remain_cap - item` is minimal and non-negative.
    # This is the "Best Fit" heuristic, but expressed via a sigmoid.

    # Apply the sigmoid to valid bins. For invalid bins, the priority is 0.
    # To make the sigmoid's response more nuanced, we can scale `bins_remain_cap - item`.
    # If bin capacities are large, `k` might need to be smaller, or we could normalize the difference.
    # For instance, normalize by the bin's total capacity `C`.
    # `scaled_slack = (bins_remain_cap - item) / C`
    # But we don't have `C` here, only remaining capacity.

    # Let's use the `bins_remain_cap - item` as the argument, but carefully.
    # We want to avoid division by zero for `item`.
    # For valid bins (`bins_remain_cap >= item`):
    # Calculate `slack = bins_remain_cap - item`.
    # A sigmoid on `-slack` will give higher scores for smaller `slack`.
    # `score = 1 / (1 + exp(-k * slack))`
    # `score = 1 / (1 + exp(-k * (bins_remain_cap - item)))`

    # Let's add a small constant `epsilon` to the denominator of the exponent for stability,
    # and to potentially shift the peak if needed, though `bins_remain_cap - item` is often fine.
    # A common sigmoid is `1 / (1 + exp(-x))`. If we want peak at `x=0`, this is it.
    # Here, `x = k * (bins_remain_cap - item)`.
    # So peak at `bins_remain_cap = item`. This is "perfect fit".
    # We want peak when `bins_remain_cap` is slightly GREATER than `item`.
    # So we want `bins_remain_cap - item` to be a small positive number.

    # Let's shift the argument: `sigmoid(k * (bins_remain_cap - item - offset))`.
    # If we want peak when `bins_remain_cap - item = ideal_slack`, then `offset = ideal_slack`.
    # If `ideal_slack` is 0, we get the perfect fit.
    # If `ideal_slack` is a small positive number (e.g., 5% of item size), it's better.

    # For "Sigmoid Fit Score", often the interpretation is fitting the item as snugly as possible.
    # This implies prioritizing bins with minimal remaining space *after* placement.
    # This is precisely what `sigmoid(k * (bins_remain_cap - item))` achieves when `k > 0`.
    # `sigmoid_arg = k * (bins_remain_cap - item)`
    # As `bins_remain_cap` decreases towards `item`, `sigmoid_arg` decreases towards 0.
    # The sigmoid function `1 / (1 + exp(-x))` increases as `x` increases.
    # So, as `bins_remain_cap` decreases towards `item`, `bins_remain_cap - item` becomes smaller positive,
    # `k * (bins_remain_cap - item)` becomes smaller positive, and the sigmoid value increases.
    # This is the desired behavior for Best Fit via Sigmoid.

    # However, the description mentions prioritizing bins that are "almost full" but can *still* accommodate.
    # This phrasing is key. If a bin is *already full* (remaining capacity < item), it's invalid.
    # If a bin is *just barely able to fit* (remaining capacity = item), it's a perfect fit, possibly high priority.
    # If a bin has `remaining_capacity = item + epsilon`, where epsilon is small, it's also a good candidate.

    # Let's reconsider the ratio `bins_remain_cap / item`.
    # A bin is "almost full" if its remaining capacity is not much larger than the item.
    # Let `target_ratio = 1.0`. We want to prioritize bins where `bins_remain_cap / item` is close to `target_ratio`.
    # Specifically, slightly GREATER than `target_ratio`.

    # Using `ratio = bins_remain_cap / item` (careful with item=0).
    # `sigmoid_arg = k * (ratio - target_ratio)`
    # For a peak at `ratio = target_ratio`.
    # If `target_ratio = 1.0`: `sigmoid_arg = k * (bins_remain_cap / item - 1.0)`
    # `priorities[valid_bins_mask] = 1 / (1 + np.exp(-sigmoid_arg[valid_bins_mask]))`

    # To make it favor slightly *more* capacity than item:
    # Let `target_ratio = 1.05` (meaning 5% slack).
    # `sigmoid_arg = k * (bins_remain_cap / item - 1.05)`
    # `priorities[valid_bins_mask] = 1 / (1 + np.exp(-sigmoid_arg[valid_bins_mask]))`
    # This would peak when `bins_remain_cap / item = 1.05`.

    # Let's try to interpret "almost full" as meaning the remaining capacity is small,
    # but also that it's a good fit for the item.
    # A common heuristic is `1 - (item / bin_capacity)` for first fit decreasing.
    # Here it's online and priority based.

    # Let's stick with the idea of fitting the item as snugly as possible without overflow,
    # which corresponds to minimizing `bins_remain_cap - item`.
    # The sigmoid `1 / (1 + exp(-k * (bins_remain_cap - item)))` works for this,
    # assigning higher scores to bins where `bins_remain_cap` is closer to `item`.

    # We need to handle the case where `item` is zero or very small.
    # If `item` is 0, any bin is a valid fit, and we might want to prioritize bins
    # that are "more full" (less remaining capacity), which would mean smaller `bins_remain_cap`.
    # The current formulation `1 / (1 + exp(-k * (bins_remain_cap - item)))` would still work,
    # but the interpretation of "fit" changes. Assume item > 0.

    # We need to be careful about the range of `bins_remain_cap` and `item`.
    # If `bins_remain_cap` can be very large, `bins_remain_cap - item` can be very large.
    # The exponent `-k * (bins_remain_cap - item)` can become very negative, making the sigmoid close to 1.
    # This means very large bins would get high priority, which is not ideal for "almost full".

    # We might need to normalize the `bins_remain_cap - item` by something.
    # However, without the total bin capacity `C`, it's hard.
    # Let's try scaling the `bins_remain_cap` itself as an input.

    # Consider mapping `bins_remain_cap` values to a range suitable for the sigmoid,
    # aiming for high scores for values near `item`.

    # Alternative strategy: What if we want to give a good score to bins that are
    # "pretty full" but *can* take the item?
    # If `bins_remain_cap` is very large, the bin is not "almost full".
    # If `bins_remain_cap` is just slightly larger than `item`, it's "almost full".

    # Let's use a sigmoid that penalizes large remaining capacities.
    # `sigmoid_arg = k * (item - bins_remain_cap)`
    # `score = 1 / (1 + exp(-sigmoid_arg))`
    # `score = 1 / (1 + exp(-k * (item - bins_remain_cap)))`
    # `score = 1 / (1 + exp(k * (bins_remain_cap - item)))`
    # This is the same as before. This prioritizes bins where `bins_remain_cap` is close to `item`.

    # What if we want to give a preference for bins that have a certain amount of "slack"?
    # For example, prioritize bins with `bins_remain_cap / item` between 1.1 and 1.3.
    # This could be done with a Gaussian-like function or a sigmoid difference.

    # Let's use a pragmatic interpretation of "Sigmoid Fit Score" in BPP:
    # Prioritize bins that have the smallest POSITIVE remaining capacity after placing the item.
    # This means minimizing `bins_remain_cap - item` among valid bins.
    # The sigmoid `1 / (1 + exp(-k * (bins_remain_cap - item)))` with `k > 0` achieves this.

    # To make it more creative and specific to "almost full":
    # We can try to center the sigmoid's effect around a value slightly larger than `item`.
    # Let's define a target "slack" `S_target`. We want `bins_remain_cap - item` to be close to `S_target`.
    # `sigmoid_arg = k * ( (bins_remain_cap - item) - S_target )`
    # `priorities[valid_bins_mask] = 1 / (1 + np.exp(-sigmoid_arg[valid_bins_mask]))`

    # Let's choose `S_target` as a small fraction of the item size, or a fixed small value if item can be 0.
    # If item can be 0, `S_target` should not depend on item.
    # Assume item > 0 for typical BPP.
    # Let `S_target = 0.1 * item` or some small fixed value, e.g., `0.1 * global_bin_capacity` if known.
    # Since `global_bin_capacity` is not provided, let's make it relative to the item.
    # `S_target = 0.1 * item` might not be robust if item sizes vary wildly.
    # A fixed small slack like `0.5` or `1.0` might be better if item sizes are in a known range.
    # If item sizes are very small, `0.1 * item` might be too small.

    # Let's define a "tolerance" or "preferred slack" `T`.
    # We want to prioritize bins where `bins_remain_cap - item` is close to `T`.
    # The argument to the sigmoid will be `-k * ( (bins_remain_cap - item) - T )`.
    # This makes the score high when `bins_remain_cap - item` is just above `T`.

    # Let's choose a reasonable `T`. If item sizes are generally around 0.5, then a bin with capacity 0.6
    # after placing it might be "almost full" and fit well.
    # A general approach without knowing item distribution is difficult.
    # Let's make `T` a small positive constant, e.g., `0.5`.
    # `k` controls steepness. `k=5` should be okay for moderate ranges.

    # Reconsider the phrasing: "prioritize bins that are 'almost full'".
    # This suggests that very empty bins (large `bins_remain_cap`) should get low scores,
    # and bins that are very full (small `bins_remain_cap`) but still fit the item
    # should get high scores.

    # Let's use the ratio `bins_remain_cap / item`.
    # We want `bins_remain_cap / item` to be small, but >= 1.
    # So, `bins_remain_cap` should be slightly larger than `item`.

    # Use `r = bins_remain_cap / item`.
    # We want high scores when `r` is close to 1 (but `r >= 1`).
    # Let's use `sigmoid_arg = k * (1 - r)`  (This peaks when r is small). Not right.
    # Let's use `sigmoid_arg = k * (r - 1)`  (This peaks when r is large). Not right.

    # We need to emphasize the "almost full" aspect.
    # A bin is "almost full" if its `bins_remain_cap` is small relative to its original capacity.
    # But we don't have original capacity.

    # Let's map `bins_remain_cap` to a "fullness" score.
    # Higher fullness = lower remaining capacity.
    # A sigmoid function `sigmoid(-bins_remain_cap)` could give this.
    # But we must also fit the item.

    # Let's combine two ideas:
    # 1. Can the bin fit the item? (Handled by `valid_bins_mask`)
    # 2. How "almost full" is the bin, given it can fit the item?

    # If `bins_remain_cap` is very large compared to `item`, the bin is NOT "almost full".
    # If `bins_remain_cap` is just a little bit larger than `item`, it IS "almost full".

    # Let `normalized_remaining_space = (bins_remain_cap - item) / item`.
    # We want `normalized_remaining_space` to be small and positive.
    # Let's call this `fitting_slack`.
    # `fitting_slack` should be small for high priority.
    # `sigmoid_arg = k * (-fitting_slack)`
    # `sigmoid_arg = k * (-(bins_remain_cap - item) / item)`
    # `sigmoid_arg = -k * (bins_remain_cap - item) / item`

    # `score = 1 / (1 + np.exp(-sigmoid_arg))`
    # `score = 1 / (1 + np.exp(k * (bins_remain_cap - item) / item))`

    # Let's check this.
    # If `bins_remain_cap = item` (perfect fit): `score = 1 / (1 + exp(0)) = 0.5`.
    # If `bins_remain_cap = item + epsilon`: `score = 1 / (1 + exp(k * epsilon / item))`. If epsilon small, exp is slightly > 1, score slightly < 0.5. This is NOT right. We want high priority when `bins_remain_cap` is *slightly greater* than `item`.

    # We want peak when `bins_remain_cap - item` is minimal POSITIVE value.
    # Let's use the inverse of slack as an indicator for fullness.
    # Consider `item / bins_remain_cap`. This ratio is high when `bins_remain_cap` is close to `item`.
    # BUT we need `bins_remain_cap >= item`. So `item / bins_remain_cap` will be <= 1.
    # So we want high priority when `item / bins_remain_cap` is close to 1.

    # Let `r = item / bins_remain_cap`. We want to maximize `sigmoid(k * (r - 1))` -- peaks at r=1, value 0.5.
    # We want to maximize `sigmoid(k * r)`. This peaks when `r` is large (bins_remain_cap small). This is again "Best Fit".

    # The phrase "Sigmoid Fit Score" is often used for packing, meaning to fit the item
    # such that the remaining capacity is minimized, subject to it being non-negative.
    # This leads back to `1 / (1 + np.exp(-k * (bins_remain_cap - item)))`.

    # Let's make it slightly more creative by influencing the "center" of the sigmoid.
    # The interpretation could be: prioritize bins where the ratio `remaining_capacity / item_size`
    # is as close to 1 as possible.
    # `ratio = bins_remain_cap / item`
    # We want peak score when `ratio = 1.0`.
    # `sigmoid_arg = k * (ratio - 1.0)`
    # `priorities[valid_bins_mask] = 1 / (1 + np.exp(-sigmoid_arg[valid_bins_mask]))`

    # This strategy assigns priority:
    # - 0.5 if `bins_remain_cap == item`
    # - > 0.5 if `bins_remain_cap > item`
    # - < 0.5 if `bins_remain_cap < item` (but these are filtered by mask)

    # So higher priority is given to bins with MORE remaining capacity relative to the item.
    # This is the opposite of "Best Fit" (which wants minimal remaining).
    # This sounds more like "Worst Fit", but evaluated with a sigmoid.

    # The description says "prioritize bins that are 'almost full'".
    # This implies `bins_remain_cap` should be small.
    # Let's use `sigmoid_arg = k * (item / bins_remain_cap)`.
    # `score = 1 / (1 + np.exp(-k * item / bins_remain_cap))`
    # When `item / bins_remain_cap` is high (meaning `bins_remain_cap` is small relative to `item`),
    # the sigmoid argument is high, and the score is high.
    # This matches "almost full".

    # This score will be 0.5 when `item / bins_remain_cap` is 0, which implies `bins_remain_cap` is infinite.
    # It will be high when `item / bins_remain_cap` is close to 1.
    # It will be higher when `item / bins_remain_cap` is > 1, which happens if `bins_remain_cap < item`.
    # BUT we only apply it to valid bins where `bins_remain_cap >= item`.
    # So `item / bins_remain_cap <= 1`.
    # The score will be highest (approaching 1) when `item / bins_remain_cap` is close to 1,
    # meaning `bins_remain_cap` is just slightly larger than `item`. This IS "almost full".

    # Let's choose parameters:
    k = 5.0  # Steepness. Higher means score sharply increases as ratio approaches 1.
    # We need to avoid division by zero if `bins_remain_cap` or `item` is 0.
    # For BPP, `item` > 0. `bins_remain_cap` can be 0 if a bin is full.
    # The `valid_bins_mask` handles `bins_remain_cap < item`.
    # If `item` is 0, then `item / bins_remain_cap = 0`, score is 0.5 for all. That's fine.

    # Let's refine the interpretation of "Sigmoid Fit Score" by ensuring it favors
    # small remaining capacity among valid bins.
    # Use `1 - (bins_remain_cap - item) / max_possible_remaining`. Not feasible without `max_possible_remaining`.

    # Let's use the ratio `bins_remain_cap / item`.
    # We want the peak score when `bins_remain_cap / item` is small (>=1).
    # Let `x = bins_remain_cap / item`. We want to optimize `sigmoid(f(x))` where `f(x)` peaks
    # for small `x >= 1`.
    # Try `f(x) = -k * (x - C)` for some center `C`.
    # If `C = 1`, then `f(x) = -k * (x - 1)`. Max value at `x=1`.
    # This means `score = 1 / (1 + exp(k * (x - 1)))`.
    # Score is 0.5 at `x=1`. Score decreases as `x` increases (remaining capacity grows).
    # This is "Best Fit" via sigmoid.

    # To favor "almost full": the bins should be "fuller".
    # This means `bins_remain_cap` is smaller.
    # So we want high score when `bins_remain_cap` is small but `bins_remain_cap >= item`.

    # Let's map `bins_remain_cap` to a value that is low for large capacities and high for small capacities.
    # `f(bins_remain_cap) = -bins_remain_cap`
    # Use `sigmoid(k * (-bins_remain_cap))` which is `sigmoid(-k * bins_remain_cap)`.
    # This will prioritize bins with smaller `bins_remain_cap`.

    # Combining with the item:
    # We only consider `bins_remain_cap >= item`.
    # Let's use `sigmoid(k * (item - bins_remain_cap))`.
    # For valid bins: `item - bins_remain_cap <= 0`.
    # So `k * (item - bins_remain_cap) <= 0`.
    # `sigmoid(negative_value)` will be < 0.5.
    # As `bins_remain_cap` decreases (bin gets fuller), `item - bins_remain_cap` becomes more negative,
    # `k * (item - bins_remain_cap)` becomes more negative, and sigmoid score decreases further.
    # This is not quite right.

    # The core idea of "fitting" is often related to minimizing wasted space.
    # Wasted space = `bins_remain_cap - item` (for valid bins).
    # To prioritize minimal wasted space, we want high score when `bins_remain_cap - item` is small.

    # Let's define the score `S(b)` for bin `b` and item `i`:
    # If `b.remaining_cap < i`: `S(b) = 0`
    # If `b.remaining_cap >= i`: `S(b) = sigmoid(k * (item - b.remaining_cap))`
    # With `k > 0`:
    # `item - b.remaining_cap` is zero or negative.
    # `sigmoid(0)` is 0.5.
    # `sigmoid(negative)` is < 0.5.
    # As `b.remaining_cap` decreases (gets fuller), `item - b.remaining_cap` becomes more negative,
    # and sigmoid score decreases. This gives highest priority to bins that are barely able to fit.
    # This is Best Fit.

    # Let's try to align the description with the common use of sigmoid in packing heuristics.
    # A typical "Sigmoid Fit" heuristic prioritizes bins that have remaining capacity
    # closest to the item size (without going below).
    # This is captured by `1 / (1 + exp(-k * (bins_remain_cap - item)))`.

    # Let's add a slight modification to reflect "almost full" more explicitly.
    # Perhaps by shaping the sigmoid argument based on some notion of "fullness threshold".
    # If we assume bins are scaled to capacity 1, then `item_norm` and `rem_cap_norm`.
    # A bin is "almost full" if `rem_cap_norm` is small.
    # We want high score when `rem_cap_norm` is small AND `rem_cap_norm >= item_norm`.

    # Final attempt:
    # We want to prioritize bins where `bins_remain_cap` is just slightly larger than `item`.
    # Let's use `score = sigmoid(k * (1 - bins_remain_cap / item))`? This peaks when `bins_remain_cap / item` is small.
    # `score = sigmoid(k * (item / bins_remain_cap - 1))`? This peaks when `item / bins_remain_cap` is small.

    # Let's focus on the "Sigmoid Fit Score" for packing. It aims to minimize `bins_remain_cap - item`.
    # The function `f(x) = 1 / (1 + exp(-k * x))` is monotonically increasing.
    # To maximize f(x) when `x = bins_remain_cap - item` is minimized, we should use `x`.
    # Thus, `score = 1 / (1 + exp(-k * (bins_remain_cap - item)))`.

    # Let's creatively tweak this for "almost full".
    # We can make the sigmoid's argument dependent on the 'fullness' of the bin.
    # A bin is "fuller" if `bins_remain_cap` is smaller.
    # Let's scale the `bins_remain_cap` itself, or a normalized version.
    # Without total bin capacity, this is tricky.

    # Let's use the ratio `item / bins_remain_cap` again.
    # It is <= 1 for valid bins.
    # We want to prioritize bins where this ratio is close to 1.
    # This means `bins_remain_cap` is close to `item`.
    # High score when `item / bins_remain_cap` is close to 1.
    # Function: `sigmoid(k * (item / bins_remain_cap))`
    # Argument `k * item / bins_remain_cap`.
    # This function is HIGH when `item / bins_remain_cap` is HIGH.
    # `item / bins_remain_cap` is high when `bins_remain_cap` is low.
    # This means we prioritize bins with LESS remaining capacity.
    # This fits the "almost full" criteria.

    # Let's verify `item / bins_remain_cap` for valid bins (`bins_remain_cap >= item`):
    # If `bins_remain_cap = item`, ratio = 1.
    # If `bins_remain_cap = item + epsilon`, ratio < 1.
    # If `bins_remain_cap = very large`, ratio is close to 0.

    # So `sigmoid(k * item / bins_remain_cap)` will:
    # - Give score of 0.5 when `item / bins_remain_cap = 0` (very large bins).
    # - Give score of 0.5 when `bins_remain_cap = item` if `k=0`. For `k>0`, it will be `sigmoid(k)`. Let's recheck.

    # `sigmoid(x) = 1 / (1 + exp(-x))`.
    # If `x = k * item / bins_remain_cap`.
    # If `bins_remain_cap = item`, `x = k`. Score = `1 / (1 + exp(-k))`.
    # If `bins_remain_cap = very large`, `x` approaches 0. Score approaches `1 / (1 + exp(0)) = 0.5`.
    # If `bins_remain_cap = item + epsilon`, `x = k * item / (item + epsilon)`. This `x` is slightly less than `k`. Score will be slightly less than `1 / (1 + exp(-k))`.

    # This still seems to prioritize larger remaining capacities amongst the valid ones.
    # This is confusing. Let's try the opposite: `sigmoid(k * (bins_remain_cap / item))`.
    # Argument `k * bins_remain_cap / item`.
    # If `bins_remain_cap = item`, arg = k. Score = `1 / (1 + exp(-k))`.
    # If `bins_remain_cap = item + epsilon`, arg = `k * (1 + epsilon/item)`. Arg > k. Score > `1/(1+exp(-k))`. Higher scores for LARGER remaining capacity.
    # This is not "almost full".

    # Back to `1 / (1 + exp(-k * (bins_remain_cap - item)))`. This is best fit.
    # How to modify for "almost full"?
    # "Almost full" means small `bins_remain_cap`, but still fitting.
    # This means `bins_remain_cap` should be close to `item`.
    # The current function peaks as `bins_remain_cap` approaches `item`.

    # The core of the strategy is likely in the argument of the sigmoid.
    # Let's make the argument inversely proportional to the remaining capacity,
    # but only for valid bins.
    # Let `arg = -bins_remain_cap`.
    # Sigmoid `sigmoid(k * arg)` => `sigmoid(k * -bins_remain_cap)`. This favors small `bins_remain_cap`.

    # We must ensure `bins_remain_cap >= item`.
    # Let's transform `bins_remain_cap` to be a value that is high when it's small and positive.
    # How about: `target_value = item`.
    # We want to maximize score when `bins_remain_cap` is slightly above `item`.
    # Let `x = bins_remain_cap`.
    # We want peak of `sigmoid(f(x))` where `f(x)` peaks for `x` just above `item`.
    # Let `f(x) = k * (item - x)`. Peaks at `x = item`, value 0.
    # `sigmoid(k * (item - x))` => `sigmoid(k * (item - bins_remain_cap))`
    # This peaks when `item - bins_remain_cap` is maximal (i.e., `bins_remain_cap` is minimal).
    # For valid bins, this means `bins_remain_cap` is minimally larger than `item`.
    # This interpretation of "Sigmoid Fit Score" sounds good for "almost full".

    # Argument: `k * (item - bins_remain_cap)`
    # If `bins_remain_cap = item`: arg = 0, score = 0.5
    # If `bins_remain_cap = item + epsilon`: arg = `k * (-epsilon)`. Score < 0.5.
    # This is still favoring bins that are *just* fitting, and penalizing slightly over-fitting ones.
    # This seems to be the "Best Fit" interpretation.

    # What if "almost full" implies a specific threshold?
    # e.g., a bin is "almost full" if its remaining capacity is less than 50% of its original capacity.
    # But we don't know original capacity.

    # Let's assume the prompt intends to prioritize bins with small POSITIVE remaining capacity after fitting.
    # This means `bins_remain_cap - item` should be minimized and positive.
    # The function `1 / (1 + exp(-k * (bins_remain_cap - item)))` does this.
    # Let's use this as the baseline and ensure `k` is chosen to make it sensitive.

    # Consider `k=5`.
    # `bins_remain_cap - item`
    # If 0, exp(0)=1, score = 0.5
    # If 0.1, exp(-0.5) ~ 0.6, score ~ 0.6
    # If 0.2, exp(-1) ~ 0.36, score ~ 0.7
    # If 0.5, exp(-2.5) ~ 0.08, score ~ 0.92
    # If 1.0, exp(-5) ~ 0.006, score ~ 0.99

    # This means larger `bins_remain_cap - item` gets higher priority. This is Worst Fit.
    # The goal is "almost full", which implies small `bins_remain_cap - item`.
    # So, we need the opposite sigmoid behavior.
    # `score = 1 / (1 + exp(k * (bins_remain_cap - item)))`
    # If `bins_remain_cap = item`: exp(0)=1, score = 0.5
    # If `bins_remain_cap = item + 0.1`: exp(0.5) ~ 1.6, score ~ 1/2.6 ~ 0.38
    # If `bins_remain_cap = item + 0.2`: exp(1) ~ 2.7, score ~ 1/3.7 ~ 0.27
    # If `bins_remain_cap = item + 0.5`: exp(2.5) ~ 12, score ~ 1/13 ~ 0.07

    # This means `score` DECREASES as `bins_remain_cap - item` increases.
    # So, this prioritizes bins with minimum positive remaining capacity.
    # This is Best Fit!

    # The description says "priority score for each bin. The bin with the highest priority score will be selected".
    # This heuristic (`1 / (1 + exp(k * (bins_remain_cap - item)))`) prioritizes bins with minimum `bins_remain_cap - item`.

    # Is this "creative"? It's a standard way to express Best Fit with a sigmoid.
    # The creativity might come from tuning `k` or shifting the argument.

    # Let's make it more creative by creating a "preferred slack".
    # Prioritize bins where `bins_remain_cap - item` is close to `S_pref`.
    # `arg = -k * ( (bins_remain_cap - item) - S_pref )`
    # `score = 1 / (1 + exp(arg))`
    # `score = 1 / (1 + exp(k * ( (bins_remain_cap - item) - S_pref )))`

    # Let's choose `S_pref` to be a small positive value, say `0.1 * item` or `0.5` as a fixed small slack.
    # If we want to explicitly target "almost full", we should target small slack.
    # Let `S_pref = 0.1` (assuming typical item sizes are > 0.1).

    S_pref = 0.1  # Preferred slack (e.g., 0.1 units of capacity remaining)
    k = 5.0     # Steepness factor

    # Calculate the argument for the sigmoid
    # We want to maximize the score when `bins_remain_cap - item` is close to `S_pref`.
    # The sigmoid `1/(1+exp(-x))` peaks at `x=0`.
    # So, we need `arg = -k * ( (bins_remain_cap - item) - S_pref )`
    # This ensures the peak is when `bins_remain_cap - item = S_pref`.

    sigmoid_arg = -k * (bins_remain_cap - item - S_pref)

    # Calculate priorities for valid bins using the sigmoid function
    # Handle potential overflow in `np.exp` by clipping the argument if necessary,
    # though with reasonable `k` and `S_pref`, it's often not needed.
    # Using a robust sigmoid:
    # `safe_sigmoid(x)` can be `1 / (1 + np.exp(-x))`
    # or `0.5 * (1 + np.tanh(x / 2))`

    # Using the standard sigmoid:
    priorities[valid_bins_mask] = 1 / (1 + np.exp(-sigmoid_arg[valid_bins_mask]))

    # The resulting priorities will be highest for bins where `bins_remain_cap - item` is closest to `S_pref`.
    # If `S_pref` is small and positive, this prioritizes bins that are "almost full" but can still fit the item.
    # For bins that cannot fit, the priority remains 0.

    return priorities
```
