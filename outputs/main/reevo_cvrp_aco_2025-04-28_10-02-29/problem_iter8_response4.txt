```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:
    """
    Heuristic function for Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling.
    Incorporates savings, geometric mean demand, inverse angle, capacity awareness, and robust sparsification.

    Args:
        distance_matrix (np.ndarray): Distance matrix between nodes (n x n).
        coordinates (np.ndarray): Euclidean coordinates of nodes (n x 2).
        demands (np.ndarray): Vector of customer demands (n).
        capacity (int): Vehicle capacity.

    Returns:
        np.ndarray: Prior indicators of how promising it is to include each edge in a solution (n x n).
    """
    n = distance_matrix.shape[0]
    heuristics_matrix = np.zeros((n, n))

    # Calculate savings matrix (Clarke-Wright Savings)
    savings_matrix = np.zeros((n, n))
    for i in range(1, n):
        for j in range(i + 1, n):
            savings_matrix[i, j] = distance_matrix[0, i] + distance_matrix[0, j] - distance_matrix[i, j]
            savings_matrix[j, i] = savings_matrix[i, j]

    # Node proximity to depot (using inverse distance, avoid division by zero)
    depot_proximity = np.zeros(n)
    for i in range(1, n):
        depot_proximity[i] = 1 / (distance_matrix[0, i] + 1e-6)

    # Demand factor (geometric mean and capacity awareness)
    demand_factor = np.zeros((n, n))
    for i in range(1, n):
        for j in range(1, n):
            if i != j:
                combined_demand = demands[i] + demands[j]
                if combined_demand > capacity:
                    demand_factor[i, j] = 0.0  # Heavily penalize if exceeding capacity
                else:
                    demand_factor[i, j] = 1 / (np.sqrt(demands[i] * demands[j]) + 1e-6)  # Geometric mean
                    demand_factor[i, j] *= (1 - (combined_demand / capacity)) # Scale by remaining capacity

    # Angle Factor (angle between nodes i and j w.r.t the depot)
    angle_factor = np.zeros((n, n))
    for i in range(1, n):
        for j in range(i + 1, n):
            vector_i = coordinates[i] - coordinates[0]
            vector_j = coordinates[j] - coordinates[0]
            norm_i = np.linalg.norm(vector_i)
            norm_j = np.linalg.norm(vector_j)
            if norm_i > 0 and norm_j > 0:
                cos_angle = np.dot(vector_i, vector_j) / (norm_i * norm_j)
                angle = np.arccos(np.clip(cos_angle, -1.0, 1.0))  # Clip to avoid domain errors
                angle_factor[i, j] = 1 / (angle + 1e-6)  # Inverse angle
                angle_factor[j, i] = angle_factor[i, j]

    # Normalize factors (handle cases where max == min)
    def safe_normalize(matrix):
        matrix_min = np.min(matrix)
        matrix_max = np.max(matrix)
        if matrix_max - matrix_min == 0:
            return np.zeros_like(matrix)  # Return zeros if all values are the same
        else:
            return (matrix - matrix_min) / (matrix_max - matrix_min + 1e-6)

    savings_matrix = safe_normalize(savings_matrix)
    depot_proximity = safe_normalize(depot_proximity)
    demand_factor = safe_normalize(demand_factor)
    angle_factor = safe_normalize(angle_factor)

    # Combine factors with weights and distance penalization
    alpha = 0.4 # Savings weight
    beta = 0.15 # Depot Proximity weight
    gamma = 0.3 # Demand Factor weight
    delta = 0.15 # Angle Factor weight

    for i in range(n):
        for j in range(n):
            if i != j:
                heuristics_matrix[i, j] = (
                    alpha * savings_matrix[i, j]
                    + beta * (depot_proximity[i] + depot_proximity[j])
                    + gamma * demand_factor[i, j]
                    + delta * angle_factor[i, j]
                ) / (distance_matrix[i, j] + 1e-6) # Penalize by Distance

    # Prioritize depot connections slightly
    for i in range(1, n):
        heuristics_matrix[0, i] *= 1.05  # Boost depot edges
        heuristics_matrix[i, 0] *= 1.05

    # Dynamic Sparsification using a robust percentile calculation
    non_zero_values = heuristics_matrix[heuristics_matrix > 0]
    if non_zero_values.size > 0:  # Ensure there are non-zero values
        threshold = np.percentile(non_zero_values, 50) # Further increased percentile for sparser graph
        heuristics_matrix[heuristics_matrix < threshold] = 0
    else:
        # If all values are zero, skip sparsification
        pass

   # Additional Sparsification: Keep only the top-k edges per node
    k = max(1, int(np.sqrt(n)))  # Adaptive k based on problem size
    for i in range(n):
        row = heuristics_matrix[i, :]
        indices = np.argpartition(row, -k)[-k:]  # Indices of k largest elements
        mask = np.zeros(row.shape, dtype=bool)
        mask[indices] = True
        heuristics_matrix[i, :] = 0  # Reset row
        heuristics_matrix[i, mask] = row[mask]  # Keep the best ones, preserving their scores
        heuristics_matrix[i, i] = 0  # Remove self loops

    # Set diagonal to zero
    for i in range(n):
        heuristics_matrix[i, i] = 0

    return heuristics_matrix
```
