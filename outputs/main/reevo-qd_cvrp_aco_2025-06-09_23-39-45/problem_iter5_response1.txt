```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:
    """
    Heuristics for Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling.

    Args:
        distance_matrix: Distance matrix (shape: n by n).
        coordinates: Euclidean coordinates of nodes (shape: n by 2).
        demands: Customer demands.
        capacity: Vehicle capacity.

    Returns:
        A matrix indicating how promising it is to include each edge in a solution.
    """
    n = distance_matrix.shape[0]

    # Initialize the heuristic matrix with zeros
    heuristic_matrix = np.zeros_like(distance_matrix, dtype=float)

    # Calculate savings for each pair of nodes based on Clarke-Wright savings algorithm.
    savings = np.zeros_like(distance_matrix, dtype=float)
    for i in range(1, n):
        for j in range(i + 1, n):
            savings[i, j] = distance_matrix[0, i] + distance_matrix[0, j] - distance_matrix[i, j]
            savings[j, i] = savings[i, j]

    # Normalize savings to be between 0 and 1.
    max_saving = np.max(savings)
    min_saving = np.min(savings)
    if max_saving > min_saving:
        normalized_savings = (savings - min_saving) / (max_saving - min_saving)
    else:
        normalized_savings = np.ones_like(savings)

    # Incorporate demand consideration.  Prioritize edges with nodes that have smaller demand.
    demand_factor = np.zeros_like(distance_matrix, dtype=float)
    for i in range(1, n):
        for j in range(1, n):
            if i != j:
                demand_factor[i, j] = 1 / (np.sqrt(demands[i] * demands[j]) + 1e-6)  # Geometric mean to penalize large demands

    # Normalize demand factor.
    max_demand = np.max(demand_factor)
    min_demand = np.min(demand_factor)
    if max_demand > min_demand:
        normalized_demand = (demand_factor - min_demand) / (max_demand - min_demand)
    else:
        normalized_demand = np.ones_like(demand_factor)

    # Distance factor: prioritize shorter edges
    distance_factor = 1 / (distance_matrix + 1e-6)
    # Normalize distance factor.
    max_distance = np.max(distance_factor)
    min_distance = np.min(distance_factor)
    if max_distance > min_distance:
        normalized_distance = (distance_factor - min_distance) / (max_distance - min_distance)
    else:
        normalized_distance = np.ones_like(distance_factor)

    # Calculate a combined score with different weights
    alpha = 0.5  # Weight for savings
    beta = 0.3   # Weight for demand
    gamma = 0.2  # Weight for distance
    heuristic_matrix = alpha * normalized_savings + beta * normalized_demand + gamma * normalized_distance

    # Sparsify the matrix: set elements below a certain threshold to zero. Adjust threshold dynamically.
    threshold = np.percentile(heuristic_matrix[heuristic_matrix > 0], 50)  # More aggressive sparsification
    heuristic_matrix[heuristic_matrix < threshold] = 0

    # Ensure that the depot (node 0) connections are always considered by increasing their weights.
    for i in range(1, n):
        heuristic_matrix[0, i] *= 2.0  # Higher bias for depot connections
        heuristic_matrix[i, 0] *= 2.0

    # Further refine by considering proximity to the depot
    depot_proximity = np.zeros((n, n))
    for i in range(1, n):
        for j in range(1, n):
            if i != j:
                depot_proximity[i, j] = 1 / (distance_matrix[0, i] + distance_matrix[0, j] + 1e-6)

    max_proximity = np.max(depot_proximity)
    min_proximity = np.min(depot_proximity)
    if max_proximity > min_proximity:
        normalized_proximity = (depot_proximity - min_proximity) / (max_proximity - min_proximity)
    else:
        normalized_proximity = np.ones_like(depot_proximity)

    heuristic_matrix = heuristic_matrix * (0.5 + 0.5 * normalized_proximity) # Blend with proximity to depot, favor closer edges

    return heuristic_matrix
```
