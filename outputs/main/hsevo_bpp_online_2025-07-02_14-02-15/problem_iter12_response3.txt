```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Prioritizes best-fit with adaptive penalties and dynamic exploration,
    incorporating bin fill level awareness and targeted fragmentation control.
    """

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if np.any(feasible_bins):
        waste = bins_remain_cap[feasible_bins] - item
        
        # Core: Prioritize best fit (minimize waste).
        priorities[feasible_bins] = 1 / (waste + 0.00001)

        # Adaptive Stochasticity: Item size dictates exploration. Larger items, less exploration.
        exploration_factor = max(0, 0.1 - (item * 0.05))  #exploration decreases as item increases
        num_feasible = np.sum(feasible_bins)
        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor

        # Bin Fill Level Awareness: Reward bins close to full but still feasible.
        fill_ratio = (1.0 - bins_remain_cap[feasible_bins]) #Assuming bin size is 1
        almost_full = (fill_ratio > 0.7)
        priorities[feasible_bins][almost_full] += 0.3 #Boost priority

        # Targeted Fragmentation Control: Penalize creating small remainders, ONLY if alternative bins exist
        small_waste = (waste < 0.1) #waste is smaller than 0.1
        
        if np.sum(feasible_bins) > 1: #check for alternative
             priorities[feasible_bins][small_waste] *= 0.5 #reduce priority if waste is too small and alternates exist

        # Dynamic "Sweet Spot" Incentive
        sweet_spot_lower = 0.7 - (item * 0.1) #Slightly adjust sweet spot
        sweet_spot_upper = 0.9 - (item * 0.05)

        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0
        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)
        priorities[feasible_bins][sweet_spot] += 0.4

    else:
        priorities[:] = -np.inf

    return priorities
```
