import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray, best_fit_epsilon: float = 6.0844208472455494e-05,
                max_exploration_factor: float = 0.30576746614270267, exploration_scaling: float = 0.016636483028667538,
                almost_full_threshold: float = 0.02885836332231445, base_penalty: float = 0.46082862599410823,
                item_penalty_scaling: float = 0.1470958264473956, large_bin_threshold_multiplier: float = 1.5129186964221595,
                large_bin_reward: float = 0.2072071058003802) -> np.ndarray:
    """Prioritizes best-fit with adaptive stochasticity and fragmentation control."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if np.any(feasible_bins):
        waste = bins_remain_cap[feasible_bins] - item

        # Best-fit prioritization
        priorities[feasible_bins] = 1 / (waste + best_fit_epsilon)

        # Adaptive Stochasticity
        num_feasible = np.sum(feasible_bins)
        exploration_factor = min(max_exploration_factor, exploration_scaling * num_feasible)
        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor

        # Fragmentation penalty (stronger for larger items)
        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]
        almost_full = wasted_space_ratio < almost_full_threshold
        penalty_factor = base_penalty + item * item_penalty_scaling #item size adjusts the penalty dynamically.
        priorities[feasible_bins][almost_full] *= penalty_factor
        priorities[feasible_bins][almost_full] = np.clip(priorities[feasible_bins][almost_full], 0, 1) #prevent overflow

        # Rewarding larger bins for smaller items
        small_item_large_bin_reward = np.where(bins_remain_cap[feasible_bins] > large_bin_threshold_multiplier * item, large_bin_reward, 0)
        priorities[feasible_bins] += small_item_large_bin_reward


    else:
        priorities[:] = -np.inf

    return priorities
