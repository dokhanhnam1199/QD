```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Prioritizes best-fit with adaptive penalties and dynamic exploration.
    Emphasizes a balance between bin utilization and preventing extreme fragmentation,
    adjusting strategies based on item size and bin availability.

    Simplified and refined for clarity and effectiveness.
    """

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if np.any(feasible_bins):
        waste = bins_remain_cap[feasible_bins] - item
        
        # Core: Prioritize best fit (minimize waste).  Simplified tiny constant.
        priorities[feasible_bins] = 1 / (waste + 1e-6)

        # Exploration:  Reduced and simplified.  Only apply to feasible bins.
        num_feasible = np.sum(feasible_bins)
        exploration_factor = 0.05 * item  # Smaller base exploration, scaled by item.
        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor


        # Fragmentation Penalty:  Focus on almost-full bins, simplified threshold.
        almost_full_threshold = 0.1
        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]
        almost_full = wasted_space_ratio < almost_full_threshold
        priorities[feasible_bins][almost_full] *= 0.2 # Reduced penalty value

        # Sweet Spot Incentive:  Simplified range, focusing on higher utilization.
        sweet_spot_lower = 0.7
        sweet_spot_upper = 0.95
        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0
        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)
        priorities[feasible_bins][sweet_spot] += 0.3

    else:
        priorities[:] = -np.inf  # No feasible bins

    return priorities
```
