import numpy as np

def priority_v2(item: float,
                  bins_remain_cap: np.ndarray,
                  inverse_waste_epsilon: float = 0.0003031777403220501,
                  stochasticity_factor: float = 0.20695058436867436,
                  almost_full_threshold: float = 0.1645486040110834,
                  almost_full_penalty: float = 0.19141906114077073,
                  large_item_threshold_multiplier: float = 2.1574190205346753,
                  large_item_reward: float = 0.7684235288085917,
                  sweet_spot_lower: float = 0.5426889443347869,
                  sweet_spot_upper: float = 0.746864139508676,
                  sweet_spot_reward: float = 0.37824791219133636) -> np.ndarray:
    """Prioritizes best-fit, adds stochasticity, and penalizes fragmentation.
    Also considers bin utilization and provides incentives for specific capacity ranges."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if np.any(feasible_bins):
        waste = bins_remain_cap[feasible_bins] - item
        
        # Prioritize based on inverse waste (best fit)
        priorities[feasible_bins] = 1 / (waste + inverse_waste_epsilon)
        
        # Add stochasticity (exploration)
        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_factor

        # Penalize almost full bins to prevent fragmentation, stronger penalty
        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]
        almost_full = wasted_space_ratio < almost_full_threshold
        priorities[feasible_bins][almost_full] *= almost_full_penalty # Reduce priority of almost full bins even more

        # Large item high reward - filling up space and avoiding future placement issues. More aggressive.
        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*large_item_threshold_multiplier,large_item_reward,0) #incentivise larger bins if enough capacity exists.
        priorities[feasible_bins] += large_cap_reward
        
        # Incentivize bins in a "sweet spot" of utilization to encourage more full bins.
        # This range (0.5-0.75) is based on experimentation and tuning - might require adjustments.
        utilization = (bins_remain_cap[feasible_bins] - waste) / (1 - waste) # Estimate utilization after placement. Assuming bin size is 1
        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)
        priorities[feasible_bins][sweet_spot] += sweet_spot_reward  # Give a boost to bins in the sweet spot

    else:
        priorities[:] = -np.inf

    return priorities
