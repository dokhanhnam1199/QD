{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes best-fit with adaptive penalties and dynamic exploration.\n    Emphasizes a balance between bin utilization and preventing extreme fragmentation,\n    adjusting strategies based on item size and bin availability.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Core: Prioritize best fit (minimize waste).  Slightly more aggressive than v1\n        priorities[feasible_bins] = 1 / (waste + 0.00001)  # Tiny constant to avoid division by zero\n\n        # Adaptive Stochasticity:  More exploration when bins are plentiful.\n        num_feasible = np.sum(feasible_bins)\n        exploration_factor = min(0.2, 0.02 * num_feasible)  # Caps at 0.2\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Fragmentation Penalty:  Stronger and more nuanced. Target almost-full bins.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05 #More aggressive\n        priorities[feasible_bins][almost_full] *= 0.2  # Significant penalty for using almost-full bins.\n\n        # Rewarding larger bins for smaller items\n        small_item_large_bin_reward = np.where(bins_remain_cap[feasible_bins] > 1.5 * item, 0.4, 0) #incentivise larger bins if item is small and capcity exists. Changed condition.\n        priorities[feasible_bins] += small_item_large_bin_reward\n\n        # Dynamic \"Sweet Spot\" Incentive: Adapt the range based on item size.\n        # Aim is to encourage utilization in a range that avoids both extreme fragmentation\n        # and under-utilization.  Smaller items should aim for higher utilization.\n        sweet_spot_lower = 0.6 - (item * 0.2) #Dynamic Lower Bound - lower bound decreases as item sizes increase. \n        sweet_spot_upper = 0.8 - (item * 0.1) #Dynamic Upper Bound - upper bound decreases as item sizes increase, less aggressively.\n\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0  # Assuming bin size is 1\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.4 #Increased the reward.\n\n    else:\n        priorities[:] = -np.inf  # No feasible bins\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes best-fit, stochasticity, fragmentation penalty, and bin fill.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Best-fit prioritization\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n\n        # Stochasticity (reduced with more feasible bins)\n        num_feasible = np.sum(feasible_bins)\n        stochasticity_factor = 0.1 / (num_feasible + 1e-6)\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_factor\n\n        # Fragmentation penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05\n        priorities[feasible_bins][almost_full] *= 0.3\n\n        # Reward significantly filled bins\n        fill_ratio = (bins_remain_cap[feasible_bins] - waste) / bins_remain_cap[feasible_bins]\n        significantly_filled = fill_ratio > 0.5\n        priorities[feasible_bins][significantly_filled] += 0.2\n\n        # Large item reward if sufficient capacity exists\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 2, 0.25, 0)\n        priorities[feasible_bins] += large_cap_reward\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), we see the code is exactly the same, indicating that performance differences are subtle and may depend on the specific problem instance or random seed. Comparing (1st) vs (20th), we see the first one has \"Adaptive Stochasticity\", \"Fragmentation Penalty\", \"Rewarding larger bins for smaller items\", and \"Dynamic \"Sweet Spot\" Incentive\" whereas the last one only has \"stochasticity\", \"Penalize almost full bins to prevent fragmentation\", and \"Incentivize bins in a \"sweet spot\" of utilization\".\n\nComparing (4th) vs (5th), the 4th heuristic uses a lot of constants while 5th heuristic uses hard code. Comparing (8th) vs (9th), the 8th has \"Adaptive stochasticity (reduce exploration as bins fill)\" and  \"Large capacity reward (adaptive threshold)\" whereas the 9th has \"Stochasticity (reduced with more feasible bins)\".\n\nComparing (15th) vs (16th), heuristic 15th has  \"Penalize almost full bins dynamically based on item size - stronger penalty for larger items\" and \"Dynamically incentivize larger bins, especially if item is large\" whereas 16th has \"Fragmentation penalty: Moderate, based on waste ratio.\" and \"Large item reward if bin has sufficient capacity.\". Comparing (19th) vs (20th), the codes are exactly the same.\n\nOverall: better heuristics tend to have more adaptive components, especially those that dynamically adjust parameters based on item size, remaining bin capacity, or the number of feasible bins. They also incorporate mechanisms to balance exploration and exploitation, with more sophisticated approaches to stochasticity. Fragmentation penalties and sweet spot incentives are common, but the way they are applied and tuned is crucial.\n- \nOkay, let's refine \"Current self-reflection\" to design better heuristics, while explicitly avoiding the pitfalls of \"Ineffective self-reflection.\"\n\nHere's a revised perspective on self-reflection to guide heuristic design:\n\n*   **Keywords:** Adaptive, Dynamic, Problem-Aware, Empirical Tuning, Balanced, Iterative Refinement.\n*   **Advice:** Focus on a core, functional heuristic. Adapt parameters based on *observable* problem characteristics. Prioritize gradual, empirically validated refinements over complex, speculative features.\n*   **Avoid:** Blindly combining factors without understanding their interactions, adding stochasticity without a clear purpose, and over-engineering with non-linear functions before establishing a solid foundation.\n*   **Explanation:** Start simple, understand your base heuristic's performance, and then introduce targeted adaptations. The goal is controlled, explainable improvements based on data, not a black box of complex interactions.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}