```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Hybrid heuristic: Best-fit, stochasticity, fragmentation penalty, utilization sweet spot, and adaptive rewards."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if np.any(feasible_bins):
        waste = bins_remain_cap[feasible_bins] - item
        
        # Best-fit prioritization (stronger)
        priorities[feasible_bins] = 10 / (waste + 0.0001)

        # Adaptive stochasticity (reduce exploration as bins fill)
        exploration_factor = max(0.01, 0.1 * np.mean(bins_remain_cap)) # Dynamic range
        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * exploration_factor

        # Fragmentation penalty (tuned threshold and penalty)
        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]
        almost_full = wasted_space_ratio < 0.1
        priorities[feasible_bins][almost_full] *= 0.2 # Strong penalty

        # Large capacity reward (adaptive threshold)
        large_cap_threshold = item * 1.25 # Adjusted threshold
        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > large_cap_threshold, 0.5, 0)
        priorities[feasible_bins] += large_cap_reward
        
        # Sweet spot utilization (encourage fuller bins)
        utilization = (bins_remain_cap[feasible_bins] - waste) # Estimate utilization after placement.
        utilization /= 1 # Assuming bin size is 1
        sweet_spot = (utilization > 0.6) & (utilization < 0.8)
        priorities[feasible_bins][sweet_spot] += 0.3

    else:
        priorities[:] = -np.inf

    return priorities
```
