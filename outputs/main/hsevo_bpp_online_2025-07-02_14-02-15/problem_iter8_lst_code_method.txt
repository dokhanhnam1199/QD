{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, and penalizes fragmentation.\n    Also considers bin utilization and provides incentives for specific capacity ranges.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit)\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Add stochasticity (exploration)\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1\n\n        # Penalize almost full bins to prevent fragmentation, stronger penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.3 # Reduce priority of almost full bins even more\n\n        # Large item high reward - filling up space and avoiding future placement issues. More aggressive.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*2,0.5,0) #incentivise larger bins if enough capacity exists.\n        priorities[feasible_bins] += large_cap_reward\n        \n        # Incentivize bins in a \"sweet spot\" of utilization to encourage more full bins.\n        # This range (0.5-0.75) is based on experimentation and tuning - might require adjustments.\n        utilization = (bins_remain_cap[feasible_bins] - waste) / (1 - waste) # Estimate utilization after placement. Assuming bin size is 1\n        sweet_spot = (utilization > 0.5) & (utilization < 0.75)\n        priorities[feasible_bins][sweet_spot] += 0.3  # Give a boost to bins in the sweet spot\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, and penalizes fragmentation.\n    Also considers bin utilization and provides incentives for specific capacity ranges.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit)\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Add stochasticity (exploration)\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1\n\n        # Penalize almost full bins to prevent fragmentation, stronger penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.3 # Reduce priority of almost full bins even more\n\n        # Large item high reward - filling up space and avoiding future placement issues. More aggressive.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*2,0.5,0) #incentivise larger bins if enough capacity exists.\n        priorities[feasible_bins] += large_cap_reward\n        \n        # Incentivize bins in a \"sweet spot\" of utilization to encourage more full bins.\n        # This range (0.5-0.75) is based on experimentation and tuning - might require adjustments.\n        utilization = (bins_remain_cap[feasible_bins] - waste) / (1 - waste) # Estimate utilization after placement. Assuming bin size is 1\n        sweet_spot = (utilization > 0.5) & (utilization < 0.75)\n        priorities[feasible_bins][sweet_spot] += 0.3  # Give a boost to bins in the sweet spot\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, and penalizes fragmentation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit)\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Add stochasticity (exploration)\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1\n\n        #Penalize almost full bins to prevent fragmentation\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.5 # Reduce priority of almost full bins\n        \n\n        #Large item high reward - filling up space and avoiding future placement issues.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*2,0.25,0) #incentivise large bins if enough capacity exists.\n        priorities[feasible_bins] += large_cap_reward\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, and penalizes fragmentation.\n       Also, considers bin fill ratio and dynamically adjusts stochasticity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit)\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Dynamically adjust stochasticity based on the number of feasible bins\n        num_feasible = np.sum(feasible_bins)\n        stochasticity_factor = 0.1 / (num_feasible + 1e-6)  # Reduce stochasticity when many bins are feasible\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_factor\n        \n\n        # Penalize almost full bins to prevent fragmentation (more aggressive)\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05  # More sensitive to almost full\n        priorities[feasible_bins][almost_full] *= 0.3  # Reduce priority more aggressively\n\n        # Reward bins that are already significantly filled\n        fill_ratio = (bins_remain_cap[feasible_bins] - waste) / bins_remain_cap[feasible_bins]\n        significantly_filled = fill_ratio > 0.5 # Adjust threshold as needed\n        priorities[feasible_bins][significantly_filled] += 0.2  # Add a small reward for filled bins\n\n        #Large item high reward - filling up space and avoiding future placement issues.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*2,0.25,0) #incentivise large bins if enough capacity exists.\n        priorities[feasible_bins] += large_cap_reward\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, and penalizes fragmentation.\n       Also, considers bin fill ratio and dynamically adjusts stochasticity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit)\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Dynamically adjust stochasticity based on the number of feasible bins\n        num_feasible = np.sum(feasible_bins)\n        stochasticity_factor = 0.1 / (num_feasible + 1e-6)  # Reduce stochasticity when many bins are feasible\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_factor\n        \n\n        # Penalize almost full bins to prevent fragmentation (more aggressive)\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05  # More sensitive to almost full\n        priorities[feasible_bins][almost_full] *= 0.3  # Reduce priority more aggressively\n\n        # Reward bins that are already significantly filled\n        fill_ratio = (bins_remain_cap[feasible_bins] - waste) / bins_remain_cap[feasible_bins]\n        significantly_filled = fill_ratio > 0.5 # Adjust threshold as needed\n        priorities[feasible_bins][significantly_filled] += 0.2  # Add a small reward for filled bins\n\n        #Large item high reward - filling up space and avoiding future placement issues.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*2,0.25,0) #incentivise large bins if enough capacity exists.\n        priorities[feasible_bins] += large_cap_reward\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines relative waste, fragmentation penalty, and stochasticity for bin packing.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Relative Waste (First-Fit Decreasing Inspired)\n    fit_mask = bins_remain_cap >= item\n    if np.any(fit_mask):\n        waste = bins_remain_cap[fit_mask] - item\n        relative_waste = waste / (item + 0.0001)\n        priorities[fit_mask] += np.exp(-5 * relative_waste)\n\n    # 2. Fragmentation Penalty\n    fragment_threshold_low = 0.1\n    fragment_threshold_high = 0.25\n    fragment_mask = (bins_remain_cap - item > fragment_threshold_low) & (bins_remain_cap - item < fragment_threshold_high)\n    priorities[fragment_mask] -= 0.5\n\n    # 3. Stochastic Exploration\n    priorities += np.random.rand(len(bins_remain_cap)) * 0.01\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best fit, reduces fragmentation, adds exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        priorities[feasible_bins] = np.exp(-5 * (waste / item)) # Prioritize smaller waste\n\n        # Fragmentation penalty\n        fragment_threshold_low = 0.1\n        fragment_threshold_high = 0.25\n        fragment_mask = (bins_remain_cap[feasible_bins] - item > fragment_threshold_low) & (bins_remain_cap[feasible_bins] - item < fragment_threshold_high)\n        priorities[feasible_bins][fragment_mask] -= 0.5\n\n        # Stochasticity\n        priorities += np.random.rand(len(bins_remain_cap)) * 0.01\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid heuristic: FFD-inspired + waste penalty + perfect fit bonus.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # FFD-inspired: Prioritize bins that can fit the item with less waste\n    fit_mask = bins_remain_cap >= item\n    if np.any(fit_mask):\n        priorities[fit_mask] += 1.0 / (bins_remain_cap[fit_mask] - item + 0.0001)\n\n    # Waste penalty: Penalize bins if item fits but creates high relative waste\n    if np.any(fit_mask):\n        remaining_space = bins_remain_cap[fit_mask] - item\n        waste_ratio = remaining_space / bins_remain_cap[fit_mask]\n        priorities[fit_mask] -= waste_ratio * 0.5  # Scale to avoid overpowering other components\n\n    # Perfect fit bonus: Reward bins where the item fits almost perfectly\n    if np.any(fit_mask):\n        remaining_space = bins_remain_cap[fit_mask] - item\n        perfect_fit_bonus = np.exp(-5 * remaining_space)  # Adjusted exponent\n        priorities[fit_mask] += perfect_fit_bonus * 0.2 #scale the bonus\n\n    # Infeasible penalty\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate bin priorities using waste, fullness, and fragmentation.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    n_bins = len(bins_remain_cap)\n\n    # 1. Waste-based priority (FFD inspired)\n    fit_mask = bins_remain_cap >= item\n    waste = bins_remain_cap[fit_mask] - item\n    relative_waste = waste / (item + 0.0001)\n    priorities[fit_mask] += np.exp(-5 * relative_waste)\n\n    # 2. Fullness priority (Next-Fit inspired)\n    bin_fullness = bins_remain_cap / (np.max(bins_remain_cap) + 0.0001)\n    priorities += np.power(1 - bin_fullness, 3)\n\n    # 3. Fragmentation penalty\n    fragmentation_penalty = np.where(bins_remain_cap < item, -1000, 0)\n    priorities += fragmentation_penalty\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization with fragmentation penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fit_mask = bins_remain_cap >= item\n    if not np.any(fit_mask):\n        return priorities - np.inf  # No valid bin, strongly discourage\n\n    waste = bins_remain_cap[fit_mask] - item\n    priorities[fit_mask] = 1.0 / (waste + 0.0001)\n\n    wasted_space_ratio = waste / bins_remain_cap[fit_mask]\n    nearly_full = wasted_space_ratio < 0.1\n    priorities[fit_mask][nearly_full] -= 0.5\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization with fragmentation penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fit_mask = bins_remain_cap >= item\n    if not np.any(fit_mask):\n        return priorities - np.inf  # No valid bin, strongly discourage\n\n    waste = bins_remain_cap[fit_mask] - item\n    priorities[fit_mask] = 1.0 / (waste + 0.0001)\n\n    wasted_space_ratio = waste / bins_remain_cap[fit_mask]\n    nearly_full = wasted_space_ratio < 0.1\n    priorities[fit_mask][nearly_full] -= 0.5\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization and bin fullness with fragmentation penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fit_mask = bins_remain_cap >= item\n    #Prioritize fitting with minimal relative waste.\n    waste = bins_remain_cap[fit_mask] - item\n    relative_waste = waste / (item + 0.0001)\n    priorities[fit_mask] += np.exp(-5 * relative_waste)\n\n    #Incentivize fuller bins (non-linear).\n    bin_fullness = bins_remain_cap / (np.max(bins_remain_cap) + 0.0001)\n    priorities += np.power(1 - bin_fullness, 3)\n\n    #Severe penalty for bins that cannot accommodate the item.\n    fragmentation_penalty = np.where(bins_remain_cap < item, -1000, 0)\n    priorities += fragmentation_penalty\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization with fragmentation penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fit_mask = bins_remain_cap >= item\n    if not np.any(fit_mask):\n        return priorities - np.inf  # No valid bin, strongly discourage\n\n    waste = bins_remain_cap[fit_mask] - item\n    priorities[fit_mask] = 1.0 / (waste + 0.0001)\n\n    wasted_space_ratio = waste / bins_remain_cap[fit_mask]\n    nearly_full = wasted_space_ratio < 0.1\n    priorities[fit_mask][nearly_full] -= 0.5\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, penalizes fragmentation,\n    and considers bin fill ratio with dynamic scaling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit) - stronger preference\n        priorities[feasible_bins] = 10 / (waste + 0.0001)\n        \n        # Add stochasticity (exploration) - reduced amplitude\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.05\n\n        # Penalize almost full bins to prevent fragmentation - adaptive penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.3 # Reduce priority more aggressively\n\n        # Reward larger bins if enough capacity exists - tweaked reward size\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*1.5, 0.2, 0) #Reduced threshold for large cap, decreased magnitude\n        priorities[feasible_bins] += large_cap_reward\n\n        # Dynamic scaling based on bin fill ratio\n        fill_ratio = (bins_remain_cap[feasible_bins] - waste) / bins_remain_cap[feasible_bins]\n        priorities[feasible_bins] *= (1 + fill_ratio * 0.5)  # Boost priority for bins that will be well-filled\n\n        # Further penalty for bins that, after placing the item, would have capacity less than a threshold.\n        small_remaining = bins_remain_cap[feasible_bins] - item < 0.1\n        priorities[feasible_bins][small_remaining] = -np.inf #Make unfeasible\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, penalizes fragmentation, and considers bin fill ratio.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit) - stronger best-fit\n        priorities[feasible_bins] = 10 / (waste + 0.0001)  # Increased impact of best-fit\n\n        # Add stochasticity (exploration) - reduced stochasticity\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.05  # Reduced stochasticity\n\n        # Penalize fragmentation - more aggressive penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.3  # Stronger penalty for almost full bins\n\n        # Reward filling bins well\n        fill_ratio = item / bins_remain_cap[feasible_bins]\n        good_fill = (fill_ratio > 0.7) & (fill_ratio <= 1.0)\n        priorities[feasible_bins][good_fill] += 0.5  # Reward bins filled well\n\n        # Large item high reward - filling up space and avoiding future placement issues, only when bin large enough\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*1.25,0.25,0) #incentivise large bins if enough capacity exists. Less restriction on bin size for the reward.\n        priorities[feasible_bins] += large_cap_reward\n\n        #Moderate penalty if item fills bin above a certain threshold.\n        overfill_penalty = np.where(fill_ratio>1, -1,0)\n        priorities[feasible_bins]+= overfill_penalty\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, penalizes fragmentation, and considers bin fill ratio.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit) - stronger best-fit\n        priorities[feasible_bins] = 10 / (waste + 0.0001)  # Increased impact of best-fit\n\n        # Add stochasticity (exploration) - reduced stochasticity\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.05  # Reduced stochasticity\n\n        # Penalize fragmentation - more aggressive penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.3  # Stronger penalty for almost full bins\n\n        # Reward filling bins well\n        fill_ratio = item / bins_remain_cap[feasible_bins]\n        good_fill = (fill_ratio > 0.7) & (fill_ratio <= 1.0)\n        priorities[feasible_bins][good_fill] += 0.5  # Reward bins filled well\n\n        # Large item high reward - filling up space and avoiding future placement issues, only when bin large enough\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*1.25,0.25,0) #incentivise large bins if enough capacity exists. Less restriction on bin size for the reward.\n        priorities[feasible_bins] += large_cap_reward\n\n        #Moderate penalty if item fills bin above a certain threshold.\n        overfill_penalty = np.where(fill_ratio>1, -1,0)\n        priorities[feasible_bins]+= overfill_penalty\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, and penalizes fragmentation, with capacity-aware adjustments.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit) - stronger best-fit emphasis\n        priorities[feasible_bins] = 10 / (waste + 0.0001)  # Increased magnitude\n\n        # Stochasticity (exploration) - reduced exploration\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.05 # Reduced exploration\n\n        # Penalize almost full bins to prevent fragmentation - tuned threshold and penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.15 # Slightly relaxed threshold\n        priorities[feasible_bins][almost_full] *= 0.3  # Stronger penalty\n\n        #Reward larger capacity bins, more aggressive\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*1.5, 0.5, 0)  #Reduced threshold, higher reward\n        priorities[feasible_bins] += large_cap_reward\n        \n        #Prioritize bins with capacity close to the item size\n        close_fit = np.abs(waste - item*0.5) / item < 0.2 #check is close to item/2\n        priorities[feasible_bins][close_fit] += 0.4 #slight encouragement if near half full after placement\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with fragmentation penalty and stochasticity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize best fit\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Stochasticity for exploration\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1\n\n        # Penalize almost full bins (fragmentation)\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.5 \n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on fit, waste, and stochasticity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return priorities\n\n    # Fit Score: Prioritize bins that can fit the item. Exponential decay.\n    fit_mask = bins_remain_cap >= item\n    waste = bins_remain_cap - item\n    relative_waste = waste / (item + 1e-6)\n    priorities[fit_mask] += np.exp(-relative_waste[fit_mask])\n\n    # Stochastic Element: Introduce randomness for exploration.\n    exploration_factor = 0.01\n    priorities += np.random.rand(len(bins_remain_cap)) * exploration_factor\n\n    # Fragmentation Penalty: Penalize small gaps.\n    fragmentation_threshold = item * 0.2\n    fragmentation_penalty = np.where((waste > 0) & (waste < fragmentation_threshold), -0.5, 0)\n    priorities += fragmentation_penalty\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on fit, waste, and stochasticity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return priorities\n\n    # Fit Score: Prioritize bins that can fit the item. Exponential decay.\n    fit_mask = bins_remain_cap >= item\n    waste = bins_remain_cap - item\n    relative_waste = waste / (item + 1e-6)\n    priorities[fit_mask] += np.exp(-relative_waste[fit_mask])\n\n    # Stochastic Element: Introduce randomness for exploration.\n    exploration_factor = 0.01\n    priorities += np.random.rand(len(bins_remain_cap)) * exploration_factor\n\n    # Fragmentation Penalty: Penalize small gaps.\n    fragmentation_threshold = item * 0.2\n    fragmentation_penalty = np.where((waste > 0) & (waste < fragmentation_threshold), -0.5, 0)\n    priorities += fragmentation_penalty\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}