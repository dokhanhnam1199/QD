{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes best-fit, adaptive stochasticity, fragmentation penalty, bin fill, and large item reward.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Best-fit: Stronger, but capped.\n        priorities[feasible_bins] = np.minimum(10 / (waste + 0.0001), 50) # Capped inverse waste\n\n        # Adaptive stochasticity: Fewer feasible bins, more exploration.\n        num_feasible = np.sum(feasible_bins)\n        stochasticity_factor = 0.1 / (num_feasible + 0.1)  #Smoother and better bounds.\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_factor\n\n        # Fragmentation penalty: Moderate, based on waste ratio.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.4  # Moderate fragmentation penalty\n\n        # Filling bins well: Reward optimal fill.\n        fill_ratio = item / bins_remain_cap[feasible_bins]\n        good_fill = (fill_ratio > 0.7) & (fill_ratio <= 1.0)\n        priorities[feasible_bins][good_fill] += 0.5 # Moderate reward\n\n        # Large item reward if bin has sufficient capacity.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 1.25, 0.25, 0) #Slightly less restrictive\n        priorities[feasible_bins] += large_cap_reward\n\n         #Moderate penalty if item fills bin above a certain threshold.\n        overfill_penalty = np.where(fill_ratio>1, -1,0)\n        priorities[feasible_bins]+= overfill_penalty\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes best-fit, adds stochasticity, penalizes fragmentation, and rewards large items.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit)\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Add stochasticity (exploration) - scale with item size\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1 * item\n\n        # Penalize almost full bins to prevent fragmentation\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.5 # Reduce priority of almost full bins\n\n        # Reward filling bins significantly but not completely\n        significant_fill = (item / bins_remain_cap[feasible_bins]) > 0.7\n        priorities[feasible_bins][significant_fill] += 0.2\n\n        #Large item high reward - filling up space and avoiding future placement issues.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*2,0.25,0) #incentivise large bins if enough capacity exists.\n        priorities[feasible_bins] += large_cap_reward\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), we see the code is exactly the same, indicating that performance differences are subtle and may depend on the specific problem instance or random seed. Comparing (1st) vs (20th), we see the first one has \"Adaptive Stochasticity\", \"Fragmentation Penalty\", \"Rewarding larger bins for smaller items\", and \"Dynamic \"Sweet Spot\" Incentive\" whereas the last one only has \"stochasticity\", \"Penalize almost full bins to prevent fragmentation\", and \"Incentivize bins in a \"sweet spot\" of utilization\".\n\nComparing (4th) vs (5th), the 4th heuristic uses a lot of constants while 5th heuristic uses hard code. Comparing (8th) vs (9th), the 8th has \"Adaptive stochasticity (reduce exploration as bins fill)\" and  \"Large capacity reward (adaptive threshold)\" whereas the 9th has \"Stochasticity (reduced with more feasible bins)\".\n\nComparing (15th) vs (16th), heuristic 15th has  \"Penalize almost full bins dynamically based on item size - stronger penalty for larger items\" and \"Dynamically incentivize larger bins, especially if item is large\" whereas 16th has \"Fragmentation penalty: Moderate, based on waste ratio.\" and \"Large item reward if bin has sufficient capacity.\". Comparing (19th) vs (20th), the codes are exactly the same.\n\nOverall: better heuristics tend to have more adaptive components, especially those that dynamically adjust parameters based on item size, remaining bin capacity, or the number of feasible bins. They also incorporate mechanisms to balance exploration and exploitation, with more sophisticated approaches to stochasticity. Fragmentation penalties and sweet spot incentives are common, but the way they are applied and tuned is crucial.\n- \nOkay, let's refine \"Current self-reflection\" to design better heuristics, while explicitly avoiding the pitfalls of \"Ineffective self-reflection.\"\n\nHere's a revised perspective on self-reflection to guide heuristic design:\n\n*   **Keywords:** Adaptive, Dynamic, Problem-Aware, Empirical Tuning, Balanced, Iterative Refinement.\n*   **Advice:** Focus on a core, functional heuristic. Adapt parameters based on *observable* problem characteristics. Prioritize gradual, empirically validated refinements over complex, speculative features.\n*   **Avoid:** Blindly combining factors without understanding their interactions, adding stochasticity without a clear purpose, and over-engineering with non-linear functions before establishing a solid foundation.\n*   **Explanation:** Start simple, understand your base heuristic's performance, and then introduce targeted adaptations. The goal is controlled, explainable improvements based on data, not a black box of complex interactions.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}