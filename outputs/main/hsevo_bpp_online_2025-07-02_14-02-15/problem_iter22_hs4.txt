import numpy as np

def priority_v2(item: float, 
                bins_remain_cap: np.ndarray,
                exploration_scale_factor: float = 0.09101631799272596,
                exploration_max: float = 0.28077082376865686,
                sweet_spot_item_factor_lower: float = 0.25301852254022483,
                sweet_spot_item_factor_upper: float = 0.12738435995536385,
                sweet_spot_base_lower: float = 0.5715882569924714,
                sweet_spot_base_upper: float = 0.9321096506814593,
                sweet_spot_reward: float = 0.3661649110741533,
                almost_full_threshold: float = 0.07436672644105932,
                almost_full_penalty: float = 0.778314168765114,
                large_cap_factor: float = 1.5249251324753916,
                large_cap_reward: float = 0.3867472808400223) -> np.ndarray:
    """Hybrid heuristic: Best-fit core, adaptive exploration, sweet spot, and fragmentation control."""

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if np.any(feasible_bins):
        waste = bins_remain_cap[feasible_bins] - item
        
        # Best-Fit Core
        priorities[feasible_bins] = 1 / (waste + 1e-5)

        # Adaptive Exploration: Scaled by item size and feasible bins
        num_feasible = np.sum(feasible_bins)
        exploration_factor = min(exploration_max, exploration_scale_factor * num_feasible * item)
        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor

        # Sweet Spot Incentive: Dynamic range based on item size.
        sweet_spot_lower = sweet_spot_base_lower - (item * sweet_spot_item_factor_lower)
        sweet_spot_upper = sweet_spot_base_upper - (item * sweet_spot_item_factor_upper)
        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0
        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)
        priorities[feasible_bins][sweet_spot] += sweet_spot_reward

        # Fragmentation Penalty: Target almost-full bins
        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]
        almost_full = wasted_space_ratio < almost_full_threshold
        priorities[feasible_bins][almost_full] *= almost_full_penalty

        # Reward larger bins based on item size.
        large_cap_reward_values = np.where(bins_remain_cap[feasible_bins] > item * large_cap_factor, large_cap_reward, 0)
        priorities[feasible_bins] += large_cap_reward_values

    else:
        priorities[:] = -np.inf

    return priorities
