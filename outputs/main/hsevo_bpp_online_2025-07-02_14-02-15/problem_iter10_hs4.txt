import numpy as np

def priority_v2(item: float, 
                bins_remain_cap: np.ndarray,
                division_avoidance_constant: float = 5.876046457943932e-05,
                max_exploration_factor: float = 0.45913196806881806,
                exploration_multiplier: float = 0.04616732558198935,
                almost_full_threshold: float = 0.012783379548118451,
                almost_full_penalty: float = 0.14955354623923298,
                large_bin_multiplier: float = 1.4347341338232666,
                small_item_large_bin_reward_amount: float = 0.30638943998003154,
                sweet_spot_lower_base: float = 0.5971232692210259,
                sweet_spot_lower_item_scaling: float = 0.1913433990351862,
                sweet_spot_upper_base: float = 0.7889670907475418,
                sweet_spot_upper_item_scaling: float = 0.0759721076356653,
                sweet_spot_reward: float = 0.4327625204305392,
                bin_size_assumption: float = 1.163158393677776) -> np.ndarray:
    """Prioritizes best-fit with adaptive penalties and dynamic exploration.
    Emphasizes a balance between bin utilization and preventing extreme fragmentation,
    adjusting strategies based on item size and bin availability."""

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if np.any(feasible_bins):
        waste = bins_remain_cap[feasible_bins] - item
        
        # Core: Prioritize best fit (minimize waste).  Slightly more aggressive than v1
        priorities[feasible_bins] = 1 / (waste + division_avoidance_constant)  # Tiny constant to avoid division by zero

        # Adaptive Stochasticity:  More exploration when bins are plentiful.
        num_feasible = np.sum(feasible_bins)
        exploration_factor = min(max_exploration_factor, exploration_multiplier * num_feasible)  # Caps at 0.2
        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor

        # Fragmentation Penalty:  Stronger and more nuanced. Target almost-full bins.
        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]
        almost_full = wasted_space_ratio < almost_full_threshold #More aggressive
        priorities[feasible_bins][almost_full] *= almost_full_penalty  # Significant penalty for using almost-full bins.

        # Rewarding larger bins for smaller items
        small_item_large_bin_reward = np.where(bins_remain_cap[feasible_bins] > large_bin_multiplier * item, small_item_large_bin_reward_amount, 0) #incentivise larger bins if item is small and capcity exists. Changed condition.
        priorities[feasible_bins] += small_item_large_bin_reward

        # Dynamic "Sweet Spot" Incentive: Adapt the range based on item size.
        # Aim is to encourage utilization in a range that avoids both extreme fragmentation
        # and under-utilization.  Smaller items should aim for higher utilization.
        sweet_spot_lower = sweet_spot_lower_base - (item * sweet_spot_lower_item_scaling) #Dynamic Lower Bound - lower bound decreases as item sizes increase. 
        sweet_spot_upper = sweet_spot_upper_base - (item * sweet_spot_upper_item_scaling) #Dynamic Upper Bound - upper bound decreases as item sizes increase, less aggressively.

        utilization = (bins_remain_cap[feasible_bins] - waste) / bin_size_assumption  # Assuming bin size is 1
        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)
        priorities[feasible_bins][sweet_spot] += sweet_spot_reward #Increased the reward.

    else:
        priorities[:] = -np.inf  # No feasible bins

    return priorities
