[
  {
    "stdout_filepath": "problem_iter14_response0.txt_stdout.txt",
    "code_path": "problem_iter14_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Best-fit, adaptive stochasticity, dynamic fragmentation penalty, adaptive large item reward.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Best-fit prioritization\n        priorities[feasible_bins] = 10 / (waste + 0.0001)\n        \n        # Adaptive stochasticity - reduce exploration as bins fill\n        num_feasible = np.sum(feasible_bins)\n        exploration_factor = max(0, 0.1 - 0.01 * num_feasible)\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n        \n        # Dynamic fragmentation penalty - adjust based on item size\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        penalty_factor = 0.2 + item * 0.5 # Adjust sensitivity of almost full depending on size.\n        priorities[feasible_bins][almost_full] *= (1 - penalty_factor)\n        \n        #Dynamically incentivize larger bins if remaining capacity is high enough\n        large_cap_threshold = item * (1.2 + item * 0.4)\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > large_cap_threshold, 0.4 + item * 0.2, 0)\n        priorities[feasible_bins] += large_cap_reward\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.058635819704831,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response1.txt_stdout.txt",
    "code_path": "problem_iter14_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with item-aware fragmentation & adaptive exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Best-fit prioritization\n        priorities[feasible_bins] = 1 / (waste + 0.00001)\n\n        # Adaptive Stochasticity\n        num_feasible = np.sum(feasible_bins)\n        exploration_factor = min(0.2, 0.02 * num_feasible)\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Fragmentation penalty (stronger for larger items)\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05\n        penalty_factor = 0.2 + item * 0.1\n        priorities[feasible_bins][almost_full] *= penalty_factor\n        priorities[feasible_bins][almost_full] = np.clip(priorities[feasible_bins][almost_full], 0, 1)\n\n        # Sweet spot reward\n        fill_ratio = item / bins_remain_cap[feasible_bins]\n        good_fill = (fill_ratio > 0.7) & (fill_ratio <= 1.0)\n        priorities[feasible_bins][good_fill] += 0.5\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 3.7495013960909587,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response2.txt_stdout.txt",
    "code_path": "problem_iter14_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive penalties, dynamic exploration based on item size.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Core: Prioritize best fit\n        priorities[feasible_bins] = 10 / (waste + 0.00001)\n\n        # Adaptive Stochasticity: Exploration decreases with item size\n        num_feasible = np.sum(feasible_bins)\n        exploration_factor = min(0.1, 0.01 * num_feasible * (1 - item))\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Fragmentation Penalty: Dynamically scaled.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < (0.05 + 0.02 * item)\n        priorities[feasible_bins][almost_full] *= 0.1\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 28.220981252493022,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response3.txt_stdout.txt",
    "code_path": "problem_iter14_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive stochasticity & dynamic fragmentation control.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Best-fit prioritization\n        priorities[feasible_bins] = 1 / (waste + 0.00001)\n\n        # Adaptive Stochasticity\n        num_feasible = np.sum(feasible_bins)\n        exploration_factor = min(0.2, 0.02 * num_feasible)\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Fragmentation penalty (stronger for larger items)\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05\n        penalty_factor = 0.2 + item * 0.1 #item size adjusts the penalty dynamically.\n        priorities[feasible_bins][almost_full] *= penalty_factor\n        priorities[feasible_bins][almost_full] = np.clip(priorities[feasible_bins][almost_full], 0, 1) #prevent overflow\n\n        # Rewarding larger bins for smaller items\n        if item < 0.3: #Only triggers when dealing with small items\n          large_bin_reward = bins_remain_cap[feasible_bins] > (1.0 - item) #is it approaching full bin?\n          priorities[feasible_bins][large_bin_reward] += 0.3\n\n        # Dynamic \"Sweet Spot\" Incentive:  Simplified, based on item size.\n        sweet_spot_lower = 0.6 - (item * 0.15)  #Dynamic Lower Bound - adjusted scale\n        sweet_spot_upper = 0.9 - (item * 0.1) #Dynamic Upper Bound - decreased upper bound\n\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0  # Assuming bin size is 1\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.3\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 3.6996410051854944,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response4.txt_stdout.txt",
    "code_path": "problem_iter14_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adaptive stochasticity, fragmentation control, and sweet spot.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Best-fit prioritization\n        priorities[feasible_bins] = 10 / (waste + 0.0001)\n        priorities[feasible_bins] = np.minimum(priorities[feasible_bins], 50)\n\n        # Adaptive stochasticity, based on item size and num of feasible bins\n        num_feasible = np.sum(feasible_bins)\n        stochasticity_factor = 0.1 * (1 - item) / (num_feasible + 0.1)\n        priorities[feasible_bins] += np.random.rand(num_feasible) * stochasticity_factor\n\n        # Fragmentation penalty. Bins with > 90% utilisation.\n        wasted_space_ratio = waste / 1.0 # binsize fixed at 1\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.4\n\n        # Dynamic sweet spot incentive\n        sweet_spot_lower = 0.6 - (item * 0.1)\n        sweet_spot_upper = 0.8 - (item * 0.05)\n\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.5\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response5.txt_stdout.txt",
    "code_path": "problem_iter14_code5.py",
    "code": "import numpy as np\n\nbest_fit_epsilon = 1e-9\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, adaptive stochasticity, and dynamic fragmentation penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Best-fit prioritization with regularization.\n        priorities[feasible_bins] = 1 / (waste + best_fit_epsilon)\n\n        # Adaptive stochasticity based on number of feasible bins\n        num_feasible = np.sum(feasible_bins)\n        stochasticity_factor = 0.1 / (num_feasible + 1e-6)\n        priorities[feasible_bins] += np.random.rand(num_feasible) * stochasticity_factor\n\n        # Dynamic fragmentation penalty: Item-aware.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05\n        penalty_factor = 0.3 + 0.2 * item  # Larger items, stronger penalty\n        priorities[feasible_bins][almost_full] *= (1 - min(penalty_factor, 0.5))\n\n        # \"Sweet spot\" reward: target bins near full capacity.\n        fill_ratio = (bins_remain_cap[feasible_bins] - waste) / bins_remain_cap[feasible_bins]\n        significantly_filled = fill_ratio > 0.5\n        priorities[feasible_bins][significantly_filled] += 0.2\n\n        # Reward for placing into larger bins, threshold adapts to item size.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * (1.5 + 0.5 * item), 0.25, 0)\n        priorities[feasible_bins] += large_cap_reward\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.058635819704831,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response6.txt_stdout.txt",
    "code_path": "problem_iter14_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive stochasticity and dynamic sweet spot.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Best-fit prioritization.\n        priorities[feasible_bins] = 1 / (waste + 0.00001)\n\n        # Adaptive stochasticity: smaller items, more exploration.\n        exploration_factor = max(0, 0.1 - (item * 0.05))\n        num_feasible = np.sum(feasible_bins)\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Sweet Spot Incentive\n        sweet_spot_lower = 0.7 - (item * 0.1)\n        sweet_spot_upper = 0.9 - (item * 0.05)\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.4\n        \n        # Fragmentation penalty: Apply a moderate penalty for small waste, only if other bins exist\n        small_waste = (waste < 0.1)\n        if np.sum(feasible_bins) > 1:\n            priorities[feasible_bins][small_waste] *= 0.5 #reduce priority\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response7.txt_stdout.txt",
    "code_path": "problem_iter14_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adaptive stochasticity, dynamic fragmentation penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Best-fit prioritization\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n\n        # Adaptive stochasticity: less exploration when bins are fuller.\n        stochasticity_scale = 0.1 * (1 - np.mean(bins_remain_cap[feasible_bins]) if len(bins_remain_cap[feasible_bins]) > 0 else 0)\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_scale\n\n        # Penalize almost full bins, scaled by item size.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        penalty = 0.5 + 0.2 * item  # Larger items, higher penalty\n        priorities[feasible_bins][almost_full] *= max(0, 1 - penalty) # Ensure not negative\n\n        # Large item reward: only if there's significantly more space.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 2, 0.5, 0)\n        priorities[feasible_bins] += large_cap_reward\n\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 20.741922616673317,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response8.txt_stdout.txt",
    "code_path": "problem_iter14_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive stochasticity and fragmentation control.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        priorities[feasible_bins] = 1 / (waste + 0.00001)\n\n        # Adaptive Stochasticity: less aggressive as bins fill.\n        num_feasible = np.sum(feasible_bins)\n        exploration_factor = min(0.1, 0.01 * num_feasible)\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Fragmentation penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        penalty = 0.7 + 0.2 * item\n        priorities[feasible_bins][almost_full] *= penalty\n\n        # Reward for large capacity\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 1.5, 0.2, 0)\n        priorities[feasible_bins] += large_cap_reward\n\n        # Dynamic sweet spot incentive\n        sweet_spot_lower = 0.6 - (item * 0.1)\n        sweet_spot_upper = 0.8 - (item * 0.05)\n\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.2\n        \n        priorities[feasible_bins] *= (1 + 0.05 * item)\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 1.5855604307937865,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response9.txt_stdout.txt",
    "code_path": "problem_iter14_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adaptive exploration and dynamic sweet spot.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n\n        exploration_factor = 0.1 * (1 - item)\n        num_feasible = np.sum(feasible_bins)\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        remaining_capacity_ratio = waste / 1.0\n        almost_full = remaining_capacity_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.5\n\n        sweet_spot_lower = 0.6 - (item * 0.15)\n        sweet_spot_upper = 0.85 - (item * 0.05)\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.3\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.168328679696844,
    "exec_success": true
  }
]