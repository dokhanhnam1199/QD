```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Prioritizes best-fit with adaptive stochasticity and fragmentation penalty."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if np.any(feasible_bins):
        waste = bins_remain_cap[feasible_bins] - item

        # Prioritize based on inverse waste (best fit)
        priorities[feasible_bins] = 1 / (waste + 0.0001)

        # Adaptive stochasticity: less exploration when bins are fuller.
        stochasticity_scale = 0.1 * (1 - np.mean(bins_remain_cap[feasible_bins]) if len(bins_remain_cap[feasible_bins]) > 0 else 0)
        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_scale

        # Penalize almost full bins, scaled by item size.
        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]
        almost_full = wasted_space_ratio < 0.1
        penalty = 0.5 + 0.2 * item  # Larger items, higher penalty
        priorities[feasible_bins][almost_full] *= max(0, 1 - penalty) # Ensure not negative

        # Large item reward: only if there's significantly more space.
        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 2, 0.5, 0)
        priorities[feasible_bins] += large_cap_reward

        # Sweet spot incentive (adaptive range)
        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0 #Assuming bin size is 1
        sweet_spot_lower = 0.5
        sweet_spot_upper = 0.75
        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)
        priorities[feasible_bins][sweet_spot] += 0.3

    else:
        priorities[:] = -np.inf

    return priorities
```
