import numpy as np

def priority_v2(item: float, 
                bins_remain_cap: np.ndarray,
                division_avoidance_constant: float = 3.2355718705165596e-05,
                max_exploration_factor: float = 0.21997513178581302,
                exploration_multiplier: float = 0.015358021686138843,
                almost_full_threshold: float = 0.01571442881352854,
                almost_full_penalty: float = 0.2018094162117562,
                large_bin_multiplier: float = 1.2846674873740698,
                small_item_large_bin_reward_amount: float = 0.492685647962375,
                sweet_spot_lower_base: float = 0.666331534770004,
                sweet_spot_lower_item_scaling: float = 0.16295658608236968,
                sweet_spot_upper_base: float = 0.8382706810636051,
                sweet_spot_upper_item_scaling: float = 0.07679243545710485,
                sweet_spot_reward: float = 0.3208925776449992,
                bin_size_assumption: float = 1.0275529259313827) -> np.ndarray:
    """Prioritizes best-fit with adaptive penalties and dynamic exploration.
    Emphasizes a balance between bin utilization and preventing extreme fragmentation,
    adjusting strategies based on item size and bin availability."""

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if np.any(feasible_bins):
        waste = bins_remain_cap[feasible_bins] - item
        
        # Core: Prioritize best fit (minimize waste).  Slightly more aggressive than v1
        priorities[feasible_bins] = 1 / (waste + division_avoidance_constant)  # Tiny constant to avoid division by zero

        # Adaptive Stochasticity:  More exploration when bins are plentiful.
        num_feasible = np.sum(feasible_bins)
        exploration_factor = min(max_exploration_factor, exploration_multiplier * num_feasible)  # Caps at 0.2
        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor

        # Fragmentation Penalty:  Stronger and more nuanced. Target almost-full bins.
        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]
        almost_full = wasted_space_ratio < almost_full_threshold #More aggressive
        priorities[feasible_bins][almost_full] *= almost_full_penalty  # Significant penalty for using almost-full bins.

        # Rewarding larger bins for smaller items
        small_item_large_bin_reward = np.where(bins_remain_cap[feasible_bins] > large_bin_multiplier * item, small_item_large_bin_reward_amount, 0) #incentivise larger bins if item is small and capcity exists. Changed condition.
        priorities[feasible_bins] += small_item_large_bin_reward

        # Dynamic "Sweet Spot" Incentive: Adapt the range based on item size.
        # Aim is to encourage utilization in a range that avoids both extreme fragmentation
        # and under-utilization.  Smaller items should aim for higher utilization.
        sweet_spot_lower = sweet_spot_lower_base - (item * sweet_spot_lower_item_scaling) #Dynamic Lower Bound - lower bound decreases as item sizes increase. 
        sweet_spot_upper = sweet_spot_upper_base - (item * sweet_spot_upper_item_scaling) #Dynamic Upper Bound - upper bound decreases as item sizes increase, less aggressively.

        utilization = (bins_remain_cap[feasible_bins] - waste) / bin_size_assumption  # Assuming bin size is 1
        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)
        priorities[feasible_bins][sweet_spot] += sweet_spot_reward #Increased the reward.

    else:
        priorities[:] = -np.inf  # No feasible bins

    return priorities
