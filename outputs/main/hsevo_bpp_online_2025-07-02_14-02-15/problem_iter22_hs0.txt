import numpy as np

def priority_v2(item: float, 
                bins_remain_cap: np.ndarray,
                exploration_scale_factor: float = 0.025453619660818286,
                exploration_max: float = 0.14427890973115934,
                sweet_spot_item_factor_lower: float = 0.1354347640082177,
                sweet_spot_item_factor_upper: float = 0.0733104415619972,
                sweet_spot_base_lower: float = 0.6598451432796733,
                sweet_spot_base_upper: float = 0.9102010069458781,
                sweet_spot_reward: float = 0.5696894833685787,
                almost_full_threshold: float = 0.06302095883629455,
                almost_full_penalty: float = 0.7410311365182239,
                large_cap_factor: float = 1.6118968401635003,
                large_cap_reward: float = 0.2331869717856654) -> np.ndarray:
    """Hybrid heuristic: Best-fit core, adaptive exploration, sweet spot, and fragmentation control."""

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if np.any(feasible_bins):
        waste = bins_remain_cap[feasible_bins] - item
        
        # Best-Fit Core
        priorities[feasible_bins] = 1 / (waste + 1e-5)

        # Adaptive Exploration: Scaled by item size and feasible bins
        num_feasible = np.sum(feasible_bins)
        exploration_factor = min(exploration_max, exploration_scale_factor * num_feasible * item)
        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor

        # Sweet Spot Incentive: Dynamic range based on item size.
        sweet_spot_lower = sweet_spot_base_lower - (item * sweet_spot_item_factor_lower)
        sweet_spot_upper = sweet_spot_base_upper - (item * sweet_spot_item_factor_upper)
        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0
        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)
        priorities[feasible_bins][sweet_spot] += sweet_spot_reward

        # Fragmentation Penalty: Target almost-full bins
        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]
        almost_full = wasted_space_ratio < almost_full_threshold
        priorities[feasible_bins][almost_full] *= almost_full_penalty

        # Reward larger bins based on item size.
        large_cap_reward_values = np.where(bins_remain_cap[feasible_bins] > item * large_cap_factor, large_cap_reward, 0)
        priorities[feasible_bins] += large_cap_reward_values

    else:
        priorities[:] = -np.inf

    return priorities
