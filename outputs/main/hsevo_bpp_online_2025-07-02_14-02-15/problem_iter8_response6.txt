```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Prioritizes best-fit, adaptive stochasticity, fragmentation penalty, bin fill, and large item reward."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if np.any(feasible_bins):
        waste = bins_remain_cap[feasible_bins] - item
        
        # Best-fit: Stronger, but capped.
        priorities[feasible_bins] = np.minimum(10 / (waste + 0.0001), 50) # Capped inverse waste

        # Adaptive stochasticity: Fewer feasible bins, more exploration.
        num_feasible = np.sum(feasible_bins)
        stochasticity_factor = 0.1 / (num_feasible + 0.1)  #Smoother and better bounds.
        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_factor

        # Fragmentation penalty: Moderate, based on waste ratio.
        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]
        almost_full = wasted_space_ratio < 0.1
        priorities[feasible_bins][almost_full] *= 0.4  # Moderate fragmentation penalty

        # Filling bins well: Reward optimal fill.
        fill_ratio = item / bins_remain_cap[feasible_bins]
        good_fill = (fill_ratio > 0.7) & (fill_ratio <= 1.0)
        priorities[feasible_bins][good_fill] += 0.5 # Moderate reward

        # Large item reward if bin has sufficient capacity.
        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 1.25, 0.25, 0) #Slightly less restrictive
        priorities[feasible_bins] += large_cap_reward

         #Moderate penalty if item fills bin above a certain threshold.
        overfill_penalty = np.where(fill_ratio>1, -1,0)
        priorities[feasible_bins]+= overfill_penalty

    else:
        priorities[:] = -np.inf

    return priorities
```
