```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Prioritizes best-fit, adds stochasticity, penalizes fragmentation, and considers bin fill ratio."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if np.any(feasible_bins):
        waste = bins_remain_cap[feasible_bins] - item
        
        # Prioritize based on inverse waste (best fit) - stronger best-fit
        priorities[feasible_bins] = 10 / (waste + 0.0001)  # Increased impact of best-fit

        # Add stochasticity (exploration) - reduced stochasticity
        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.05  # Reduced stochasticity

        # Penalize fragmentation - more aggressive penalty
        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]
        almost_full = wasted_space_ratio < 0.1
        priorities[feasible_bins][almost_full] *= 0.3  # Stronger penalty for almost full bins

        # Reward filling bins well
        fill_ratio = item / bins_remain_cap[feasible_bins]
        good_fill = (fill_ratio > 0.7) & (fill_ratio <= 1.0)
        priorities[feasible_bins][good_fill] += 0.5  # Reward bins filled well

        # Large item high reward - filling up space and avoiding future placement issues, only when bin large enough
        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*1.25,0.25,0) #incentivise large bins if enough capacity exists. Less restriction on bin size for the reward.
        priorities[feasible_bins] += large_cap_reward

        #Moderate penalty if item fills bin above a certain threshold.
        overfill_penalty = np.where(fill_ratio>1, -1,0)
        priorities[feasible_bins]+= overfill_penalty

    else:
        priorities[:] = -np.inf

    return priorities
```
