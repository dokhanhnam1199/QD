[
  {
    "stdout_filepath": "problem_iter17_response0.txt_stdout.txt",
    "code_path": "problem_iter17_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive exploration and fragmentation control.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Best-fit prioritization\n        priorities[feasible_bins] = 10 / (waste + 0.0001)\n        priorities[feasible_bins] = np.minimum(priorities[feasible_bins], 50)\n\n        # Adaptive stochasticity\n        num_feasible = np.sum(feasible_bins)\n        stochasticity_factor = 0.1 * (1 - item) / (num_feasible + 0.1)\n        priorities[feasible_bins] += np.random.rand(num_feasible) * stochasticity_factor\n\n        # Fragmentation penalty\n        wasted_space_ratio = waste / 1.0\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.4\n\n        # Dynamic sweet spot incentive\n        sweet_spot_lower = 0.6 - (item * 0.1)\n        sweet_spot_upper = 0.8 - (item * 0.05)\n\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.5\n\n        # Rewarding larger bins for smaller items\n        small_item_large_bin_reward = np.where(bins_remain_cap[feasible_bins] > 1.6 * item, 0.5, 0) #Increased reward and slightly larger bin requirement\n        priorities[feasible_bins] += small_item_large_bin_reward\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.5073793378540135,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response1.txt_stdout.txt",
    "code_path": "problem_iter17_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, adaptive exploration, and dynamic sweet spot. \n    Prioritizes based on item size and bin diversity.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        priorities[feasible_bins] = 1 / (waste + 0.00001)\n\n        num_feasible = np.sum(feasible_bins)\n        capacity_std = np.std(bins_remain_cap[feasible_bins])\n        exploration_factor = min(0.3, 0.05 * num_feasible + 0.1 * capacity_std)\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05\n        priorities[feasible_bins][almost_full] *= 0.1\n\n        sweet_spot_lower = 0.6 - (item * 0.2) - (capacity_std * 0.02)\n        sweet_spot_upper = 0.8 - (item * 0.1) + (capacity_std * 0.02)\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.5\n\n        very_small_remaining = bins_remain_cap[feasible_bins] - item < 0.1\n        priorities[feasible_bins][very_small_remaining] *= 0.3\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 3.211009174311931,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response2.txt_stdout.txt",
    "code_path": "problem_iter17_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive stochasticity and dynamic penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Best-fit prioritization.\n        priorities[feasible_bins] = 1 / (waste + 0.00001)\n\n        # Adaptive stochasticity: scale with remaining capacity.\n        stochasticity_scale = 0.1 * (1 - np.mean(bins_remain_cap[feasible_bins]) if len(bins_remain_cap[feasible_bins]) > 0 else 0)\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_scale\n\n\n        # Penalize almost full bins, scaled by item size.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        penalty = 0.5 + 0.2 * item  # Larger items, higher penalty\n        priorities[feasible_bins][almost_full] *= max(0, 1 - penalty)\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 8.516154766653381,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response3.txt_stdout.txt",
    "code_path": "problem_iter17_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive exploration and sweet spot incentives.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Best-fit prioritization\n        priorities[feasible_bins] = 1 / (waste + 0.00001)\n\n        # Adaptive Exploration\n        num_feasible = np.sum(feasible_bins)\n        exploration_factor = min(0.2, 0.05 * num_feasible * (1 - item))\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Sweet Spot Incentive\n        sweet_spot_lower = 0.6 - (item * 0.2)\n        sweet_spot_upper = 0.9 - (item * 0.1)\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.5\n\n        # Fragmentation Penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        if num_feasible > 1:\n             priorities[feasible_bins][almost_full] *= 0.4 #reduced penalty\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 35.6102911846829,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response4.txt_stdout.txt",
    "code_path": "problem_iter17_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, adaptive stochasticity, item-aware fragmentation penalty, and large bin reward.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Best-fit prioritization with small constant to avoid division by zero\n        priorities[feasible_bins] = 1 / (waste + 1e-6)\n\n        # Adaptive stochasticity: scaled by remaining capacity\n        stochasticity_scale = 0.1 * (1 - np.mean(bins_remain_cap[feasible_bins]) if len(bins_remain_cap[feasible_bins]) > 0 else 0)\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_scale\n\n        # Item-aware fragmentation penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        penalty = 0.3 + 0.2 * item  # Larger items, higher penalty\n        priorities[feasible_bins][almost_full] *= max(0, 1 - penalty)  # Ensure not negative\n\n        # Reward for large bins relative to the item size\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 2, 0.25, 0)\n        priorities[feasible_bins] += large_cap_reward\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 21.080973274830484,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response5.txt_stdout.txt",
    "code_path": "problem_iter17_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins using best-fit, adaptive stochasticity, and sweet spot.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Best-fit prioritization.\n        priorities[feasible_bins] = 1 / (waste + 0.00001)\n\n        # Adaptive stochasticity: smaller items, more exploration.\n        exploration_factor = max(0, 0.1 - (item * 0.05))\n        num_feasible = np.sum(feasible_bins)\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Sweet Spot Incentive\n        sweet_spot_lower = 0.7 - (item * 0.1)\n        sweet_spot_upper = 0.9 - (item * 0.05)\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0\n        sweet_spot = (utilization >= sweet_spot_lower) & (utilization <= sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.4\n        \n        # Fragmentation penalty: Apply a moderate penalty for small waste, only if other bins exist\n        small_waste = (waste < 0.1)\n        if np.sum(feasible_bins) > 1:\n            priorities[feasible_bins][small_waste] *= 0.5 #reduce priority\n\n        # Reward Larger Bins for Smaller Items - from version 0\n        small_item_threshold = 0.3\n        large_bin_threshold = 1.5 * item\n        if item < small_item_threshold:\n            large_bin = bins_remain_cap[feasible_bins] > large_bin_threshold\n            priorities[feasible_bins][large_bin] += 0.5\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response6.txt_stdout.txt",
    "code_path": "problem_iter17_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid heuristic: Best-fit core, adaptive exploration, sweet spot, and fragmentation control.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Best-Fit Core\n        priorities[feasible_bins] = 1 / (waste + 1e-5)\n\n        # Adaptive Exploration: Scaled by item size and feasible bins\n        num_feasible = np.sum(feasible_bins)\n        exploration_factor = min(0.2, 0.05 * num_feasible * item)\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Sweet Spot Incentive: Dynamic range based on item size.\n        sweet_spot_lower = 0.6 - (item * 0.2)\n        sweet_spot_upper = 0.9 - (item * 0.1)\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.4\n\n        # Fragmentation Penalty: Target almost-full bins\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.08\n        priorities[feasible_bins][almost_full] *= 0.7\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 3.689668927004388,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response7.txt_stdout.txt",
    "code_path": "problem_iter17_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, adaptive stochasticity, and item-aware penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        priorities[feasible_bins] = 1 / (waste + 1e-9)\n\n        # Adaptive stochasticity: scaled by feasible bin count.\n        num_feasible = np.sum(feasible_bins)\n        exploration_factor = 0.1 / (num_feasible + 1e-6)\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Item-aware fragmentation penalty.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05\n        penalty_factor = 0.3 + 0.2 * item  # Adjust penalty with item size.\n        priorities[feasible_bins][almost_full] *= (1 - min(penalty_factor, 0.5))\n\n        # Sweet spot incentive near full capacity.\n        fill_ratio = (bins_remain_cap[feasible_bins] - waste) / 1.0\n        significantly_filled = fill_ratio > 0.5\n        priorities[feasible_bins][significantly_filled] += 0.2\n\n        # Reward larger bins based on item size.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 1.5, 0.2, 0)\n        priorities[feasible_bins] += large_cap_reward\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 1.685281212604716,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response8.txt_stdout.txt",
    "code_path": "problem_iter17_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive stochasticity and dynamic sweet spot.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Best-fit prioritization\n        priorities[feasible_bins] = 10 / (waste + 0.0001)\n        priorities[feasible_bins] = np.minimum(priorities[feasible_bins], 50)\n\n        # Adaptive stochasticity\n        num_feasible = np.sum(feasible_bins)\n        stochasticity_factor = 0.1 * (1 - item) / (num_feasible + 0.1)\n        priorities[feasible_bins] += np.random.rand(num_feasible) * stochasticity_factor\n\n        # Dynamic sweet spot incentive\n        sweet_spot_lower = 0.6 - (item * 0.1)\n        sweet_spot_upper = 0.8 - (item * 0.05)\n\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0 # binsize fixed at 1\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.5\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response9.txt_stdout.txt",
    "code_path": "problem_iter17_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive exploration and sweet spot incentive.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Best-fit prioritization.\n        priorities[feasible_bins] = 1 / (waste + 0.00001)\n\n        # Adaptive stochasticity\n        exploration_factor = max(0, 0.1 - (item * 0.05))\n        num_feasible = np.sum(feasible_bins)\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Sweet Spot Incentive, adjust range based on item size.\n        sweet_spot_lower = 0.6 - (item * 0.3)\n        sweet_spot_upper = 0.9 - (item * 0.2)\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.6\n\n        # Bonus for filling a bin completely.\n        almost_full_bin = waste < 0.05\n        priorities[feasible_bins][almost_full_bin] += 0.8\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response0.txt_stdout.txt",
    "code_path": "problem_iter18_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive penalties and dynamic exploration.\n    Emphasizes a balance between bin utilization and preventing extreme fragmentation,\n    adjusting strategies based on item size and bin availability. Includes bin history.\n    This version prioritizes simplicity and demonstrable impact, validated empirically.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Core: Prioritize best fit (minimize waste).\n        priorities[feasible_bins] = 1 / (waste + 1e-9)  # Tiny constant to avoid division by zero\n\n        # Adaptive Exploration:  Simple exploration scaled by item size and feasibility.\n        exploration_factor = 0.05 * item * np.sum(feasible_bins) # Keep exploration simple initially.\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * exploration_factor\n\n        # Fragmentation Penalty: Focus on almost-full bins with a simple penalty.\n        almost_full_threshold = 0.1  # Define \"almost full\" as remaining capacity <= 10% of bin size\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < almost_full_threshold\n        priorities[feasible_bins][almost_full] *= 0.5  # Simple penalty: reduce priority by half.\n\n        # Sweet Spot Incentive: Prioritize bins within a desirable utilization range.\n        sweet_spot_lower = 0.6\n        sweet_spot_upper = 0.9\n        utilization = (bins_remain_cap[feasible_bins] - waste)\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.3  # Add a reward for bins in the sweet spot.\n\n        # Bin Usage History: Penalize recently used bins (if available).\n        try:\n            bin_usage_history  # Check if bin_usage_history exists\n            usage_penalty = bin_usage_history[feasible_bins] * 0.1  # Simple penalty.\n            priorities[feasible_bins] -= usage_penalty\n        except NameError:\n            pass  # If bin_usage_history doesn't exist, skip this step.\n\n    else:\n        priorities[:] = -np.inf  # No feasible bins\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 35.79976067012365,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response1.txt_stdout.txt",
    "code_path": "problem_iter18_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive exploration and capacity-aware adjustments.\n    Focuses on balancing bin utilization and preventing fragmentation, adjusting exploration\n    based on the relative item size to the available bin capacities.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Core: Prioritize best fit (minimize waste).  Slightly stronger preference for tighter fits.\n        priorities[feasible_bins] = 1 / (waste + 1e-9) #Avoid division by zero\n\n        # Adaptive Exploration: Scale exploration based on item size relative to bin capacities.\n        # Smaller items in larger bins trigger more exploration, and vice versa.\n        relative_item_size = item / bins_remain_cap[feasible_bins]\n        exploration_factor = 0.1 * (1 - relative_item_size)  # Higher exploration for smaller items relative to bin size\n        exploration_factor = np.clip(exploration_factor, 0.01, 0.2) #Clamp exploration factor\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * exploration_factor\n\n        # Capacity-Aware Fragmentation Penalty: Penalize bins that, after packing,\n        # will have a remaining capacity close to common item sizes.\n        # Idea: avoid leaving bins with just enough space for frequently occurring items.\n\n        # Example: Assume common item sizes are around 0.2, 0.3, 0.4 (can be dynamically adjusted)\n        common_item_sizes = np.array([0.2, 0.3, 0.4])\n        remaining_capacity_after_packing = waste\n        \n        fragmentation_penalty = np.zeros_like(remaining_capacity_after_packing)\n        for size in common_item_sizes:\n            fragmentation_penalty += np.exp(-np.abs(remaining_capacity_after_packing - size) / 0.05)  # Gaussian-like penalty\n            \n        priorities[feasible_bins] -= 0.05 * fragmentation_penalty # Apply penalty\n\n        # Small Item Placement Boost: Give a small bonus to bins that are significantly larger than the item.\n        # Helps distribute smaller items more evenly.\n        large_bin_bonus = np.where(bins_remain_cap[feasible_bins] > 2 * item, 0.05, 0.0)  # Increased threshold\n        priorities[feasible_bins] += large_bin_bonus\n    else:\n        priorities[:] = -np.inf  # No feasible bins\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 60.041882728360605,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response2.txt_stdout.txt",
    "code_path": "problem_iter18_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive exploration and bin utilization awareness.\n\n    This version focuses on simplicity and problem-aware adjustments.\n    It prioritizes bins with sufficient space, introduces adaptive exploration,\n    and penalizes bins with low utilization *after* placement.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Core: Prioritize best fit (minimize waste).\n        priorities[feasible_bins] = 1 / (waste + 1e-9)  # Adding a small constant to avoid division by zero\n\n        # Adaptive Exploration: Reduce exploration as the bin gets fuller\n        exploration_factor = np.clip(1.0 - bins_remain_cap[feasible_bins], 0.0, 0.2) #Explore less as bins are empty\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * exploration_factor\n\n        # Encourage filling bins to a reasonable level, but only *after* placing the item\n        # Target utilization between 70% and 95% after placing item.\n        future_utilization = (bins_remain_cap[feasible_bins] - item)\n        sweet_spot = (future_utilization > 0.05) & (future_utilization < 0.30)\n\n        priorities[feasible_bins][sweet_spot] *= 2.0 #give a significant boost to bins that will be within the utilization range\n\n    else:\n        priorities[:] = -np.inf  # No feasible bins\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response3.txt_stdout.txt",
    "code_path": "problem_iter18_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive elements, focusing on simplicity and effectiveness.\n    Emphasizes a balance between bin utilization and preventing fragmentation,\n    adjusting strategies based on item size and bin availability.  Removes most parameters\n    and focuses on core heuristics. Aims for a more robust and interpretable solution.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Core: Prioritize best fit (minimize waste).  Avoid division by zero more robustly.\n        priorities[feasible_bins] = 1.0 / (waste + 1e-9)\n\n        # Exploration:  Simpler adaptive exploration based on the number of feasible bins.\n        num_feasible = np.sum(feasible_bins)\n        exploration_factor = 0.1 / (1 + num_feasible)  # Inverse relationship: less exploration when many options\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Fragmentation Penalty: Discourage filling bins that are already very full.\n        almost_full_threshold = 0.1  # 10% remaining capacity\n        almost_full = waste / bins_remain_cap[feasible_bins] < almost_full_threshold\n        priorities[feasible_bins][almost_full] *= 0.5  # Reduce priority by half\n\n        # Sweet spot reward: Incentivize utilization in a reasonable range.\n        sweet_spot_lower = 0.5\n        sweet_spot_upper = 0.9\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0  # Assuming bin size is 1\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.3 #Slightly increase reward\n\n        # Bin Usage History (Optional): Penalize recently used bins.  Keep it simple.\n        try:\n            bin_usage_history  # Check if it exists\n            usage_penalty = bin_usage_history[feasible_bins] * 0.05 # Reduce the usage penalty\n            priorities[feasible_bins] -= usage_penalty\n        except NameError:\n            pass  # If bin_usage_history doesn't exist, skip this penalty.\n\n\n    else:\n        priorities[:] = -np.inf  # No feasible bins\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response4.txt_stdout.txt",
    "code_path": "problem_iter18_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive penalties and dynamic exploration.\n    Emphasizes a balance between bin utilization and preventing extreme fragmentation,\n    adjusting strategies based on item size and bin availability.\n\n    This version focuses on simplicity and problem-aware enhancements over excessive parameters.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Core: Prioritize best fit (minimize waste).  Simpler, more direct.\n        priorities[feasible_bins] = 1.0 / (waste + 1e-9)  # Avoid division by zero, smaller constant\n\n        # Adaptive Exploration:  Scale exploration *down* as bins get tighter.\n        # This encourages exploration when there's more choice, and exploitation when bins are scarce.\n        exploration_factor = 0.1 * (1.0 - (item / bins_remain_cap[feasible_bins]))\n        exploration_factor = np.clip(exploration_factor, 0, 0.1)  # Ensure it's not negative or too large\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * exploration_factor\n\n        # Fragmentation Penalty:  Only penalize if the resulting fill level is VERY high.  More targeted.\n        remaining_capacity_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full_penalty = 0.5  # Reduced penalty\n        almost_full = remaining_capacity_ratio < 0.1 # More restrictive \"almost full\"\n        priorities[feasible_bins][almost_full] *= (1 - almost_full_penalty)  #Apply Penalty\n\n        #Reward Larger Bins for small items only if the bin isn't almost full already.\n        small_item_reward = 0.3\n        small_item_threshold = 0.25 #Item must be < 25% of bin size for reward\n        if item < small_item_threshold:\n            large_bin = bins_remain_cap[feasible_bins] > item*2 #Must be at least twice the size.\n            priorities[feasible_bins][large_bin] += small_item_reward\n\n    else:\n        priorities[:] = -np.inf  # No feasible bins\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 7.558835261268444,
    "exec_success": true
  }
]