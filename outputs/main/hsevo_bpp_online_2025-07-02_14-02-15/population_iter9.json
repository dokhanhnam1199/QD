[
  {
    "stdout_filepath": "problem_iter8_response0.txt_stdout.txt",
    "code_path": "problem_iter8_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, stochasticity, fragmentation penalty, and bin fill.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Best-fit prioritization\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n\n        # Stochasticity (reduced with more feasible bins)\n        num_feasible = np.sum(feasible_bins)\n        stochasticity_factor = 0.1 / (num_feasible + 1e-6)\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_factor\n\n        # Fragmentation penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05\n        priorities[feasible_bins][almost_full] *= 0.3\n\n        # Reward significantly filled bins\n        fill_ratio = (bins_remain_cap[feasible_bins] - waste) / bins_remain_cap[feasible_bins]\n        significantly_filled = fill_ratio > 0.5\n        priorities[feasible_bins][significantly_filled] += 0.2\n\n        # Large item reward if sufficient capacity exists\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 2, 0.25, 0)\n        priorities[feasible_bins] += large_cap_reward\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 2.3534104507379476,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response1.txt_stdout.txt",
    "code_path": "problem_iter8_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, stochasticity, sweet spot utilization, large item reward.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit)\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Add stochasticity, scaled by remaining capacity\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1 * (bins_remain_cap[feasible_bins]/np.max(bins_remain_cap))\n\n        # Penalize almost full bins to prevent fragmentation\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.5\n\n        # Large item high reward\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*2,0.5,0)\n        priorities[feasible_bins] += large_cap_reward\n        \n        # Incentivize bins in a \"sweet spot\" of utilization\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1  # Assuming bin size is 1\n        sweet_spot = (utilization > 0.5) & (utilization < 0.75)\n        priorities[feasible_bins][sweet_spot] += 0.3\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 83.45632229756681,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response2.txt_stdout.txt",
    "code_path": "problem_iter8_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, penalizes fragmentation, and rewards large items.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit)\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Add stochasticity (exploration) - scale with item size\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1 * item\n\n        # Penalize almost full bins to prevent fragmentation\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.5 # Reduce priority of almost full bins\n\n        # Reward filling bins significantly but not completely\n        significant_fill = (item / bins_remain_cap[feasible_bins]) > 0.7\n        priorities[feasible_bins][significant_fill] += 0.2\n\n        #Large item high reward - filling up space and avoiding future placement issues.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*2,0.25,0) #incentivise large bins if enough capacity exists.\n        priorities[feasible_bins] += large_cap_reward\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 7.728360590347029,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response3.txt_stdout.txt",
    "code_path": "problem_iter8_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best fit, reduces fragmentation, adds exploration, utilization bonus.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        priorities[feasible_bins] = np.exp(-5 * (waste / item))  # Prioritize smaller waste\n\n        # Fragmentation penalty\n        fragment_threshold_low = 0.1\n        fragment_threshold_high = 0.25\n        fragment_mask = (bins_remain_cap[feasible_bins] - item > fragment_threshold_low) & (bins_remain_cap[feasible_bins] - item < fragment_threshold_high)\n        priorities[feasible_bins][fragment_mask] -= 0.5\n\n        # Utilization bonus: Reward bins that become nearly full after packing\n        post_fill_ratio = (bins_remain_cap[feasible_bins] - item) / bins_remain_cap[feasible_bins]\n        nearly_full_mask = post_fill_ratio < 0.1\n        priorities[feasible_bins][nearly_full_mask] += 0.3  # Give a utilization bonus\n\n        # Stochasticity, scaled to remaining capacity\n        priorities += np.random.rand(len(bins_remain_cap)) * 0.01 * (bins_remain_cap.mean() / (bins_remain_cap.std()+1e-6)) #scale by mean/std\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.168328679696844,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response4.txt_stdout.txt",
    "code_path": "problem_iter8_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, and dynamic fragmentation penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Best-fit prioritization\n        priorities[feasible_bins] = 10 / (waste + 0.0001)\n\n        # Stochasticity for exploration\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.05\n\n        # Dynamic fragmentation penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.5  # Aggressive penalty\n\n        # Reward for bins that will be well-filled\n        fill_ratio = (bins_remain_cap[feasible_bins] - waste) / bins_remain_cap[feasible_bins]\n        priorities[feasible_bins] *= (1 + fill_ratio * 0.2)\n\n        small_remaining = bins_remain_cap[feasible_bins] - item < 0.1\n        priorities[feasible_bins][small_remaining] = -np.inf\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.01874750698045,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response5.txt_stdout.txt",
    "code_path": "problem_iter8_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins: best-fit, stochasticity, fragmentation penalty, utilization sweet spot.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fit_mask = bins_remain_cap >= item\n\n    if not np.any(fit_mask):\n        return priorities - np.inf\n\n    waste = bins_remain_cap[fit_mask] - item\n    priorities[fit_mask] = 1.0 / (waste + 0.0001)\n\n    wasted_space_ratio = waste / bins_remain_cap[fit_mask]\n    nearly_full = wasted_space_ratio < 0.1\n    priorities[fit_mask][nearly_full] += 0.5 # reward near full bins\n\n    # Stochasticity\n    exploration_factor = 0.01\n    priorities[fit_mask] += np.random.rand(np.sum(fit_mask)) * exploration_factor\n\n    # Fragmentation Penalty\n    fragmentation_threshold = item * 0.2\n    fragmentation_penalty = np.where(waste < fragmentation_threshold, -0.3, 0) # reduce penalty\n    priorities[fit_mask] += fragmentation_penalty\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.527323494216204,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response6.txt_stdout.txt",
    "code_path": "problem_iter8_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adaptive stochasticity, fragmentation penalty, bin fill, and large item reward.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Best-fit: Stronger, but capped.\n        priorities[feasible_bins] = np.minimum(10 / (waste + 0.0001), 50) # Capped inverse waste\n\n        # Adaptive stochasticity: Fewer feasible bins, more exploration.\n        num_feasible = np.sum(feasible_bins)\n        stochasticity_factor = 0.1 / (num_feasible + 0.1)  #Smoother and better bounds.\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_factor\n\n        # Fragmentation penalty: Moderate, based on waste ratio.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.4  # Moderate fragmentation penalty\n\n        # Filling bins well: Reward optimal fill.\n        fill_ratio = item / bins_remain_cap[feasible_bins]\n        good_fill = (fill_ratio > 0.7) & (fill_ratio <= 1.0)\n        priorities[feasible_bins][good_fill] += 0.5 # Moderate reward\n\n        # Large item reward if bin has sufficient capacity.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 1.25, 0.25, 0) #Slightly less restrictive\n        priorities[feasible_bins] += large_cap_reward\n\n         #Moderate penalty if item fills bin above a certain threshold.\n        overfill_penalty = np.where(fill_ratio>1, -1,0)\n        priorities[feasible_bins]+= overfill_penalty\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.058635819704831,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response7.txt_stdout.txt",
    "code_path": "problem_iter8_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, encourages fullness, and penalizes fragmentation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Best-Fit Prioritization (Minimize Waste)\n    fit_mask = bins_remain_cap >= item\n    if np.any(fit_mask):\n        waste = bins_remain_cap[fit_mask] - item\n        relative_waste = waste / (item + 0.0001)\n        priorities[fit_mask] += np.exp(-5 * relative_waste)\n\n    # 2. Encourage Fuller Bins\n    bin_fullness = bins_remain_cap / (np.max(bins_remain_cap) + 0.0001)\n    priorities += np.power(1 - bin_fullness, 3)\n\n    # 3. Fragmentation Penalty\n    fragment_threshold_low = 0.1\n    fragment_threshold_high = 0.25\n    fragment_mask = (bins_remain_cap - item > fragment_threshold_low) & (bins_remain_cap - item < fragment_threshold_high)\n    priorities[fragment_mask] -= 0.5\n\n    # 4. Stochastic Exploration\n    priorities += np.random.rand(len(bins_remain_cap)) * 0.01\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response8.txt_stdout.txt",
    "code_path": "problem_iter8_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fragmentation penalty, and fill ratio reward.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fit_mask = bins_remain_cap >= item\n    \n    if not np.any(fit_mask):\n        return priorities - np.inf\n    \n    waste = bins_remain_cap[fit_mask] - item\n    \n    # Best-fit prioritization\n    priorities[fit_mask] = 1.0 / (waste + 0.0001)\n    \n    # Fragmentation penalty\n    wasted_space_ratio = waste / bins_remain_cap[fit_mask]\n    nearly_full = wasted_space_ratio < 0.1\n    priorities[fit_mask][nearly_full] -= 0.5\n    \n    # Fill ratio reward\n    fill_ratio = item / bins_remain_cap[fit_mask]\n    good_fill = (fill_ratio > 0.7) & (fill_ratio <= 1.0)\n    priorities[fit_mask][good_fill] += 0.5\n    \n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response9.txt_stdout.txt",
    "code_path": "problem_iter8_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid heuristic: Best-fit, stochasticity, fragmentation penalty, utilization sweet spot, and adaptive rewards.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Best-fit prioritization (stronger)\n        priorities[feasible_bins] = 10 / (waste + 0.0001)\n\n        # Adaptive stochasticity (reduce exploration as bins fill)\n        exploration_factor = max(0.01, 0.1 * np.mean(bins_remain_cap)) # Dynamic range\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * exploration_factor\n\n        # Fragmentation penalty (tuned threshold and penalty)\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.2 # Strong penalty\n\n        # Large capacity reward (adaptive threshold)\n        large_cap_threshold = item * 1.25 # Adjusted threshold\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > large_cap_threshold, 0.5, 0)\n        priorities[feasible_bins] += large_cap_reward\n        \n        # Sweet spot utilization (encourage fuller bins)\n        utilization = (bins_remain_cap[feasible_bins] - waste) # Estimate utilization after placement.\n        utilization /= 1 # Assuming bin size is 1\n        sweet_spot = (utilization > 0.6) & (utilization < 0.8)\n        priorities[feasible_bins][sweet_spot] += 0.3\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 2.253689668927018,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response0.txt_stdout.txt",
    "code_path": "problem_iter9_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive penalties and dynamic exploration.\n    Emphasizes a balance between bin utilization and preventing extreme fragmentation,\n    adjusting strategies based on item size and bin availability.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Core: Prioritize best fit (minimize waste).  Slightly more aggressive than v1\n        priorities[feasible_bins] = 1 / (waste + 0.00001)  # Tiny constant to avoid division by zero\n\n        # Adaptive Stochasticity:  More exploration when bins are plentiful.\n        num_feasible = np.sum(feasible_bins)\n        exploration_factor = min(0.2, 0.02 * num_feasible)  # Caps at 0.2\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Fragmentation Penalty:  Stronger and more nuanced. Target almost-full bins.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05 #More aggressive\n        priorities[feasible_bins][almost_full] *= 0.2  # Significant penalty for using almost-full bins.\n\n        # Rewarding larger bins for smaller items\n        small_item_large_bin_reward = np.where(bins_remain_cap[feasible_bins] > 1.5 * item, 0.4, 0) #incentivise larger bins if item is small and capcity exists. Changed condition.\n        priorities[feasible_bins] += small_item_large_bin_reward\n\n        # Dynamic \"Sweet Spot\" Incentive: Adapt the range based on item size.\n        # Aim is to encourage utilization in a range that avoids both extreme fragmentation\n        # and under-utilization.  Smaller items should aim for higher utilization.\n        sweet_spot_lower = 0.6 - (item * 0.2) #Dynamic Lower Bound - lower bound decreases as item sizes increase. \n        sweet_spot_upper = 0.8 - (item * 0.1) #Dynamic Upper Bound - upper bound decreases as item sizes increase, less aggressively.\n\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0  # Assuming bin size is 1\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.4 #Increased the reward.\n\n    else:\n        priorities[:] = -np.inf  # No feasible bins\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 1.0769844435580445,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response1.txt_stdout.txt",
    "code_path": "problem_iter9_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, manages fragmentation, and adapts to item size.\n    It uses a more refined penalty for almost-full bins and introduces a bonus\n    for filling bins close to a target utilization. Also dynamically adjusts\n    stochasticity based on the number of feasible bins.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit), with a small offset\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n\n        # Dynamic Stochasticity: Reduce randomness when fewer choices exist.\n        num_feasible = np.sum(feasible_bins)\n        stochasticity_factor = min(0.2, 1 / (num_feasible + 1))  # Scale stochasticity\n        priorities[feasible_bins] += np.random.rand(num_feasible) * stochasticity_factor\n\n        # Refined Fragmentation Penalty: More gradual and tunable.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.15 #Increased threshold\n        penalty_factor = 0.5 # Tune this penalty factor\n        priorities[feasible_bins][almost_full] *= penalty_factor\n\n        # Target Utilization Bonus: Incentivize bins nearing a specific utilization.\n        # Dynamically calculate a target based on remaining capacity\n        target_utilization = 0.7  # Adjustable parameter. Aim for roughly 70% fill rate.\n\n        post_fill_utilization = (bins_remain_cap[feasible_bins] - waste) / 1 # Assuming bin size is 1\n\n        utilization_diff = np.abs(post_fill_utilization - target_utilization)\n        utilization_bonus = np.exp(-utilization_diff * 5) * 0.2  # Gaussian-like bonus, tune width via multiplier\n        priorities[feasible_bins] += utilization_bonus\n        \n        #Large item incentive : Encourage to use almost full bins\n        almost_full_item = wasted_space_ratio < 0.25\n        large_item_bonus = np.where((item>0.6)&almost_full_item, 0.4,0)\n        priorities[feasible_bins] += large_item_bonus\n\n\n    else:\n        priorities[:] = -np.inf  # Mark infeasible bins with negative infinity\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response2.txt_stdout.txt",
    "code_path": "problem_iter9_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, and penalizes fragmentation.\n    Also considers bin utilization and provides incentives for specific capacity ranges.\n    This version focuses on simplicity, clear parameters, and problem-adaptive behavior.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Prioritize based on inverse waste (best fit), adding a small constant for stability\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n\n        # Add stochasticity (exploration) - but less aggressively and only when needed\n        if np.random.rand() < 0.2:  #Reduced stochasticity\n            priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.05\n\n        # Penalize almost full bins to prevent fragmentation, more controlled penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.7  # Reduced penalty\n\n        # Reward for placing large items in bins with sufficient capacity, tweaked threshold\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 1.5, 0.2, 0)\n        priorities[feasible_bins] += large_cap_reward\n\n        # Incentivize bins in a \"sweet spot\" of utilization. Adjusted range and incentive\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0 #Assuming bin size is 1\n        sweet_spot = (utilization > 0.6) & (utilization < 0.8)\n        priorities[feasible_bins][sweet_spot] += 0.2  # Reduced sweet spot bonus\n\n        # Dynamically adjust best-fit priority based on item size\n        # Larger items get a slightly stronger preference for best fit.\n        priorities[feasible_bins] *= (1 + 0.1 * item) #Up to 10% best fit increase based on item size\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 1.685281212604716,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response3.txt_stdout.txt",
    "code_path": "problem_iter9_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds moderate stochasticity, actively manages fragmentation,\n    dynamically adjusts based on item size, and encourages balanced bin utilization.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit), with a slight smoothing factor\n        priorities[feasible_bins] = 1 / (waste + 0.001)\n        \n        # Moderate stochasticity for exploration, scaled by item size.  Smaller items get more stochasticity.\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * (0.05 / (item + 0.1))\n\n        # Aggressively penalize almost full bins to combat fragmentation, relative to item size.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < (0.1 + 0.05*item) #Dynamic threshold based on item size\n        priorities[feasible_bins][almost_full] *= 0.2  # Further reduce priority of almost full bins\n\n        # Reward filling up larger bins, but only if the item is reasonably large. This mitigates issues of tiny items over-filling large bins\n        if item > 0.2:\n            large_cap_reward = np.where(bins_remain_cap[feasible_bins] > (1 - item)*0.8, 0.4, 0)\n            priorities[feasible_bins] += large_cap_reward\n        \n        # Incentivize bins towards a target utilization range, adjusted dynamically\n        target_utilization_low = 0.6 - 0.1 * item  # Target lower for larger items\n        target_utilization_high = 0.8 - 0.05*item #Target higher for smaller items.\n        \n        utilization = (bins_remain_cap[feasible_bins] - waste) \n        utilization /= 1.0 #Assuming bin size is 1\n        sweet_spot = (utilization >= target_utilization_low) & (utilization <= target_utilization_high)\n        priorities[feasible_bins][sweet_spot] += 0.3  # Give a boost to bins in the sweet spot.\n\n        # Small Items to empty bins:\n        empty_ish = bins_remain_cap[feasible_bins] > 0.9\n        if item < 0.1:\n             priorities[feasible_bins][empty_ish] += 0.2\n\n    else:\n        priorities[:] = -np.inf # Assign negative infinity priority to infeasible bins\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response4.txt_stdout.txt",
    "code_path": "problem_iter9_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, and penalizes fragmentation.\n    Also considers bin utilization and provides incentives for specific capacity ranges.\n    This version focuses on a more robust best-fit, dynamic penalty for almost full bins,\n    and adaptive incentives for larger bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit) - stronger emphasis\n        priorities[feasible_bins] = 10 / (waste + 0.0001)  # Scale up the impact of best-fit\n\n        # Add stochasticity (exploration) - reduced and adaptive\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.05 #reduce exploration to exploit near best-fit solutions\n\n        # Penalize almost full bins dynamically based on item size - stronger penalty for larger items\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        \n        # Adaptive penalty. Larger items increase the need for efficient bin usage.\n        penalty_factor = 0.2 + item * 0.6  # Increased magnitude\n        priorities[feasible_bins][almost_full] *= (1 - penalty_factor)  # Stronger penalty for almost full bins\n\n        # Dynamically incentivize larger bins, especially if item is large\n        large_cap_threshold = item * (1.2 + item * 0.4) #The more space taken, the more important\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > large_cap_threshold, 0.4 + item * 0.3, 0) # Adjust reward dynamically\n        priorities[feasible_bins] += large_cap_reward\n        \n        # Incentivize bins in a \"sweet spot\" of utilization to encourage more full bins - Adjust range\n        utilization = (bins_remain_cap[feasible_bins] - waste) / (1 - waste) # Assuming bin size is 1\n        sweet_spot = (utilization > 0.6) & (utilization < 0.85) # narrower range\n        priorities[feasible_bins][sweet_spot] += 0.2 # Reduce sweet spot influence\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.058635819704831,
    "exec_success": true
  }
]