{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive penalties and dynamic exploration.\n    Emphasizes a balance between bin utilization and preventing extreme fragmentation,\n    adjusting strategies based on item size and bin availability.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Core: Prioritize best fit (minimize waste).  Slightly more aggressive than v1\n        priorities[feasible_bins] = 1 / (waste + 0.00001)  # Tiny constant to avoid division by zero\n\n        # Adaptive Stochasticity:  More exploration when bins are plentiful.\n        num_feasible = np.sum(feasible_bins)\n        exploration_factor = min(0.2, 0.02 * num_feasible)  # Caps at 0.2\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Fragmentation Penalty:  Stronger and more nuanced. Target almost-full bins.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05 #More aggressive\n        priorities[feasible_bins][almost_full] *= 0.2  # Significant penalty for using almost-full bins.\n\n        # Rewarding larger bins for smaller items\n        small_item_large_bin_reward = np.where(bins_remain_cap[feasible_bins] > 1.5 * item, 0.4, 0) #incentivise larger bins if item is small and capcity exists. Changed condition.\n        priorities[feasible_bins] += small_item_large_bin_reward\n\n        # Dynamic \"Sweet Spot\" Incentive: Adapt the range based on item size.\n        # Aim is to encourage utilization in a range that avoids both extreme fragmentation\n        # and under-utilization.  Smaller items should aim for higher utilization.\n        sweet_spot_lower = 0.6 - (item * 0.2) #Dynamic Lower Bound - lower bound decreases as item sizes increase. \n        sweet_spot_upper = 0.8 - (item * 0.1) #Dynamic Upper Bound - upper bound decreases as item sizes increase, less aggressively.\n\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0  # Assuming bin size is 1\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.4 #Increased the reward.\n\n    else:\n        priorities[:] = -np.inf  # No feasible bins\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive penalties and dynamic exploration.\n    Emphasizes a balance between bin utilization and preventing extreme fragmentation,\n    adjusting strategies based on item size and bin availability.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Core: Prioritize best fit (minimize waste).  Slightly more aggressive than v1\n        priorities[feasible_bins] = 1 / (waste + 0.00001)  # Tiny constant to avoid division by zero\n\n        # Adaptive Stochasticity:  More exploration when bins are plentiful.\n        num_feasible = np.sum(feasible_bins)\n        exploration_factor = min(0.2, 0.02 * num_feasible)  # Caps at 0.2\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Fragmentation Penalty:  Stronger and more nuanced. Target almost-full bins.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05 #More aggressive\n        priorities[feasible_bins][almost_full] *= 0.2  # Significant penalty for using almost-full bins.\n\n        # Rewarding larger bins for smaller items\n        small_item_large_bin_reward = np.where(bins_remain_cap[feasible_bins] > 1.5 * item, 0.4, 0) #incentivise larger bins if item is small and capcity exists. Changed condition.\n        priorities[feasible_bins] += small_item_large_bin_reward\n\n        # Dynamic \"Sweet Spot\" Incentive: Adapt the range based on item size.\n        # Aim is to encourage utilization in a range that avoids both extreme fragmentation\n        # and under-utilization.  Smaller items should aim for higher utilization.\n        sweet_spot_lower = 0.6 - (item * 0.2) #Dynamic Lower Bound - lower bound decreases as item sizes increase. \n        sweet_spot_upper = 0.8 - (item * 0.1) #Dynamic Upper Bound - upper bound decreases as item sizes increase, less aggressively.\n\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0  # Assuming bin size is 1\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.4 #Increased the reward.\n\n    else:\n        priorities[:] = -np.inf  # No feasible bins\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive penalties and dynamic exploration.\n    Emphasizes a balance between bin utilization and preventing extreme fragmentation,\n    adjusting strategies based on item size and bin availability.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Core: Prioritize best fit (minimize waste).  Slightly more aggressive than v1\n        priorities[feasible_bins] = 1 / (waste + 0.00001)  # Tiny constant to avoid division by zero\n\n        # Adaptive Stochasticity:  More exploration when bins are plentiful.\n        num_feasible = np.sum(feasible_bins)\n        exploration_factor = min(0.2, 0.02 * num_feasible)  # Caps at 0.2\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Fragmentation Penalty:  Stronger and more nuanced. Target almost-full bins.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05 #More aggressive\n        priorities[feasible_bins][almost_full] *= 0.2  # Significant penalty for using almost-full bins.\n\n        # Rewarding larger bins for smaller items\n        small_item_large_bin_reward = np.where(bins_remain_cap[feasible_bins] > 1.5 * item, 0.4, 0) #incentivise larger bins if item is small and capcity exists. Changed condition.\n        priorities[feasible_bins] += small_item_large_bin_reward\n\n        # Dynamic \"Sweet Spot\" Incentive: Adapt the range based on item size.\n        # Aim is to encourage utilization in a range that avoids both extreme fragmentation\n        # and under-utilization.  Smaller items should aim for higher utilization.\n        sweet_spot_lower = 0.6 - (item * 0.2) #Dynamic Lower Bound - lower bound decreases as item sizes increase. \n        sweet_spot_upper = 0.8 - (item * 0.1) #Dynamic Upper Bound - upper bound decreases as item sizes increase, less aggressively.\n\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0  # Assuming bin size is 1\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.4 #Increased the reward.\n\n    else:\n        priorities[:] = -np.inf  # No feasible bins\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, \n                bins_remain_cap: np.ndarray,\n                division_avoidance_constant: float = 2.2551341742466785e-05,\n                max_exploration_factor: float = 0.487205191482894,\n                exploration_multiplier: float = 0.0200176065585862,\n                almost_full_threshold: float = 0.08352896199002037,\n                almost_full_penalty: float = 0.4183253558302489,\n                large_bin_multiplier: float = 1.4347341338232666,\n                small_item_large_bin_reward_amount: float = 0.45906047244029347,\n                sweet_spot_lower_base: float = 0.5971232692210259,\n                sweet_spot_lower_item_scaling: float = 0.1252803503937176,\n                sweet_spot_upper_base: float = 0.7712661392055856,\n                sweet_spot_upper_item_scaling: float = 0.06253139411723733,\n                sweet_spot_reward: float = 0.5259025154379071,\n                bin_size_assumption: float = 1.193925122471392) -> np.ndarray:\n    \"\"\"Prioritizes best-fit with adaptive penalties and dynamic exploration.\n    Emphasizes a balance between bin utilization and preventing extreme fragmentation,\n    adjusting strategies based on item size and bin availability.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Core: Prioritize best fit (minimize waste).  Slightly more aggressive than v1\n        priorities[feasible_bins] = 1 / (waste + division_avoidance_constant)  # Tiny constant to avoid division by zero\n\n        # Adaptive Stochasticity:  More exploration when bins are plentiful.\n        num_feasible = np.sum(feasible_bins)\n        exploration_factor = min(max_exploration_factor, exploration_multiplier * num_feasible)  # Caps at 0.2\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Fragmentation Penalty:  Stronger and more nuanced. Target almost-full bins.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < almost_full_threshold #More aggressive\n        priorities[feasible_bins][almost_full] *= almost_full_penalty  # Significant penalty for using almost-full bins.\n\n        # Rewarding larger bins for smaller items\n        small_item_large_bin_reward = np.where(bins_remain_cap[feasible_bins] > large_bin_multiplier * item, small_item_large_bin_reward_amount, 0) #incentivise larger bins if item is small and capcity exists. Changed condition.\n        priorities[feasible_bins] += small_item_large_bin_reward\n\n        # Dynamic \"Sweet Spot\" Incentive: Adapt the range based on item size.\n        # Aim is to encourage utilization in a range that avoids both extreme fragmentation\n        # and under-utilization.  Smaller items should aim for higher utilization.\n        sweet_spot_lower = sweet_spot_lower_base - (item * sweet_spot_lower_item_scaling) #Dynamic Lower Bound - lower bound decreases as item sizes increase. \n        sweet_spot_upper = sweet_spot_upper_base - (item * sweet_spot_upper_item_scaling) #Dynamic Upper Bound - upper bound decreases as item sizes increase, less aggressively.\n\n        utilization = (bins_remain_cap[feasible_bins] - waste) / bin_size_assumption  # Assuming bin size is 1\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += sweet_spot_reward #Increased the reward.\n\n    else:\n        priorities[:] = -np.inf  # No feasible bins\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, and penalizes fragmentation.\n    Also considers bin utilization and provides incentives for specific capacity ranges.\n    This version focuses on simplicity, clear parameters, and problem-adaptive behavior.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Prioritize based on inverse waste (best fit), adding a small constant for stability\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n\n        # Add stochasticity (exploration) - but less aggressively and only when needed\n        if np.random.rand() < 0.2:  #Reduced stochasticity\n            priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.05\n\n        # Penalize almost full bins to prevent fragmentation, more controlled penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.7  # Reduced penalty\n\n        # Reward for placing large items in bins with sufficient capacity, tweaked threshold\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 1.5, 0.2, 0)\n        priorities[feasible_bins] += large_cap_reward\n\n        # Incentivize bins in a \"sweet spot\" of utilization. Adjusted range and incentive\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0 #Assuming bin size is 1\n        sweet_spot = (utilization > 0.6) & (utilization < 0.8)\n        priorities[feasible_bins][sweet_spot] += 0.2  # Reduced sweet spot bonus\n\n        # Dynamically adjust best-fit priority based on item size\n        # Larger items get a slightly stronger preference for best fit.\n        priorities[feasible_bins] *= (1 + 0.1 * item) #Up to 10% best fit increase based on item size\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, and penalizes fragmentation.\n    Also considers bin utilization and provides incentives for specific capacity ranges.\n    This version focuses on simplicity, clear parameters, and problem-adaptive behavior.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Prioritize based on inverse waste (best fit), adding a small constant for stability\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n\n        # Add stochasticity (exploration) - but less aggressively and only when needed\n        if np.random.rand() < 0.2:  #Reduced stochasticity\n            priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.05\n\n        # Penalize almost full bins to prevent fragmentation, more controlled penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.7  # Reduced penalty\n\n        # Reward for placing large items in bins with sufficient capacity, tweaked threshold\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 1.5, 0.2, 0)\n        priorities[feasible_bins] += large_cap_reward\n\n        # Incentivize bins in a \"sweet spot\" of utilization. Adjusted range and incentive\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0 #Assuming bin size is 1\n        sweet_spot = (utilization > 0.6) & (utilization < 0.8)\n        priorities[feasible_bins][sweet_spot] += 0.2  # Reduced sweet spot bonus\n\n        # Dynamically adjust best-fit priority based on item size\n        # Larger items get a slightly stronger preference for best fit.\n        priorities[feasible_bins] *= (1 + 0.1 * item) #Up to 10% best fit increase based on item size\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, and penalizes fragmentation.\n    Also considers bin utilization and provides incentives for specific capacity ranges.\n    This version focuses on simplicity, clear parameters, and problem-adaptive behavior.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Prioritize based on inverse waste (best fit), adding a small constant for stability\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n\n        # Add stochasticity (exploration) - but less aggressively and only when needed\n        if np.random.rand() < 0.2:  #Reduced stochasticity\n            priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.05\n\n        # Penalize almost full bins to prevent fragmentation, more controlled penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.7  # Reduced penalty\n\n        # Reward for placing large items in bins with sufficient capacity, tweaked threshold\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 1.5, 0.2, 0)\n        priorities[feasible_bins] += large_cap_reward\n\n        # Incentivize bins in a \"sweet spot\" of utilization. Adjusted range and incentive\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0 #Assuming bin size is 1\n        sweet_spot = (utilization > 0.6) & (utilization < 0.8)\n        priorities[feasible_bins][sweet_spot] += 0.2  # Reduced sweet spot bonus\n\n        # Dynamically adjust best-fit priority based on item size\n        # Larger items get a slightly stronger preference for best fit.\n        priorities[feasible_bins] *= (1 + 0.1 * item) #Up to 10% best fit increase based on item size\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid heuristic: Best-fit, stochasticity, fragmentation penalty, utilization sweet spot, and adaptive rewards.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Best-fit prioritization (stronger)\n        priorities[feasible_bins] = 10 / (waste + 0.0001)\n\n        # Adaptive stochasticity (reduce exploration as bins fill)\n        exploration_factor = max(0.01, 0.1 * np.mean(bins_remain_cap)) # Dynamic range\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * exploration_factor\n\n        # Fragmentation penalty (tuned threshold and penalty)\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.2 # Strong penalty\n\n        # Large capacity reward (adaptive threshold)\n        large_cap_threshold = item * 1.25 # Adjusted threshold\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > large_cap_threshold, 0.5, 0)\n        priorities[feasible_bins] += large_cap_reward\n        \n        # Sweet spot utilization (encourage fuller bins)\n        utilization = (bins_remain_cap[feasible_bins] - waste) # Estimate utilization after placement.\n        utilization /= 1 # Assuming bin size is 1\n        sweet_spot = (utilization > 0.6) & (utilization < 0.8)\n        priorities[feasible_bins][sweet_spot] += 0.3\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, stochasticity, fragmentation penalty, and bin fill.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Best-fit prioritization\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n\n        # Stochasticity (reduced with more feasible bins)\n        num_feasible = np.sum(feasible_bins)\n        stochasticity_factor = 0.1 / (num_feasible + 1e-6)\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_factor\n\n        # Fragmentation penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05\n        priorities[feasible_bins][almost_full] *= 0.3\n\n        # Reward significantly filled bins\n        fill_ratio = (bins_remain_cap[feasible_bins] - waste) / bins_remain_cap[feasible_bins]\n        significantly_filled = fill_ratio > 0.5\n        priorities[feasible_bins][significantly_filled] += 0.2\n\n        # Large item reward if sufficient capacity exists\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 2, 0.25, 0)\n        priorities[feasible_bins] += large_cap_reward\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, stochasticity, fragmentation penalty, and bin fill.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Best-fit prioritization\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n\n        # Stochasticity (reduced with more feasible bins)\n        num_feasible = np.sum(feasible_bins)\n        stochasticity_factor = 0.1 / (num_feasible + 1e-6)\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_factor\n\n        # Fragmentation penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05\n        priorities[feasible_bins][almost_full] *= 0.3\n\n        # Reward significantly filled bins\n        fill_ratio = (bins_remain_cap[feasible_bins] - waste) / bins_remain_cap[feasible_bins]\n        significantly_filled = fill_ratio > 0.5\n        priorities[feasible_bins][significantly_filled] += 0.2\n\n        # Large item reward if sufficient capacity exists\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 2, 0.25, 0)\n        priorities[feasible_bins] += large_cap_reward\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, stochasticity, fragmentation penalty, and bin fill.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Best-fit prioritization\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n\n        # Stochasticity (reduced with more feasible bins)\n        num_feasible = np.sum(feasible_bins)\n        stochasticity_factor = 0.1 / (num_feasible + 1e-6)\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_factor\n\n        # Fragmentation penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05\n        priorities[feasible_bins][almost_full] *= 0.3\n\n        # Reward significantly filled bins\n        fill_ratio = (bins_remain_cap[feasible_bins] - waste) / bins_remain_cap[feasible_bins]\n        significantly_filled = fill_ratio > 0.5\n        priorities[feasible_bins][significantly_filled] += 0.2\n\n        # Large item reward if sufficient capacity exists\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 2, 0.25, 0)\n        priorities[feasible_bins] += large_cap_reward\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, fragmentation penalty, and fill ratio reward.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fit_mask = bins_remain_cap >= item\n    \n    if not np.any(fit_mask):\n        return priorities - np.inf\n    \n    waste = bins_remain_cap[fit_mask] - item\n    \n    # Best-fit prioritization\n    priorities[fit_mask] = 1.0 / (waste + 0.0001)\n    \n    # Fragmentation penalty\n    wasted_space_ratio = waste / bins_remain_cap[fit_mask]\n    nearly_full = wasted_space_ratio < 0.1\n    priorities[fit_mask][nearly_full] -= 0.5\n    \n    # Fill ratio reward\n    fill_ratio = item / bins_remain_cap[fit_mask]\n    good_fill = (fill_ratio > 0.7) & (fill_ratio <= 1.0)\n    priorities[fit_mask][good_fill] += 0.5\n    \n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds moderate stochasticity, actively manages fragmentation,\n    dynamically adjusts based on item size, and encourages balanced bin utilization.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit), with a slight smoothing factor\n        priorities[feasible_bins] = 1 / (waste + 0.001)\n        \n        # Moderate stochasticity for exploration, scaled by item size.  Smaller items get more stochasticity.\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * (0.05 / (item + 0.1))\n\n        # Aggressively penalize almost full bins to combat fragmentation, relative to item size.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < (0.1 + 0.05*item) #Dynamic threshold based on item size\n        priorities[feasible_bins][almost_full] *= 0.2  # Further reduce priority of almost full bins\n\n        # Reward filling up larger bins, but only if the item is reasonably large. This mitigates issues of tiny items over-filling large bins\n        if item > 0.2:\n            large_cap_reward = np.where(bins_remain_cap[feasible_bins] > (1 - item)*0.8, 0.4, 0)\n            priorities[feasible_bins] += large_cap_reward\n        \n        # Incentivize bins towards a target utilization range, adjusted dynamically\n        target_utilization_low = 0.6 - 0.1 * item  # Target lower for larger items\n        target_utilization_high = 0.8 - 0.05*item #Target higher for smaller items.\n        \n        utilization = (bins_remain_cap[feasible_bins] - waste) \n        utilization /= 1.0 #Assuming bin size is 1\n        sweet_spot = (utilization >= target_utilization_low) & (utilization <= target_utilization_high)\n        priorities[feasible_bins][sweet_spot] += 0.3  # Give a boost to bins in the sweet spot.\n\n        # Small Items to empty bins:\n        empty_ish = bins_remain_cap[feasible_bins] > 0.9\n        if item < 0.1:\n             priorities[feasible_bins][empty_ish] += 0.2\n\n    else:\n        priorities[:] = -np.inf # Assign negative infinity priority to infeasible bins\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adaptive stochasticity, fragmentation penalty, bin fill, and large item reward.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Best-fit: Stronger, but capped.\n        priorities[feasible_bins] = np.minimum(10 / (waste + 0.0001), 50) # Capped inverse waste\n\n        # Adaptive stochasticity: Fewer feasible bins, more exploration.\n        num_feasible = np.sum(feasible_bins)\n        stochasticity_factor = 0.1 / (num_feasible + 0.1)  #Smoother and better bounds.\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_factor\n\n        # Fragmentation penalty: Moderate, based on waste ratio.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.4  # Moderate fragmentation penalty\n\n        # Filling bins well: Reward optimal fill.\n        fill_ratio = item / bins_remain_cap[feasible_bins]\n        good_fill = (fill_ratio > 0.7) & (fill_ratio <= 1.0)\n        priorities[feasible_bins][good_fill] += 0.5 # Moderate reward\n\n        # Large item reward if bin has sufficient capacity.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 1.25, 0.25, 0) #Slightly less restrictive\n        priorities[feasible_bins] += large_cap_reward\n\n         #Moderate penalty if item fills bin above a certain threshold.\n        overfill_penalty = np.where(fill_ratio>1, -1,0)\n        priorities[feasible_bins]+= overfill_penalty\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, and penalizes fragmentation.\n    Also considers bin utilization and provides incentives for specific capacity ranges.\n    This version focuses on a more robust best-fit, dynamic penalty for almost full bins,\n    and adaptive incentives for larger bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit) - stronger emphasis\n        priorities[feasible_bins] = 10 / (waste + 0.0001)  # Scale up the impact of best-fit\n\n        # Add stochasticity (exploration) - reduced and adaptive\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.05 #reduce exploration to exploit near best-fit solutions\n\n        # Penalize almost full bins dynamically based on item size - stronger penalty for larger items\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        \n        # Adaptive penalty. Larger items increase the need for efficient bin usage.\n        penalty_factor = 0.2 + item * 0.6  # Increased magnitude\n        priorities[feasible_bins][almost_full] *= (1 - penalty_factor)  # Stronger penalty for almost full bins\n\n        # Dynamically incentivize larger bins, especially if item is large\n        large_cap_threshold = item * (1.2 + item * 0.4) #The more space taken, the more important\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > large_cap_threshold, 0.4 + item * 0.3, 0) # Adjust reward dynamically\n        priorities[feasible_bins] += large_cap_reward\n        \n        # Incentivize bins in a \"sweet spot\" of utilization to encourage more full bins - Adjust range\n        utilization = (bins_remain_cap[feasible_bins] - waste) / (1 - waste) # Assuming bin size is 1\n        sweet_spot = (utilization > 0.6) & (utilization < 0.85) # narrower range\n        priorities[feasible_bins][sweet_spot] += 0.2 # Reduce sweet spot influence\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adaptive stochasticity, fragmentation penalty, bin fill, and large item reward.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Best-fit: Stronger, but capped.\n        priorities[feasible_bins] = np.minimum(10 / (waste + 0.0001), 50) # Capped inverse waste\n\n        # Adaptive stochasticity: Fewer feasible bins, more exploration.\n        num_feasible = np.sum(feasible_bins)\n        stochasticity_factor = 0.1 / (num_feasible + 0.1)  #Smoother and better bounds.\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_factor\n\n        # Fragmentation penalty: Moderate, based on waste ratio.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.4  # Moderate fragmentation penalty\n\n        # Filling bins well: Reward optimal fill.\n        fill_ratio = item / bins_remain_cap[feasible_bins]\n        good_fill = (fill_ratio > 0.7) & (fill_ratio <= 1.0)\n        priorities[feasible_bins][good_fill] += 0.5 # Moderate reward\n\n        # Large item reward if bin has sufficient capacity.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 1.25, 0.25, 0) #Slightly less restrictive\n        priorities[feasible_bins] += large_cap_reward\n\n         #Moderate penalty if item fills bin above a certain threshold.\n        overfill_penalty = np.where(fill_ratio>1, -1,0)\n        priorities[feasible_bins]+= overfill_penalty\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, penalizes fragmentation, and rewards large items.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit)\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Add stochasticity (exploration) - scale with item size\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1 * item\n\n        # Penalize almost full bins to prevent fragmentation\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.5 # Reduce priority of almost full bins\n\n        # Reward filling bins significantly but not completely\n        significant_fill = (item / bins_remain_cap[feasible_bins]) > 0.7\n        priorities[feasible_bins][significant_fill] += 0.2\n\n        #Large item high reward - filling up space and avoiding future placement issues.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*2,0.25,0) #incentivise large bins if enough capacity exists.\n        priorities[feasible_bins] += large_cap_reward\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, penalizes fragmentation, and rewards large items.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit)\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Add stochasticity (exploration) - scale with item size\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1 * item\n\n        # Penalize almost full bins to prevent fragmentation\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.5 # Reduce priority of almost full bins\n\n        # Reward filling bins significantly but not completely\n        significant_fill = (item / bins_remain_cap[feasible_bins]) > 0.7\n        priorities[feasible_bins][significant_fill] += 0.2\n\n        #Large item high reward - filling up space and avoiding future placement issues.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*2,0.25,0) #incentivise large bins if enough capacity exists.\n        priorities[feasible_bins] += large_cap_reward\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, stochasticity, sweet spot utilization, large item reward.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit)\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Add stochasticity, scaled by remaining capacity\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1 * (bins_remain_cap[feasible_bins]/np.max(bins_remain_cap))\n\n        # Penalize almost full bins to prevent fragmentation\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.5\n\n        # Large item high reward\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*2,0.5,0)\n        priorities[feasible_bins] += large_cap_reward\n        \n        # Incentivize bins in a \"sweet spot\" of utilization\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1  # Assuming bin size is 1\n        sweet_spot = (utilization > 0.5) & (utilization < 0.75)\n        priorities[feasible_bins][sweet_spot] += 0.3\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, stochasticity, sweet spot utilization, large item reward.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit)\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Add stochasticity, scaled by remaining capacity\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1 * (bins_remain_cap[feasible_bins]/np.max(bins_remain_cap))\n\n        # Penalize almost full bins to prevent fragmentation\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.5\n\n        # Large item high reward\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*2,0.5,0)\n        priorities[feasible_bins] += large_cap_reward\n        \n        # Incentivize bins in a \"sweet spot\" of utilization\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1  # Assuming bin size is 1\n        sweet_spot = (utilization > 0.5) & (utilization < 0.75)\n        priorities[feasible_bins][sweet_spot] += 0.3\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}