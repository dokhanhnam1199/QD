{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes best-fit with adaptive penalties and dynamic exploration.\n    Emphasizes a balance between bin utilization and preventing extreme fragmentation,\n    adjusting strategies based on item size and bin availability. Includes bin history.\n    V2: Simplifies and focuses on core components with refined parameters.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Core: Prioritize best fit (minimize waste).  Slightly more aggressive.\n        tiny_constant = 1e-06  #Keep it very small\n        priorities[feasible_bins] = 1 / (waste + tiny_constant)\n\n        # Adaptive Stochasticity: Exploration based on remaining capacity and item size.\n        num_feasible = np.sum(feasible_bins)\n        exploration_base = 0.05\n        max_exploration = 0.2\n        exploration_factor = min(max_exploration, exploration_base * (1- bins_remain_cap[feasible_bins].mean()) * item ) #Exploration scales with item size and how full the bins are.\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Fragmentation Penalty: Target almost-full bins, tuned threshold and penalty\n        almost_full_threshold = 0.1  #Slightly higher threshold.\n        almost_full_penalty = 0.2 #Increase the penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < almost_full_threshold\n        priorities[feasible_bins][almost_full] *= (1-almost_full_penalty)  # Apply Penalty\n\n        # Rewarding larger bins for smaller items - adjusted parameters\n        small_item_bin_multiple = 1.5 #Slightly less restrictive\n        small_item_reward = 0.5 #Reduce reward\n        small_item_large_bin_reward = np.where(bins_remain_cap[feasible_bins] > small_item_bin_multiple * item, small_item_reward, 0)\n        priorities[feasible_bins] += small_item_large_bin_reward\n\n        # Dynamic \"Sweet Spot\" Incentive: Simplified and more focused.\n        sweet_spot_lower_base = 0.6\n        sweet_spot_upper_base = 0.9\n        sweet_spot_reward = 0.3\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0  # Assuming bin size is 1\n        sweet_spot = (utilization > sweet_spot_lower_base) & (utilization < sweet_spot_upper_base)\n        priorities[feasible_bins][sweet_spot] += sweet_spot_reward\n\n        # Bin History:  Simplified penalty.\n        try:\n            bin_usage_history\n            usage_penalty_factor = 0.1 # Moderate penalty.\n            usage_penalty = bin_usage_history[feasible_bins] * usage_penalty_factor\n            priorities[feasible_bins] -= usage_penalty\n        except NameError:\n            pass\n\n    else:\n        priorities[:] = -np.inf  # No feasible bins\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes best-fit, adaptive exploration, and dynamic sweet spot.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Best-fit prioritization\n        priorities[feasible_bins] = 1 / (waste + 0.00001)\n\n        # Adaptive Exploration\n        num_feasible = np.sum(feasible_bins)\n        exploration_factor = min(0.2, 0.05 * num_feasible * (1 - item))\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Dynamic Sweet Spot Incentive\n        sweet_spot_lower = 0.6 - (item * 0.2)\n        sweet_spot_upper = 0.9 - (item * 0.1)\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.5\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the 1st has a much more complex and adaptive system for exploration, fragmentation penalty, and sweet spot incentive, including parameter tuning and bin history, while the 20th uses simpler, static calculations.\nComparing (2nd best) vs (second worst), we see 2nd has the bin history, while 19th focuses on the core components, best-fit, adaptive exploration, and a dynamic sweet spot.\nComparing (1st) vs (2nd), we see the difference is the presence of explicit default argument values and imports of unnecessary libraries like `math`, `scipy`, and `torch` in the 2nd, which do not affect the logic.\nComparing (3rd) vs (4th), we see that the 3rd uses dynamic sweet spot incentive ranges and includes a reward for larger bins based on item size while the 4th uses a fixed sweet spot range and rewards small items in large bins. The 4th also attempts bin history but may fail because bin_usage_history may not exist.\nComparing (second worst) vs (worst), we see that the 19th incorporates a dynamic sweet spot and item-dependent exploration, while the 20th has a simpler exploration factor and sweet spot calculation. Overall: The better heuristics are characterized by more sophisticated adaptive strategies, parameter tuning, and consideration of bin history (when available), whereas the poorer ones rely on simplified static calculations and lack item-specific adjustments.\n- \nHere's a refined perspective on self-reflection for heuristic design, aiming for effective strategies:\n\n*   **Keywords:** Adaptive, Empirical, Incremental, Balance.\n\n*   **Advice:** Focus on simple, adaptive components first. Validate each addition empirically before further complexity.\n\n*   **Avoid:** Over-parameterization, premature optimization, and complex, non-linear combinations of factors without clear justification.\n\n*   **Explanation:** Start with a baseline heuristic, then add adaptive elements iteratively, ensuring each addition demonstrably improves performance through rigorous testing. Prioritize understandability and maintainability.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}