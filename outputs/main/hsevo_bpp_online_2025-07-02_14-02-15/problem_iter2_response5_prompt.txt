{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Higher value means higher priority.\n\n    This version prioritizes bins that can accommodate the item\n    with minimal remaining space, but also penalizes bins that are\n    too full (close to full capacity after placing the item) as well\n    as nearly empty bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Filter out bins that cannot accommodate the item\n    valid_bins = bins_remain_cap >= item\n    \n    if not np.any(valid_bins):\n        # If no bin can accommodate the item, assign a small, negative priority\n        # to all bins to represent that none of them are suitable. This forces the creation\n        # of a new bin by a higher level strategy\n        return np.full_like(bins_remain_cap, -1.0)\n\n    # Calculate remaining space after placing the item\n    remaining_space = bins_remain_cap - item\n\n    # Calculate utilization after placing the item (relative to original capacity, assumed to be 1)\n    utilization = 1 - remaining_space\n    \n    # Calculate score for the valid bins. \n    # A higher score suggests a better fit\n\n    # Score based on how tightly the item fits. Bins with low remaining space get a boost.\n    tightness_score = np.exp(-5 * remaining_space) #Exponentially favors small remaining spaces\n    #Avoid division by zero. When remaining_space is zero it becomes Inf so clip the max.\n    tightness_score = np.clip(tightness_score, a_min = 0, a_max = 1e5)\n        \n    # Score based on the utilization. Slightly prefer not filling the bin too much.\n    utilization_score = np.exp(-2 * (utilization - 0.75)**2) # prefer near 0.75 fill\n\n    #Combine both scores\n    priorities[valid_bins] = tightness_score[valid_bins] * utilization_score[valid_bins]\n    \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n    Inspired by the concept of spacetime curvature in General Relativity,\n    we consider both the remaining capacity and the relative size of the item\n    to the remaining capacity, but with a non-linear, gravity-inspired approach.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Avoid division by zero by adding a small epsilon\n    epsilon = 1e-9\n    \n    # Calculate the \"gravitational potential\" based on remaining capacity.\n    # Larger capacity means weaker \"gravity\", thus lower potential.\n    potential = -bins_remain_cap\n\n    # Calculate the \"gravitational force\" exerted by the item on each bin.\n    # A larger item exerts a stronger \"force\", especially on smaller bins.\n    # Using the inverse square law (approximated) with exponential scaling\n    # to create a highly non-linear relationship and emphasize bins\n    # that are a slightly better fit. We scale by the bin capacity to give a smaller\n    # penalty to large bins.\n    \n    force = (item / (bins_remain_cap + epsilon)**2) * np.exp(-(item-bins_remain_cap)/item)\n\n    # Combine potential and force to get the priority. Bins with a\n    # higher combined potential (lower absolute negative value) and a stronger force\n    # (item fits well) are prioritized. Subtract force from the potential.\n    # Clipping to avoid any numerical issues due to small remaining cap.\n    bins_remain_cap_clipped = np.clip(bins_remain_cap, a_min=epsilon, a_max=None)\n    \n    \n    priority = (bins_remain_cap_clipped - item)* np.exp(-np.abs(bins_remain_cap_clipped-item)/(item+epsilon)) \n    #We try prioritizing the bins, where residual_cap is closer to the item size\n    # and the remaining capacity is close to the item size. This encourages bins to not have\n    # extremely small or extremely large residual capacities.\n    #Another term to slightly discourage bins that don't fit.\n    #force = force - (item - bins_remain_cap)*(item > bins_remain_cap)\n\n    return priority\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the best heuristic uses a potential energy well inspired approach combined with quantum tunneling for exploration, while the worst uses a simple waste-based priority combined with a fill level preference. The best approach balances near-perfect fits, waste penalization, and stochastic exploration. The worst uses a combination of waste priority and fill level preference.\n\nComparing (2nd) vs (19th), we see the 2nd best heuristic uses the concept of alternating currents, prioritizes near-perfect fits, discourages capacity wastage, and pushes bins closer to full when near maximum capacity, whereas the 19th one gives high priority to bins that can fit the item well without excessive space left, also prioritizes bins where remaining space is close to mean and penalizing either too small or too large remaining space. The better one boosts full bins; the worse one demotes when either too small/large space.\n\nComparing (3rd) vs (4th), we see that the 3rd heuristic penalizes infeasible bins with -inf, and uses a `1/waste` for valid bins, along with fill ratios. The 4th heuristic simply gives a `1/(waste + small_constant)` priority to feasible bins. The 3rd includes -inf for invalid bins which guides the search process more effectively and also bonus for bins that are already relatively full.\n\nComparing (5th) vs (6th), we see that the 5th heuristic uses `1/bins_remain_cap` for valid bins along with perfect fit bonus. It penalizes the fuller bins if no bins can fit the item (extremely low priority). The 6th heuristics computes slack (cap - item), and sets priority to  `1.0 / (slack + 0.0001) + (1 - cap)` if can fit or -1000 otherwise. 5th heuristices uses `1/bins_remain_cap[valid_bins]` and a perfect fit bonus which may be more effective.\n\nComparing (second worst) vs (worst), we see that both consider waste and fill level. However, the second worst uses numpy array operations, while the worst one uses a for loop which is slower. The second worst also uses `fill_level_priority = (1 - (new_remaining_capacity / 1.0)) ** 2` to encourage higher fill levels.\n\nOverall:\n\nThe better heuristics combine several factors: (1) prioritize bins that can fit, (2) minimize waste, (3) consider relative waste with respect to the item size and remaining capacity, (4) use non-linear functions like exp to create a potential well effect, (5) add stochastic elements to explore search space, (6) avoid excessive fragmentation by penalizing nearly full bins, (7) use numpy array operations for speed. Worse heuristics tend to use simpler linear combinations of waste and fill level, or focus too much on just minimizing waste without considering fragmentation. They may also use loops instead of array operations.\n- \nOkay, let's refine \"Current self-reflection\" to design better heuristics, keeping in mind that we want to create a useful guide and avoid ineffective points.\n\nHere's a structured redefinition:\n\n*   **Keywords:** Non-linearity, stochasticity, fragmentation penalty, relative waste, array operations, multi-factor integration.\n\n*   **Advice:** Design heuristics that integrate diverse factors through non-linear functions. Use stochastic elements for exploration while penalizing fragmented solutions. Evaluate waste relative to item size. Utilize efficient array operations for speed.\n\n*   **Avoid:** Generic statements without concrete implementation strategies; vague descriptions of \"exploration\" without specifying the stochastic method.\n\n*   **Explanation:** Effective heuristics require a blend of diverse optimization techniques. Integrating non-linear functions allows to model complex relationships. Stochasticity balances exploration and exploitation. Relative waste is a more accurate measure than absolute waste. Utilizing array operations provides for efficient computation.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}