{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\nCurrent heuristics:\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes best-fit with adaptive penalties and dynamic exploration.\n    Emphasizes a balance between bin utilization and preventing extreme fragmentation,\n    adjusting strategies based on item size and bin availability.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Core: Prioritize best fit (minimize waste).  Slightly more aggressive than v1\n        priorities[feasible_bins] = 1 / (waste + 0.00001)  # Tiny constant to avoid division by zero\n\n        # Adaptive Stochasticity:  More exploration when bins are plentiful.\n        num_feasible = np.sum(feasible_bins)\n        exploration_factor = min(0.2, 0.02 * num_feasible)  # Caps at 0.2\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Fragmentation Penalty:  Stronger and more nuanced. Target almost-full bins.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05 #More aggressive\n        priorities[feasible_bins][almost_full] *= 0.2  # Significant penalty for using almost-full bins.\n\n        # Rewarding larger bins for smaller items\n        small_item_large_bin_reward = np.where(bins_remain_cap[feasible_bins] > 1.5 * item, 0.4, 0) #incentivise larger bins if item is small and capcity exists. Changed condition.\n        priorities[feasible_bins] += small_item_large_bin_reward\n\n        # Dynamic \"Sweet Spot\" Incentive: Adapt the range based on item size.\n        # Aim is to encourage utilization in a range that avoids both extreme fragmentation\n        # and under-utilization.  Smaller items should aim for higher utilization.\n        sweet_spot_lower = 0.6 - (item * 0.2) #Dynamic Lower Bound - lower bound decreases as item sizes increase. \n        sweet_spot_upper = 0.8 - (item * 0.1) #Dynamic Upper Bound - upper bound decreases as item sizes increase, less aggressively.\n\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0  # Assuming bin size is 1\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.4 #Increased the reward.\n\n    else:\n        priorities[:] = -np.inf  # No feasible bins\n\n    return priorities\n\nNow, think outside the box write a mutated function `priority_v2` better than current version.\nYou can use some hints below:\n- \nOkay, let's refine \"Current self-reflection\" to design better heuristics, while explicitly avoiding the pitfalls of \"Ineffective self-reflection.\"\n\nHere's a revised perspective on self-reflection to guide heuristic design:\n\n*   **Keywords:** Adaptive, Dynamic, Problem-Aware, Empirical Tuning, Balanced, Iterative Refinement.\n*   **Advice:** Focus on a core, functional heuristic. Adapt parameters based on *observable* problem characteristics. Prioritize gradual, empirically validated refinements over complex, speculative features.\n*   **Avoid:** Blindly combining factors without understanding their interactions, adding stochasticity without a clear purpose, and over-engineering with non-linear functions before establishing a solid foundation.\n*   **Explanation:** Start simple, understand your base heuristic's performance, and then introduce targeted adaptations. The goal is controlled, explainable improvements based on data, not a black box of complex interactions.\n\n\nOutput code only and enclose your code with Python code block: ```python ... ```.\nI'm going to tip $999K for a better solution!"}