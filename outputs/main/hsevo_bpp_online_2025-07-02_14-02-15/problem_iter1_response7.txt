```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    This function prioritizes bins based on a combination of factors,
    inspired by quantum mechanics principles like probability and energy levels.

    Args:
        item: Size of item to be added to the bin.
        bins_remain_cap: Array of capacities for each bin.

    Return:
        Array of same size as bins_remain_cap with priority score of each bin.
    """

    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # 1. Suitability based on remaining capacity (Inverse Energy, larger is better)
    suitability = bins_remain_cap - item
    suitability[suitability < 0] = -np.inf  # Invalid bins get very low priority
    # scale such that if bins_remain_cap == item, we get 0
    suitability = np.exp(suitability/item) if item > 0 else np.exp(suitability)
    #2. Fill percentage relative to item size. Analogous to "wave collapse".
    # We either fit well or we don't, and this term provides a sharp preference
    # when we are near a perfect fit. (but never above capacity)
    fit_ratio = item / bins_remain_cap
    fit_term = np.exp(-np.abs(fit_ratio - 1) * 5) #Higher sharpness term.

    #3. Avoidance of near-full bins, acting as an exclusion principle,
    # preventing "overcrowding".
    near_full = (bins_remain_cap < 1.1 * item) & (bins_remain_cap > item)
    near_full_penalty = -5*near_full # Apply negative penalty.
    #if item > 0:
    #    near_full_penalty = -2*near_full/(item+0.0001)
    # else:
    #    near_full_penalty = -2*near_full

    priorities = suitability + 0.8 * fit_term + near_full_penalty #Combining with weights.
    #Prioritize larger bins. Prevents fragmenting the search space too much.
    priorities = priorities + (bins_remain_cap/np.max(bins_remain_cap)) *0.2

    return priorities
```
