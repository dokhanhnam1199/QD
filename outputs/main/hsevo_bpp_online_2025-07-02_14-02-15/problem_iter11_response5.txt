```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Combines best-fit, adaptive stochasticity, and dynamic fragmentation penalty."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if np.any(feasible_bins):
        waste = bins_remain_cap[feasible_bins] - item

        # Best-fit prioritization with small constant
        priorities[feasible_bins] = 1 / (waste + 0.0001)

        # Adaptive stochasticity based on the number of feasible bins
        num_feasible = np.sum(feasible_bins)
        stochasticity_factor = 0.1 / (num_feasible + 1e-6)  # Reduce exploration as bins fill
        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_factor

        # Dynamic fragmentation penalty based on item size
        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]
        almost_full = wasted_space_ratio < 0.05
        penalty_factor = 0.3 + 0.2 * item  # Larger items incur a stronger penalty
        priorities[feasible_bins][almost_full] *= (1- min(penalty_factor, 0.5))  # cap to 0.5

        # Reward significantly filled bins
        fill_ratio = (bins_remain_cap[feasible_bins] - waste) / bins_remain_cap[feasible_bins]
        significantly_filled = fill_ratio > 0.5
        priorities[feasible_bins][significantly_filled] += 0.2

        # Large item reward if sufficient capacity exists, dynamic threshold
        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * (1.5 + 0.5 * item), 0.25, 0) #threshold adapts to item size
        priorities[feasible_bins] += large_cap_reward

    else:
        priorities[:] = -np.inf

    return priorities
```
