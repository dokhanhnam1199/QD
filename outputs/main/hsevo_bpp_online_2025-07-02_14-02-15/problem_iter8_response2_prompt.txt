{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes best-fit, adds stochasticity, and penalizes fragmentation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit)\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Add stochasticity (exploration)\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1\n\n        #Penalize almost full bins to prevent fragmentation\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.5 # Reduce priority of almost full bins\n        \n\n        #Large item high reward - filling up space and avoiding future placement issues.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*2,0.25,0) #incentivise large bins if enough capacity exists.\n        priorities[feasible_bins] += large_cap_reward\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit with fragmentation penalty and stochasticity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize best fit\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Stochasticity for exploration\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1\n\n        # Penalize almost full bins (fragmentation)\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.5 \n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic `priority_v2` incorporates \"best-fit\" prioritization, stochasticity for exploration, fragmentation penalty, utilization sweet spot, and large item reward. The worst only considers fit score (exponential decay on relative waste), stochasticity, and fragmentation penalty.  (2nd best) vs (2nd worst) the code is similar. Comparing (1st) vs (2nd), we see the function are similar, therefore small adjustments to parameters can significantly impact performance. (3rd) vs (4th), we see that the 4th heuristic dynamically adjusts stochasticity and rewards significantly filled bins, while the 3rd one is simpler. Comparing (second worst) vs (worst), we see the codes are similar. Overall: the best heuristics incorporate more factors and adaptive parameters, while simpler heuristics focusing only on basic factors like waste tend to perform worse. The weighting of different factors, such as the strength of the fragmentation penalty or the magnitude of stochasticity, significantly impacts heuristic performance. Sweet spot and dynamic scaling of parameters are useful.\n- \nOkay, let's refine \"Current self-reflection\" to make it more actionable for designing better heuristics, avoiding the pitfalls of \"Ineffective self-reflection.\"\n\nHere's a revised approach:\n\n*   **Keywords:** Iterative refinement, empirical tuning, dynamic adaptation, balanced factors.\n*   **Advice:** Start simple, measure impact of added complexity, adjust based on problem state, and focus on performance metrics.\n*   **Avoid:** Unjustified complexity, pre-mature stochasticity, and complex non-linear functions without clear justification.\n*   **Explanation:** Build heuristics incrementally, focusing on demonstrable performance gains at each step. Prioritize clear, tunable parameters, and adaptive responses to problem characteristics.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}