```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Combines best-fit, adaptive fragmentation penalty, and dynamic sweet spot incentive."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if not np.any(feasible_bins):
        return priorities - np.inf

    waste = bins_remain_cap[feasible_bins] - item

    # Best-fit prioritization
    priorities[feasible_bins] = 1.0 / (waste + 0.0001)

    # Adaptive fragmentation penalty (stronger for larger items)
    wasted_space_ratio = waste / bins_remain_cap[feasible_bins]
    penalty_threshold = 0.1 + (item * 0.05) #Adaptive threshold
    nearly_full = wasted_space_ratio < penalty_threshold
    priorities[feasible_bins][nearly_full] -= 0.5 * (1 + item)  # Scale penalty by item size

    # Dynamic "sweet spot" incentive
    sweet_spot_lower = 0.6 - (item * 0.2)
    sweet_spot_upper = 0.8 - (item * 0.1)
    utilization = item / bins_remain_cap[feasible_bins]
    sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)
    priorities[feasible_bins][sweet_spot] += 0.5

    # Adaptive stochasticity (less exploration when fewer bins are available)
    num_feasible = np.sum(feasible_bins)
    exploration_factor = min(0.2, 0.5 / (num_feasible + 1)) # Inverse exploration
    priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor

    return priorities
```
