```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Prioritizes best-fit with dynamic sweet spot and adaptive penalty.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if np.any(feasible_bins):
        waste = bins_remain_cap[feasible_bins] - item
        priorities[feasible_bins] = 1 / (waste + 0.00001)

        # Adaptive Stochasticity: less aggressive as bins fill.
        num_feasible = np.sum(feasible_bins)
        exploration_factor = min(0.1, 0.01 * num_feasible)
        if np.random.rand() < 0.2:  # Add stochasticity only sometimes
            priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor

        # Fragmentation Penalty: Stronger when item is large.
        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]
        almost_full = wasted_space_ratio < 0.1
        penalty = 0.7 + 0.2 * item #up to 20% stronger penalty depending on item size
        priorities[feasible_bins][almost_full] *= penalty

        # Reward for large capacity
        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item * 1.5, 0.2, 0)
        priorities[feasible_bins] += large_cap_reward


        # Dynamic "Sweet Spot" Incentive: Adapt the range based on item size.
        sweet_spot_lower = 0.6 - (item * 0.1)
        sweet_spot_upper = 0.8 - (item * 0.05)

        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0
        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)
        priorities[feasible_bins][sweet_spot] += 0.2

        priorities[feasible_bins] *= (1 + 0.05 * item) #Up to 5% best fit increase based on item size

    else:
        priorities[:] = -np.inf

    return priorities
```
