[
  {
    "stdout_filepath": "problem_iter5_response0.txt_stdout.txt",
    "code_path": "problem_iter5_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines relative waste, fragmentation penalty, and stochasticity for bin packing.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. Relative Waste (First-Fit Decreasing Inspired)\n    fit_mask = bins_remain_cap >= item\n    if np.any(fit_mask):\n        waste = bins_remain_cap[fit_mask] - item\n        relative_waste = waste / (item + 0.0001)\n        priorities[fit_mask] += np.exp(-5 * relative_waste)\n\n    # 2. Fragmentation Penalty\n    fragment_threshold_low = 0.1\n    fragment_threshold_high = 0.25\n    fragment_mask = (bins_remain_cap - item > fragment_threshold_low) & (bins_remain_cap - item < fragment_threshold_high)\n    priorities[fragment_mask] -= 0.5\n\n    # 3. Stochastic Exploration\n    priorities += np.random.rand(len(bins_remain_cap)) * 0.01\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 3.839250099720782,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response1.txt_stdout.txt",
    "code_path": "problem_iter5_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid heuristic: FFD-inspired + waste penalty + perfect fit bonus.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # FFD-inspired: Prioritize bins that can fit the item with less waste\n    fit_mask = bins_remain_cap >= item\n    if np.any(fit_mask):\n        priorities[fit_mask] += 1.0 / (bins_remain_cap[fit_mask] - item + 0.0001)\n\n    # Waste penalty: Penalize bins if item fits but creates high relative waste\n    if np.any(fit_mask):\n        remaining_space = bins_remain_cap[fit_mask] - item\n        waste_ratio = remaining_space / bins_remain_cap[fit_mask]\n        priorities[fit_mask] -= waste_ratio * 0.5  # Scale to avoid overpowering other components\n\n    # Perfect fit bonus: Reward bins where the item fits almost perfectly\n    if np.any(fit_mask):\n        remaining_space = bins_remain_cap[fit_mask] - item\n        perfect_fit_bonus = np.exp(-5 * remaining_space)  # Adjusted exponent\n        priorities[fit_mask] += perfect_fit_bonus * 0.2 #scale the bonus\n\n    # Infeasible penalty\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response2.txt_stdout.txt",
    "code_path": "problem_iter5_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization and bin fullness with fragmentation penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fit_mask = bins_remain_cap >= item\n    #Prioritize fitting with minimal relative waste.\n    waste = bins_remain_cap[fit_mask] - item\n    relative_waste = waste / (item + 0.0001)\n    priorities[fit_mask] += np.exp(-5 * relative_waste)\n\n    #Incentivize fuller bins (non-linear).\n    bin_fullness = bins_remain_cap / (np.max(bins_remain_cap) + 0.0001)\n    priorities += np.power(1 - bin_fullness, 3)\n\n    #Severe penalty for bins that cannot accommodate the item.\n    fragmentation_penalty = np.where(bins_remain_cap < item, -1000, 0)\n    priorities += fragmentation_penalty\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response3.txt_stdout.txt",
    "code_path": "problem_iter5_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins based on fit, waste, and stochasticity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return priorities\n\n    # Fit Score: Prioritize bins that can fit the item. Exponential decay.\n    fit_mask = bins_remain_cap >= item\n    waste = bins_remain_cap - item\n    relative_waste = waste / (item + 1e-6)\n    priorities[fit_mask] += np.exp(-relative_waste[fit_mask])\n\n    # Stochastic Element: Introduce randomness for exploration.\n    exploration_factor = 0.01\n    priorities += np.random.rand(len(bins_remain_cap)) * exploration_factor\n\n    # Fragmentation Penalty: Penalize small gaps.\n    fragmentation_threshold = item * 0.2\n    fragmentation_penalty = np.where((waste > 0) & (waste < fragmentation_threshold), -0.5, 0)\n    priorities += fragmentation_penalty\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.826485839648992,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response4.txt_stdout.txt",
    "code_path": "problem_iter5_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization with fragmentation penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fit_mask = bins_remain_cap >= item\n    if not np.any(fit_mask):\n        return priorities - np.inf  # No valid bin, strongly discourage\n\n    waste = bins_remain_cap[fit_mask] - item\n    priorities[fit_mask] = 1.0 / (waste + 0.0001)\n\n    wasted_space_ratio = waste / bins_remain_cap[fit_mask]\n    nearly_full = wasted_space_ratio < 0.1\n    priorities[fit_mask][nearly_full] -= 0.5\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response5.txt_stdout.txt",
    "code_path": "problem_iter5_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit with fragmentation penalty and stochasticity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize best fit\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Stochasticity for exploration\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1\n\n        # Penalize almost full bins (fragmentation)\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.5 \n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.238133226964499,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response6.txt_stdout.txt",
    "code_path": "problem_iter5_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best fit, reduces fragmentation, adds exploration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        priorities[feasible_bins] = np.exp(-5 * (waste / item)) # Prioritize smaller waste\n\n        # Fragmentation penalty\n        fragment_threshold_low = 0.1\n        fragment_threshold_high = 0.25\n        fragment_mask = (bins_remain_cap[feasible_bins] - item > fragment_threshold_low) & (bins_remain_cap[feasible_bins] - item < fragment_threshold_high)\n        priorities[feasible_bins][fragment_mask] -= 0.5\n\n        # Stochasticity\n        priorities += np.random.rand(len(bins_remain_cap)) * 0.01\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 3.9289988033506273,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response7.txt_stdout.txt",
    "code_path": "problem_iter5_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate bin priorities using waste, fullness, and fragmentation.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    n_bins = len(bins_remain_cap)\n\n    # 1. Waste-based priority (FFD inspired)\n    fit_mask = bins_remain_cap >= item\n    waste = bins_remain_cap[fit_mask] - item\n    relative_waste = waste / (item + 0.0001)\n    priorities[fit_mask] += np.exp(-5 * relative_waste)\n\n    # 2. Fullness priority (Next-Fit inspired)\n    bin_fullness = bins_remain_cap / (np.max(bins_remain_cap) + 0.0001)\n    priorities += np.power(1 - bin_fullness, 3)\n\n    # 3. Fragmentation penalty\n    fragmentation_penalty = np.where(bins_remain_cap < item, -1000, 0)\n    priorities += fragmentation_penalty\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response8.txt_stdout.txt",
    "code_path": "problem_iter5_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, and penalizes fragmentation.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit)\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Add stochasticity (exploration)\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1\n\n        #Penalize almost full bins to prevent fragmentation\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.5 # Reduce priority of almost full bins\n        \n\n        #Large item high reward - filling up space and avoiding future placement issues.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*2,0.25,0) #incentivise large bins if enough capacity exists.\n        priorities[feasible_bins] += large_cap_reward\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 1.8847227762265748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter5_response9.txt_stdout.txt",
    "code_path": "problem_iter5_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines potential well fit, relative waste, stochasticity,\n    and fragmentation penalty for bin selection.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return priorities\n\n    # Potential well around near-perfect fits.\n    fit_difference = bins_remain_cap - item\n    near_fit_mask = fit_difference >= 0\n    priorities[near_fit_mask] = np.exp(-np.abs(fit_difference[near_fit_mask]) / (item + 1e-6))\n\n    # Relative wasted space penalty.\n    wasted_space = bins_remain_cap - item\n    priorities[eligible_bins] -= 0.5 * (wasted_space[eligible_bins] / (bins_remain_cap[eligible_bins] + 1e-6))\n\n    # Stochastic exploration: favor fuller bins with small probability.\n    fill_level = 1 - (bins_remain_cap / np.max(bins_remain_cap))\n    priorities += 0.01 * np.random.rand(len(bins_remain_cap)) * fill_level**2\n\n    # Fragmentation penalty\n    fragment_threshold_low = 0.1\n    fragment_threshold_high = 0.25\n    fragment_mask = (bins_remain_cap - item > fragment_threshold_low) & (bins_remain_cap - item < fragment_threshold_high)\n    priorities[fragment_mask] -= 0.3\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, and penalizes fragmentation.\n       Also, considers bin fill ratio and dynamically adjusts stochasticity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit)\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Dynamically adjust stochasticity based on the number of feasible bins\n        num_feasible = np.sum(feasible_bins)\n        stochasticity_factor = 0.1 / (num_feasible + 1e-6)  # Reduce stochasticity when many bins are feasible\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_factor\n        \n\n        # Penalize almost full bins to prevent fragmentation (more aggressive)\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05  # More sensitive to almost full\n        priorities[feasible_bins][almost_full] *= 0.3  # Reduce priority more aggressively\n\n        # Reward bins that are already significantly filled\n        fill_ratio = (bins_remain_cap[feasible_bins] - waste) / bins_remain_cap[feasible_bins]\n        significantly_filled = fill_ratio > 0.5 # Adjust threshold as needed\n        priorities[feasible_bins][significantly_filled] += 0.2  # Add a small reward for filled bins\n\n        #Large item high reward - filling up space and avoiding future placement issues.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*2,0.25,0) #incentivise large bins if enough capacity exists.\n        priorities[feasible_bins] += large_cap_reward\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 2.3534104507379476,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response1.txt_stdout.txt",
    "code_path": "problem_iter6_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, and penalizes fragmentation, with capacity-aware adjustments.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit) - stronger best-fit emphasis\n        priorities[feasible_bins] = 10 / (waste + 0.0001)  # Increased magnitude\n\n        # Stochasticity (exploration) - reduced exploration\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.05 # Reduced exploration\n\n        # Penalize almost full bins to prevent fragmentation - tuned threshold and penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.15 # Slightly relaxed threshold\n        priorities[feasible_bins][almost_full] *= 0.3  # Stronger penalty\n\n        #Reward larger capacity bins, more aggressive\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*1.5, 0.5, 0)  #Reduced threshold, higher reward\n        priorities[feasible_bins] += large_cap_reward\n        \n        #Prioritize bins with capacity close to the item size\n        close_fit = np.abs(waste - item*0.5) / item < 0.2 #check is close to item/2\n        priorities[feasible_bins][close_fit] += 0.4 #slight encouragement if near half full after placement\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.1284403669724865,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response2.txt_stdout.txt",
    "code_path": "problem_iter6_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, penalizes fragmentation,\n    and considers bin fill ratio with dynamic scaling.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit) - stronger preference\n        priorities[feasible_bins] = 10 / (waste + 0.0001)\n        \n        # Add stochasticity (exploration) - reduced amplitude\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.05\n\n        # Penalize almost full bins to prevent fragmentation - adaptive penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.3 # Reduce priority more aggressively\n\n        # Reward larger bins if enough capacity exists - tweaked reward size\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*1.5, 0.2, 0) #Reduced threshold for large cap, decreased magnitude\n        priorities[feasible_bins] += large_cap_reward\n\n        # Dynamic scaling based on bin fill ratio\n        fill_ratio = (bins_remain_cap[feasible_bins] - waste) / bins_remain_cap[feasible_bins]\n        priorities[feasible_bins] *= (1 + fill_ratio * 0.5)  # Boost priority for bins that will be well-filled\n\n        # Further penalty for bins that, after placing the item, would have capacity less than a threshold.\n        small_remaining = bins_remain_cap[feasible_bins] - item < 0.1\n        priorities[feasible_bins][small_remaining] = -np.inf #Make unfeasible\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.078579976067022,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response3.txt_stdout.txt",
    "code_path": "problem_iter6_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, and penalizes fragmentation.\n    Also considers bin utilization and provides incentives for specific capacity ranges.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit)\n        priorities[feasible_bins] = 1 / (waste + 0.0001)\n        \n        # Add stochasticity (exploration)\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.1\n\n        # Penalize almost full bins to prevent fragmentation, stronger penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.3 # Reduce priority of almost full bins even more\n\n        # Large item high reward - filling up space and avoiding future placement issues. More aggressive.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*2,0.5,0) #incentivise larger bins if enough capacity exists.\n        priorities[feasible_bins] += large_cap_reward\n        \n        # Incentivize bins in a \"sweet spot\" of utilization to encourage more full bins.\n        # This range (0.5-0.75) is based on experimentation and tuning - might require adjustments.\n        utilization = (bins_remain_cap[feasible_bins] - waste) / (1 - waste) # Estimate utilization after placement. Assuming bin size is 1\n        sweet_spot = (utilization > 0.5) & (utilization < 0.75)\n        priorities[feasible_bins][sweet_spot] += 0.3  # Give a boost to bins in the sweet spot\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 3,
    "tryHS": true,
    "obj": 1.3063422417231776,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response4.txt_stdout.txt",
    "code_path": "problem_iter6_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, penalizes fragmentation, and considers bin fill ratio.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit) - stronger best-fit\n        priorities[feasible_bins] = 10 / (waste + 0.0001)  # Increased impact of best-fit\n\n        # Add stochasticity (exploration) - reduced stochasticity\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * 0.05  # Reduced stochasticity\n\n        # Penalize fragmentation - more aggressive penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1\n        priorities[feasible_bins][almost_full] *= 0.3  # Stronger penalty for almost full bins\n\n        # Reward filling bins well\n        fill_ratio = item / bins_remain_cap[feasible_bins]\n        good_fill = (fill_ratio > 0.7) & (fill_ratio <= 1.0)\n        priorities[feasible_bins][good_fill] += 0.5  # Reward bins filled well\n\n        # Large item high reward - filling up space and avoiding future placement issues, only when bin large enough\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*1.25,0.25,0) #incentivise large bins if enough capacity exists. Less restriction on bin size for the reward.\n        priorities[feasible_bins] += large_cap_reward\n\n        #Moderate penalty if item fills bin above a certain threshold.\n        overfill_penalty = np.where(fill_ratio>1, -1,0)\n        priorities[feasible_bins]+= overfill_penalty\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.078579976067022,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter7_response1.txt_stdout.txt",
    "code_path": "problem_iter7_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                  bins_remain_cap: np.ndarray,\n                  inverse_waste_epsilon: float = 0.0009517416013681764,\n                  stochasticity_factor: float = 0.09745591089394652,\n                  almost_full_threshold: float = 0.09034869261671735,\n                  almost_full_penalty: float = 0.2795796732517142,\n                  large_item_threshold_multiplier: float = 1.995355054549088,\n                  large_item_reward: float = 0.7684235288085917,\n                  sweet_spot_lower: float = 0.5201023505737072,\n                  sweet_spot_upper: float = 0.7365385725120408,\n                  sweet_spot_reward: float = 0.3890936279437447) -> np.ndarray:\n    \"\"\"Prioritizes best-fit, adds stochasticity, and penalizes fragmentation.\n    Also considers bin utilization and provides incentives for specific capacity ranges.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Prioritize based on inverse waste (best fit)\n        priorities[feasible_bins] = 1 / (waste + inverse_waste_epsilon)\n        \n        # Add stochasticity (exploration)\n        priorities[feasible_bins] += np.random.rand(np.sum(feasible_bins)) * stochasticity_factor\n\n        # Penalize almost full bins to prevent fragmentation, stronger penalty\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < almost_full_threshold\n        priorities[feasible_bins][almost_full] *= almost_full_penalty # Reduce priority of almost full bins even more\n\n        # Large item high reward - filling up space and avoiding future placement issues. More aggressive.\n        large_cap_reward = np.where(bins_remain_cap[feasible_bins] > item*large_item_threshold_multiplier,large_item_reward,0) #incentivise larger bins if enough capacity exists.\n        priorities[feasible_bins] += large_cap_reward\n        \n        # Incentivize bins in a \"sweet spot\" of utilization to encourage more full bins.\n        # This range (0.5-0.75) is based on experimentation and tuning - might require adjustments.\n        utilization = (bins_remain_cap[feasible_bins] - waste) / (1 - waste) # Estimate utilization after placement. Assuming bin size is 1\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += sweet_spot_reward  # Give a boost to bins in the sweet spot\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities",
    "response_id": 1,
    "tryHS": true,
    "obj": 1.3063422417231776,
    "exec_success": true
  }
]