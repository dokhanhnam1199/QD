```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Prioritizes best-fit with enhanced adaptive penalties, dynamic exploration,
    and capacity-aware bin selection. Aims for a balance between bin utilization,
    fragmentation prevention, and strategic item placement based on available
    capacity and item size."""

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if np.any(feasible_bins):
        waste = bins_remain_cap[feasible_bins] - item
        
        # Core: Prioritize best fit (minimize waste). Increased emphasis.
        priorities[feasible_bins] = 2 / (waste + 0.00001)

        # Adaptive Stochasticity: Item-size dependent exploration. Smaller items explore more.
        num_feasible = np.sum(feasible_bins)
        exploration_factor = min(0.3, 0.05 * num_feasible * (1 - item))  # Smaller items = more exploration
        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor

        # Enhanced Fragmentation Penalty: Accounts for relative waste and bin capacity.
        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]
        almost_full = wasted_space_ratio < 0.05
        priorities[feasible_bins][almost_full] *= 0.1  # More aggressive penalty

        # Capacity-Aware Reward: Prioritize bins with sufficient *relative* capacity.
        # Avoids overfilling smaller bins and encourages utilization of larger ones.
        relative_capacity = bins_remain_cap[feasible_bins] / (1 + item) #Scale by item size.
        sufficient_capacity = relative_capacity > 0.75 #Slightly increased condition.
        priorities[feasible_bins][sufficient_capacity] += 0.5 #Increase reward.

        # Dynamic "Sweet Spot" Incentive: Adaptive range based on item size *and* overall capacity.
        # Aims for optimal utilization considering both item and available space.
        sweet_spot_lower = 0.6 - (item * 0.3) #Increased weight.
        sweet_spot_upper = 0.9 - (item * 0.15) #Increased weight.

        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0
        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)
        priorities[feasible_bins][sweet_spot] += 0.6 #Increased reward.

        #Bin Diversity Reward: Reward bins with a remaining capacity close to the average remaining capacity
        average_remaining_capacity = np.mean(bins_remain_cap)
        capacity_difference = np.abs(bins_remain_cap[feasible_bins] - average_remaining_capacity)
        capacity_diversity_bonus = np.exp(-capacity_difference) * 0.2 #Apply gaussian distibution.
        priorities[feasible_bins] += capacity_diversity_bonus

    else:
        priorities[:] = -np.inf  # No feasible bins

    return priorities
```
