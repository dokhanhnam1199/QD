```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Prioritizes best-fit with adaptive penalties and dynamic exploration.
    Emphasizes a balance between bin utilization and preventing extreme fragmentation,
    adjusting strategies based on item size and bin availability. Includes bin history.
    """

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if np.any(feasible_bins):
        waste = bins_remain_cap[feasible_bins] - item
        
        # Core: Prioritize best fit (minimize waste).
        priorities[feasible_bins] = 1 / (waste + 1e-9)  # Tiny constant to avoid division by zero

        # Exploration: Add some randomness to explore different options.  Reduced exploration.
        num_feasible = np.sum(feasible_bins)
        exploration_factor = 0.01 * item  # Further reduced and scale by item size
        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor

        # Fragmentation Penalty: Target almost-full bins.  Simplified logic.
        almost_full_threshold = 0.1
        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]
        almost_full = wasted_space_ratio < almost_full_threshold
        priorities[feasible_bins][almost_full] *= 0.5  # Significant penalty for using almost-full bins.

        # Reward for placing smaller items into bins with larger remaining capacity. Simplified scaling.
        if item < 0.2:  # Only apply for smaller items
            large_bin_threshold = 0.7
            large_bin = bins_remain_cap[feasible_bins] > large_bin_threshold
            priorities[feasible_bins][large_bin] += 0.3  # Increased reward for large bins

        # Sweet spot incentive, simplified.
        sweet_spot_lower = 0.6 - (0.1 * item)
        sweet_spot_upper = 0.9 - (0.05 * item)

        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0  # Assuming bin size is 1
        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)
        priorities[feasible_bins][sweet_spot] += 0.2

        # Bin History: Penalize bins that have been filled recently more aggressively.
        # This requires an external mechanism (not part of this function) to track bin usage.
        # This is a placeholder:  You'd need to maintain 'bin_usage_history' externally.
        # Example: bin_usage_history = np.zeros_like(bins_remain_cap) #Initialize to all zeros
        # Higher values = recently used more.

        #In a separate step, you would update this value: bin_usage_history[chosen_bin] += 1

        #The following assumes that bin_usage_history exist in the scope.
        try:
            bin_usage_history #Test if the variable exists, exception otherwise
            usage_penalty = bin_usage_history[feasible_bins] * 0.05 #Scaling factor can be tuned.
            priorities[feasible_bins] -= usage_penalty #Penalize using this bin more.
        except NameError:
            pass #If it doesn't exist, continue without this feature.

    else:
        priorities[:] = -np.inf  # No feasible bins

    return priorities
```
