```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Prioritizes best-fit with adaptive penalties and dynamic exploration.
    Emphasizes a balance between bin utilization and preventing extreme fragmentation,
    adjusting strategies based on item size and bin availability.
    Version 2: Implements a more robust exploration strategy based on bin diversity and better sweet spot definition."""

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if np.any(feasible_bins):
        waste = bins_remain_cap[feasible_bins] - item
        
        # Core: Prioritize best fit (minimize waste).  Slightly more aggressive than v1
        priorities[feasible_bins] = 1 / (waste + 0.00001)  # Tiny constant to avoid division by zero

        # Adaptive Stochasticity:  More exploration when bins are plentiful or bin capacities are diverse.
        num_feasible = np.sum(feasible_bins)
        capacity_std = np.std(bins_remain_cap[feasible_bins])
        exploration_factor = min(0.3, 0.05 * num_feasible + 0.1 * capacity_std)  # Caps at 0.3, considers capacity diversity
        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor

        # Fragmentation Penalty:  Stronger and more nuanced. Target almost-full bins.
        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]
        almost_full = wasted_space_ratio < 0.05 #More aggressive
        priorities[feasible_bins][almost_full] *= 0.1  # Significant penalty for using almost-full bins. More aggressive penalty.

        # Rewarding larger bins for smaller items, but with diminishing returns.
        small_item_large_bin_reward = np.where(bins_remain_cap[feasible_bins] > 1.5 * item, 0.3 * np.exp(-item), 0) # Diminishing return based on item size.
        priorities[feasible_bins] += small_item_large_bin_reward

        # Dynamic "Sweet Spot" Incentive: Adapt the range based on item size and a bit of bin capacity
        sweet_spot_lower = 0.6 - (item * 0.2) - (capacity_std * 0.02) #Dynamic Lower Bound - lower bound decreases as item sizes increase. + capacity
        sweet_spot_upper = 0.8 - (item * 0.1) + (capacity_std * 0.02) #Dynamic Upper Bound - upper bound decreases as item sizes increase, less aggressively. + capacity

        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0  # Assuming bin size is 1
        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)
        priorities[feasible_bins][sweet_spot] += 0.5 #Increased the reward.

        #Penalize bins that after adding the item will have very little space left.
        very_small_remaining = bins_remain_cap[feasible_bins] - item < 0.1
        priorities[feasible_bins][very_small_remaining] *= 0.3 #Significant penalty
    else:
        priorities[:] = -np.inf  # No feasible bins

    return priorities
```
