import numpy as np

def priority_v2(item: float,
                bins_remain_cap: np.ndarray,
                waste_epsilon: float = 7.072434745469424e-09,
                exploration_scale: float = 0.122767014487516,
                almost_full_threshold: float = 0.03903177893939867,
                penalty_base: float = 0.3170974934035287,
                penalty_scale: float = 0.2170723196232508,
                max_penalty_reduction: float = 0.42126206032793057,
                significantly_filled_threshold: float = 0.4564700482161885,
                sweet_spot_incentive: float = 0.11391865524853802,
                large_cap_factor: float = 1.776755213824402,
                large_cap_reward: float = 0.25454964287821247) -> np.ndarray:
    """Combines best-fit, adaptive stochasticity, and item-aware penalty."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    feasible_bins = bins_remain_cap >= item

    if np.any(feasible_bins):
        waste = bins_remain_cap[feasible_bins] - item
        priorities[feasible_bins] = 1 / (waste + waste_epsilon)

        # Adaptive stochasticity: scaled by feasible bin count.
        num_feasible = np.sum(feasible_bins)
        exploration_factor = exploration_scale / (num_feasible + waste_epsilon)
        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor

        # Item-aware fragmentation penalty.
        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]
        almost_full = wasted_space_ratio < almost_full_threshold
        penalty_factor = penalty_base + penalty_scale * item  # Adjust penalty with item size.
        priorities[feasible_bins][almost_full] *= (1 - min(penalty_factor, max_penalty_reduction))

        # Sweet spot incentive near full capacity.
        fill_ratio = (bins_remain_cap[feasible_bins] - waste) / 1.0
        significantly_filled = fill_ratio > significantly_filled_threshold
        priorities[feasible_bins][significantly_filled] += sweet_spot_incentive

        # Reward larger bins based on item size.
        large_cap_reward_values = np.where(bins_remain_cap[feasible_bins] > item * large_cap_factor, large_cap_reward, 0)
        priorities[feasible_bins] += large_cap_reward_values
    else:
        priorities[:] = -np.inf

    return priorities
