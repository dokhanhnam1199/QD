{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes best-fit with adaptive stochasticity and fragmentation control.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n\n        # Best-fit prioritization\n        priorities[feasible_bins] = 1 / (waste + 0.00001)\n\n        # Adaptive Stochasticity\n        num_feasible = np.sum(feasible_bins)\n        exploration_factor = min(0.2, 0.02 * num_feasible)\n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Fragmentation penalty (stronger for larger items)\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.05\n        penalty_factor = 0.2 + item * 0.1 #item size adjusts the penalty dynamically.\n        priorities[feasible_bins][almost_full] *= penalty_factor\n        priorities[feasible_bins][almost_full] = np.clip(priorities[feasible_bins][almost_full], 0, 1) #prevent overflow\n\n        # Rewarding larger bins for smaller items\n        small_item_large_bin_reward = np.where(bins_remain_cap[feasible_bins] > 1.5 * item, 0.4, 0)\n        priorities[feasible_bins] += small_item_large_bin_reward\n\n\n    else:\n        priorities[:] = -np.inf\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes best-fit with adaptive penalties and dynamic exploration.\n    Emphasizes a balance between bin utilization and preventing extreme fragmentation,\n    adjusting strategies based on item size and bin availability. This version\n    focuses on simplified adaptive components and a more robust handling of edge cases.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        waste = bins_remain_cap[feasible_bins] - item\n        \n        # Core: Prioritize best fit (minimize waste).\n        priorities[feasible_bins] = 1 / (waste + 0.00001)  # Tiny constant to avoid division by zero\n\n        # Adaptive Stochasticity:  Exploration proportional to available capacity, capped.\n        total_capacity = np.sum(bins_remain_cap)\n        exploration_factor = min(0.1, total_capacity * 0.001) # Proportional to total remaining capacity\n        num_feasible = np.sum(feasible_bins)        \n        priorities[feasible_bins] += np.random.rand(num_feasible) * exploration_factor\n\n        # Fragmentation Penalty:  Focus on *relative* wasted space. Less aggressive, more stable.\n        wasted_space_ratio = waste / bins_remain_cap[feasible_bins]\n        almost_full = wasted_space_ratio < 0.1 # Less aggressive threshold\n        priorities[feasible_bins][almost_full] *= 0.5  # Reduced penalty\n\n        # Reward larger bins for small items, but only if it's a *significant* size difference.\n        if item < 0.3: #Only triggers when dealing with small items\n          large_bin_reward = bins_remain_cap[feasible_bins] > (1.0 - item) #is it approaching full bin?\n          priorities[feasible_bins][large_bin_reward] += 0.3\n        \n\n        # Dynamic \"Sweet Spot\" Incentive:  Simplified, based on item size.\n        sweet_spot_lower = 0.6 - (item * 0.15)  #Dynamic Lower Bound - adjusted scale\n        sweet_spot_upper = 0.9 - (item * 0.1) #Dynamic Upper Bound - decreased upper bound\n\n        utilization = (bins_remain_cap[feasible_bins] - waste) / 1.0  # Assuming bin size is 1\n        sweet_spot = (utilization > sweet_spot_lower) & (utilization < sweet_spot_upper)\n        priorities[feasible_bins][sweet_spot] += 0.3\n\n    else:\n        priorities[:] = -np.inf  # No feasible bins\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), we see both are identical. This suggests the ranking process might not be perfectly accurate or there are other factors influencing the ranking beyond the code itself.\nComparing (3rd) vs (4th), the primary difference is that the 3rd version parameterizes most of the magic numbers, making the heuristic more configurable but also more complex. The 4th version has hardcoded values but introduces a dynamic \"sweet spot\" incentive, potentially improving performance.\nComparing (5th) vs (6th), these are identical, similar to the first two.\n\nComparing (1st) vs (5th), the best-fit prioritization in (5th) uses `10 / (waste + 0.0001)` while (1st) uses `1 / (waste + 0.00001)`.  The higher constant in the numerator in (5th) could lead to a stronger best-fit bias initially. Stochasticity in (5th) is scaled by `0.1 * np.mean(bins_remain_cap)`, which is adaptive to the bin fill levels, while (1st) scales with the number of feasible bins.  Fragmentation penalty in (5th) is a direct multiplication by 0.2, while (1st) has a more nuanced approach with `penalty_factor = 0.2 + item * 0.1`. The large item reward in (5th) uses a fixed threshold `item * 1.25`, while (1st) uses `1.5 * item` as the threshold to rewards.\n\nComparing (20th) vs (19th), they are identical.\nComparing (18th) vs (17th), these are identical.\n\nComparing (second worst) vs (worst), (20th) vs (19th) there is no difference\nOverall: The better heuristics tend to incorporate item-size awareness into various components like fragmentation penalty, exploration factor and sweet spot incentives. They use adaptive stochasticity, often based on the number of feasible bins or the mean remaining capacity. Introducing a \"sweet spot\" to prioritize bins with utilization in a specific range seems to be a beneficial strategy. Penalizing fragmentation dynamically based on the size of the item being placed is also frequently observed in the better heuristics. Simpler is better, avoid unnescessary paramaterization.\n- \nOkay, let's redefine \"Current Self-Reflection\" for designing better heuristics, focusing on actionable advice and avoiding the pitfalls of ineffective reflection.\n\nHere's a breakdown:\n\n*   **Keywords:** Adaptive components, empirical tuning, iterative refinement, problem state.\n*   **Advice:** Build heuristics incrementally, starting with a simple, working base. Prioritize adaptive mechanisms over static parameters. Use empirical testing to tune weights and thresholds.\n*   **Avoid:** Premature complexity, non-linear functions without justification, and excessive customization.\n*   **Explanation:** Focus on gradual refinement and data-driven decisions. Begin with basic adaptive strategies and build upon them, avoiding overly complex models initially.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}