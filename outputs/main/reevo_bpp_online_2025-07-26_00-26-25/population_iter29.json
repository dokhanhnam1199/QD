[
  {
    "stdout_filepath": "problem_iter28_response0.txt_stdout.txt",
    "code_path": "problem_iter28_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins by considering inverse remaining capacity,\n    slightly favors early bins for balanced packing, and avoids harsh penalties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # Higher score for bins with less remaining capacity but only if the item fits\n    priority_scores = np.where(new_remain_cap >= 0, 1.0 / (new_remain_cap + 1), 0)\n    \n    # Slightly favor early bins for balanced packing\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 3.9988033506182825,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter28_response1.txt_stdout.txt",
    "code_path": "problem_iter28_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins by inversely proportional to remaining capacity,\n    harshly penalizes overfills, and slightly favors early bins for balanced packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # Higher score for bins with less remaining capacity but only if the item fits\n    priority_scores = np.where(new_remain_cap >= 0, 1.0 / (new_remain_cap + 1), -np.inf)\n    \n    # Penalize overfills harshly\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Slightly favor early bins for balanced packing\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.005 * bin_indices\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 4.038691663342641,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter28_response2.txt_stdout.txt",
    "code_path": "problem_iter28_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation uses inverse capacity scoring for nearly full bins,\n    applies harsh penalties for overfills, and provides a moderate bias towards\n    earlier bins to promote balanced bin packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score with inverse capacity scoring\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (new_remain_cap + 1), -np.inf)\n    \n    # Penalize overfilling severely by setting score to -inf\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Moderate preference for earlier bins to balance the process\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= bin_indices * 0.05\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter28_response3.txt_stdout.txt",
    "code_path": "problem_iter28_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to reduce fragmentation by prioritizing bins that are\n    nearly full and penalizing overfills harshly. It avoids small items in bins that\n    are almost full to ensure efficient use of space.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # We give a higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that are already nearly full to avoid them taking more small items\n    near_full_threshold = 0.1 * np.max(bins_remain_cap)  # Threshold for nearly full bins\n    priority_scores = np.where(bins_remain_cap <= near_full_threshold, priority_scores, 0)\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 4.487435181491823,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter28_response4.txt_stdout.txt",
    "code_path": "problem_iter28_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation inversely prioritizes bins with low remaining capacity,\n    penalizes overfills harshly, and slightly favors early bins for balanced packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Priority score inversely proportional to remaining capacity\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (new_remain_cap + 1e-6), -np.inf)\n    \n    # Penalize overfills harshly\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Slightly favor early bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 4.028719585161557,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter28_response5.txt_stdout.txt",
    "code_path": "problem_iter28_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that are almost full while avoiding overfills.\n    It also avoids overly full bins to maintain diversity and ensures small items are not packed into nearly full bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score for bins that can fit the item\n    priority_scores = np.where(new_remain_cap >= 0, -new_remain_cap, -np.inf)\n    \n    # Penalize overfills harshly\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Avoid bins that are already more than 75% full to maintain diversity\n    max_initial_cap = np.max(bins_remain_cap + item)\n    threshold = 0.75 * max_initial_cap\n    priority_scores[bins_remain_cap < threshold] *= 1.5\n    \n    # Slightly favor small items not going into very nearly full bins\n    priority_scores[new_remain_cap <= 0.1 * max_initial_cap] *= 0.8\n    \n    return priority_scores",
    "response_id": 5,
    "obj": 3.9988033506182825,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter28_response6.txt_stdout.txt",
    "code_path": "problem_iter28_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation avoids harsh penalties, slightly favors early bins,\n    and prefers bins filling nearly to capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Priority score inversely proportional to remaining capacity, avoid harsh penalties\n    positive_scores = np.where(new_remain_cap >= 0, 1 / (new_remain_cap + 1), 0)\n    \n    # Slightly favor early bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    balance_scores = 0.01 * bin_indices\n    \n    # Final priority scores\n    priority_scores = positive_scores - balance_scores\n    \n    return priority_scores",
    "response_id": 6,
    "obj": 3.9988033506182825,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter28_response7.txt_stdout.txt",
    "code_path": "problem_iter28_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that are almost full while avoiding overfills.\n    It maintains diversity by penalizing bins that are already more than 75% full and\n    avoids packing small items into nearly full bins unless no other option is available.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score for bins that can fit the item\n    priority_scores = np.where(new_remain_cap >= 0, -new_remain_cap, -np.inf)\n    \n    # Penalize overfills harshly\n    priority_scores = np.where(new_remain_cap < 0, -np.inf, priority_scores)\n    \n    # Avoid bins that are already more than 75% full to maintain diversity\n    initial_capacities = bins_remain_cap + item\n    fullness = 1 - (bins_remain_cap / initial_capacities)\n    priority_scores[fullness > 0.75] *= 0.1\n    \n    # Slightly favor bins with initially lower remaining capacity to maintain balance\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.001 * bin_indices\n    \n    return priority_scores",
    "response_id": 7,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter28_response8.txt_stdout.txt",
    "code_path": "problem_iter28_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to reduce fragmentation by preferring bins that are\n    almost filled, penalizing bins that would exceed their capacity, and avoiding bins\n    that are already more than half full to prevent them from taking more small items.\n    It focuses on filling bins nearly to capacity without favoring early bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a base score of negative new remaining capacity\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that would be overfilled\n    priority_scores = np.where(new_remain_cap < 0, -np.inf, priority_scores)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * bins_remain_cap.max()\n    penalty_factor = 0.5  # Penalty factor for bins more than half full\n    priority_scores = np.where(bins_remain_cap <= half_full_threshold, priority_scores, priority_scores * (1 - penalty_factor))\n    \n    return priority_scores",
    "response_id": 8,
    "obj": 4.068607897885915,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter28_response9.txt_stdout.txt",
    "code_path": "problem_iter28_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on prioritizing bins that are nearly full,\n    penalizing bins that cannot hold the item, and slightly favoring early bins\n    to reduce fragmentation effectively.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot hold the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Prioritize bins with less remaining capacity after adding the item\n    # (i.e., nearly full bins get higher scores)\n    priority_scores = -priority_scores\n    \n    # Slight preference for early bins\n    early_bin_preference = np.arange(len(bins_remain_cap)) * 0.01\n    \n    # Combine the scores\n    priority_scores = priority_scores + early_bin_preference\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter29_response0.txt_stdout.txt",
    "code_path": "problem_iter29_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to reduce fragmentation and prefers bins that are\n    almost filled while penalizing bins that exceed a certain capacity threshold.\n    It favors early bins slightly, balances via near-full preference, and avoids\n    early disqualification for balanced and effective packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    max_cap = np.max(bins_remain_cap)\n    half_full_threshold = 0.5 * max_cap\n    small_item_threshold = 0.1 * max_cap\n\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n\n    # Calculate the priority score\n    # We give a higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n\n    # Penalize bins that are already more than half full to avoid them taking more small items\n    priority_scores = np.where(bins_remain_cap <= half_full_threshold, priority_scores, priority_scores * 0.9)\n\n    # Slightly favor early bins\n    early_bin_factor = np.linspace(1.1, 1, len(bins_remain_cap))\n    priority_scores *= early_bin_factor\n\n    # Penalize overfills harshly\n    priority_scores = np.where(new_remain_cap < 0, -np.inf, priority_scores)\n\n    # Avoid early disqualification for very small items\n    priority_scores = np.where(item <= small_item_threshold, priority_scores / 0.9, priority_scores)\n\n    return priority_scores",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter29_response1.txt_stdout.txt",
    "code_path": "problem_iter29_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to reduce fragmentation and prefers bins that are\n    almost filled while avoiding overfills. It also penalizes bins that exceed a\n    certain capacity threshold and favors early bins slightly, balancing via near-full preference,\n    and avoids early disqualification for balanced and effective packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high penalty for bins that would overflow\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Give a higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -priority_scores\n    \n    # Favor early bins slightly\n    priority_scores *= (1 - np.arange(len(bins_remain_cap)) * 0.01)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    max_cap = np.max(bins_remain_cap)\n    half_full_threshold = 0.5 * max_cap\n    priority_scores = np.where(bins_remain_cap <= half_full_threshold, priority_scores, -max_cap)\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 4.646988432389324,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter29_response2.txt_stdout.txt",
    "code_path": "problem_iter29_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to reduce fragmentation and prefers bins that are\n    almost filled while penalizing bins that exceed a certain capacity threshold.\n    It favors early bins slightly, balances via near-full preference, and avoids\n    early disqualification for balanced and effective packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    max_cap = np.max(bins_remain_cap)\n    half_full_threshold = 0.5 * max_cap\n\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n\n    # Base priority based on remaining capacity\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n\n    # Penalize overfills harshly\n    priority_scores = np.where(new_remain_cap < 0, -np.inf, priority_scores)\n\n    # Favor early bins slightly\n    gradual_degradation = np.arange(len(bins_remain_cap)) * -0.01\n    priority_scores += gradual_degradation\n\n    # Favor bins that are near full but not over half\n    priority_scores = np.where((bins_remain_cap > half_full_threshold) & (bins_remain_cap <= 0.9 * max_cap), priority_scores + 10, priority_scores)\n\n    # Avoid early disqualification for bins that are almost full\n    priority_scores = np.where((bins_remain_cap <= half_full_threshold) & (bins_remain_cap >= item), priority_scores + 1, priority_scores)\n\n    return priority_scores",
    "response_id": 2,
    "obj": 99.47147985640208,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter29_response3.txt_stdout.txt",
    "code_path": "problem_iter29_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to reduce fragmentation and prefers bins that are\n    almost filled while penalizing bins that exceed a certain capacity threshold.\n    It favors early bins slightly, balances via near-full preference, and avoids\n    early disqualification for balanced and effective packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    max_cap = np.max(bins_remain_cap)\n    half_full_threshold = 0.5 * max_cap\n\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n\n    # Base priority is the inverse of remaining capacity, penalize overfills harshly\n    base_priority = np.where(new_remain_cap >= 0, -1 / (new_remain_cap + 1e-6), -np.inf)\n\n    # Penalize bins that are already more than half full to avoid them taking more small items\n    base_priority = np.where(bins_remain_cap <= half_full_threshold, base_priority, -np.inf)\n\n    # Favor early bins slightly\n    bin_indices = np.arange(len(bins_remain_cap))\n    early_bin_bonus = 0.1 * (max_cap - bins_remain_cap) / max_cap\n\n    # Calculate the final priority score\n    priority_scores = base_priority + early_bin_bonus\n\n    return priority_scores",
    "response_id": 3,
    "obj": 10.341045073793383,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter29_response4.txt_stdout.txt",
    "code_path": "problem_iter29_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to reduce fragmentation and prefers bins that are\n    almost filled while penalizing bins that exceed a certain capacity threshold.\n    It favors early bins slightly, balances via near-full preference, and avoids\n    early disqualification for balanced and effective packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    max_cap = np.max(bins_remain_cap)\n    half_full_threshold = 0.5 * max_cap\n\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n\n    # Base priority based on remaining capacity\n    priority_scores = np.where(new_remain_cap >= 0, -new_remain_cap, -np.inf)\n    \n    # Penalize bins that are more than half full\n    priority_scores[bins_remain_cap <= half_full_threshold] *= 1.5\n    \n    # Favor early bins but slightly (decrease their penalty)\n    early_bin_bonus = 1 / (np.arange(len(bins_remain_cap)) + 1)\n    priority_scores += early_bin_bonus\n\n    return priority_scores",
    "response_id": 4,
    "obj": 4.01874750698045,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]