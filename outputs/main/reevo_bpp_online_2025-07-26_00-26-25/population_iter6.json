[
  {
    "stdout_filepath": "problem_iter6_response0.txt_stdout.txt",
    "code_path": "problem_iter6_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on the fullness of each bin and penalizes bins that\n    cannot fit the item. It uses efficient numpy operations for better performance.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate how full each bin is\n    fullness = 1 - (bins_remain_cap / bins_remain_cap.max(initial=1))\n    \n    # Penalize bins that cannot fit the current item\n    penalty = np.where(bins_remain_cap < item, -1, 0)\n    \n    # Combine fullness and penalization for priority score\n    priority = fullness + penalty\n    \n    return priority",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response1.txt_stdout.txt",
    "code_path": "problem_iter6_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation favors bins that are almost full to reduce fragmentation\n    and penalizes bins that are overfilled or nearly overfilled. It aims to\n    minimize the number of bins used by efficiently packing items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a base score that decreases with remaining capacity\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_capacity = 0.5 * np.max(bins_remain_cap)\n    priority_scores = np.where(bins_remain_cap <= half_capacity, priority_scores, priority_scores * 0.1)\n    \n    # Break ties by slightly favoring earlier bins (lower indices)\n    priority_scores += 1e-7 * np.arange(len(bins_remain_cap))\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 2.293577981651376,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response2.txt_stdout.txt",
    "code_path": "problem_iter6_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation uses positive scoring for bins that can fit the item,\n    penalizes bins that would be overfilled severely, and favors earlier bins\n    to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Favor bins that can fit the item with higher priority for bins closer to being full\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor early bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 3.9988033506182825,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response3.txt_stdout.txt",
    "code_path": "problem_iter6_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on reducing fragmentation by preferring bins that\n    are almost filled and penalizes infeasible bins directly with negative scores.\n    It also rigorously penalizes bins that are more than half full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high value (small negative) for feasible bins\n    priority_scores = np.where(new_remain_cap >= 0, -new_remain_cap, -np.inf)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * np.max(bins_remain_cap + item)\n    priority_scores = np.where(bins_remain_cap >= half_full_threshold, -np.inf, priority_scores)\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response4.txt_stdout.txt",
    "code_path": "problem_iter6_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes feasible bins, penalizes overfill, focuses on large gaps, and avoids half-full bins taking small items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high value for feasible bins\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), 0)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    max_capacity = np.max(bins_remain_cap) + item\n    half_full_threshold = 0.5 * max_capacity\n    priority_scores = np.where(bins_remain_cap < half_full_threshold, priority_scores, priority_scores * 0.5)\n    \n    # Boost bins with the smallest gap after placing the item\n    feasible_bins = bins_remain_cap >= item\n    if np.any(feasible_bins):\n        gaps = new_remain_cap[feasible_bins]\n        min_gap = np.min(gaps)\n        priority_scores[feasible_bins & (gaps == min_gap)] += 0.5  # Boost bins with the smallest gap\n\n    return priority_scores",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response5.txt_stdout.txt",
    "code_path": "problem_iter6_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on filling bins with higher priority given they\n    have less remaining capacity but can still hold the item. It heavily penalizes\n    bins that cannot hold the item and slightly favors earlier bins to avoid\n    fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority with zero\n    priority_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Favor bins that can still hold the item\n    can_fit_item_mask = new_remain_cap >= 0\n    if np.any(can_fit_item_mask):\n        # Prioritize bins that are closer to being full\n        priority_scores[can_fit_item_mask] = 1 / (1 + new_remain_cap[can_fit_item_mask])\n    \n    # Penalize bins that cannot hold the item by setting their priority to -np.inf\n    priority_scores[~can_fit_item_mask] = -np.inf\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 5,
    "obj": 3.9988033506182825,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response6.txt_stdout.txt",
    "code_path": "problem_iter6_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on minimizing gaps in bins and avoiding overfill.\n    It penalizes bins that would be overfilled harshly and favors bins that are\n    almost filled. Early bins receive a slight preference.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Favor bins that are less likely to be overfilled and prioritize by minimal remaining capacity\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Penalize bins that would be overfilled\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Favor early bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.001 * bin_indices\n    \n    return priority_scores",
    "response_id": 6,
    "obj": 4.038691663342641,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response7.txt_stdout.txt",
    "code_path": "problem_iter6_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that are nearly full and penalizes bins\n    that cannot fit the current item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate how full each bin is\n    max_cap = np.max(bins_remain_cap, initial=1)\n    fullness = 1 - (bins_remain_cap / max_cap)\n    \n    # Penalize bins that cannot fit the current item\n    penalty = np.where(bins_remain_cap < item, -1, 0)\n    \n    # Combine fullness and penalization for priority score\n    priority = fullness + penalty\n    \n    return priority",
    "response_id": 7,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response8.txt_stdout.txt",
    "code_path": "problem_iter6_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation simplifies the logic to prioritize bins that are closer to being full\n    while penalizing those that cannot fit the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Penalize bins that cannot fit the item by setting their priority to -1\n    penalty_mask = bins_remain_cap < item\n    priority_scores = -np.ones_like(bins_remain_cap, dtype=float)\n    \n    # Prioritize bins with more remaining capacity above item size\n    feasible_capacities = bins_remain_cap[~penalty_mask]\n    if feasible_capacities.size > 0:\n        # Calculate priority based on remaining capacity\n        priority_scores[~penalty_mask] = 1 / (feasible_capacities + 1e-6)  # Adding small epsilon to avoid division by zero\n    \n    return priority_scores",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter6_response9.txt_stdout.txt",
    "code_path": "problem_iter6_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on reducing fragmentation and prefers bins that\n    are almost filled without being overfilled. Overfilled bins are penalized severely,\n    and early bins are favored slightly to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Favor bins that are less likely to be overfilled\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor early bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 3.9988033506182825,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]