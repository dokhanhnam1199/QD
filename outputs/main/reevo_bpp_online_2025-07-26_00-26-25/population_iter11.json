[
  {
    "stdout_filepath": "problem_iter10_response0.txt_stdout.txt",
    "code_path": "problem_iter10_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on filling bins that have less remaining capacity\n    but can still hold the item. It heavily penalizes bins that cannot hold the\n    item and slightly favors earlier bins to avoid fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority with zero\n    priority_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Favor bins that can still hold the item\n    can_fit_item_mask = new_remain_cap >= 0\n    if np.any(can_fit_item_mask):\n        # Prioritize bins that are closer to being full\n        priority_scores[can_fit_item_mask] = 1 / (1 + new_remain_cap[can_fit_item_mask])\n    \n    # Penalize bins that cannot hold the item by setting their priority to -np.inf\n    priority_scores[~can_fit_item_mask] = -np.inf\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 3.9988033506182825,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response1.txt_stdout.txt",
    "code_path": "problem_iter10_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that can fit the item, favors bins that are closer to being full,\n    and slightly favors earlier bins to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a large negative value for infeasible bins\n    priority_scores = np.full_like(bins_remain_cap, -np.inf)\n    \n    # Assign priority scores for feasible bins, favoring bins that are closer to being full\n    feasible_bins = new_remain_cap >= 0\n    priority_scores[feasible_bins] = -new_remain_cap[feasible_bins]\n    \n    # Slightly favor earlier bins by adding a small penalty based on bin index\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.05 * bin_indices\n    \n    return priority_scores",
    "response_id": 1,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 31, in priority_v2\n    return priority_scores\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n6\n1\n"
  },
  {
    "stdout_filepath": "problem_iter10_response2.txt_stdout.txt",
    "code_path": "problem_iter10_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on filling bins that are closer to being full,\n    penalizes bins that cannot hold the item, and slightly favors earlier bins\n    to minimize fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high value (small negative) for feasible bins\n    # The closer a bin is to being full, the higher its priority\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.001 * bin_indices\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 4.038691663342641,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response3.txt_stdout.txt",
    "code_path": "problem_iter10_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation harshly penalizes overfills, slightly favors earlier bins,\n    and adjusts the half-full penalty dynamically to minimize fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize heavily for overfills\n    overfill_penalty = np.where(new_remain_cap < 0, -np.inf, 0)\n    \n    # Calculate the priority score: higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, 0) + overfill_penalty\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * (bins_remain_cap + item)\n    half_full_penalty = np.where(new_remain_cap < half_full_threshold, 0, -0.1)\n    \n    # Favor earlier bins slightly by adding a small bonus that decreases with index\n    index_bonus = np.arange(len(bins_remain_cap)) * -0.01\n    \n    # Combine all adjustments into the priority scores\n    priority_scores += half_full_penalty + index_bonus\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response4.txt_stdout.txt",
    "code_path": "problem_iter10_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on minimizing gaps in bins and avoiding overfill.\n    It uses positive incentives for bins with minimal gaps and harsh penalties for bins that would be overfilled.\n    It also slightly favors earlier bins to avoid creating gaps at the beginning.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with negative infinity for overfilled bins\n    priority_scores = np.full_like(bins_remain_cap, -np.inf)\n    \n    # Apply a positive incentive for bins with minimal remaining capacity after adding the item\n    valid_bins = new_remain_cap >= 0\n    priority_scores[valid_bins] = 1 / (1 + new_remain_cap[valid_bins])\n    \n    # Slightly favor earlier bins by subtracting a small positive penalty based on bin index\n    num_bins = len(bins_remain_cap)\n    bin_indices = np.arange(num_bins)\n    priority_scores -= 0.001 * bin_indices\n    \n    return priority_scores",
    "response_id": 4,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 33, in priority_v2\n    num_bins = len(bins_remain_cap)\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n6\n1\n"
  },
  {
    "stdout_filepath": "problem_iter10_response5.txt_stdout.txt",
    "code_path": "problem_iter10_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers remaining capacity, harshly penalizes overfills,\n    favors earlier bins, minimizes fragmentation, and adjusts half-full penalties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize heavily for overfills\n    overfill_penalty = np.where(new_remain_cap < 0, -np.inf, 0)\n    \n    # Calculate the priority score: higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, 0) + overfill_penalty\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * (np.max(bins_remain_cap) + item)\n    priority_scores[np.where(bins_remain_cap < half_full_threshold)] -= 5\n    \n    # Favor earlier bins with a slight bias\n    num_bins = len(bins_remain_cap)\n    bin_index_penalty = np.linspace(0, 0.5, num_bins)\n    priority_scores -= bin_index_penalty\n    \n    return priority_scores",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response6.txt_stdout.txt",
    "code_path": "problem_iter10_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on the remaining capacity after adding the item,\n    penalizing overpacking, and simplifying the logic.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # We give a higher score if the remaining capacity is small (i.e., almost full)\n    # Penalize bins that cannot fit the item by setting their score to -inf\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    return priority_scores",
    "response_id": 6,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response7.txt_stdout.txt",
    "code_path": "problem_iter10_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation simplifies the priority logic, heavily penalizes bins that are nearly full,\n    slightly prioritizes earlier bins, and slightly favors bins with larger remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a base score that increases with remaining capacity\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that are nearly full (less than 10% remaining capacity)\n    nearly_full_threshold = 0.1 * np.max(bins_remain_cap)\n    priority_scores = np.where(new_remain_cap <= nearly_full_threshold, priority_scores * 0.01, priority_scores)\n    \n    # Break ties by slightly favoring earlier bins (lower indices)\n    priority_scores += 1e-6 * np.arange(len(bins_remain_cap))\n    \n    return priority_scores",
    "response_id": 7,
    "obj": 149.30195452732352,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response8.txt_stdout.txt",
    "code_path": "problem_iter10_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on filling bins that are closer to being full,\n    penalizes bins that cannot hold the item, and slightly favors earlier bins\n    to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores\n    priority_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Favor bins that can still hold the item\n    can_fit_item_mask = new_remain_cap >= 0\n    if np.any(can_fit_item_mask):\n        # Prioritize bins that are closer to being full\n        priority_scores[can_fit_item_mask] = 1 / (1 + new_remain_cap[can_fit_item_mask])\n    \n    # Penalize bins that cannot hold the item\n    priority_scores[~can_fit_item_mask] = -np.inf\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 8,
    "obj": 3.9988033506182825,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter10_response9.txt_stdout.txt",
    "code_path": "problem_iter10_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on filling bins that are closer to being full,\n    penalizes bins that cannot hold the item, and slightly favors earlier bins\n    to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high value for feasible bins, penalizing infeasibility harshly\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor slightly earlier bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 3.9988033506182825,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response0.txt_stdout.txt",
    "code_path": "problem_iter11_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on feasible bins, penalizes overfills harshly,\n    slightly favors fuller bins, and minimizes fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores\n    priority_scores = np.zeros_like(bins_remain_cap)\n    \n    # Mask for feasible bins\n    feasible_bins = new_remain_cap >= 0\n    \n    # Penalize overfills harshly\n    priority_scores[~feasible_bins] = -np.inf\n    \n    # Favor slightly fuller bins dynamically\n    # We give higher scores to bins that are closer to being full, among feasible bins\n    priority_scores[feasible_bins] = -new_remain_cap[feasible_bins]\n    \n    return priority_scores",
    "response_id": 0,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 26, in priority_v2\n    bin_indices = np.arange(len(bins_remain_cap))\nOverflowError: cannot convert float infinity to integer\n8\n1\n"
  },
  {
    "stdout_filepath": "problem_iter11_response1.txt_stdout.txt",
    "code_path": "problem_iter11_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on feasible bins, penalizes overfills harshly,\n    slightly favors earlier bins that are fuller, and minimizes fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot fit the item with a very low score\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Favor bins that are fuller to reduce fragmentation\n    priority_scores += np.max(bins_remain_cap) - bins_remain_cap\n    \n    # Slightly prefer earlier bins that are fuller\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores += 0.1 * (np.max(bins_remain_cap) - bins_remain_cap) * (bin_indices / len(bin_indices))\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 6.05305145592342,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response2.txt_stdout.txt",
    "code_path": "problem_iter11_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on feasible bins, penalizes overfills harshly,\n    slightly favors earlier bins that are fuller, and minimizes fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot fit the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Slightly favor bins that are fuller by adding a small positive bias\n    fill_ratio = (1 - new_remain_cap / np.max(bins_remain_cap)) * 0.1\n    priority_scores = np.where(new_remain_cap >= 0, priority_scores + fill_ratio, priority_scores)\n    \n    # Penalize bins that are more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * np.max(bins_remain_cap + item)\n    priority_scores = np.where(bins_remain_cap < half_full_threshold, priority_scores, 0.01 * priority_scores)\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 13.711607499002792,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response3.txt_stdout.txt",
    "code_path": "problem_iter11_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on feasible bins, penalizes overfills harshly,\n    slightly favors earlier bins that are fuller, and minimizes fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot fit the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Slightly favor bins that are fuller by adding a small positive bias\n    fill_ratio = (1 - new_remain_cap / np.max(bins_remain_cap)) * 0.1\n    priority_scores = np.where(new_remain_cap >= 0, priority_scores + fill_ratio, priority_scores)\n    \n    # Penalize bins that are more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * np.max(bins_remain_cap + item)\n    priority_scores = np.where(bins_remain_cap < half_full_threshold, priority_scores, 0.01 * priority_scores)\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 13.711607499002792,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response4.txt_stdout.txt",
    "code_path": "problem_iter11_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on feasible bins, penalizes overfills harshly,\n    slightly favors earlier bins that are fuller, and minimizes fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot fit the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Slightly favor bins that are fuller by adding a small positive bias\n    fill_ratio = (1 - new_remain_cap / np.max(bins_remain_cap)) * 0.1\n    priority_scores = np.where(new_remain_cap >= 0, priority_scores + fill_ratio, priority_scores)\n    \n    # Penalize bins that are more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * np.max(bins_remain_cap + item)\n    priority_scores = np.where(bins_remain_cap < half_full_threshold, priority_scores, 0.01 * priority_scores)\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 13.711607499002792,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]