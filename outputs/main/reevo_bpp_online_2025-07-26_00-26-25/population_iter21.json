[
  {
    "stdout_filepath": "problem_iter20_response0.txt_stdout.txt",
    "code_path": "problem_iter20_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation directly penalizes bins that cannot hold the item,\n    prioritizes bins with less remaining capacity, and slightly favors earlier bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot hold the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Prioritize bins with less remaining capacity after adding the item (lower is better)\n    priority_scores = 1 / (1 + priority_scores)\n    \n    # Favor earlier bins by subtracting a small value multiplied by the bin index\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores += 0.01 * (len(bins_remain_cap) - bin_indices)\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 3.9988033506182825,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response1.txt_stdout.txt",
    "code_path": "problem_iter20_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation directly penalizes bins that cannot hold the item,\n    prioritizes bins with less remaining capacity, and slightly favors earlier bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot hold the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Prioritize bins with less remaining capacity after adding the item (lower is better)\n    priority_scores = 1 / (1 + priority_scores)\n    \n    # Favor earlier bins by subtracting a small value multiplied by the bin index\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores += 0.01 * (len(bins_remain_cap) - bin_indices)\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 3.9988033506182825,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response2.txt_stdout.txt",
    "code_path": "problem_iter20_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins by inverse remaining capacity, penalizes overfills heavily, \n    favors early bins slightly, and focuses on simplifying scoring.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Start with a base priority score inversely proportional to remaining capacity\n    # If adding the item overfills the bin, assign a very low priority score\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (new_remain_cap + 1e-6), -np.inf)\n    \n    # Favor early bins slightly to reduce fragmentation\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores += 0.1 * (1 / (bin_indices + 1))\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 4.01874750698045,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response3.txt_stdout.txt",
    "code_path": "problem_iter20_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that are nearly full, harshly penalizes bins that cannot hold the item,\n    and slightly favors earlier bins to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot hold the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores += 0.01 * (len(bins_remain_cap) - bin_indices)\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 3.9988033506182825,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response4.txt_stdout.txt",
    "code_path": "problem_iter20_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins by an inverse function of the remaining capacity,\n    heavily penalizes overfills, and slightly favors early bins to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Start with a base priority score inversely proportional to remaining capacity\n    # If adding the item overfills the bin, assign a very low priority score\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (new_remain_cap + 1e-6), -np.inf)\n    \n    # Favor early bins slightly to reduce fragmentation\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores += 0.1 * (1 / (bin_indices + 1))\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 4.01874750698045,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response5.txt_stdout.txt",
    "code_path": "problem_iter20_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that are nearly full, harshly penalizes bins that cannot hold the item,\n    and uses mild index decay for early bins to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot hold the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Use mild index decay for early bins to reduce fragmentation\n    bin_indices = np.arange(len(bins_remain_cap))\n    decay_factor = 1 / (1 + 0.1 * bin_indices)\n    priority_scores *= decay_factor\n    \n    return priority_scores",
    "response_id": 5,
    "obj": 4.058635819704831,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response6.txt_stdout.txt",
    "code_path": "problem_iter20_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation strictly penalizes bins that cannot hold the item,\n    prioritizes bins that can fit the item with the least remaining capacity,\n    and slightly favors earlier bins to minimize fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot hold the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Prioritize bins with less remaining capacity after adding the item (lower is better)\n    priority_scores = 1 / (1 + priority_scores)\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins, uniquely by using a decay factor\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 6,
    "obj": 3.9988033506182825,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response7.txt_stdout.txt",
    "code_path": "problem_iter20_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity of bins, penalizes overfills,\n    prefers early bins slightly, and avoids overcrowding existing bins that are already\n    more than half full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Assign a base priority score based on the remaining capacity after adding the item\n    # Higher priority for bins that are almost full after adding the item\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    priority_scores = np.where(bins_remain_cap < 0.5 * np.max(bins_remain_cap + item), priority_scores, priority_scores / 2)\n    \n    # Favor early bins slightly to reduce fragmentation\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores += 0.1 * (1 / (bin_indices + 1))\n    \n    return priority_scores",
    "response_id": 7,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response8.txt_stdout.txt",
    "code_path": "problem_iter20_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prefers bins that are nearly full, heavily penalizes overfills,\n    slightly favors earlier bins, and avoids overly packing large items by penalizing bins\n    that are already more than half full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot hold the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    max_bin_cap = np.max(bins_remain_cap + item)\n    half_capacity = 0.5 * max_bin_cap\n    priority_scores = np.where(bins_remain_cap >= half_capacity, priority_scores - half_capacity, priority_scores)\n    \n    # Favor earlier bins slightly to reduce fragmentation\n    bin_indices = np.arange(len(bins_remain_cap)) + 1  # Start from 1 to avoid division by zero\n    priority_scores += 0.05 / bin_indices\n    \n    return priority_scores",
    "response_id": 8,
    "obj": 24.611088950937372,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response9.txt_stdout.txt",
    "code_path": "problem_iter20_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that can fit the item with the least remaining capacity,\n    harshly penalizes bins that cannot hold the item, and slightly favors earlier bins to minimize fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot hold the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Prioritize bins with less remaining capacity after adding the item (lower is better)\n    priority_scores = 1 / (1 + priority_scores)\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins, uniquely by using a decay factor\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 3.9988033506182825,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response0.txt_stdout.txt",
    "code_path": "problem_iter21_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation favors bins with low remaining capacity, penalizes overfills\n    severely, and mildly favors early bins to reduce fragmentation and achieve balanced packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # We give a higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize overfills severely\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Mildly favor early bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= bin_indices * 0.01  # Small penalty for later bins\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response1.txt_stdout.txt",
    "code_path": "problem_iter21_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation favors bins with low remaining capacity, penalizes overfills\n    severely, and mildly favors early bins to reduce fragmentation and achieve balanced packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # Favor bins with low remaining capacity; assign a high negative score to bins that can fit the item\n    priority_scores = np.where(new_remain_cap >= 0, -new_remain_cap, -np.inf)\n    \n    # Penalize overfills severely\n    priority_scores = np.where(priority_scores == -np.inf, -np.inf, priority_scores)\n    \n    # Mildly favor early bins to reduce fragmentation and achieve balanced packing\n    early_bin_factor = 0.01 * np.arange(len(bins_remain_cap))\n    priority_scores += early_bin_factor\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response2.txt_stdout.txt",
    "code_path": "problem_iter21_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation favors bins with low remaining capacity, penalizes overfills\n    severely, and mildly favors early bins to reduce fragmentation and achieve balanced packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # Favor bins with low remaining capacity and penalize overfills\n    priority_scores = np.where(new_remain_cap >= 0, -new_remain_cap, -np.inf)\n    \n    # Penalize bins that overfill\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Mildly favor early bins to reduce fragmentation and achieve balanced packing\n    priority_scores -= 0.01 * np.arange(len(bins_remain_cap))\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response3.txt_stdout.txt",
    "code_path": "problem_iter21_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation favors bins with low remaining capacity, penalizes overfills\n    severely, and mildly favors early bins to reduce fragmentation and achieve balanced packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # Favor bins with low remaining capacity and penalize overfills severely\n    priority_scores = np.where(new_remain_cap >= 0, -new_remain_cap, -np.inf)\n    \n    # Mildly favor earlier bins to reduce fragmentation and achieve balanced packing\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores += -bin_indices * 0.01\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response4.txt_stdout.txt",
    "code_path": "problem_iter21_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation favors bins with low remaining capacity, penalizes overfills\n    severely, and mildly favors early bins to reduce fragmentation and achieve balanced packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # We give a higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize overfills severely\n    priority_scores = np.where(new_remain_cap < 0, -np.inf, priority_scores)\n    \n    # Mildly favor early bins for reduced fragmentation and balanced packing\n    num_bins = len(bins_remain_cap)\n    bin_indices = np.arange(num_bins)\n    adjustment_factor = 0.01  # Small factor to slightly favor early bins\n    priority_scores -= bin_indices * adjustment_factor\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]