[
  {
    "stdout_filepath": "problem_iter16_response0.txt_stdout.txt",
    "code_path": "problem_iter16_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on filling bins that are closer to being full,\n    penalizes bins that cannot hold the item, and slightly favors earlier bins\n    to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high value for feasible bins\n    # The closer a bin is to being full, the higher its priority\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 114.51934583167132,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response1.txt_stdout.txt",
    "code_path": "problem_iter16_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins by inverse remaining capacity, penalizes overfills heavily, \n    favors early bins slightly, and focuses on simplifying scoring.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Start with a base priority score inversely proportional to remaining capacity\n    # If adding the item overfills the bin, assign a very low priority score\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (new_remain_cap + 1e-6), -np.inf)\n    \n    # Favor early bins slightly to reduce fragmentation\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores += 0.1 * (1 / (bin_indices + 1))\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 4.01874750698045,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response2.txt_stdout.txt",
    "code_path": "problem_iter16_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on filling bins that are closer to being full,\n    penalizes bins that cannot hold the item, and slightly favors earlier bins\n    to minimize fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high value (small negative) for feasible bins\n    # The closer a bin is to being full, the higher its priority\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor earlier bins by adding a more significant bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.05 * bin_indices\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response3.txt_stdout.txt",
    "code_path": "problem_iter16_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins by inverse remaining capacity, penalizes overfills heavily, \n    favors early bins slightly, and focuses on simplifying scoring.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Start with a base priority score inversely proportional to remaining capacity\n    # If adding the item overfills the bin, assign a very low priority score\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (new_remain_cap + 1e-6), -np.inf)\n    \n    # Favor early bins slightly to reduce fragmentation\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores += 0.1 * (1 / (bin_indices + 1))\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 4.01874750698045,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response4.txt_stdout.txt",
    "code_path": "problem_iter16_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on filling bins that are nearly full while\n    penalizing bins that cannot hold the item. It avoids biasing early bins\n    and ensures that overfilled bins are not considered.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high value (smaller number) for feasible bins\n    # The closer a bin is to being full, the higher its priority\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * np.max(bins_remain_cap + item)\n    priority_scores[new_remain_cap < half_full_threshold] *= 0\n    \n    return -priority_scores",
    "response_id": 4,
    "obj": 4.487435181491823,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response5.txt_stdout.txt",
    "code_path": "problem_iter16_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins by inverse remaining capacity, penalizes\n    overfills heavily, and favors earlier bins slightly to improve bin utilization dynamically.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score: higher for smaller remaining capacity\n    priority_scores = -new_remain_cap\n    \n    # Penalize overfills heavily\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Favor early bins slightly\n    early_bin_bonus = 1 / (np.arange(len(bins_remain_cap)) + 1)\n    priority_scores += early_bin_bonus\n    \n    return priority_scores",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response6.txt_stdout.txt",
    "code_path": "problem_iter16_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins by the inverse of their remaining capacity after adding the item,\n    heavily penalizes overfills, and slightly favors early bins to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Assign a base priority score inversely proportional to remaining capacity\n    # If adding the item overfills the bin, assign a very low priority score\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (new_remain_cap + 1e-6), -np.inf)\n    \n    # Favor early bins slightly to reduce fragmentation\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores += 0.1 * (1 / (bin_indices + 1))\n    \n    return priority_scores",
    "response_id": 6,
    "obj": 4.01874750698045,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response7.txt_stdout.txt",
    "code_path": "problem_iter16_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to reduce fragmentation and avoid overfills by\n    prioritizing bins that are nearly full without being overfilled. It also penalizes\n    bins that are overly empty to encourage better space utilization.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    max_initial_cap = np.max(bins_remain_cap + item)\n    priority_scores[bins_remain_cap < 0.5 * max_initial_cap] *= 0.5\n    \n    # Penalize bins that are overly empty to encourage better space utilization\n    priority_scores[bins_remain_cap > 0.8 * max_initial_cap] *= 0.5\n    \n    return priority_scores",
    "response_id": 7,
    "obj": 4.078579976067022,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response8.txt_stdout.txt",
    "code_path": "problem_iter16_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that are nearly full, harshly penalizes bins that cannot hold the item,\n    and slightly favors earlier bins to minimize fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot hold the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins, uniquely by using a decay factor\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 8,
    "obj": 3.9988033506182825,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter16_response9.txt_stdout.txt",
    "code_path": "problem_iter16_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and aims to reduce\n    fragmentation by preferring bins that are almost filled while penalizing overfills heavily.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # Give a higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize overfills heavily by setting a very low score\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Adjust priority for bins that are already quite full to avoid them taking more small items\n    # We assume 'quite full' means less than half the capacity of the fullest bin\n    max_bin_cap = max(bins_remain_cap) + item\n    priority_scores[bins_remain_cap < 0.5 * max_bin_cap] *= 0.5\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response0.txt_stdout.txt",
    "code_path": "problem_iter17_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used recently. It aims to reduce fragmentation by preferring bins that\n    are almost filled, penalizing overfills heavily, and favoring early bins slightly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a base score of the remaining capacity\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize overfills heavily\n    priority_scores = np.where(new_remain_cap < 0, priority_scores - 1e5, priority_scores)\n    \n    # Prioritize nearly full bins slightly more\n    priority_scores += (1 - new_remain_cap / np.max(bins_remain_cap + item)) / 2\n    \n    # Favor early bins slightly for dynamic balancing\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= bin_indices * 0.01\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 114.36976465895492,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response1.txt_stdout.txt",
    "code_path": "problem_iter17_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used recently. It aims to reduce fragmentation by preferring bins that\n    are almost filled, penalizing overfills heavily, and favoring early bins slightly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize overfills heavily\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Prioritize nearly full bins\n    priority_scores = -priority_scores  # Invert to prioritize low positive values\n    \n    # Favor early bins slightly for dynamic balancing and improved utilization\n    num_bins = len(bins_remain_cap)\n    dynamic_balance_factor = np.exp(-np.linspace(0, 1, num_bins) * 4)\n    priority_scores *= dynamic_balance_factor\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * np.max(bins_remain_cap + item)\n    priority_scores = np.where(bins_remain_cap < half_full_threshold, priority_scores, -np.inf)\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response2.txt_stdout.txt",
    "code_path": "problem_iter17_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used recently. It aims to reduce fragmentation by preferring bins that\n    are almost filled, penalizing overfills heavily, and favoring early bins slightly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize overfills heavily\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Prioritize nearly full bins\n    priority_scores = -priority_scores  # Invert to prioritize low positive values\n    \n    # Favor early bins slightly for dynamic balancing and improved utilization\n    num_bins = len(bins_remain_cap)\n    dynamic_balance_factor = np.exp(-np.linspace(0, 1, num_bins) * 4)\n    priority_scores *= dynamic_balance_factor\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * np.max(bins_remain_cap + item)\n    priority_scores = np.where(bins_remain_cap < half_full_threshold, priority_scores, -np.inf)\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response3.txt_stdout.txt",
    "code_path": "problem_iter17_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used recently. It aims to reduce fragmentation by preferring bins that\n    are almost filled, penalizing overfills heavily, and favoring early bins slightly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize overfills heavily\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Prioritize nearly full bins\n    priority_scores = -priority_scores  # Invert to prioritize low positive values\n    \n    # Favor early bins slightly for dynamic balancing and improved utilization\n    num_bins = len(bins_remain_cap)\n    dynamic_balance_factor = np.exp(-np.linspace(0, 1, num_bins) * 4)\n    priority_scores *= dynamic_balance_factor\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * np.max(bins_remain_cap + item)\n    priority_scores = np.where(bins_remain_cap < half_full_threshold, priority_scores, -np.inf)\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response4.txt_stdout.txt",
    "code_path": "problem_iter17_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used recently. It aims to reduce fragmentation by preferring bins that\n    are almost filled, penalizing overfills heavily, and favoring early bins slightly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Base priority score: higher score for bins that will be less empty after adding the item\n    priority_scores = -new_remain_cap\n    \n    # Penalize overfills heavily by setting their score to a very low value\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * np.max(bins_remain_cap + item, initial=item)\n    priority_scores[bins_remain_cap < half_full_threshold] -= 10 * item\n    \n    # Favor early bins slightly to improve dynamic balancing and utilization\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= bin_indices * 0.01\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 75.67810131631433,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]