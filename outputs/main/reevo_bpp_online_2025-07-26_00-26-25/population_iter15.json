[
  {
    "stdout_filepath": "problem_iter14_response0.txt_stdout.txt",
    "code_path": "problem_iter14_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on filling bins that are closer to being full,\n    penalizes bins that cannot hold the item, and slightly favors earlier bins\n    to minimize fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high value (small negative) for feasible bins\n    # The closer a bin is to being full, the higher its priority\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    # Further prioritize bins that are more than half full to minimize fragmentation\n    half_full_threshold = 0.5 * np.max(bins_remain_cap)\n    priority_scores[bins_remain_cap < half_full_threshold] *= 0.9\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 3.9788591942560925,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response1.txt_stdout.txt",
    "code_path": "problem_iter14_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on remaining capacity, penalizes overfills,\n    and avoids complexity by simplifying the logic.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize heavily for overfills\n    overfill_penalty = np.where(new_remain_cap < 0, -np.inf, 0)\n    \n    # Calculate the priority score: higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, 0) + overfill_penalty\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response2.txt_stdout.txt",
    "code_path": "problem_iter14_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on filling bins that are closer to being full,\n    penalizes bins that cannot hold the item, and slightly favors earlier bins\n    to minimize fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high value (small negative) for feasible bins\n    # The closer a bin is to being full, the higher its priority\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 3.9988033506182825,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response3.txt_stdout.txt",
    "code_path": "problem_iter14_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on filling bins that are closer to being full,\n    penalizes bins that cannot hold the item, and slightly favors earlier bins\n    to minimize fragmentation. It adjusts parameters via experimentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high value (small negative) for feasible bins\n    # The closer a bin is to being full, the higher its priority\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.001 * bin_indices\n    \n    # Adjust parameters for better performance\n    # Increasing the penalty for infeasible bins\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Fine-tuning the favoring of earlier bins\n    priority_scores -= 0.0005 * bin_indices\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 4.058635819704831,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response4.txt_stdout.txt",
    "code_path": "problem_iter14_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins by considering the inverse of the remaining\n    capacity after adding the item, while penalizing bins that are nearly full and\n    favoring those that are underused but can still fit the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with high values for feasible bins\n    # The closer a bin is to being full, the higher its priority\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    max_bin_cap = np.max(bins_remain_cap + item)\n    priority_scores -= np.where(bins_remain_cap < 0.5 * max_bin_cap, 0, 0.5 * priority_scores)\n    \n    # Favor bins that are underused but can still fit the item\n    priority_scores += np.where(new_remain_cap > 0.5 * max_bin_cap, 0.1, 0)\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 3.599920223374565,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response5.txt_stdout.txt",
    "code_path": "problem_iter14_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on harshly penalizing overfills, slightly penalizing bins that are more than 60% full,\n    and favors earlier bins to minimize fragmentation and improve efficiency.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Harshly penalize overfills\n    overfill_penalty = np.where(new_remain_cap < 0, -np.inf, 0)\n    \n    # Calculate the priority score: higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, 0) + overfill_penalty\n    \n    # Slightly penalize bins that are already more than 60% full\n    half_full_threshold = 0.6 * (np.max(bins_remain_cap) + item)\n    priority_scores[new_remain_cap < half_full_threshold] -= 1\n    \n    # Favor earlier bins with a linear bias\n    num_bins = len(bins_remain_cap)\n    bin_index_bonus = np.linspace(1, 0, num_bins) * 0.1  # Bonus decreases with bin index\n    priority_scores += bin_index_bonus\n    \n    return priority_scores",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response6.txt_stdout.txt",
    "code_path": "problem_iter14_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation simplifies scoring by heavily penalizing overfills and\n    targeting bins nearing fullness to encourage better compactness and efficiency.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Harshly penalize overfills\n    overfill_penalty = np.where(new_remain_cap < 0, -np.inf, 0)\n    \n    # Calculate the priority score: higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -new_remain_cap + overfill_penalty\n    \n    # Penalize bins that are already less than 10% empty to avoid them taking more small items\n    priority_scores[new_remain_cap < 0.1 * np.max(bins_remain_cap)] = -np.inf\n    \n    return priority_scores",
    "response_id": 6,
    "obj": 15.167530913442375,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response7.txt_stdout.txt",
    "code_path": "problem_iter14_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on the remaining capacity and penalizes bins that are over half full.\n    It aims to reduce fragmentation by preferring bins that are almost filled.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score for feasible bins\n    priority_scores = np.where(new_remain_cap >= 0, -new_remain_cap, -np.inf)\n    \n    # Penalize bins that are more than half full\n    half_full_threshold = 0.5 * np.max(bins_remain_cap + item)\n    priority_scores = np.where(bins_remain_cap >= half_full_threshold, -np.inf, priority_scores)\n    \n    return priority_scores",
    "response_id": 7,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response8.txt_stdout.txt",
    "code_path": "problem_iter14_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation harshly penalizes overfills, adjusts half-full thresholds,\n    and uses linear biases for bin positions to minimize fragmentation and favor earlier bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Harshly penalize overfills\n    overfill_penalty = np.where(new_remain_cap < 0, -np.inf, 0)\n    \n    # Calculate the priority score: higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, 0) + overfill_penalty\n    \n    # Adjust penalty for bins that are already more than 75% full to avoid them taking more small items\n    half_full_threshold = 0.75 * (np.max(bins_remain_cap) + item)\n    priority_scores[new_remain_cap < half_full_threshold] -= 5\n    \n    # Favor earlier bins with a linear bias\n    num_bins = len(bins_remain_cap)\n    bin_index_penalty = np.linspace(0, 1, num_bins)\n    priority_scores -= bin_index_penalty\n    \n    return priority_scores",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response9.txt_stdout.txt",
    "code_path": "problem_iter14_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that are nearly full, harshly penalizes bins that cannot hold the item,\n    and slightly favors earlier bins to minimize fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot hold the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 3.9988033506182825,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response0.txt_stdout.txt",
    "code_path": "problem_iter15_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins by inverse remaining capacity, penalizes overfills heavily, \n    favors early bins slightly, and focuses on simplifying scoring.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Start with a base priority score inversely proportional to remaining capacity\n    base_priority = np.where(new_remain_cap >= 0, 1.0 / (new_remain_cap + 1e-6), -np.inf)\n    \n    # Penalize overfills heavily\n    penalty_factor = 1000  # This factor can be adjusted via experimentation\n    priority_scores = np.where(new_remain_cap < 0, base_priority - penalty_factor * np.abs(new_remain_cap), base_priority)\n    \n    # Favor early bins slightly\n    favoring_factor = 0.01  # This factor can be adjusted via experimentation\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= bin_indices * favoring_factor\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 4.028719585161557,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response1.txt_stdout.txt",
    "code_path": "problem_iter15_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins by inverse remaining capacity, penalizes overfills heavily, \n    favors early bins slightly, and focuses on simplifying scoring.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Start with a base priority score inversely proportional to remaining capacity\n    # If adding the item overfills the bin, assign a very low priority score\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (new_remain_cap + 1e-6), -np.inf)\n    \n    # Favor early bins slightly to reduce fragmentation\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores += 0.1 * (1 / (bin_indices + 1))\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 4.01874750698045,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response2.txt_stdout.txt",
    "code_path": "problem_iter15_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins by inverse remaining capacity, penalizes overfills heavily, \n    favors early bins slightly, and focuses on simplifying scoring.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Start with a base priority score inversely proportional to remaining capacity\n    # Smaller remaining capacity gets higher priority\n    priority_scores = 1 / (new_remain_cap + 1e-9)  # Avoid division by zero with a small epsilon\n    \n    # Penalize overfills heavily\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Favor early bins slightly by adding a small bonus for earlier bins\n    priority_scores += (1 - np.arange(len(bins_remain_cap)) / len(bins_remain_cap)) / 10\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response3.txt_stdout.txt",
    "code_path": "problem_iter15_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins by inverse remaining capacity, penalizes overfills heavily, \n    favors early bins slightly, and focuses on simplifying scoring.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score based on inverse remaining capacity\n    priority_scores = -new_remain_cap\n    \n    # Penalize heavily if the item does not fit in the bin\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Favor early bins slightly by adding a small bonus\n    early_bonus = np.linspace(0, 0.1, num=len(bins_remain_cap))\n    priority_scores += early_bonus\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter15_response4.txt_stdout.txt",
    "code_path": "problem_iter15_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins by inverse remaining capacity, penalizes\n    overfills heavily, and favors early bins slightly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score: higher for smaller remaining capacity\n    priority_scores = -new_remain_cap\n    \n    # Penalize overfills heavily\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Favor early bins slightly\n    early_bin_bonus = 1 / (np.arange(len(bins_remain_cap)) + 1)\n    priority_scores += early_bin_bonus\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]