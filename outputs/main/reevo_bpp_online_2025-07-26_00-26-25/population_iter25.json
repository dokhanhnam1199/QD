[
  {
    "stdout_filepath": "problem_iter24_response0.txt_stdout.txt",
    "code_path": "problem_iter24_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation uses positive scores, inversely prioritizes bins with less remaining capacity,\n    and gently favors later bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot hold the item with 0 score\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), 0)\n    \n    # Favor later bins by adding a small value multiplied by the bin index\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores += 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 3.9988033506182825,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response1.txt_stdout.txt",
    "code_path": "problem_iter24_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to reduce fragmentation by preferring bins that\n    have reduced capacity less than half of the current maximum bin capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores\n    priority_scores = np.full(bins_remain_cap.shape, -np.inf)\n    \n    # Set the priority score for bins that can accommodate the item\n    can_accommodate = new_remain_cap >= 0\n    priority_scores[can_accommodate] = -new_remain_cap[can_accommodate]\n    \n    # Get the maximum remaining capacity of bins that can accommodate the item\n    max_new_remain_cap = np.max(new_remain_cap[can_accommodate])\n    \n    # Penalize bins that have reduced capacity more than half of the max capacity among feasible bins\n    penalty_condition = (new_remain_cap < 0.5 * max_new_remain_cap) & can_accommodate\n    priority_scores[penalty_condition] = -np.inf\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 75.64818508177106,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response2.txt_stdout.txt",
    "code_path": "problem_iter24_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on prioritizing bins that are nearly full,\n    penalizing bins that cannot hold the item strictly, and balancing small item distribution.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot hold the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Prioritize bins with less remaining capacity after adding the item\n    # (i.e., nearly full bins get higher scores)\n    priority_scores = -priority_scores\n    \n    # Penalize bins that are more than half full to avoid them taking more small items\n    half_max_possible_cap = 0.5 * np.max(bins_remain_cap + item)\n    priority_scores = np.where(bins_remain_cap + item <= half_max_possible_cap, -np.inf, priority_scores)\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 16.254487435181492,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response3.txt_stdout.txt",
    "code_path": "problem_iter24_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to reduce fragmentation and prefers bins that are\n    almost filled, penalizing bins that exceed a certain capacity threshold.\n    It avoids overfilling bins that are more than half full and focuses on\n    filling bins nearly to capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # We give a higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * np.max(bins_remain_cap)\n    priority_scores = np.where(bins_remain_cap <= half_full_threshold, priority_scores, 0)\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 1.146788990825688,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response4.txt_stdout.txt",
    "code_path": "problem_iter24_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on prioritizing bins that are nearly full,\n    penalizing bins that cannot hold the item or are too large, and avoids\n    rigidly rewarding early bin placement.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot hold the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Prioritize bins with less remaining capacity after adding the item\n    # (i.e., nearly full bins get higher scores)\n    priority_scores = -priority_scores\n    \n    # Penalize bins that are more than half full to avoid them taking more small items\n    # Calculate maximum possible capacity from initial bins to determine the threshold\n    max_possible_cap = np.max(bins_remain_cap + item)\n    threshold = 0.5 * max_possible_cap\n    \n    # Set priority scores to 0 for bins with remaining capacity after adding the item less than the threshold\n    priority_scores = np.where(new_remain_cap < threshold, priority_scores, 0)\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 2.8919026725169528,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response5.txt_stdout.txt",
    "code_path": "problem_iter24_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins by inversely proportional to remaining capacity,\n    harshly penalizes overfills, and slightly favors early bins for balanced packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # Higher score for bins with less remaining capacity but only if the item fits\n    priority_scores = np.where(new_remain_cap >= 0, 1.0 / (new_remain_cap + 1), -np.inf)\n    \n    # Penalize overfills harshly\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Slightly favor early bins for balanced packing\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 5,
    "obj": 3.9988033506182825,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response6.txt_stdout.txt",
    "code_path": "problem_iter24_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation favors bins with less remaining capacity, penalizes overfills strictly,\n    and slightly favors early bins for balanced packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # Higher score for bins with less remaining capacity but only if the item fits\n    priority_scores = np.where(new_remain_cap >= 0, 1.0 / (new_remain_cap + 1), -np.inf)\n    \n    # Penalize overfills strictly\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Slightly favor early bins for balanced packing\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 6,
    "obj": 3.9988033506182825,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response7.txt_stdout.txt",
    "code_path": "problem_iter24_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation inversely prioritizes bins with low remaining capacity,\n    penalizes overfills harshly, and slightly favors early bins for balanced packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Priority score inversely proportional to remaining capacity\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (new_remain_cap + 1e-6), -np.inf)\n    \n    # Penalize overfills harshly\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Slightly favor early bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 7,
    "obj": 4.028719585161557,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response8.txt_stdout.txt",
    "code_path": "problem_iter24_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to prioritize bins that are almost full while avoiding overfills.\n    It also avoids overly full bins and favors bins with remaining capacity.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # We give a higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize overfills harshly\n    priority_scores = np.where(new_remain_cap < 0, -np.inf, priority_scores)\n    \n    # Avoid bins that are already more than half full to avoid them taking more small items\n    max_initial_cap = np.max(bins_remain_cap + item)\n    priority_scores = np.where(bins_remain_cap < 0.5 * max_initial_cap, priority_scores, 0.1 * priority_scores)\n    \n    return priority_scores",
    "response_id": 8,
    "obj": 2.253689668927018,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter24_response9.txt_stdout.txt",
    "code_path": "problem_iter24_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation inversely prioritizes bins with low remaining capacity,\n    penalizes overfills harshly, and slightly favors early bins for balanced packing.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Priority score inversely proportional to remaining capacity\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (new_remain_cap + 1e-6), -np.inf)\n    \n    # Penalize overfills harshly\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Slightly favor early bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 4.028719585161557,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter25_response0.txt_stdout.txt",
    "code_path": "problem_iter25_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to reduce fragmentation and prefers bins that are\n    almost filled while penalizing bins that exceed a certain capacity threshold.\n    It slightly favors bins that have been used less (early bin favoring) and\n    focuses on filling bins nearly to capacity, but harshly penalizes overfilling.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Base priority score is the inverse of the new remaining capacity for non-overfilled bins\n    priority_scores = np.where(new_remain_cap >= 0, 1.0 / (new_remain_cap + 1), -np.inf)\n    \n    # Penalize overfilling harshly\n    penalty_factor = 10\n    priority_scores = np.where(new_remain_cap < 0, new_remain_cap * penalty_factor, priority_scores)\n    \n    # Favor early bins slightly by adding a small bonus\n    early_bin_bonus = 1 / (np.arange(len(bins_remain_cap)) + 1)\n    priority_scores += early_bin_bonus\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * np.max(bins_remain_cap)\n    priority_scores = np.where(bins_remain_cap <= half_full_threshold, priority_scores, priority_scores * 0.9)\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 4.27802153968888,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter25_response1.txt_stdout.txt",
    "code_path": "problem_iter25_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to reduce fragmentation and prefers bins that are\n    almost filled while penalizing bins that exceed a certain capacity threshold.\n    It slightly favors bins that have been used less (early bin favoring) and\n    focuses on filling bins nearly to capacity with small item distribution.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # We give a higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * np.max(bins_remain_cap + item)  # Adjust threshold to account for item size\n    priority_scores = np.where(bins_remain_cap <= half_full_threshold, priority_scores, priority_scores * 0.1)\n    \n    # Apply minor early bin favoring by slightly increasing the score for bins with more remaining capacity\n    min_cap = np.min(bins_remain_cap[bins_remain_cap >= 0])\n    max_cap = np.max(bins_remain_cap[bins_remain_cap >= 0])\n    if max_cap > min_cap:\n        capacity_factor = (bins_remain_cap - min_cap) / (max_cap - min_cap)\n        priority_scores = priority_scores + 1 - capacity_factor * 0.1\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 2.263661747108102,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter25_response2.txt_stdout.txt",
    "code_path": "problem_iter25_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to reduce fragmentation and prefers bins that are\n    almost filled while penalizing bins that exceed a certain capacity threshold.\n    It slightly favors bins that have been used less (early bin favoring) and\n    focuses on filling bins nearly to capacity with small item distribution.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Base priority score for bins that can fit the item\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (new_remain_cap + 1e-9), -np.inf)\n    \n    # Penalize overfilled bins heavily\n    priority_scores = np.where(new_remain_cap < 0, priority_scores - 100, priority_scores)\n    \n    # Minor favoring of early-used bins to distribute small items\n    num_bins = len(bins_remain_cap)\n    bin_indices = np.arange(num_bins)\n    priority_scores += (num_bins - bin_indices) * 0.01\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 4.028719585161557,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter25_response3.txt_stdout.txt",
    "code_path": "problem_iter25_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to reduce fragmentation and prefers bins that are\n    almost filled while penalizing bins that exceed a certain capacity threshold.\n    It slightly favors bins that have been used less (early bin favoring) and\n    focuses on filling bins nearly to capacity with small item distribution.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # We give a higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * np.max(bins_remain_cap + item)  # Adjusted to account for item size\n    priority_scores = np.where(bins_remain_cap <= half_full_threshold, priority_scores, 0)\n    \n    # Minor early bin favoring (penalize bins that have been used more, slightly)\n    early_bin_favoring_factor = 0.01 * np.sum(bins_remain_cap) / len(bins_remain_cap)\n    bin_usage_factor = np.argsort(np.argsort(bins_remain_cap))[::-1] * early_bin_favoring_factor\n    priority_scores -= bin_usage_factor\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 22.895891503789404,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter25_response4.txt_stdout.txt",
    "code_path": "problem_iter25_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation aims to reduce fragmentation and prefers bins that are\n    almost filled, penalizing bins that exceed a certain capacity threshold.\n    It avoids overfilling bins that are more than half full and focuses on\n    filling bins nearly to capacity. It also mildly favors early bins and penalizes overfill.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a base value\n    priority_scores = np.zeros_like(bins_remain_cap)\n    \n    # Calculate the penalty for overfilling\n    overfill_penalty = np.where(new_remain_cap < 0, 1000 * -np.abs(new_remain_cap), 0)\n    \n    # Give higher scores for bins that are nearly full\n    fill_bonus = np.where(new_remain_cap >= 0, -new_remain_cap, 0)\n    \n    # Slight preference for earlier bins\n    early_bin_favor = np.linspace(1, 0, len(bins_remain_cap))\n    \n    # Combine the scores\n    priority_scores = fill_bonus + overfill_penalty + early_bin_favor\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]