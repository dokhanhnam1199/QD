[
  {
    "stdout_filepath": "problem_iter4_response0.txt_stdout.txt",
    "code_path": "problem_iter4_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation simplifies the logic to prioritize bins that are closer to being full\n    while penalizing those that cannot fit the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Penalize bins that cannot fit the item\n    penalty_mask = bins_remain_cap < item\n    priority_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Prioritize bins with more remaining capacity above item size\n    feasible_capacities = bins_remain_cap[~penalty_mask]\n    if feasible_capacities.size > 0:\n        # Calculate priority based on remaining capacity\n        priority_scores[~penalty_mask] = 1 / (feasible_capacities + 1e-6)  # Adding small epsilon to avoid division by zero\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response1.txt_stdout.txt",
    "code_path": "problem_iter4_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on the fullness of each bin and penalizes bins that\n    cannot fit the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate how full each bin is\n    fullness = 1 - (bins_remain_cap / bins_remain_cap.max(initial=1))\n    \n    # Penalize bins that cannot fit the current item\n    penalty = np.where(bins_remain_cap < item, -1, 0)\n    \n    # Combine fullness and penalization for priority score\n    priority = fullness + penalty\n    \n    return priority",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response2.txt_stdout.txt",
    "code_path": "problem_iter4_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that are nearly full while penalizing\n    bins that cannot fit the current item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate how full each bin is\n    fullness = 1 - (bins_remain_cap / np.max(bins_remain_cap, initial=1))\n    \n    # Penalize bins that cannot fit the current item\n    penalty = np.where(bins_remain_cap < item, -1, 0)\n    \n    # Combine fullness and penalization for priority score\n    priority = fullness + penalty\n    \n    return priority",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response3.txt_stdout.txt",
    "code_path": "problem_iter4_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes feasible bins, penalizes overfill, focuses on large gaps, and avoids half-full bins taking small items.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high value for feasible bins\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), 0)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    max_capacity = np.max(bins_remain_cap) + item\n    half_full_threshold = 0.5 * max_capacity\n    priority_scores = np.where(bins_remain_cap < half_full_threshold, priority_scores, priority_scores * 0.5)\n    \n    # Boost bins with the smallest gap after placing the item\n    feasible_bins = bins_remain_cap >= item\n    if np.any(feasible_bins):\n        gaps = new_remain_cap[feasible_bins]\n        min_gap = np.min(gaps)\n        priority_scores[feasible_bins & (new_remain_cap == min_gap)] += 0.5  # Boost bins with the smallest gap\n\n    return priority_scores",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response4.txt_stdout.txt",
    "code_path": "problem_iter4_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Penalize bins that cannot fit the item by setting their priority to -inf\n    priority_scores = -np.inf * np.ones_like(bins_remain_cap)\n    \n    # Consider bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    priority_scores[can_fit_mask] = -(bins_remain_cap[can_fit_mask] - item)\n    \n    # Break ties by slightly favoring earlier bins (lower indices)\n    priority_scores += 1e-7 * np.arange(len(bins_remain_cap))\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response5.txt_stdout.txt",
    "code_path": "problem_iter4_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Heuristic: Prioritize bins that can still fit the item and have remaining capacity closest to the item size\n    priority_scores = np.zeros_like(bins_remain_cap)\n    \n    # Calculate the absolute difference between remaining capacity and item size\n    gaps = np.abs(bins_remain_cap - item)\n    \n    # Penalize bins that cannot fit the item by setting their priority to -inf\n    priority_scores[bins_remain_cap < item] = -np.inf\n    \n    # For bins that can fit the item, lower gap means higher priority\n    priority_scores[bins_remain_cap >= item] = -gaps[bins_remain_cap >= item]\n    \n    # Break ties by slightly favoring earlier bins (lower indices)\n    priority_scores += 1e-7 * np.arange(len(bins_remain_cap))\n    \n    return priority_scores",
    "response_id": 5,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 24, in priority_v2\n    # Initialize priority scores with negative infinity for infeasible bins\nOverflowError: cannot convert float infinity to integer\n6\n1\n"
  },
  {
    "stdout_filepath": "problem_iter4_response6.txt_stdout.txt",
    "code_path": "problem_iter4_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and aims to reduce\n    fragmentation by preferring bins that are almost filled. It also penalizes\n    bins that are more than half full and handles infeasibility clearly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with negative infinity for infeasible bins\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    max_capacity = np.max(bins_remain_cap) + item\n    half_full_threshold = 0.5 * max_capacity\n    priority_scores = np.where(bins_remain_cap >= half_full_threshold, priority_scores * 0.5, priority_scores)\n    \n    # Prioritize bins that are almost full by giving them higher scores\n    priority_scores = -priority_scores  # Invert scores to prioritize lower remaining capacity\n    \n    return priority_scores",
    "response_id": 6,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response7.txt_stdout.txt",
    "code_path": "problem_iter4_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and the number of\n    bins used using a weighted score. Bins that are closer to being full get higher\n    priority, but the priority is slightly reduced for bins that have less remaining\n    capacity than the item to prevent unused bin scenarios. Bins with the smallest\n    gap after placing the item receive a significant boost to their priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Linear decreasing priority based on remaining capacity\n    # Use a max function to avoid negative priorities and ensure feasibility\n    priority = np.maximum(0, bins_remain_cap - item) / item\n    \n    # Give a clear preference to bins that can fit the item at all\n    can_fit_item_mask = bins_remain_cap >= item\n    priority[~can_fit_item_mask] = -1  # Set priority to -1 for bins that cannot fit the item\n\n    # Boost bins with the smallest gap after placing the item\n    if np.any(can_fit_item_mask):\n        gaps = bins_remain_cap[can_fit_item_mask] - item\n        min_gap = np.min(gaps)\n        priority[can_fit_item_mask & (gaps == min_gap)] += 1  # Boost bins with the smallest gap\n\n    return priority",
    "response_id": 7,
    "obj": 51.90466693258875,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response8.txt_stdout.txt",
    "code_path": "problem_iter4_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity and penalizes bins that\n    cannot fit the item, prioritizing bins that are nearly full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate how full each bin is\n    fullness = 1 - (bins_remain_cap / np.max(bins_remain_cap, initial=1))\n    \n    # Penalize bins that cannot fit the current item\n    penalty = np.where(bins_remain_cap < item, -1, 0)\n    \n    # Combine fullness and penalization for priority score\n    priority = fullness + penalty\n    \n    return priority",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter4_response9.txt_stdout.txt",
    "code_path": "problem_iter4_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on reducing fragmentation by preferring bins that\n    are almost filled and penalizes infeasibility without using negative scores.\n    It also balances the penalty for bins that are more than half full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high value for feasible bins\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), 0)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * np.max(bins_remain_cap + item)\n    priority_scores = np.where(bins_remain_cap < half_full_threshold, priority_scores, priority_scores * 0.5)\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]