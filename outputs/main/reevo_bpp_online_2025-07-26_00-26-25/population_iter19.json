[
  {
    "stdout_filepath": "problem_iter18_response0.txt_stdout.txt",
    "code_path": "problem_iter18_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that are nearly full, harshly penalizes bins that cannot hold the item,\n    and slightly favors earlier bins to minimize fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot hold the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins using a decay factor\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 3.9988033506182825,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response1.txt_stdout.txt",
    "code_path": "problem_iter18_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that are nearly full, harshly penalizes bins that cannot hold the item,\n    and slightly favors earlier bins to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot hold the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 3.9988033506182825,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response2.txt_stdout.txt",
    "code_path": "problem_iter18_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and aims to reduce\n    fragmentation by preferring bins that are almost full, while heavily penalizing\n    overfills. It also slightly favors earlier bins to maintain a balanced usage.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # Higher score for bins that are almost full\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    max_bin_cap = np.max(bins_remain_cap + item)\n    priority_scores = np.where(bins_remain_cap < 0.5 * max_bin_cap, priority_scores, 0)\n    \n    # Favor early bins slightly to reduce fragmentation\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores += 0.05 * (1 / (bin_indices + 1))\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 2.183885121659363,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response3.txt_stdout.txt",
    "code_path": "problem_iter18_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins by inverse remaining capacity, penalizes overfills heavily, \n    favors early bins slightly, and focuses on simplifying scoring.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Start with a base priority score inversely proportional to remaining capacity\n    # If adding the item overfills the bin, assign a very low priority score\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (new_remain_cap + 1e-6), -np.inf)\n    \n    # Favor early bins slightly to reduce fragmentation\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores += 0.1 * (1 / (bin_indices + 1))\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 4.01874750698045,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response4.txt_stdout.txt",
    "code_path": "problem_iter18_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins by the inverse of their remaining capacity after adding the item,\n    heavily penalizes overfills, and slightly favors early bins to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Assign a base priority score inversely proportional to remaining capacity\n    # If adding the item overfills the bin, assign a very low priority score\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (new_remain_cap + 1e-6), -np.inf)\n    \n    # Favor early bins slightly to reduce fragmentation\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores += 0.1 * (1 / (bin_indices + 1))\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 4.01874750698045,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response5.txt_stdout.txt",
    "code_path": "problem_iter18_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins by an inverse function of the remaining capacity,\n    heavily penalizes overfills, and slightly favors early bins to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Start with a base priority score inversely proportional to remaining capacity\n    # If adding the item overfills the bin, assign a very low priority score\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (new_remain_cap + 1e-6), -np.inf)\n    \n    # Favor early bins slightly to reduce fragmentation\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores += 0.1 * (1 / (bin_indices + 1))\n    \n    return priority_scores",
    "response_id": 5,
    "obj": 4.01874750698045,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response6.txt_stdout.txt",
    "code_path": "problem_iter18_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that can fit the item with the least remaining capacity,\n    harshly penalizes bins that cannot hold the item, and slightly favors earlier bins to minimize fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot hold the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Prioritize bins with less remaining capacity after adding the item (lower is better)\n    priority_scores = 1 / (1 + priority_scores)\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins, uniquely by using a decay factor\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 6,
    "obj": 3.9988033506182825,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response7.txt_stdout.txt",
    "code_path": "problem_iter18_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on filling bins that are closer to being full,\n    penalizes bins that cannot hold the item, and significantly favors earlier bins\n    to minimize fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high value (small negative) for feasible bins\n    # The closer a bin is to being full, the higher its priority\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor earlier bins by adding a more significant bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.1 * bin_indices\n    \n    return priority_scores",
    "response_id": 7,
    "obj": 4.068607897885915,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response8.txt_stdout.txt",
    "code_path": "problem_iter18_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that are nearly full, harshly penalizes bins that cannot hold the item,\n    and slightly favors earlier bins to minimize fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot hold the item with -inf\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins using a decay factor\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 8,
    "obj": 3.9988033506182825,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response9.txt_stdout.txt",
    "code_path": "problem_iter18_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes nearly full bins, penalizes overfills heavily,\n    and slightly favors early bins for dynamic balancing and improved utilization.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of remaining capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize overfills heavily\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Prioritize nearly full bins\n    priority_scores = -priority_scores  # Invert to prioritize low positive values\n    \n    # Favor early bins slightly for dynamic balancing and improved utilization\n    num_bins = len(bins_remain_cap)\n    dynamic_balance_factor = np.exp(-np.linspace(0, 1, num_bins) * 2)  # Reduced exponent for slight favoring\n    priority_scores *= dynamic_balance_factor\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter19_response0.txt_stdout.txt",
    "code_path": "problem_iter19_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity and dynamically decays\n    preference for early bins to reduce fragmentation. It inversely prioritizes\n    bins based on their remaining capacity and penalizes overfills strictly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score (higher score for bins with less remaining capacity)\n    priority_scores = 1 / (new_remain_cap + 1)  # Add 1 to avoid division by zero\n\n    # Penalize overfills by setting their score to a very low value\n    priority_scores = np.where(new_remain_cap >= 0, priority_scores, -np.inf)\n\n    # Decay early bin preference by multiplying by an inverse index decay factor\n    n_bins = len(bins_remain_cap)\n    priority_scores *= 1 / (np.arange(1, n_bins + 1) ** 0.5)  # Decay factor\n\n    return priority_scores",
    "response_id": 0,
    "obj": 4.028719585161557,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter19_response1.txt_stdout.txt",
    "code_path": "problem_iter19_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity and dynamically decays\n    preference for early-used bins to reduce fragmentation. It incorporates\n    inverse capacity for prioritization and strictly penalizes overfills.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize overfills by setting their scores to a very low value\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Inverse capacity prioritization: prefer bins that are almost full\n    priority_scores = 1.0 / (priority_scores + 1e-5)  # Add a small epsilon to avoid division by zero\n    \n    # Decay preference for early-used bins by a factor that depends on the bin's index\n    decay_factor = 0.95\n    priority_scores *= np.power(decay_factor, np.arange(len(bins_remain_cap)))\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 4.068607897885915,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter19_response2.txt_stdout.txt",
    "code_path": "problem_iter19_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity and dynamically decays\n    preference for early-used bins to reduce fragmentation. It incorporates\n    inverse capacity for prioritization and strictly penalizes overfills.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # Assign -inf to bins that cannot fit the item\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (new_remain_cap + 1), -np.inf)\n    \n    # Decay early bin preference dynamically to reduce fragmentation\n    # This can be done by multiplying by a factor based on the bin index\n    num_bins = len(bins_remain_cap)\n    decay_factor = np.array([(1 / (i + 1)) for i in range(num_bins)])\n    \n    priority_scores *= decay_factor\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 4.198244914240141,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter19_response3.txt_stdout.txt",
    "code_path": "problem_iter19_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity and dynamically decays\n    preference for early-used bins to reduce fragmentation. It avoids overfills\n    strictly and simplifies scoring.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n\n    # Calculate the priority score\n    # Higher score for bins where item fits and with less remaining capacity (almost full)\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (new_remain_cap + 1e-6), -np.inf)\n\n    # Decay early bin preference dynamically: linear decay based on bin index\n    num_bins = len(bins_remain_cap)\n    decay_factor = np.linspace(1, 0.5, num_bins)\n    priority_scores *= decay_factor\n\n    return priority_scores",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter19_response4.txt_stdout.txt",
    "code_path": "problem_iter19_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity and dynamically decays\n    preference for early bins to reduce fragmentation. It prefers bins that are\n    almost filled but avoids overfills strictly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score based on the inverse of new remaining capacity\n    priority_scores = np.where(new_remain_cap >= 0, 1.0 / (new_remain_cap + 1), -np.inf)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    max_cap = np.max(bins_remain_cap + item)\n    priority_scores = np.where(bins_remain_cap < 0.5 * max_cap, priority_scores, 0)\n    \n    # Decay early preference by penalizing bins with higher indices\n    decay_factor = 1.0 / (np.arange(len(bins_remain_cap)) + 1)\n    priority_scores *= decay_factor\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 4.198244914240141,
    "SLOC": 8.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]