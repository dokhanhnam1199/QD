[
  {
    "stdout_filepath": "problem_iter12_response0.txt_stdout.txt",
    "code_path": "problem_iter12_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers both the remaining capacity and aims to balance\n    between filling bins almost to capacity and maintaining some underused capacity\n    to avoid fragmentation. It penalizes bins that are overly packed and favors\n    bins that are underused but can still fit the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high value for feasible bins\n    # The closer a bin is to being full, the higher its priority\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    max_bin_cap = np.max(bins_remain_cap + item)\n    priority_scores -= np.where(bins_remain_cap < 0.5 * max_bin_cap, 0, priority_scores)\n    \n    # Favor bins that are underused but can still fit the item\n    priority_scores -= np.where(new_remain_cap > 0.5 * max_bin_cap, 0.01, 0)\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response1.txt_stdout.txt",
    "code_path": "problem_iter12_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on filling bins that are closer to being full,\n    penalizes bins that cannot hold the item, and slightly favors earlier bins\n    to minimize fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high value (small negative) for feasible bins\n    # The closer a bin is to being full, the higher its priority\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 3.9988033506182825,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response2.txt_stdout.txt",
    "code_path": "problem_iter12_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on filling bins that are closer to being full,\n    penalizes bins that cannot hold the item, and slightly favors earlier bins\n    to minimize fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high value (small negative) for feasible bins\n    # The closer a bin is to being full, the higher its priority\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.001 * bin_indices\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 4.038691663342641,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response3.txt_stdout.txt",
    "code_path": "problem_iter12_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes feasible bins, penalizes small remaining capacities harshly,\n    and slightly favors earlier bins to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize infeasible bins harshly\n    feasibility_penalty = np.where(new_remain_cap < 0, -np.inf, 0)\n    \n    # Penalize bins with small remaining capacities harshly\n    small_capacity_penalty = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), 0)\n    \n    # Favor slightly earlier bins by adding a slight bonus for earlier bins\n    num_bins = len(bins_remain_cap)\n    bin_index_bonus = np.linspace(0, 0.1, num_bins)\n    \n    # Calculate priority scores\n    priority_scores = feasibility_penalty - small_capacity_penalty + bin_index_bonus\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 63.153171120861586,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response4.txt_stdout.txt",
    "code_path": "problem_iter12_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on the remaining capacity and penalizes bins that are over half full.\n    It aims to reduce fragmentation by preferring bins that are almost filled.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score for feasible bins\n    priority_scores = np.where(new_remain_cap >= 0, -new_remain_cap, -np.inf)\n    \n    # Penalize bins that are more than half full\n    half_full_threshold = 0.5 * (np.max(bins_remain_cap) + item)\n    priority_scores = np.where(bins_remain_cap < half_full_threshold, priority_scores, -np.inf)\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response5.txt_stdout.txt",
    "code_path": "problem_iter12_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on remaining capacity, harshly penalizes overfills,\n    favors earlier bins, minimizes fragmentation, and adjusts penalties for bins that are more than half full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize heavily for overfills\n    overfill_penalty = np.where(new_remain_cap < 0, -np.inf, 0)\n    \n    # Calculate the priority score: higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, 0) + overfill_penalty\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * (np.max(bins_remain_cap) + item)\n    priority_scores = np.where(bins_remain_cap < half_full_threshold, priority_scores, priority_scores - 5)\n    \n    # Favor earlier bins with a slight bias\n    num_bins = len(bins_remain_cap)\n    bin_index_penalty = np.linspace(0, 0.5, num_bins)\n    priority_scores -= bin_index_penalty\n    \n    return priority_scores",
    "response_id": 5,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response6.txt_stdout.txt",
    "code_path": "problem_iter12_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on the remaining capacity and penalizes bins that are over half full.\n    It aims to reduce fragmentation by preferring bins that are almost filled.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score for feasible bins\n    priority_scores = np.where(new_remain_cap >= 0, -new_remain_cap, -np.inf)\n    \n    # Penalize bins that are more than half full\n    half_full_threshold = 0.5 * (np.max(bins_remain_cap) + item)\n    priority_scores = np.where(bins_remain_cap < half_full_threshold, priority_scores, -np.inf)\n    \n    return priority_scores",
    "response_id": 6,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response7.txt_stdout.txt",
    "code_path": "problem_iter12_code7.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on filling bins that are closer to being full,\n    penalizes bins that cannot hold the item, and slightly favors earlier bins\n    to minimize fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high value (small negative) for feasible bins\n    # The closer a bin is to being full, the higher its priority\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 7,
    "obj": 3.9988033506182825,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response8.txt_stdout.txt",
    "code_path": "problem_iter12_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation harshly penalizes overfills, adjusts half-full thresholds,\n    and uses linear biases for bin positions to minimize fragmentation and favor earlier bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Harshly penalize overfills\n    overfill_penalty = np.where(new_remain_cap < 0, -np.inf, 0)\n    \n    # Calculate the priority score: higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, 0) + overfill_penalty\n    \n    # Adjust penalty for bins that are already more than 70% full to avoid them taking more small items\n    half_full_threshold = 0.7 * (np.max(bins_remain_cap) + item)\n    priority_scores[new_remain_cap < half_full_threshold] -= 10\n    \n    # Favor earlier bins with a linear bias\n    num_bins = len(bins_remain_cap)\n    bin_index_penalty = np.linspace(0, 1, num_bins)\n    priority_scores -= bin_index_penalty\n    \n    return priority_scores",
    "response_id": 8,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response9.txt_stdout.txt",
    "code_path": "problem_iter12_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes earlier bins, harshly penalizes overfills,\n    and dynamically adjusts half-full penalties to minimize fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize heavily for overfills\n    overfill_penalty = np.where(new_remain_cap < 0, -np.inf, 0)\n    \n    # Calculate the priority score: higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, 0) + overfill_penalty\n    \n    # Dynamically penalize bins that are more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * (bins_remain_cap + item)\n    half_full_penalty = np.where(half_full_threshold > 0, np.where(new_remain_cap > half_full_threshold, -0.1, 0), 0)\n    \n    # Favor earlier bins slightly by adding a small bonus that decreases with index\n    index_bonus = np.arange(len(bins_remain_cap)) * -0.01\n    \n    # Combine all adjustments into the priority scores\n    priority_scores += half_full_penalty + index_bonus\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter13_response0.txt_stdout.txt",
    "code_path": "problem_iter13_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on remaining capacity, favors early bins, and\n    penalizes overfills harshly while balancing bins that are half-full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize heavily if the item overfills the bin\n    priority_scores = np.where(new_remain_cap < 0, -np.inf, new_remain_cap)\n    \n    # Favor early bins slightly by adding a small bonus based on bin index\n    num_bins = len(bins_remain_cap)\n    early_bin_bonus = np.linspace(1, 0, num_bins)  # Highest bonus for first bin\n    \n    # Balance half-full bins by reducing their priority\n    half_full_threshold = 0.5 * np.max(bins_remain_cap)\n    balance_factor = np.where(bins_remain_cap < half_full_threshold, 0.8, 1)\n    \n    # Combine all factors to get the final priority score\n    priority_scores = priority_scores * balance_factor * early_bin_bonus\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 88.7016354208217,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter13_response1.txt_stdout.txt",
    "code_path": "problem_iter13_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity and penalizes overfills.\n    It favors half-full bins and early bins while simplifying scoring to reduce\n    fragmentation and enhance feasibility.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a base score based on remaining capacity\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize overfills harshly\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Balance the score for bins that are half full or more, penalizing them less\n    half_full_threshold = 0.5 * np.max(bins_remain_cap)\n    priority_scores[bins_remain_cap <= half_full_threshold] += half_full_threshold\n    \n    # Favor early bins slightly by adding a small bonus based on bin index\n    early_bin_bonus = np.arange(len(bins_remain_cap)) * 0.01\n    priority_scores += early_bin_bonus\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 91.2644595133626,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter13_response2.txt_stdout.txt",
    "code_path": "problem_iter13_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on remaining capacity, favors early bins, and\n    penalizes overfills harshly. It balances half-full bins to reduce\n    fragmentation and enhance feasibility.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Favor early bins slightly by adding a small bonus based on bin index\n    bin_count = len(bins_remain_cap)\n    early_bin_bonus = np.linspace(1, 0, bin_count) * 0.1  # Bonus decreases with bin index\n    priority_scores += early_bin_bonus\n    \n    # Penalize overfills heavily\n    priority_scores[new_remain_cap < 0] += -np.inf\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    max_cap = np.max(bins_remain_cap + item)\n    penalty_mask = (bins_remain_cap < 0.5 * max_cap) & (new_remain_cap >= 0)\n    priority_scores[penalty_mask] *= 0.5  # Reduce priority for half-full bins\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 149.30195452732352,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter13_response3.txt_stdout.txt",
    "code_path": "problem_iter13_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity and penalizes bins that are\n    more than half full. It favors bins that are almost filled to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize overfills harshly by setting their score to a very low number\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Favor early bins slightly by adding a small bonus score based on bin index\n    num_bins = len(bins_remain_cap)\n    index_bonus = np.arange(num_bins) / float(num_bins)  # Normalize index to be between 0 and 1\n    priority_scores += index_bonus * 0.01  # Small bonus for earlier bins\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    max_bin_cap = np.max(bins_remain_cap + item)\n    priority_scores = np.where(bins_remain_cap < 0.5 * max_bin_cap, priority_scores, priority_scores * 0.1)\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 21.400079776625464,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter13_response4.txt_stdout.txt",
    "code_path": "problem_iter13_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity and penalizes bins that are\n    more than half full. It favors bins that are almost filled to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize overfills harshly by setting their score to a very low negative number\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Favor early bins by slightly increasing their priority scores\n    num_bins = len(bins_remain_cap)\n    early_bin_bonus = np.linspace(0, 0.1, num_bins)\n    priority_scores += early_bin_bonus\n    \n    # Penalize bins that are more than half full\n    bin_capacity = np.max(bins_remain_cap + item)\n    priority_scores = np.where(bins_remain_cap < 0.5 * bin_capacity, priority_scores, priority_scores - 0.5)\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 149.30195452732352,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]