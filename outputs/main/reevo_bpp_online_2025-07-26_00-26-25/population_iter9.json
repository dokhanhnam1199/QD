[
  {
    "stdout_filepath": "problem_iter8_response0.txt_stdout.txt",
    "code_path": "problem_iter8_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on filling bins that are closer to being full,\n    penalizes bins that cannot hold the item, and slightly favors earlier bins\n    to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores\n    priority_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Favor bins that can still hold the item\n    can_fit_item_mask = new_remain_cap >= 0\n    if np.any(can_fit_item_mask):\n        # Prioritize bins that are closer to being full\n        priority_scores[can_fit_item_mask] = 1 / (1 + new_remain_cap[can_fit_item_mask])\n    \n    # Penalize bins that cannot hold the item\n    priority_scores[~can_fit_item_mask] = -np.inf\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 3.9988033506182825,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response1.txt_stdout.txt",
    "code_path": "problem_iter8_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, recent_bins_usage: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity, penalizes bins that are\n    already more than half full, and prefers bins that have been used more recently.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        recent_bins_usage: Array indicating how recently each bin was used (lower values indicate more recent usage).\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # We give a higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * (bins_remain_cap + item)\n    priority_scores = np.where(new_remain_cap < half_full_threshold, priority_scores, priority_scores / 2)\n    \n    # Boost bins that have been used more recently\n    priority_scores += recent_bins_usage\n    \n    return priority_scores",
    "response_id": 1,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\nTypeError: priority_v2() missing 1 required positional argument: 'recent_bins_usage'\n7\n1\n"
  },
  {
    "stdout_filepath": "problem_iter8_response2.txt_stdout.txt",
    "code_path": "problem_iter8_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on filling bins that have less remaining capacity\n    but can still hold the item. It heavily penalizes bins that cannot hold the\n    item and slightly favors earlier bins to avoid fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority with zero\n    priority_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Favor bins that can still hold the item\n    can_fit_item_mask = new_remain_cap >= 0\n    if np.any(can_fit_item_mask):\n        # Prioritize bins that are closer to being full\n        priority_scores[can_fit_item_mask] = 1 / (1 + new_remain_cap[can_fit_item_mask])\n    \n    # Penalize bins that cannot hold the item by setting their priority to -np.inf\n    priority_scores[~can_fit_item_mask] = -np.inf\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 2,
    "obj": 3.9988033506182825,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response3.txt_stdout.txt",
    "code_path": "problem_iter8_code3.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on filling bins that are closer to being full,\n    penalizes bins that cannot hold the item, and slightly favors earlier bins\n    to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a high value (small negative) for feasible bins\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Favor earlier bins by adding a slight bonus for earlier bins\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 3.9988033506182825,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response4.txt_stdout.txt",
    "code_path": "problem_iter8_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation favors bins that are close to being full to reduce fragmentation\n    and penalizes bins that are overfilled or nearly overfilled. It also considers the\n    utility of each bin and breaks ties strategically.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a base score that decreases with remaining capacity\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (new_remain_cap + 1e-6), -np.inf)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_capacity = 0.5 * np.max(bins_remain_cap)\n    priority_scores = np.where(bins_remain_cap <= half_capacity, priority_scores, priority_scores * 0.2)\n    \n    # Consider bin utility by penalizing bins that are already filled to a significant extent\n    priority_scores = np.where(bins_remain_cap <= 0.1 * np.max(bins_remain_cap), priority_scores * 0.01, priority_scores)\n    \n    # Break ties by slightly favoring earlier bins (lower indices)\n    priority_scores += 1e-7 * np.arange(len(bins_remain_cap))\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 4.078579976067022,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response5.txt_stdout.txt",
    "code_path": "problem_iter8_code5.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on minimizing gaps in bins and avoiding overfill.\n    It uses positive incentives for bins with minimal gaps and harsh penalties for bins that would be overfilled.\n    It also slightly favors earlier bins to avoid creating gaps at the beginning.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Apply a positive incentive for bins with minimal remaining capacity after adding the item\n    priority_scores = np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), -np.inf)\n    \n    # Penalize bins that would be overfilled\n    priority_scores[new_remain_cap < 0] = -np.inf\n    \n    # Slightly favor earlier bins by adding a small positive bonus\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.001 * bin_indices\n    \n    return priority_scores",
    "response_id": 5,
    "obj": 4.038691663342641,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response6.txt_stdout.txt",
    "code_path": "problem_iter8_code6.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation prioritizes bins that are nearly full to reduce fragmentation,\n    penalizes overfills, favors items placed in earlier bins (lower indices), and\n    adjusts penalties for bins that are more than half full.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a base score that decreases with remaining capacity\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    max_capacity = np.max(bins_remain_cap) + item\n    half_full_threshold = 0.5 * max_capacity\n    priority_scores = np.where(bins_remain_cap <= half_full_threshold, priority_scores, priority_scores * 0.1)\n    \n    # Favor earlier bins (lower indices) slightly to break ties\n    priority_scores += 1e-7 * np.arange(len(bins_remain_cap))\n    \n    return priority_scores",
    "response_id": 6,
    "obj": 2.2437175907459115,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response7.txt_stdout.txt",
    "code_path": "problem_iter8_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, bin_usage: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity, penalizes bins that are\n    already more than half full, and factors in the recent usage of bins to avoid\n    overloading frequently used bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n        bin_usage: Array of usage counts for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score based on remaining capacity\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that are already more than half full\n    half_full_threshold = 0.5 * np.max(bins_remain_cap + item)\n    priority_scores = np.where(bins_remain_cap < half_full_threshold, priority_scores, 0)\n    \n    # Penalize bins that have been used more recently\n    usage_penalty = np.max(bin_usage) - bin_usage\n    priority_scores = priority_scores + usage_penalty\n    \n    return priority_scores",
    "response_id": 7,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\nTypeError: priority_v2() missing 1 required positional argument: 'bin_usage'\n7\n1\n"
  },
  {
    "stdout_filepath": "problem_iter8_response8.txt_stdout.txt",
    "code_path": "problem_iter8_code8.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation focuses on reducing fragmentation by favoring bins with minimal\n    remaining capacity post-item addition. Additionally, it penalizes early bins slightly\n    to reduce fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize bins that cannot fit the current item\n    penalty = np.where(new_remain_cap < 0, -np.inf, 0)\n    \n    # Favor bins with minimal remaining capacity post-item\n    priority_scores = penalty + np.where(new_remain_cap >= 0, 1 / (1 + new_remain_cap), 0)\n    \n    # Penalize early bins slightly\n    bin_indices = np.arange(len(bins_remain_cap))\n    priority_scores -= 0.01 * bin_indices\n    \n    return priority_scores",
    "response_id": 8,
    "obj": 3.9988033506182825,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter8_response9.txt_stdout.txt",
    "code_path": "problem_iter8_code9.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation penalizes bins that are nearly full to minimize fragmentation,\n    favors earlier bins to reduce fragmentation across bins, and penalizes overfills.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Initialize priority scores with a base score that decreases with remaining capacity\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that are nearly full (less than 10% remaining capacity)\n    nearly_full_threshold = 0.1 * np.max(bins_remain_cap)\n    priority_scores = np.where(new_remain_cap <= nearly_full_threshold, priority_scores * 0.01, priority_scores)\n    \n    # Break ties by slightly favoring earlier bins (lower indices)\n    priority_scores += 1e-6 * np.arange(len(bins_remain_cap))\n    \n    return priority_scores",
    "response_id": 9,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response0.txt_stdout.txt",
    "code_path": "problem_iter9_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers the remaining capacity, penalizes overfills,\n    favors early bins, minimizes fragmentation, and strategically breaks ties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Returns:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score: higher score for bins that fit the item and are less fragmented\n    priority_scores = np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that are more than half full to avoid taking more small items\n    max_capacity = np.max(bins_remain_cap + item)\n    half_full_threshold = 0.5 * max_capacity\n    priority_scores = np.where(bins_remain_cap < half_full_threshold, priority_scores, 0)\n    \n    # Favor early bins by slightly increasing their priority in case of ties\n    num_bins = len(bins_remain_cap)\n    bin_indices = np.arange(num_bins)\n    priority_scores -= bin_indices * 1e-6  # Small decrement to prioritize early bins\n    \n    return priority_scores",
    "response_id": 0,
    "obj": 12.225767850019958,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response1.txt_stdout.txt",
    "code_path": "problem_iter9_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers remaining capacity, penalizes overfills harshly,\n    favors earlier bins, minimizes fragmentation, and adjusts half-full penalties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize heavily for overfills\n    overfill_penalty = np.where(new_remain_cap < 0, -np.inf, 0)\n    \n    # Calculate the priority score\n    # Give a higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, 0) + overfill_penalty\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * np.max(bins_remain_cap + item)\n    half_full_penalty = np.where(bins_remain_cap < half_full_threshold, 0, -10)\n    priority_scores += half_full_penalty\n    \n    # Favor earlier bins with a slight bias\n    num_bins = len(bins_remain_cap)\n    bin_index_penalty = np.linspace(0, 0.5, num_bins)\n    priority_scores -= bin_index_penalty\n    \n    return priority_scores",
    "response_id": 1,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response2.txt_stdout.txt",
    "code_path": "problem_iter9_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers remaining capacity, penalizes overfills harshly,\n    favors earlier bins, minimizes fragmentation, and adjusts half-full penalties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Calculate the priority score\n    # We give a higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, -np.inf)\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_penalty = np.where(bins_remain_cap < 0.5 * np.max(bins_remain_cap + item), priority_scores / 2, priority_scores)\n    \n    # Favor earlier bins slightly by adding a small incremental bonus for earlier bins\n    num_bins = len(bins_remain_cap)\n    bin_index_bonus = np.linspace(0, 1, num_bins)  # Creates a bonus from 0 to 1 for each bin index\n    \n    # Adjust the priority scores with the bonus and penalties\n    final_priority_scores = half_full_penalty + bin_index_bonus\n    \n    return final_priority_scores",
    "response_id": 2,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response3.txt_stdout.txt",
    "code_path": "problem_iter9_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers remaining capacity, penalizes overfills harshly,\n    favors earlier bins, minimizes fragmentation, and adjusts half-full penalties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize heavily for overfills\n    overfill_penalty = np.where(new_remain_cap < 0, -np.inf, 0)\n    \n    # Calculate the priority score\n    # Give a higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, 0) + overfill_penalty\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * np.max(bins_remain_cap + item)\n    half_full_penalty = np.where(bins_remain_cap < half_full_threshold, 0, -0.1)\n    \n    # Favor earlier bins slightly\n    index_penalty = -0.01 * np.arange(len(bins_remain_cap))\n    \n    # Combine penalties\n    priority_scores += half_full_penalty + index_penalty\n    \n    return priority_scores",
    "response_id": 3,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter9_response4.txt_stdout.txt",
    "code_path": "problem_iter9_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This implementation considers remaining capacity, penalizes overfills harshly,\n    favors earlier bins, minimizes fragmentation, and adjusts half-full penalties.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the remaining capacity after adding the item\n    new_remain_cap = bins_remain_cap - item\n    \n    # Penalize heavily for overfills\n    overfill_penalty = np.where(new_remain_cap < 0, -np.inf, 0)\n    \n    # Calculate the priority score\n    # Give a higher score if the remaining capacity is small (i.e., almost full)\n    priority_scores = -np.where(new_remain_cap >= 0, new_remain_cap, 0) + overfill_penalty\n    \n    # Penalize bins that are already more than half full to avoid them taking more small items\n    half_full_threshold = 0.5 * np.max(bins_remain_cap + item)\n    half_full_penalty = np.where(bins_remain_cap < half_full_threshold, 0, -0.1)\n    \n    # Favor earlier bins slightly by adding a small bonus that decreases with index\n    index_bonus = np.arange(len(bins_remain_cap)) * -0.01\n    \n    # Combine all adjustments into the priority scores\n    priority_scores += half_full_penalty + index_bonus\n    \n    return priority_scores",
    "response_id": 4,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  }
]