```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Combines adaptive weights, dynamic penalties, and strategic randomness."""

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    can_fit = bins_remain_cap >= item
    bin_capacity = bins_remain_cap.max()

    if not np.any(can_fit):
        return np.full_like(priorities, -1.0)

    valid_bins = np.where(can_fit)[0]
    remaining_after = bins_remain_cap[can_fit] - item
    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity

    # Waste Minimization
    waste = remaining_after
    tightness = 1 / (waste + 0.0001)

    # Target Fill Level
    target_fill_level = 0.8 * bin_capacity
    fill_level = bins_remain_cap[can_fit]
    fill_diff = np.abs(fill_level - target_fill_level)
    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))

    # Dynamic Near-Full Management
    near_full_threshold = 0.15 * bin_capacity
    is_near_full = remaining_after < near_full_threshold
    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0)

    # Smaller Item Bonus
    small_item_threshold = bin_capacity * 0.3
    if item < small_item_threshold:
        almost_full_threshold = bin_capacity * 0.08
        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))
    else:
        almost_full_bonus = 0.0

    # Larger Item Penalty
    large_item_threshold = bin_capacity * 0.7
    if item > large_item_threshold:
        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.15 * bin_capacity), -0.8 * (item/bin_capacity), 0.0)
    else:
        small_space_penalty = 0.0

    # Adaptive Weighting
    item_size_factor = item / bin_capacity
    utilization_factor = np.mean(bins_utilization)
    remaining_capacity_factor = np.mean(bins_remain_cap[can_fit] / bin_capacity)

    tightness_weight = 0.3 * (1 - item_size_factor) * (1 + utilization_factor) * (1 + remaining_capacity_factor)
    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor) * (1 - remaining_capacity_factor)
    near_full_weight = 0.15
    small_item_weight = 0.075
    large_item_weight = 0.075

    # Strategic Randomness (Tie-breaking)
    num_valid_bins = len(valid_bins)
    if num_valid_bins > 1:
        best_priority = np.max((tightness_weight * tightness +
                                   fill_weight * fill_score +
                                   near_full_weight * near_full_penalty +
                                   small_item_weight * almost_full_bonus +
                                   large_item_weight * small_space_penalty))

        potential_bins = valid_bins[np.isclose((tightness_weight * tightness +
                                   fill_weight * fill_score +
                                   near_full_weight * near_full_penalty +
                                   small_item_weight * almost_full_bonus +
                                   large_item_weight * small_space_penalty), best_priority)]
        if len(potential_bins) > 1:
             chosen_bin = np.random.choice(potential_bins)
             #Assign high probability to selected bin, so that it will be packed
             randomness = np.zeros(len(valid_bins))
             chosen_idx = np.where(valid_bins == chosen_bin)[0]
             randomness[chosen_idx] = 0.01
        else:
            randomness = np.zeros(len(valid_bins))
    else:
         randomness = np.zeros(len(valid_bins))

    # Learning Rate (Bin Diversity Reward)
    learning_rate = 0.01
    bin_diversity_reward = (1 / (np.std(bins_remain_cap[can_fit]) + 0.0001)) * learning_rate

    priorities[valid_bins] = (tightness_weight * tightness +
                               fill_weight * fill_score +
                               near_full_weight * near_full_penalty +
                               small_item_weight * almost_full_bonus +
                               large_item_weight * small_space_penalty +
                               randomness + bin_diversity_reward)

    return priorities
```
