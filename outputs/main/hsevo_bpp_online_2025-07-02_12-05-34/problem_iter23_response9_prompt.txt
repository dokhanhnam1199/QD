{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Adaptive weights, strategic randomness, problem-specific objectives by adaptive\n    exploration vs exploitation.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.15 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0)\n\n    # Smaller Item Bonus\n    small_item_threshold = bin_capacity * 0.3\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty\n    large_item_threshold = bin_capacity * 0.7\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.15 * bin_capacity), -0.8 * (item/bin_capacity), 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n    remaining_capacity_factor = np.mean(bins_remain_cap[can_fit] / bin_capacity)\n\n    tightness_weight = 0.3 * (1 - item_size_factor) * (1 + utilization_factor) * (1 + remaining_capacity_factor)\n    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor) * (1 - remaining_capacity_factor)\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # Strategic Randomness\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor) * (1 + remaining_capacity_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # Learning Rate & bin diversity reward\n    learning_rate = 0.01\n    bin_diversity_reward = (1 / (np.std(bins_remain_cap[can_fit]) + 0.0001)) * learning_rate\n\n    #Adaptive exploration vs exploitation\n    exploration_prob = 0.1  # Probability of exploration\n\n    if np.random.rand() < exploration_prob: #Explore by reducing the weight\n        tightness_weight *= (1 - learning_rate)\n        fill_weight *= (1 + learning_rate)\n    else: # Exploit by increasing the weight\n       tightness_weight *= (1 + learning_rate)\n       fill_weight *= (1 - learning_rate)\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness + bin_diversity_reward)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Enhanced heuristic for online bin packing, focusing on waste minimization,\n    target fill levels, dynamic adjustments, and strategic randomness.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization: Emphasize smaller waste\n    waste = remaining_after\n    tightness = np.exp(-5 * waste / bin_capacity)  # Exponential to favor smaller waste\n\n    # Target Fill Level: Aim for a range, penalize both under and over\n    target_fill_level_low = 0.70 * bin_capacity\n    target_fill_level_high = 0.90 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n\n    fill_score = np.where(\n        fill_level < target_fill_level_low,\n        np.exp(-((fill_level - target_fill_level_low)**2) / (2 * (bin_capacity * 0.1)**2)),  # Gaussian penalty for underfill\n        np.where(\n            fill_level > target_fill_level_high,\n            np.exp(-((fill_level - target_fill_level_high)**2) / (2 * (bin_capacity * 0.1)**2)),  # Gaussian penalty for overfill\n            1.0  # Ideal: within target range\n        )\n    )\n\n    # Dynamic Near-Full Management: Stronger penalty, adaptive threshold\n    near_full_threshold = 0.15 * bin_capacity  # Slightly larger threshold\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item / bin_capacity), 0.0)  # Stronger penalty\n\n    # Anticipatory Penalty: If remaining space is too small for common items\n    avg_item_size = 0.2 * bin_capacity  # Estimate average item size\n    anticipatory_penalty = np.where(remaining_after < (0.5 * avg_item_size), -0.5, 0.0)  # Penalize if too small\n\n    # Item Size Consideration: Reward fitting larger items well\n    item_fit_score = np.exp(-np.abs(remaining_after - (0.1 * bin_capacity)) / (bin_capacity * 0.2)) if item > (0.5 * bin_capacity) else 0.0\n\n    # Adaptive Weighting: Based on item size and average bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.4 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.3 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.15\n    anticipatory_weight = 0.1\n    item_fit_weight = 0.05\n\n    # Strategic Randomness: Scaled by item size and decreased over time\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # Introduce a decay factor over time (simulated by a global variable or function)\n    # decay_factor = get_decay_factor()  # Retrieve a decay factor that decreases over time\n    # randomness *= decay_factor\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               anticipatory_weight * anticipatory_penalty +\n                               item_fit_weight * item_fit_score +\n                               randomness)\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), we see that they are identical.\nComparing (3rd) vs (4th), we see the 3rd has \"Anticipatory Near-Full Penalty (Stronger penalty, scaled by item size)\" and \"Strategic Randomness (Controlled, decays slower for smaller items)\", while the 4th does not. The 4th uses item size and bin utilization in adaptive weighting, while the 3rd only uses item size.\nComparing (2nd worst) vs (worst), we see the worst one uses much more hyperparameter and `scipy`, `random`, `math`, `torch`, which may not be necessary and cause overhead.\nComparing (1st) vs (11th), we see the 1st has many considerations like waste minimization, target fill level, and near-full management, while the 11th is just the start of the function.\nComparing (19th) vs (20th), the 20th enhanced heuristic focuses on a range of target fill levels, using Gaussian penalties for both underfill and overfill, and includes an anticipatory penalty based on average item size and an item fit score. The 19th does not.\nOverall: Top heuristics combine waste minimization, target fill level, dynamic penalties (near full, smaller item bonus, larger item penalty), adaptive weighting (item size, utilization), and strategic randomness. The weights are often made adaptive with learning rate to further enhance the performance. High-performing heuristics often include mechanisms to reduce fragmentation, like an anticipatory penalty or an item fit score. Less effective heuristics either lack key components, use simpler calculations, or fail to adapt to item sizes. Over-parameterization also lead to low performance.\n- \nOkay, let's redefine \"Current self-reflection\" to design better bin packing heuristics, while avoiding the pitfalls of \"Ineffective self-reflection.\" Here's a breakdown:\n\n*   **Keywords:** Adaptive weighting, dynamic penalties/bonuses, target fill, stochasticity, item characteristics, bin state.\n\n*   **Advice:** Focus on *how* to make these elements adaptive and dynamic. Develop clear, measurable metrics for bin utilization and item characteristics to drive adaptation. Implement decaying randomness.\n\n*   **Avoid:** Overly complex rules, focusing solely on individual factors in isolation, and premature optimization (code duplication before concept validation).\n\n*   **Explanation:** Shift from *what* factors to consider (waste minimization, etc.) to *how* they interact dynamically. The key is creating a feedback loop where item properties and bin states influence weighting, penalties, and randomness. Simpler core logic with sophisticated adaptation is preferred.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}