[
  {
    "stdout_filepath": "problem_iter17_response0.txt_stdout.txt",
    "code_path": "problem_iter17_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weights, dynamic penalties, and decaying randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.78 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.7 * (item / bin_capacity), 0.0)\n\n    # Adaptive Weighting: item size & bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.4 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.2\n\n    # Decaying Stochasticity:\n    randomness_scale = 0.015 / (1 + item_size_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 0,
    "tryHS": true,
    "obj": 0.8276824890307208,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response1.txt_stdout.txt",
    "code_path": "problem_iter17_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weights, dynamic near-full penalty, and decaying randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0)\n\n    # Adaptive Weighting: item size & bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.5 * (1 - item_size_factor)\n    fill_weight = 0.5 * (1 + item_size_factor)\n    near_full_weight = 0.2\n\n    # Decaying randomness scaled by item size and remaining capacity\n    randomness_scale = 0.01 * (1 + item_size_factor) * (1 + bins_remain_cap[can_fit] / bin_capacity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.437574790586359,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response2.txt_stdout.txt",
    "code_path": "problem_iter17_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive weights, near-empty bonus, decaying randomness, and dynamic fill target.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level (Dynamic)\n    current_utilization = np.mean((bin_capacity - bins_remain_cap) / bin_capacity)\n    target_fill_level = 0.7 + 0.1 * current_utilization # Adjust dynamically\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level * bin_capacity)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Empty Bonus (Encourage initial bin use)\n    near_empty_threshold = 0.9 * bin_capacity\n    is_near_empty = bins_remain_cap[can_fit] > near_empty_threshold\n    near_empty_bonus = np.where(is_near_empty, 0.2 * (1 - item/bin_capacity), 0.0)\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8 * (item/bin_capacity), 0.0)\n\n    # Adaptive Weighting: item size & bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.4 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_empty_weight = 0.1\n    near_full_weight = 0.1\n\n    # Decaying Randomness\n    if not hasattr(priority_v2, \"time_step\"):\n        priority_v2.time_step = 1\n    else:\n        priority_v2.time_step += 1\n    exploration_factor = np.exp(-priority_v2.time_step / 1000.0)\n    randomness_scale = 0.01 * (1 + item_size_factor) * exploration_factor # Decay over time\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_empty_weight * near_empty_bonus +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 2.762265656162749,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response3.txt_stdout.txt",
    "code_path": "problem_iter17_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic: Combines dynamic fill target, near-full penalty, and intelligent stochasticity based on item size and bin utilization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Dynamic Target Fill Level: Adaptive to Item Size\n    item_size_ratio = item / bin_capacity\n    dynamic_target_fill = 0.75 * bin_capacity * (1 - 0.2 * item_size_ratio)\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - dynamic_target_fill)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Management with Dynamic Penalty:\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity) * (1 + item_size_ratio), 0.0)\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Intelligent Stochasticity:\n    bin_similarity = np.std(bins_utilization)\n    randomness_scale = 0.01 * (1 + item_size_ratio) * (1 - bin_similarity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n    \n    #Adaptive Weights\n    tightness_weight = 0.40\n    fill_weight = 0.30\n    near_full_weight = 0.15\n    randomness_weight = 0.15\n\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness_weight * randomness)\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 2.712405265257284,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response4.txt_stdout.txt",
    "code_path": "problem_iter17_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill, near-empty bonus, and decaying randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Target fill level (adaptive)\n    target_fill = 0.75 * bin_capacity\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / bin_capacity)\n    priorities[valid_bins] += fill_priority * 0.4  # Increased weight\n\n    # Near-full/Near-empty\n    nearly_full_threshold = 0.1 * bin_capacity\n    nearly_empty_threshold = 0.9 * bin_capacity\n\n    near_full_penalty = np.where(remaining_after < nearly_full_threshold, -0.5, 0.0)\n    near_empty_bonus = np.where(bins_remain_cap[can_fit] > nearly_empty_threshold, 0.2, 0.0)  # Increase bonus\n    priorities[valid_bins] += near_full_penalty + near_empty_bonus\n\n    # Decaying randomness based on item size\n    item_size_weight = item / bin_capacity\n    randomness = np.random.rand(len(valid_bins)) * 0.02 * (1 - item_size_weight)\n    priorities[valid_bins] += randomness\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 146.94854407658556,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response5.txt_stdout.txt",
    "code_path": "problem_iter17_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weighting and dynamic elements with decaying randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0)\n\n    # Smaller Item Bonus\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.05 * bin_capacity), -0.8 * (item/bin_capacity), 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n    learning_rate = 0.1\n\n    tightness_weight = 0.35\n    fill_weight = 0.35\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    tightness_weight += learning_rate * (1 - item_size_factor) * (1 + utilization_factor) - tightness_weight\n    fill_weight += learning_rate * (1 + item_size_factor) * (1 - utilization_factor) - fill_weight\n\n    # Decaying Randomness based on item size and bin utilization\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 6.352213801356207,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response6.txt_stdout.txt",
    "code_path": "problem_iter17_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, adaptive bonuses/penalties, and decaying randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    # Waste minimization (Best-Fit)\n    waste = bins_remain_cap[can_fit] - item\n    priorities[can_fit] = 1.0 / (1e-6 + waste)\n\n    # Target fill level\n    max_bin_cap = np.max(bins_remain_cap)\n    target_fill = 0.8 * max_bin_cap\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / max_bin_cap)\n    priorities[can_fit] += fill_priority * 0.1\n\n    # Near-full penalty, scaled by item size\n    nearly_full_threshold = 0.1 * max_bin_cap\n    nearly_full = bins_remain_cap < nearly_full_threshold\n    priorities[nearly_full] -= 0.4 * (item / max_bin_cap) #Larger items get bigger penalty.\n\n    # Small item bonus to almost full bins\n    small_item_threshold = 0.2 * max_bin_cap\n    if item < small_item_threshold:\n      almost_full_threshold = 0.1 * max_bin_cap\n      almost_full_valid_bins = bins_remain_cap[can_fit] < almost_full_threshold + item\n      almost_full_indices = np.where(can_fit)[0][almost_full_valid_bins]\n      priorities[almost_full_indices] += 0.2\n\n    # Adaptive Randomness (decaying with item size and remaining capacity)\n    randomness = np.random.rand(np.sum(can_fit)) * 0.01 * (1 - item/max_bin_cap) * (bins_remain_cap[can_fit] / max_bin_cap)\n    priorities[can_fit] += randomness\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response7.txt_stdout.txt",
    "code_path": "problem_iter17_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, dynamic target fill, near-full penalty, and intelligent stochasticity.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Dynamic Target Fill Level\n    item_size_ratio = item / bin_capacity\n    dynamic_target_fill = 0.75 * bin_capacity * (1 - 0.2 * item_size_ratio)\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - dynamic_target_fill)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity) , 0.0)\n\n    # Intelligent Stochasticity\n    bin_similarity = np.std(bins_utilization)\n    randomness_scale = 0.01 * (1 + item_size_ratio) * (1 - bin_similarity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # Adaptive Weighting (tuned)\n    tightness_weight = 0.40\n    fill_weight = 0.30\n    near_full_weight = 0.15\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 2.0941364180295174,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response8.txt_stdout.txt",
    "code_path": "problem_iter17_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, dynamic penalties, and adaptive randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    max_bin_cap = bins_remain_cap.max()\n    bins_utilization = (max_bin_cap - bins_remain_cap[can_fit]) / max_bin_cap\n\n    # Waste minimization\n    waste = remaining_after\n    tightness = 1.0 / (1e-6 + waste)\n    tightness_weight = 0.4\n\n    # Target fill level\n    target_fill = 0.75 * max_bin_cap\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / max_bin_cap)\n    fill_weight = 0.3\n\n    # Near-full penalty and near-empty bonus\n    nearly_full_threshold = 0.1 * max_bin_cap\n    nearly_empty_threshold = 0.9 * max_bin_cap\n    near_full_penalty = np.where(remaining_after < nearly_full_threshold, -0.5, 0.0)\n    near_empty_bonus = np.where(bins_remain_cap[can_fit] > nearly_empty_threshold, 0.1, 0.0)\n    penalty_weight = 0.2\n\n    # Item size consideration (adaptive randomness)\n    item_size_weight = item / max_bin_cap\n    randomness_scale = 0.01 * (1 - item_size_weight)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n    random_weight = 0.1\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                              fill_weight * fill_priority +\n                              penalty_weight * (near_full_penalty + near_empty_bonus) +\n                              random_weight * randomness)\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 1.6753091344236206,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response9.txt_stdout.txt",
    "code_path": "problem_iter17_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weighting, dynamic target fill, and intelligent stochasticity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # 1. Waste Minimization\n    waste = remaining_after\n    inverse_waste = 1 / (waste + 0.0001)\n    tightness = inverse_waste\n\n    # 2. Dynamic Target Fill Level\n    item_size_ratio = item / bin_capacity\n    dynamic_target_fill = 0.75 * bin_capacity * (1 - 0.2 * item_size_ratio)\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - dynamic_target_fill)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # 3. Near-Full Management with Dynamic Penalty\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0)\n\n    # 4. Intelligent Stochasticity\n    bin_similarity = np.std(bins_utilization)\n    randomness_scale = 0.01 * (1 + item_size_ratio) * (1 - bin_similarity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # 5. Adaptive Weighting\n    tightness_weight = 0.40\n    fill_weight = 0.30\n    near_full_weight = 0.30 # Increased weight\n    \n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 1.705225368966895,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response0.txt_stdout.txt",
    "code_path": "problem_iter18_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced heuristic: adaptive weights, dynamic near-full, item size considerations, and randomness,\n       with improved waste management and exploration.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization: Exponential scaling to penalize large waste more severely\n    waste = remaining_after\n    waste_penalty = np.exp(waste / bin_capacity)\n\n    # Target Fill Level: Gaussian target for a soft preference\n    target_fill_level = 0.8 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = (fill_level - target_fill_level)\n    fill_score = np.exp(-(fill_diff**2) / (2 * (bin_capacity * 0.1)**2))  # Gaussian\n\n    # Dynamic Near-Full Management: Contextual penalty\n    near_full_threshold = 0.15 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item / bin_capacity) * (1 - bins_utilization), 0.0)\n\n    # Smaller Item Bonus: Consider bins close to full, proportional to item size\n    small_item_threshold = bin_capacity * 0.3\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001)) * (item / small_item_threshold)\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty: Only if it leads to very low bin utilization\n    large_item_threshold = bin_capacity * 0.7\n    if item > large_item_threshold:\n        small_space_threshold = 0.15 * bin_capacity  # Increased threshold\n        small_space_penalty = np.where(remaining_after < small_space_threshold, -0.8 * (item / bin_capacity) * (1 + bins_utilization), 0.0)\n    else:\n        small_space_penalty = 0.0\n    \n    # Encourage balanced bin utilization\n    balance_bonus = -np.abs(bins_utilization - np.mean(bins_utilization))\n\n    # Adaptive Weighting: Enhanced sensitivity\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    waste_weight = 0.30 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.30 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n    balance_weight = 0.1\n\n    # Stochasticity: Adjusted scaling for better exploration, reduced for very large items\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor) * (1 - (item > 0.9 * bin_capacity)) # Reduced for large items\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (waste_weight / waste_penalty +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               balance_weight * balance_bonus +\n                               randomness)\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 37.49501396090945,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response1.txt_stdout.txt",
    "code_path": "problem_iter18_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced heuristic with refined adaptive weights, dynamic strategies, and controlled randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # 1. Waste Minimization (Tightness) - Enhanced\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)  # Avoid division by zero\n\n    # 2. Target Fill Level - Adaptive Target\n    # Target adjusts based on average remaining capacity and item size\n    avg_remaining = np.mean(bins_remain_cap[can_fit])\n    target_fill_level = min(0.9 * bin_capacity, avg_remaining + 0.1*bin_capacity) # Target near avg remaining, up to 90% full\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.25))  # Adjusted scaling\n\n    # 3. Dynamic Near-Full Management - Aggressive\n    near_full_threshold = 0.10 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item / bin_capacity), 0.0) # Increased penalty\n\n    # 4. Item Size Bonuses/Penalties - Context Aware\n    small_item_threshold = bin_capacity * 0.2\n    large_item_threshold = bin_capacity * 0.8\n\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.05 * bin_capacity), -0.8 * (item / bin_capacity), 0.0) # Stricter penalty\n    else:\n        small_space_penalty = 0.0\n\n    # 5. Bin Diversity Encouragement\n    # Penalize bins that are very similar in remaining capacity to promote diversity\n    capacity_std = np.std(bins_remain_cap[can_fit])\n    diversity_bonus = np.exp(-capacity_std / bin_capacity) # High std -> High bonus.\n\n    # 6. Adaptive Weighting Scheme - More Dynamic\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n    remaining_capacity_factor = avg_remaining / bin_capacity\n\n    # Weights now react to item size, utilization and average remaning capacity\n    tightness_weight = 0.3 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.3 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.2 * (1 - remaining_capacity_factor) # Less remaining capacity -> More importance on near full\n    small_item_weight = 0.1 * (1 + item_size_factor) # Smaller items -> more importance\n    large_item_weight = 0.1 * (1 - item_size_factor) # Larger items -> less importance\n\n    # 7. Controlled Stochasticity - Adaptive Scale\n    # Randomness scales with item size, utilization, and bin fill level\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor) * (1 - remaining_capacity_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # 8. Combine Priorities\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               0.05 * diversity_bonus +\n                               randomness)\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 57.95771838851217,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response2.txt_stdout.txt",
    "code_path": "problem_iter18_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced heuristic: adaptive weights, dynamic near-full, item size considerations, learning rate and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity  # Slightly higher target\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.15 * bin_capacity # Adjusted Threshold\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0) # Increased Penalty\n\n    # Smaller Item Bonus (if item fits nearly perfectly into a near-full bin)\n    small_item_threshold = bin_capacity * 0.3 #Adjusted Threshold\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08 # Adjusted Threshold\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty (if placing it leaves very little space)\n    large_item_threshold = bin_capacity * 0.7\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.15 * bin_capacity), -0.8 * (item/bin_capacity), 0.0) # Increased Penalty\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting: item size & bin utilization & bin remaining capacity\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n    remaining_capacity_factor = np.mean(bins_remain_cap[can_fit] / bin_capacity)\n\n    tightness_weight = 0.3 * (1 - item_size_factor) * (1 + utilization_factor) * (1 + remaining_capacity_factor) #increased weight for tightness\n    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor) * (1 - remaining_capacity_factor) #increased weight for fill_score\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # Stochasticity scaled by item size and bin utilization\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor) * (1 + remaining_capacity_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # Learning Rate\n    learning_rate = 0.01\n    #Bin Diversity Reward\n    bin_diversity_reward = (1 / (np.std(bins_remain_cap[can_fit]) + 0.0001)) * learning_rate\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness + bin_diversity_reward)\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 21.041084962106105,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response3.txt_stdout.txt",
    "code_path": "problem_iter18_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced heuristic: adaptive weights, dynamic near-full, item size considerations, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization (refined)\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level (adaptive)\n    target_fill_level = 0.7 * bin_capacity # Adjusted target fill\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management (enhanced)\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0) # Increased penalty\n\n    # Smaller Item Bonus (if item fits nearly perfectly into a near-full bin) - Modified bonus calculation\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08 # Tighter threshold\n        almost_full_bonus = np.where(is_near_full, np.exp(-remaining_after / (almost_full_threshold + 0.0001)), 0.0) # Only apply bonus if near full\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty (if placing it leaves very little space) - Modified penalty and threshold\n    large_item_threshold = bin_capacity * 0.7\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.05 * bin_capacity), -0.8 * (item/bin_capacity), 0.0) # Increased penalty, tighter threshold\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting: item size & bin utilization (refined)\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization) if len(bins_utilization) > 0 else 0.0 #Handling empty bins_utilization case\n\n    tightness_weight = 0.4 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.125\n    small_item_weight = 0.05 # Slightly reduced weight\n    large_item_weight = 0.025 # Significantly reduced weight\n\n\n    # Stochasticity scaled by item size and bin utilization (adaptive scaling)\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # Bin diversity penalty - encourages using a wider range of bins\n    bin_diversity_bonus = np.zeros_like(bins_remain_cap[can_fit], dtype=float)\n    unique_capacities = np.unique(bins_remain_cap)\n    if len(unique_capacities) > 1:  #Give some diversity bonus\n        bin_diversity_bonus = 0.01 * (bins_remain_cap[can_fit] / bin_capacity)  #Normalize between 0-0.01\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness + bin_diversity_bonus)\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 1.3262863980853679,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter18_response4.txt_stdout.txt",
    "code_path": "problem_iter18_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced heuristic: adaptive weights, dynamic near-full, item size considerations, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization (Inverse Waste)\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity  # Slightly higher target\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.25)) # Adjusted scaling\n\n    # Dynamic Near-Full Management - Stronger Penalty\n    near_full_threshold = 0.1 * bin_capacity  # Tighter threshold\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0)  # Stronger penalty\n\n    # Smaller Item Bonus (if item fits nearly perfectly into a near-full bin) - More nuanced\n    small_item_threshold = bin_capacity * 0.25\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08 # Even more strict almost full\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001)) * (1 - (item / small_item_threshold))  # Scale bonus by item size\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty (if placing it leaves very little space) - Stronger penalty and Adaptive\n    large_item_threshold = bin_capacity * 0.75\n    if item > large_item_threshold:\n        small_space_threshold = 0.1 * bin_capacity\n        small_space_penalty = np.where(remaining_after < small_space_threshold, -0.8 * (item/bin_capacity) * (1 - (bin_capacity - item)/bin_capacity), 0.0) #Adaptive penalty based on remaining space.\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting: item size & bin utilization - Refined\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.4 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.1\n    small_item_weight = 0.05\n    large_item_weight = 0.05\n\n    # Stochasticity scaled by item size and bin utilization - Reduced and controlled\n    randomness_scale = 0.01 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # Introduce a bin diversity factor.  Prioritize bins that have different fill levels compared to average\n    bin_fill_levels = bin_capacity - bins_remain_cap[can_fit]\n    avg_fill_level = np.mean(bin_fill_levels)\n    diversity_factor = np.abs(bin_fill_levels - avg_fill_level) / bin_capacity\n    diversity_weight = 0.02\n    diversity_bonus = diversity_weight * diversity_factor\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness + diversity_bonus)\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 1.685281212604716,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter19_response0.txt_stdout.txt",
    "code_path": "problem_iter19_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                target_fill_level_ratio: float = 0.6129489691159813,\n                fill_score_decay_rate: float = 0.27595081121759657,\n                near_full_threshold_ratio: float = 0.14761463123689608,\n                near_full_penalty_factor: float = 0.8047855504286721,\n                tightness_weight_base: float = 0.35410376190024634,\n                fill_weight_base: float = 0.2805577825502325,\n                near_full_weight: float = 0.2764121461301743,\n                randomness_scale_factor: float = 0.015075750478632508,\n                waste_epsilon: float = 0.00024461288975876234) -> np.ndarray:\n    \"\"\"Combines adaptive weights, dynamic penalties, and decaying randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.487435181491823,
    "exec_success": true
  }
]