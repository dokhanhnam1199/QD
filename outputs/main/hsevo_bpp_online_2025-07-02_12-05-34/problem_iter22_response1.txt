import numpy as np

def priority_v2(item: float,
                bins_remain_cap: np.ndarray,
                target_fill_level_ratio: float = 0.9200786349575198,
                fill_score_decay_rate_ratio: float = 0.2243161758531247,
                near_full_threshold_ratio: float = 0.15981331338518862,
                near_full_penalty_ratio: float = 0.7968528568852987,
                learning_rate: float = 0.11668844443659572,
                tightness_weight: float = 0.39276653401943684,
                fill_weight: float = 0.25966518027318164,
                near_full_weight: float = 0.18353923790727739,
                random_weight: float = 0.18167886877990497,
                randomness_scale_factor: float = 0.04845836413284313,
                waste_minimization_epsilon: float = 0.0006712555456305034) -> np.ndarray:
    """Combines waste minimization, target fill, dynamic penalties, adaptive weighting, and decaying randomness based on item size and bin utilization."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    can_fit = bins_remain_cap >= item

    if not np.any(can_fit):
        return np.full_like(priorities, -1.0)

    valid_bins = np.where(can_fit)[0]
    remaining_after = bins_remain_cap[can_fit] - item
    bin_capacity = bins_remain_cap.max()
    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity

    # Waste Minimization
    waste = remaining_after
    tightness = 1 / (waste + waste_minimization_epsilon)

    # Target Fill Level
    target_fill_level = target_fill_level_ratio * bin_capacity
    fill_level = bins_remain_cap[can_fit]
    fill_diff = np.abs(fill_level - target_fill_level)
    fill_score = np.exp(-fill_diff / (bin_capacity * fill_score_decay_rate_ratio))

    # Dynamic Near-Full Management
    near_full_threshold = near_full_threshold_ratio * bin_capacity
    is_near_full = remaining_after < near_full_threshold
    near_full_penalty = np.where(is_near_full, -near_full_penalty_ratio * (item/bin_capacity), 0.0)


    item_size_factor = item / bin_capacity
    utilization_factor = np.mean(bins_utilization)


    tightness_weight += learning_rate * (1 - item_size_factor) * (1 + utilization_factor) - tightness_weight
    fill_weight += learning_rate * (1 + item_size_factor) * (1 - utilization_factor) - fill_weight

    # Decaying Randomness based on item size and bin utilization
    randomness_scale = randomness_scale_factor * (1 + item_size_factor) * (1 - utilization_factor)
    randomness = np.random.normal(0, randomness_scale, len(valid_bins))

    priorities[valid_bins] = (tightness_weight * tightness +
                               fill_weight * fill_score +
                               near_full_weight * near_full_penalty +
                               random_weight * randomness)

    return priorities
