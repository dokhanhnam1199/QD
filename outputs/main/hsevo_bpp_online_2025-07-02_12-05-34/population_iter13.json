[
  {
    "stdout_filepath": "problem_iter11_response0.txt_stdout.txt",
    "code_path": "problem_iter11_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, target fill, waste minimization, and randomness with dynamic weights.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        priorities[:] = np.random.rand(len(priorities)) * 0.0001\n        return priorities\n\n    remaining_space = bins_remain_cap[valid_bins] - item\n    fit_score = 1.0 / (remaining_space + 0.0001)\n\n    target_fill = bins_remain_cap.max() * 0.75\n    fill_level_diff = np.abs(bins_remain_cap[valid_bins] - target_fill)\n    fill_level_score = 1.0 / (fill_level_diff + 0.0001)\n\n    waste_threshold = bins_remain_cap.max() * 0.25\n    waste_score = np.where(remaining_space > waste_threshold, 0.1, 1.0)\n\n    # Adaptive Weighting based on item size.\n    if item > bins_remain_cap.max() * 0.5:\n        fit_weight = 0.3\n        fill_weight = 0.3\n        waste_weight = 0.4  # Prioritize waste for larger items\n    else:\n        fit_weight = 0.6\n        fill_weight = 0.3\n        waste_weight = 0.1\n\n    combined_score = (fit_weight * fit_score + fill_weight * fill_level_score + waste_weight * waste_score)\n\n    priorities[valid_bins] = combined_score\n    priorities[valid_bins] += np.random.rand(np.sum(valid_bins)) * 0.1 # Add randomness\n\n    # Near-full penalty from priority_v1\n    remaining_after_add = bins_remain_cap[valid_bins] - item\n    near_full_penalty = np.where(remaining_after_add < (0.1*bins_remain_cap.max()), -0.5, 0.0)\n    priorities[valid_bins] += near_full_penalty\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 5.055843637814125,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response1.txt_stdout.txt",
    "code_path": "problem_iter11_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, target fill, near-full penalty, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float) - np.inf\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        # Best fit - Minimize waste\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] = -waste\n\n        # Target fill level\n        target_capacity = 0.75 * bins_remain_cap.max()\n        capacity_diff = np.abs(bins_remain_cap[valid_bins] - target_capacity)\n        priorities[valid_bins] += 0.5 / (capacity_diff + 0.0001)\n\n        # Near-full penalty\n        remaining_after_add = bins_remain_cap[valid_bins] - item\n        near_full_penalty = np.where(remaining_after_add < (0.1*bins_remain_cap.max()), -0.5, 0.0)\n        priorities[valid_bins] += near_full_penalty\n\n        # Randomness\n        priorities[valid_bins] += np.random.rand(np.sum(valid_bins)) * 0.01\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.058635819704831,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response2.txt_stdout.txt",
    "code_path": "problem_iter11_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, near-full penalty, and adaptive weights.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n\n    # Waste minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target fill level\n    target_fill_level = 0.75 * bins_remain_cap.max()\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bins_remain_cap.max() * 0.2))\n\n    # Near-full penalty\n    near_full_threshold = 0.1 * bins_remain_cap.max()\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -1.0 * (item / bins_remain_cap.max()), 0.0)\n\n    # Adaptive Weighting\n    item_size_ratio = item / bins_remain_cap.max()\n    tightness_weight = 0.5 - 0.2 * item_size_ratio\n    fill_weight = 0.2 + 0.2 * item_size_ratio\n    near_full_weight = 0.2 + 0.1 * item_size_ratio\n\n    tightness_weight = np.clip(tightness_weight, 0.1, 0.5)\n    fill_weight = np.clip(fill_weight, 0.1, 0.4)\n    near_full_weight = np.clip(near_full_weight, 0.1, 0.3)\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty)\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 2.6525727961707357,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response3.txt_stdout.txt",
    "code_path": "problem_iter11_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, near-full penalty, and item size bonus.\n    Adaptive weights are used.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, 0.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n\n    # Waste minimization: Prioritize tighter fits\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target fill level (e.g., 75%): Reward bins closer to target\n    target_fill_level = 0.75 * bins_remain_cap.max()\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bins_remain_cap.max() * 0.2))\n\n    # Near-full penalty\n    near_full_threshold = 0.1 * bins_remain_cap.max()\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.5, 0.0)\n\n    # Small item bonus\n    small_item_threshold = bins_remain_cap.max() * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bins_remain_cap.max() * 0.1\n        almost_full_bonus = (bins_remain_cap[can_fit] > item) * np.exp(-remaining_after / almost_full_threshold)\n    else:\n        almost_full_bonus = 0\n\n    # Adaptive weights based on item size\n    if item < bins_remain_cap.max() * 0.1:\n        tightness_weight = 0.3\n        fill_weight = 0.4\n        near_full_weight = 0.1\n        small_item_weight = 0.2\n    elif item > bins_remain_cap.max() * 0.5:\n        tightness_weight = 0.5\n        fill_weight = 0.2\n        near_full_weight = 0.2\n        small_item_weight = 0.1\n    else:\n        tightness_weight = 0.4\n        fill_weight = 0.3\n        near_full_weight = 0.2\n        small_item_weight = 0.1\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus)\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 2.193857199840447,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response4.txt_stdout.txt",
    "code_path": "problem_iter11_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins using tightness, target fill, waste, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        priorities[:] = np.random.rand(len(priorities)) * 0.0001\n        return priorities\n\n    remaining_space = bins_remain_cap[valid_bins] - item\n    fit_score = 1.0 / (remaining_space + 0.0001)\n\n    target_fill = bins_remain_cap.max() * 0.75\n    fill_level_diff = np.abs(bins_remain_cap[valid_bins] - target_fill)\n    fill_level_score = 1.0 / (fill_level_diff + 0.0001)\n\n    waste_threshold = bins_remain_cap.max() * 0.25\n    waste_score = np.where(remaining_space > waste_threshold, 0.1, 1.0)\n\n    num_valid = np.sum(valid_bins)\n    if num_valid > 5:\n        fit_weight = 0.6\n        fill_weight = 0.3\n        waste_weight = 0.1\n    else:\n        fit_weight = 0.4\n        fill_weight = 0.4\n        waste_weight = 0.2\n\n    combined_score = (fit_weight * fit_score + fill_weight * fill_level_score + waste_weight * waste_score)\n\n    priorities[valid_bins] = combined_score\n    priorities[valid_bins] += np.random.rand(np.sum(valid_bins)) * 0.1\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 4.028719585161557,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response5.txt_stdout.txt",
    "code_path": "problem_iter11_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines waste minimization, target fill, near-full penalty, \n    adaptive weighting and stochasticity. Item-size aware.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.5, 0.0)\n\n    # Adaptive Weighting based on item size\n    item_size_factor = item / bin_capacity\n    tightness_weight = 0.5 * (1 - item_size_factor)\n    fill_weight = 0.3 * (1 + item_size_factor)\n    near_full_weight = 0.2\n\n    # Stochasticity\n    randomness = np.random.normal(0, 0.01, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 1.6055045871559654,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response6.txt_stdout.txt",
    "code_path": "problem_iter11_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, near-full penalty, randomness, and item size consideration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float) - np.inf\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        # Waste minimization\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] = -waste\n\n        # Target fill level\n        target_capacity = 0.75 * bins_remain_cap.max()\n        capacity_diff = np.abs(bins_remain_cap[valid_bins] - target_capacity)\n        priorities[valid_bins] += 0.5 / (capacity_diff + 0.0001)\n\n        # Near-full penalty\n        remaining_after_add = bins_remain_cap[valid_bins] - item\n        near_full_penalty = np.where(remaining_after_add < (0.1*bins_remain_cap.max()), -0.5, 0.0)\n        priorities[valid_bins] += near_full_penalty\n\n        # Randomness\n        priorities[valid_bins] += np.random.rand(np.sum(valid_bins)) * 0.01\n\n         # Fill percentage bonus\n        fill_percentage = item / bins_remain_cap[valid_bins]\n        priorities[valid_bins] += fill_percentage\n    \n        # Item Size Consideration: Penalize placing large items in bins with little extra space\n        large_item_threshold = 0.5 * bins_remain_cap.max()\n        if item > large_item_threshold:\n            small_space_penalty = np.where(bins_remain_cap[valid_bins] < (item + 0.1 * bins_remain_cap.max()), -0.2, 0.0)\n            priorities[valid_bins] += small_space_penalty\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.058635819704831,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response7.txt_stdout.txt",
    "code_path": "problem_iter11_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, near-full penalty, and adaptive weights.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        priorities[:] = np.random.rand(len(priorities)) * 0.0001\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n\n    # Tightness score\n    tightness = 1 / (remaining_after + 0.0001)\n\n    # Target fill level score\n    target_fill = bins_remain_cap.max() * 0.75\n    fill_level_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_level_score = np.exp(-fill_level_diff / (bins_remain_cap.max() * 0.2))\n\n    # Near-full penalty\n    near_full_threshold = 0.1 * bins_remain_cap.max()\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.5, 0.0)\n\n    # Adaptive weighting\n    num_valid = np.sum(can_fit)\n    if num_valid > 5:\n        tightness_weight = 0.5\n        fill_weight = 0.3\n        near_full_weight = 0.2\n    else:\n        tightness_weight = 0.4\n        fill_weight = 0.4\n        near_full_weight = 0.2\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_level_score +\n                               near_full_weight * near_full_penalty)\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 2.532907857997616,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response8.txt_stdout.txt",
    "code_path": "problem_iter11_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines waste minimization, target fill, adaptive weighting,\n    edge case handling, and stochasticity for improved bin packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.7, 0.0)\n\n    # Small Item Bonus\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0\n\n    # Large Item Penalty\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6, 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting (Dynamically adjust based on item size and bin states)\n    item_size_factor = item / bin_capacity  # Normalize item size\n    tightness_weight = 0.4 * (1 - item_size_factor) # Smaller items, prioritize tightness\n    fill_weight = 0.3 * (1 + item_size_factor)   # Larger items, prioritize target fill\n    near_full_weight = 0.2\n    small_item_weight = 0.1\n    large_item_weight = 0.1\n\n    # Stochasticity\n    randomness = np.random.normal(0, 0.01, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 0.8974870362983646,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter11_response9.txt_stdout.txt",
    "code_path": "problem_iter11_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, near-full penalty, and randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    # Waste minimization\n    waste = bins_remain_cap[can_fit] - item\n    priorities[can_fit] = 1.0 / (1e-6 + waste)\n\n    # Target fill level\n    max_bin_cap = np.max(bins_remain_cap)\n    target_fill = 0.8 * max_bin_cap\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / max_bin_cap)\n    priorities[can_fit] += fill_priority * 0.1\n\n    # Near-full penalty\n    nearly_full_threshold = 0.1 * max_bin_cap\n    nearly_full = bins_remain_cap < nearly_full_threshold\n    priorities[nearly_full] *= 0.5\n\n    # Randomness\n    randomness = np.random.rand(np.sum(can_fit)) * 0.01\n    priorities[can_fit] += randomness\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 3.9988033506182825,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response0.txt_stdout.txt",
    "code_path": "problem_iter12_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines waste minimization, target fill, adaptive weighting,\n    edge case handling, stochasticity, bin diversity, and item fragmentation\n    considerations for improved bin packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.7, 0.0)\n\n    # Small Item Bonus\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0\n\n    # Large Item Penalty\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6, 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting (Dynamically adjust based on item size and bin states)\n    item_size_factor = item / bin_capacity  # Normalize item size\n    tightness_weight = 0.4 * (1 - item_size_factor) # Smaller items, prioritize tightness\n    fill_weight = 0.3 * (1 + item_size_factor)   # Larger items, prioritize target fill\n    near_full_weight = 0.2\n    small_item_weight = 0.1\n    large_item_weight = 0.1\n\n    # Bin Diversity (Encourage filling bins with similar fill levels)\n    bin_fill_std = bins_remain_cap.std()\n    diversity_score = np.exp(-bin_fill_std / bin_capacity)\n    diversity_weight = 0.05 # Moderate impact to avoid over-prioritization\n\n    # Item Fragmentation Consideration (Try to avoid creating very small spaces)\n    fragmentation_threshold = 0.05 * bin_capacity  # Adjust as needed\n    fragmentation_penalty = np.where((remaining_after > 0) & (remaining_after < fragmentation_threshold), -0.5, 0.0)\n    fragmentation_weight = 0.1\n\n    # Stochasticity (Adjusted scale for finer-grained exploration)\n    randomness = np.random.normal(0, 0.005, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               diversity_weight * diversity_score +\n                               fragmentation_weight * fragmentation_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 1.1667331471878786,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response1.txt_stdout.txt",
    "code_path": "problem_iter12_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Enhanced heuristic combining waste minimization, target fill, adaptive weighting,\n    edge case handling, stochasticity, bin diversity, and learning from past decisions.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization (Efficiency)\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level (Balance)\n    target_fill_level = 0.8 * bin_capacity  # Slightly higher target\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.15))  # Sharper peak at target\n\n    # Near-Full Penalty (Resource Optimization)\n    near_full_threshold = 0.15 * bin_capacity  # Adjusted threshold\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.8, 0.0)  # Stronger penalty\n\n    # Small Item Bonus (Fragmentation Reduction)\n    small_item_threshold = bin_capacity * 0.25  # Adjusted threshold\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.12  # Adjusted threshold\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0\n\n    # Large Item Penalty (Strategic Placement)\n    large_item_threshold = bin_capacity * 0.75  # Adjusted threshold\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.15 * bin_capacity), -0.7, 0.0)  # Stronger penalty\n    else:\n        small_space_penalty = 0.0\n\n    # Bin Diversity Encouragement\n    bin_utilization = (bin_capacity - bins_remain_cap) / bin_capacity\n    bin_diversity_bonus = np.zeros_like(bins_remain_cap[can_fit], dtype=float)\n    for i, bin_index in enumerate(valid_bins):\n        # Encourage bins with utilization close to the average\n        bin_diversity_bonus[i] = np.exp(-np.abs(bin_utilization[bin_index] - np.mean(bin_utilization)) / 0.2)\n\n    # Adaptive Weighting (Dynamic Adjustment)\n    item_size_factor = item / bin_capacity  # Normalize item size\n    tightness_weight = 0.35 * (1 - item_size_factor)  # Smaller items, prioritize tightness\n    fill_weight = 0.35 * (1 + item_size_factor)  # Larger items, prioritize target fill\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n    diversity_weight = 0.05  # Introduce weight for bin diversity\n\n    # Stochasticity (Exploration)\n    randomness = np.random.normal(0, 0.0075, len(valid_bins))  # Reduced randomness\n\n    # Combination of Factors\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               diversity_weight * bin_diversity_bonus +\n                               randomness)\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99996981000004 seconds"
  },
  {
    "stdout_filepath": "problem_iter12_response2.txt_stdout.txt",
    "code_path": "problem_iter12_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines waste minimization, target fill, adaptive weighting,\n    edge case handling, stochasticity, and bin diversity for improved bin packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.7, 0.0)\n\n    # Small Item Bonus\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0\n\n    # Large Item Penalty\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6, 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting (Dynamically adjust based on item size and bin states)\n    item_size_factor = item / bin_capacity  # Normalize item size\n    tightness_weight = 0.4 * (1 - item_size_factor) # Smaller items, prioritize tightness\n    fill_weight = 0.3 * (1 + item_size_factor)   # Larger items, prioritize target fill\n    near_full_weight = 0.2\n    small_item_weight = 0.1\n    large_item_weight = 0.1\n\n    # Bin Diversity Encouragement: Penalize bins with similar fill levels to promote variance\n    fill_level_std = np.std(bins_remain_cap)\n    diversity_bonus = np.exp(-np.abs(bins_remain_cap[can_fit] - np.mean(bins_remain_cap)) / (fill_level_std + 0.0001)) if fill_level_std > 0.01 else 0.0\n    diversity_weight = 0.05\n\n    # Stochasticity (Reduced for more stability, but still present)\n    randomness = np.random.normal(0, 0.005, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               diversity_weight * diversity_bonus +\n                               randomness)\n\n    return priorities",
    "response_id": 2,
    "tryHS": true,
    "obj": 0.8875149581172807,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response3.txt_stdout.txt",
    "code_path": "problem_iter12_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Enhanced heuristic combining waste minimization, target fill,\n    adaptive weighting based on bin utilization and item size,\n    dynamic near-full management, and a refined stochastic component.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.15))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.15 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8, 0.0)  # Stronger penalty\n\n    # Smaller Item Bonus\n    small_item_threshold = bin_capacity * 0.25\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty\n    large_item_threshold = bin_capacity * 0.75\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.7, 0.0) #Increased penalty\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting: Reacting to bin utilization & item size\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization) #Global view\n\n    # Adjust weights based on item size AND overall bin utilization.\n    tightness_weight = 0.35 * (1 - item_size_factor) * (1+utilization_factor)\n    fill_weight = 0.35 * (1 + item_size_factor) * (1-utilization_factor)\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # Refined Stochasticity: scaled by item size and bin utilization\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 3.709613083366578,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter12_response4.txt_stdout.txt",
    "code_path": "problem_iter12_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines waste minimization, target fill, adaptive weighting,\n    edge case handling, and stochasticity for improved bin packing.\n    Improves upon v1 by incorporating bin diversity and a dynamic penalty\n    for exceeding a target number of bins used. Also utilizes a decaying\n    randomness factor.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    num_bins = len(bins_remain_cap)\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.7, 0.0)\n\n    # Small Item Bonus\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0\n\n    # Large Item Penalty\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6, 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting (Dynamically adjust based on item size and bin states)\n    item_size_factor = item / bin_capacity  # Normalize item size\n    tightness_weight = 0.4 * (1 - item_size_factor) # Smaller items, prioritize tightness\n    fill_weight = 0.3 * (1 + item_size_factor)   # Larger items, prioritize target fill\n    near_full_weight = 0.2\n    small_item_weight = 0.1\n    large_item_weight = 0.1\n\n    # Bin Diversity Encouragement: Prioritize bins with different fill levels\n    fill_std = np.std(bins_remain_cap)\n    diversity_bonus = fill_std / bin_capacity  # Normalize diversity\n\n    # Dynamic Bin Count Penalty: Encourage packing into fewer bins\n    bins_used = np.sum(bins_remain_cap < bin_capacity)\n    target_bins = int(np.ceil(np.sum(item) / bin_capacity)) if isinstance(item,float) else int(np.ceil(np.sum(item)/bin_capacity))\n    over_bins = max(0, bins_used - target_bins)\n    bin_count_penalty = -0.1 * over_bins\n\n    # Decaying Stochasticity: Reduce randomness over time (simulated)\n    # This would ideally be managed externally to track the \"packing progress\".\n    # Here, we approximate it using the mean remaining capacity\n    packing_progress = np.mean(bins_remain_cap) / bin_capacity\n    randomness_strength = max(0.0, 0.01 * (1 - packing_progress))  # Reduced randomness\n    randomness = np.random.normal(0, randomness_strength, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               diversity_bonus +\n                               bin_count_penalty+\n                               randomness)\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 1.5855604307937865,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter13_response0.txt_stdout.txt",
    "code_path": "problem_iter13_code0.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                target_fill_level_ratio: float = 0.6992928630053263,\n                fill_score_decay_ratio: float = 0.07459682967134672,\n                near_full_threshold_ratio: float = 0.11850581042669553,\n                near_full_penalty_value: float = -0.9862394728472232,\n                small_item_threshold_ratio: float = 0.342743072230004,\n                almost_full_threshold_ratio: float = 0.025760130264521397,\n                large_item_threshold_ratio: float = 0.5513530975406856,\n                small_space_penalty_value: float = -0.5764437457290348,\n                tightness_weight_base: float = 0.3563164734777171,\n                fill_weight_base: float = 0.680407089104551,\n                near_full_weight: float = 0.2517943181770199,\n                small_item_weight: float = 0.5118280048492347,\n                large_item_weight: float = 0.28411289316797284,\n                diversity_weight: float = 0.38031775041770266,\n                diversity_threshold_ratio: float = 0.07466597885029373,\n                randomness_scale: float = 0.004462977028169032) -> np.ndarray:\n    \"\"\"\n    Combines waste minimization, target fill, adaptive weighting,\n    edge case handling, stochasticity, and bin diversity for improved bin packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)",
    "response_id": 0,
    "tryHS": true,
    "obj": 4.487435181491823,
    "exec_success": true
  }
]