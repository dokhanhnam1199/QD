{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Enhanced heuristic with adaptive weighting, dynamic penalties/bonuses,\n    target fill, decaying stochasticity, and item/bin state awareness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # 1. Waste Minimization with Adaptive Tightness\n    waste = remaining_after\n    base_tightness = 1 / (waste + 0.0001)\n    # Adapt tightness based on item size: smaller items benefit more from tight fits.\n    item_size_factor = item / bin_capacity\n    tightness = base_tightness * (1 + (1 - item_size_factor))  # Boost tightness for small items\n\n\n    # 2. Target Fill Level with Dynamic Target\n    # Adjust target fill based on average bin utilization: if bins are filling up, aim higher.\n    avg_utilization = np.mean(bins_utilization)\n    target_fill_level = (0.65 + 0.2 * avg_utilization) * bin_capacity #was 0.75\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # 3. Dynamic Near-Full Management\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    # Adaptive penalty: larger penalty if the item is also large relative to bin capacity\n    near_full_penalty = np.where(is_near_full, -0.7 * (item/bin_capacity) * (1+bins_utilization), 0.0)\n\n    # 4. Smaller Item Bonus (if item fits nearly perfectly into a near-full bin)\n    small_item_threshold = bin_capacity * 0.25\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # 5. Larger Item Penalty (if placing it leaves very little space)\n    large_item_threshold = bin_capacity * 0.75\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6 * (item/bin_capacity), 0.0) #was 0.7\n    else:\n        small_space_penalty = 0.0\n\n    # 6. Adaptive Weighting: item size & bin utilization\n    #   - Emphasis on tightness when item is small and bins aren't fully utilized\n    #   - Emphasis on fill when item is large or bins are highly utilized\n    tightness_weight = 0.35 * (1.2 - item_size_factor) * (1.1 - avg_utilization) #was (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.35 * (0.8 + item_size_factor) * (0.9 + avg_utilization) #was (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # 7. Decaying Stochasticity\n    #   - Reduce randomness as bins fill up to stabilize the packing\n    randomness_scale = 0.015 * (1 + item_size_factor) * (1 - avg_utilization) #was 0.015 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Hybrid heuristic: Adaptive fill target, near-full/small-item bonuses, and decaying randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization (Tightness)\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level (Adaptive)\n    current_utilization = np.mean((bin_capacity - bins_remain_cap) / bin_capacity)\n    target_fill_level = 0.7 + 0.1 * current_utilization\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill_level * bin_capacity)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8 * (item / bin_capacity), 0.0)\n\n    # Smaller Item Bonus\n    small_item_threshold = bin_capacity * 0.3\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Adaptive Weighting: Item size and Bin Utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.3 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n\n    # Strategic Randomness (Decaying)\n    if not hasattr(priority_v2, \"time_step\"):\n        priority_v2.time_step = 1\n    else:\n        priority_v2.time_step += 1\n    exploration_factor = np.exp(-priority_v2.time_step / 1000.0)\n    randomness_scale = 0.01 * (1 + item_size_factor) * exploration_factor\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus+\n                               randomness)\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), we see no difference. Comparing (1st) vs (20th), we observe that the best heuristic incorporates a learning rate to adapt the weights of tightness and fill, strategic randomness that decays based on item size and bin utilization, and a dynamic near-full management system. The 20th heuristic uses a simpler static weighting and a different approach to target fill levels, using a combination of low and high thresholds. Comparing (2nd) vs (3rd), (1st) uses adaptive weighting and randomness while (3rd) uses static weighting. Comparing (3rd) vs (4th), (4th) has adaptive weighting and strategic randomness. Comparing (second worst) vs (worst), the second worst incorporates a small item bonus and adaptive weighting, while the worst only focuses on waste minimization and adaptive penalties without dynamically adjusting the weights or utilizing any bonus system for small items. Comparing (11th) vs (12th), we see no difference. Comparing (1st) vs (11th), the key difference is that (11th) introduces small and large item bonuses and penalties and adjusts target fill based on average bin utilization. Overall: the better heuristics incorporate adaptive weighting based on item size and bin utilization, strategic randomness, dynamic penalties and bonuses based on item size and bin state, and adaptive target fill levels. They also tend to have more sophisticated methods for waste minimization.\n- \nOkay, I understand. Let's redefine \"Current self-reflection\" to make it more effective for designing better bin packing heuristics, while explicitly avoiding the pitfalls of \"Ineffective self-reflection.\"\n\nHere's a breakdown to guide the process:\n\n*   **Keywords:** Adaptive learning, dynamic adjustment, multi-objective balancing, stochastic exploration, performance feedback.\n\n*   **Advice:** Focus on learning from past packing outcomes to dynamically adjust parameters like target fill levels, penalty/bonus weights, and the degree of randomness. Use a multi-objective approach that explicitly models different performance goals (waste, fill, balance).\n\n*   **Avoid:** Broad, generic statements like \"simpler is better\" or \"consider multiple factors.\" Avoid feature repetition and focusing on static configurations of heuristics.\n\n*   **Explanation:** Effective heuristics need to learn and adapt. A system for tracking performance and feeding that back into heuristic parameter adjustment is key. The learning should adjust the balance between conflicting objectives. Instead of just saying \"use randomness,\" focus on strategies like decaying randomness or randomness driven by performance.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}