```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Advanced heuristic with adaptive weighting, dynamic penalties, and controlled randomness."""

    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    can_fit = bins_remain_cap >= item

    if not np.any(can_fit):
        return np.full_like(priorities, -1.0)

    valid_bins = np.where(can_fit)[0]
    remaining_after = bins_remain_cap[can_fit] - item
    bin_capacity = bins_remain_cap.max()
    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity

    # 1. Waste Minimization with Adaptive Tightness
    waste = remaining_after
    # Use a more aggressive scaling for tightness.  Smaller waste is *much* better.
    tightness = 1 / (waste**0.75 + 0.0001)

    # 2. Target Fill Level with Dynamic Adjustment
    target_fill_level = 0.75 * bin_capacity  #Initial target
    # Adapt target fill based on average bin utilization
    target_fill_level += 0.1 * bin_capacity * (np.mean(bins_utilization) - 0.5)  #Adjust target
    target_fill_level = np.clip(target_fill_level, 0.5 * bin_capacity, 0.9 * bin_capacity) # Clamp target

    fill_level = bins_remain_cap[can_fit]
    fill_diff = np.abs(fill_level - target_fill_level)
    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))

    # 3. Dynamic Near-Full Management
    near_full_threshold = 0.12 * bin_capacity
    is_near_full = remaining_after < near_full_threshold
    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0)  #Stronger Penalty

    # 4. Item Size Considerations
    small_item_threshold = bin_capacity * 0.25
    large_item_threshold = bin_capacity * 0.75
    almost_full_threshold = bin_capacity * 0.1

    almost_full_bonus = np.where((item < small_item_threshold) & (remaining_after < almost_full_threshold),
                                  np.exp(-remaining_after / (almost_full_threshold / 2 + 0.0001)), 0.0)  #More aggressive bonus

    small_space_penalty = np.where((item > large_item_threshold) & (bins_remain_cap[can_fit] < (item + 0.05 * bin_capacity)),
                                    -0.8 * (item/bin_capacity), 0.0) #Stricter penalty if item almost doesnt fit

    # 5. Adaptive Weighting
    item_size_factor = item / bin_capacity
    utilization_factor = np.mean(bins_utilization)

    # Weights that adapt based on item size and bin utilization
    tightness_weight = 0.4 * (1 - item_size_factor) * (1 + utilization_factor)
    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor)
    near_full_weight = 0.12
    small_item_weight = 0.04
    large_item_weight = 0.04

    # 6. Controlled Randomness
    # Decaying randomness: more randomness early on, less later
    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)
    # Simulate "cooling" - reduce randomness as bins fill
    cooling_factor = np.exp(-utilization_factor * 5)  # Adjust exponent as needed
    randomness_scale *= cooling_factor

    randomness = np.random.normal(0, randomness_scale, len(valid_bins))

    priorities[valid_bins] = (tightness_weight * tightness +
                               fill_weight * fill_score +
                               near_full_weight * near_full_penalty +
                               small_item_weight * almost_full_bonus +
                               large_item_weight * small_space_penalty +
                               randomness)

    return priorities
```
