{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced heuristic: adaptive weights, dynamic near-full, item size considerations, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8 * (item/bin_capacity), 0.0)\n\n    # Smaller Item Bonus (if item fits nearly perfectly into a near-full bin)\n    small_item_threshold = bin_capacity * 0.25\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty (if placing it leaves very little space)\n    large_item_threshold = bin_capacity * 0.75\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.7 * (item/bin_capacity), 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting: item size & bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.35 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.35 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # Stochasticity scaled by item size and bin utilization\n    randomness_scale = 0.015 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced heuristic: adaptive weights, dynamic near-full, item size considerations, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8 * (item/bin_capacity), 0.0)\n\n    # Smaller Item Bonus (if item fits nearly perfectly into a near-full bin)\n    small_item_threshold = bin_capacity * 0.25\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty (if placing it leaves very little space)\n    large_item_threshold = bin_capacity * 0.75\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.7 * (item/bin_capacity), 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting: item size & bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.35 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.35 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # Stochasticity scaled by item size and bin utilization\n    randomness_scale = 0.015 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid heuristic: Adaptive weighting, target fill, and stochasticity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.15))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.5, 0.0)\n\n    # Item size consideration\n    item_size_factor = item / bin_capacity\n    tightness_weight = 0.5 * (1 - item_size_factor)\n    fill_weight = 0.5 * (1 + item_size_factor)\n    near_full_weight = 0.2\n    \n    # Stochasticity - scaled by remaining capacity\n    randomness_scale = 0.01 * (1 + bins_remain_cap[can_fit] / bin_capacity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, near-full penalty, item size.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.5, 0.0)\n\n    # Adaptive Weighting based on item size\n    item_size_factor = item / bin_capacity\n    tightness_weight = 0.5 * (1 - item_size_factor)\n    fill_weight = 0.3 * (1 + item_size_factor)\n    near_full_weight = 0.2\n\n    # Stochasticity (Decaying)\n    randomness = np.random.normal(0, 0.01 / (1 + item_size_factor), len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, near-full penalty, item size.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.5, 0.0)\n\n    # Adaptive Weighting based on item size\n    item_size_factor = item / bin_capacity\n    tightness_weight = 0.5 * (1 - item_size_factor)\n    fill_weight = 0.3 * (1 + item_size_factor)\n    near_full_weight = 0.2\n\n    # Stochasticity (Decaying)\n    randomness = np.random.normal(0, 0.01 / (1 + item_size_factor), len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced heuristic: adaptive weights, dynamic near-full, item size considerations, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level (Adaptive)\n    target_fill_level = 0.75 * bin_capacity  # Could be a learned parameter\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8 * (item/bin_capacity), 0.0)\n\n    # Smaller Item Bonus (if item fits nearly perfectly into a near-full bin)\n    small_item_threshold = bin_capacity * 0.25\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty (if placing it leaves very little space)\n    large_item_threshold = bin_capacity * 0.75\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.7 * (item/bin_capacity), 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Bin Diversity Encouragement\n    bin_diversity = np.std(bins_utilization)\n    diversity_bonus = 0.05 * (1-bin_diversity)  # Encourage different fill levels\n\n    # Adaptive Weighting: item size & bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    # Time-dependent weighting (simulated annealing style)\n    time_decay = 0.999  # Simulate annealing decay\n    # Create a static variable (not ideal in pure functions, but useful here to represent time)\n    if not hasattr(priority_v2, \"time_step\"):\n        priority_v2.time_step = 1\n    else:\n         priority_v2.time_step += 1\n\n    exploration_factor = np.exp(-priority_v2.time_step / 1000.0)  # Decay over time\n\n    tightness_weight = 0.35 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.35 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n    diversity_weight = 0.05  # Weight for bin diversity\n\n    # Stochasticity scaled by item size and bin utilization\n    randomness_scale = 0.015 * (1 + item_size_factor) * (1 - utilization_factor) * exploration_factor\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               diversity_weight * diversity_bonus +\n                               randomness)\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, adaptive weighting, and stochasticity.\n    Improved by adding small item bonus and dynamic bin count penalty.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    num_bins = len(bins_remain_cap)\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty (Slightly reduced penalty)\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.6, 0.0)\n\n    # Small Item Bonus\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    tightness_weight = 0.5 * (1 - item_size_factor)\n    fill_weight = 0.4 * (1 + item_size_factor)\n    near_full_weight = 0.1\n\n    # Dynamic Bin Count Penalty\n    bins_used = np.sum(bins_remain_cap < bin_capacity)\n    target_bins = int(np.ceil(np.sum(item) / bin_capacity)) if isinstance(item, float) else int(np.ceil(np.sum(item)/bin_capacity))\n\n    over_bins = max(0, bins_used - target_bins)\n    bin_count_penalty = -0.05 * over_bins\n    # Randomness\n    randomness = np.random.rand(len(valid_bins)) * 0.01\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               almost_full_bonus * 0.2 +\n                               bin_count_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, adaptive weighting, and stochasticity.\n    Improved by adding small item bonus and dynamic bin count penalty.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    num_bins = len(bins_remain_cap)\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty (Slightly reduced penalty)\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.6, 0.0)\n\n    # Small Item Bonus\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    tightness_weight = 0.5 * (1 - item_size_factor)\n    fill_weight = 0.4 * (1 + item_size_factor)\n    near_full_weight = 0.1\n\n    # Dynamic Bin Count Penalty\n    bins_used = np.sum(bins_remain_cap < bin_capacity)\n    target_bins = int(np.ceil(np.sum(item) / bin_capacity)) if isinstance(item, float) else int(np.ceil(np.sum(item)/bin_capacity))\n\n    over_bins = max(0, bins_used - target_bins)\n    bin_count_penalty = -0.05 * over_bins\n    # Randomness\n    randomness = np.random.rand(len(valid_bins)) * 0.01\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               almost_full_bonus * 0.2 +\n                               bin_count_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Advanced heuristic: adaptive learning rate, dynamic target fill, item fragmentation consideration, bin diversity, and intelligent stochasticity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # 1. Waste Minimization with Adaptive Learning:\n    waste = remaining_after\n    inverse_waste = 1 / (waste + 0.0001)\n    # Adaptive learning rate based on how full the bins are on average\n    learning_rate = np.mean(bins_utilization)\n    tightness = inverse_waste * (1 + learning_rate)\n\n    # 2. Dynamic Target Fill Level: Adaptive to Item Size Distribution\n    # Dynamically adjust target based on item size; shift it lower if item is big\n    item_size_ratio = item / bin_capacity\n    dynamic_target_fill = 0.75 * bin_capacity * (1 - 0.2 * item_size_ratio)\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - dynamic_target_fill)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # 3. Near-Full Management with Dynamic Penalty:\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    # Increase the penalty if the item is large to discourage creating tiny splits\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity) * (1 + item_size_ratio), 0.0)\n\n    # 4. Item Fragmentation Consideration: Encourage larger items in less full bins.\n    large_item_threshold = bin_capacity * 0.6\n    if item > large_item_threshold:\n        fragmentation_penalty = np.where(bins_utilization < 0.5, 0.1, 0.0) * (item / bin_capacity)\n    else:\n        fragmentation_penalty = 0.0\n\n    # 5. Bin Diversity: Balance usage between bins.\n    bin_diversity_bonus = 0.1 * (1 - bins_utilization)\n\n    # 6. Intelligent Stochasticity:\n    # Introduce more randomness when bins are similarly filled\n    bin_similarity = np.std(bins_utilization)\n    randomness_scale = 0.01 * (1 + item_size_ratio) * (1 - bin_similarity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # 7. Adaptive Weighting (tuned)\n    tightness_weight = 0.40\n    fill_weight = 0.30\n    near_full_weight = 0.15\n    fragmentation_weight = 0.075\n    diversity_weight = 0.075\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               fragmentation_weight * fragmentation_penalty +\n                               diversity_weight * bin_diversity_bonus +\n                               randomness)\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Advanced heuristic: adaptive learning rate, dynamic target fill, item fragmentation consideration, bin diversity, and intelligent stochasticity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # 1. Waste Minimization with Adaptive Learning:\n    waste = remaining_after\n    inverse_waste = 1 / (waste + 0.0001)\n    # Adaptive learning rate based on how full the bins are on average\n    learning_rate = np.mean(bins_utilization)\n    tightness = inverse_waste * (1 + learning_rate)\n\n    # 2. Dynamic Target Fill Level: Adaptive to Item Size Distribution\n    # Dynamically adjust target based on item size; shift it lower if item is big\n    item_size_ratio = item / bin_capacity\n    dynamic_target_fill = 0.75 * bin_capacity * (1 - 0.2 * item_size_ratio)\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - dynamic_target_fill)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # 3. Near-Full Management with Dynamic Penalty:\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    # Increase the penalty if the item is large to discourage creating tiny splits\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity) * (1 + item_size_ratio), 0.0)\n\n    # 4. Item Fragmentation Consideration: Encourage larger items in less full bins.\n    large_item_threshold = bin_capacity * 0.6\n    if item > large_item_threshold:\n        fragmentation_penalty = np.where(bins_utilization < 0.5, 0.1, 0.0) * (item / bin_capacity)\n    else:\n        fragmentation_penalty = 0.0\n\n    # 5. Bin Diversity: Balance usage between bins.\n    bin_diversity_bonus = 0.1 * (1 - bins_utilization)\n\n    # 6. Intelligent Stochasticity:\n    # Introduce more randomness when bins are similarly filled\n    bin_similarity = np.std(bins_utilization)\n    randomness_scale = 0.01 * (1 + item_size_ratio) * (1 - bin_similarity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # 7. Adaptive Weighting (tuned)\n    tightness_weight = 0.40\n    fill_weight = 0.30\n    near_full_weight = 0.15\n    fragmentation_weight = 0.075\n    diversity_weight = 0.075\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               fragmentation_weight * fragmentation_penalty +\n                               diversity_weight * bin_diversity_bonus +\n                               randomness)\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Advanced heuristic: adaptive learning rate, dynamic target fill, item fragmentation consideration, bin diversity, and intelligent stochasticity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # 1. Waste Minimization with Adaptive Learning:\n    waste = remaining_after\n    inverse_waste = 1 / (waste + 0.0001)\n    # Adaptive learning rate based on how full the bins are on average\n    learning_rate = np.mean(bins_utilization)\n    tightness = inverse_waste * (1 + learning_rate)\n\n    # 2. Dynamic Target Fill Level: Adaptive to Item Size Distribution\n    # Dynamically adjust target based on item size; shift it lower if item is big\n    item_size_ratio = item / bin_capacity\n    dynamic_target_fill = 0.75 * bin_capacity * (1 - 0.2 * item_size_ratio)\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - dynamic_target_fill)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # 3. Near-Full Management with Dynamic Penalty:\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    # Increase the penalty if the item is large to discourage creating tiny splits\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity) * (1 + item_size_ratio), 0.0)\n\n    # 4. Item Fragmentation Consideration: Encourage larger items in less full bins.\n    large_item_threshold = bin_capacity * 0.6\n    if item > large_item_threshold:\n        fragmentation_penalty = np.where(bins_utilization < 0.5, 0.1, 0.0) * (item / bin_capacity)\n    else:\n        fragmentation_penalty = 0.0\n\n    # 5. Bin Diversity: Balance usage between bins.\n    bin_diversity_bonus = 0.1 * (1 - bins_utilization)\n\n    # 6. Intelligent Stochasticity:\n    # Introduce more randomness when bins are similarly filled\n    bin_similarity = np.std(bins_utilization)\n    randomness_scale = 0.01 * (1 + item_size_ratio) * (1 - bin_similarity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # 7. Adaptive Weighting (tuned)\n    tightness_weight = 0.40\n    fill_weight = 0.30\n    near_full_weight = 0.15\n    fragmentation_weight = 0.075\n    diversity_weight = 0.075\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               fragmentation_weight * fragmentation_penalty +\n                               diversity_weight * bin_diversity_bonus +\n                               randomness)\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Advanced heuristic: adaptive learning rate, dynamic target fill, item fragmentation consideration, bin diversity, and intelligent stochasticity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # 1. Waste Minimization with Adaptive Learning:\n    waste = remaining_after\n    inverse_waste = 1 / (waste + 0.0001)\n    # Adaptive learning rate based on how full the bins are on average\n    learning_rate = np.mean(bins_utilization)\n    tightness = inverse_waste * (1 + learning_rate)\n\n    # 2. Dynamic Target Fill Level: Adaptive to Item Size Distribution\n    # Dynamically adjust target based on item size; shift it lower if item is big\n    item_size_ratio = item / bin_capacity\n    dynamic_target_fill = 0.75 * bin_capacity * (1 - 0.2 * item_size_ratio)\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - dynamic_target_fill)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # 3. Near-Full Management with Dynamic Penalty:\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    # Increase the penalty if the item is large to discourage creating tiny splits\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity) * (1 + item_size_ratio), 0.0)\n\n    # 4. Item Fragmentation Consideration: Encourage larger items in less full bins.\n    large_item_threshold = bin_capacity * 0.6\n    if item > large_item_threshold:\n        fragmentation_penalty = np.where(bins_utilization < 0.5, 0.1, 0.0) * (item / bin_capacity)\n    else:\n        fragmentation_penalty = 0.0\n\n    # 5. Bin Diversity: Balance usage between bins.\n    bin_diversity_bonus = 0.1 * (1 - bins_utilization)\n\n    # 6. Intelligent Stochasticity:\n    # Introduce more randomness when bins are similarly filled\n    bin_similarity = np.std(bins_utilization)\n    randomness_scale = 0.01 * (1 + item_size_ratio) * (1 - bin_similarity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # 7. Adaptive Weighting (tuned)\n    tightness_weight = 0.40\n    fill_weight = 0.30\n    near_full_weight = 0.15\n    fragmentation_weight = 0.075\n    diversity_weight = 0.075\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               fragmentation_weight * fragmentation_penalty +\n                               diversity_weight * bin_diversity_bonus +\n                               randomness)\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced heuristic: adaptive weights, dynamic near-full, item size considerations,\n    learning rate based adjustments and randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity # Increased target fill level\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.1 * bin_capacity  # Slightly tighter near-full\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0) # Increased penalty\n\n    # Smaller Item Bonus (if item fits nearly perfectly into a near-full bin)\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty (if placing it leaves very little space)\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.05 * bin_capacity), -0.8 * (item/bin_capacity), 0.0) # Stricter penalty\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting: item size & bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    # Introduce a 'learning rate' concept to dynamically adjust weights\n    learning_rate = 0.1\n\n    # Define initial weights\n    tightness_weight = 0.35\n    fill_weight = 0.35\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # Adjust weights based on item size and utilization\n    tightness_weight += learning_rate * (1 - item_size_factor) * (1 + utilization_factor) - tightness_weight\n    fill_weight += learning_rate * (1 + item_size_factor) * (1 - utilization_factor) - fill_weight\n\n\n    # Stochasticity scaled by item size and bin utilization\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # Apply the weights\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced heuristic: adaptive weights, dynamic near-full, item size considerations,\n    learning rate based adjustments and randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity # Increased target fill level\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.1 * bin_capacity  # Slightly tighter near-full\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0) # Increased penalty\n\n    # Smaller Item Bonus (if item fits nearly perfectly into a near-full bin)\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty (if placing it leaves very little space)\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.05 * bin_capacity), -0.8 * (item/bin_capacity), 0.0) # Stricter penalty\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting: item size & bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    # Introduce a 'learning rate' concept to dynamically adjust weights\n    learning_rate = 0.1\n\n    # Define initial weights\n    tightness_weight = 0.35\n    fill_weight = 0.35\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # Adjust weights based on item size and utilization\n    tightness_weight += learning_rate * (1 - item_size_factor) * (1 + utilization_factor) - tightness_weight\n    fill_weight += learning_rate * (1 + item_size_factor) * (1 - utilization_factor) - fill_weight\n\n\n    # Stochasticity scaled by item size and bin utilization\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # Apply the weights\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced heuristic: adaptive weights, dynamic near-full, item size considerations,\n    learning rate based adjustments and randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity # Increased target fill level\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.1 * bin_capacity  # Slightly tighter near-full\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0) # Increased penalty\n\n    # Smaller Item Bonus (if item fits nearly perfectly into a near-full bin)\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty (if placing it leaves very little space)\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.05 * bin_capacity), -0.8 * (item/bin_capacity), 0.0) # Stricter penalty\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting: item size & bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    # Introduce a 'learning rate' concept to dynamically adjust weights\n    learning_rate = 0.1\n\n    # Define initial weights\n    tightness_weight = 0.35\n    fill_weight = 0.35\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # Adjust weights based on item size and utilization\n    tightness_weight += learning_rate * (1 - item_size_factor) * (1 + utilization_factor) - tightness_weight\n    fill_weight += learning_rate * (1 + item_size_factor) * (1 - utilization_factor) - fill_weight\n\n\n    # Stochasticity scaled by item size and bin utilization\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # Apply the weights\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced heuristic: adaptive weights, dynamic near-full, item size considerations,\n    learning rate based adjustments and randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity # Increased target fill level\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.1 * bin_capacity  # Slightly tighter near-full\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0) # Increased penalty\n\n    # Smaller Item Bonus (if item fits nearly perfectly into a near-full bin)\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty (if placing it leaves very little space)\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.05 * bin_capacity), -0.8 * (item/bin_capacity), 0.0) # Stricter penalty\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting: item size & bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    # Introduce a 'learning rate' concept to dynamically adjust weights\n    learning_rate = 0.1\n\n    # Define initial weights\n    tightness_weight = 0.35\n    fill_weight = 0.35\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # Adjust weights based on item size and utilization\n    tightness_weight += learning_rate * (1 - item_size_factor) * (1 + utilization_factor) - tightness_weight\n    fill_weight += learning_rate * (1 + item_size_factor) * (1 - utilization_factor) - fill_weight\n\n\n    # Stochasticity scaled by item size and bin utilization\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # Apply the weights\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced heuristic: adaptive weights, dynamic near-full, item size considerations,\n    learning rate based adjustments and randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity # Increased target fill level\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.1 * bin_capacity  # Slightly tighter near-full\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0) # Increased penalty\n\n    # Smaller Item Bonus (if item fits nearly perfectly into a near-full bin)\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty (if placing it leaves very little space)\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.05 * bin_capacity), -0.8 * (item/bin_capacity), 0.0) # Stricter penalty\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting: item size & bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    # Introduce a 'learning rate' concept to dynamically adjust weights\n    learning_rate = 0.1\n\n    # Define initial weights\n    tightness_weight = 0.35\n    fill_weight = 0.35\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # Adjust weights based on item size and utilization\n    tightness_weight += learning_rate * (1 - item_size_factor) * (1 + utilization_factor) - tightness_weight\n    fill_weight += learning_rate * (1 + item_size_factor) * (1 - utilization_factor) - fill_weight\n\n\n    # Stochasticity scaled by item size and bin utilization\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # Apply the weights\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, near-full/empty penalties, and adaptive randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    # Waste minimization (Best-Fit)\n    waste = bins_remain_cap[can_fit] - item\n    priorities[can_fit] = 1.0 / (1e-6 + waste)\n\n    # Target fill level\n    max_bin_cap = np.max(bins_remain_cap)\n    target_fill = 0.75 * max_bin_cap\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / max_bin_cap)\n    priorities[can_fit] += fill_priority * 0.1\n\n    # Near-full penalty\n    nearly_full_threshold = 0.1 * max_bin_cap\n    nearly_full = bins_remain_cap < nearly_full_threshold\n    priorities[nearly_full] *= 0.5\n\n     # Nearly-empty bonus\n    nearly_empty_threshold = 0.9 * max_bin_cap\n    nearly_empty_valid = (bins_remain_cap[can_fit] > nearly_empty_threshold)\n    nearly_empty_indices = np.where(can_fit)[0][nearly_empty_valid]\n\n    priorities[nearly_empty_indices] += 0.05 # Small bonus for using empty bins.\n\n    # Adaptive Randomness (decaying with item size)\n    randomness = np.random.rand(np.sum(can_fit)) * 0.01 * (1 - item/max_bin_cap) # Reduce randomness for large items\n    priorities[can_fit] += randomness\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining waste minimization, target fill, and dynamic penalties.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    # Waste minimization\n    waste = bins_remain_cap[can_fit] - item\n    priorities[can_fit] = 1.0 / (1e-6 + waste)\n\n    # Target fill level\n    max_bin_cap = np.max(bins_remain_cap)\n    target_fill = 0.75 * max_bin_cap\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / max_bin_cap)\n    priorities[can_fit] += fill_priority * 0.2\n\n    # Near-full/Near-empty penalty (dynamic)\n    remaining_after_add = bins_remain_cap[can_fit] - item\n    nearly_full_threshold = 0.1 * max_bin_cap\n    nearly_empty_threshold = 0.9 * max_bin_cap  # Encourage bin utilization\n\n    near_full_penalty = np.where(remaining_after_add < nearly_full_threshold, -0.5, 0.0)\n    near_empty_bonus = np.where(bins_remain_cap[can_fit] > nearly_empty_threshold, 0.1, 0.0) # Small bonus\n    priorities[can_fit] += near_full_penalty + near_empty_bonus\n\n    # Item Size Consideration (adaptive weighting)\n    item_size_weight = item / max_bin_cap  # Normalize item size\n    priorities[can_fit] *= (1 + item_size_weight * 0.5)  # Larger items get higher priority\n\n    # Randomness (decaying)\n    randomness = np.random.rand(np.sum(can_fit)) * 0.01 * (1 - item_size_weight) # Less randomness for large items\n    priorities[can_fit] += randomness\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining waste minimization, target fill, and dynamic penalties.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    # Waste minimization\n    waste = bins_remain_cap[can_fit] - item\n    priorities[can_fit] = 1.0 / (1e-6 + waste)\n\n    # Target fill level\n    max_bin_cap = np.max(bins_remain_cap)\n    target_fill = 0.75 * max_bin_cap\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / max_bin_cap)\n    priorities[can_fit] += fill_priority * 0.2\n\n    # Near-full/Near-empty penalty (dynamic)\n    remaining_after_add = bins_remain_cap[can_fit] - item\n    nearly_full_threshold = 0.1 * max_bin_cap\n    nearly_empty_threshold = 0.9 * max_bin_cap  # Encourage bin utilization\n\n    near_full_penalty = np.where(remaining_after_add < nearly_full_threshold, -0.5, 0.0)\n    near_empty_bonus = np.where(bins_remain_cap[can_fit] > nearly_empty_threshold, 0.1, 0.0) # Small bonus\n    priorities[can_fit] += near_full_penalty + near_empty_bonus\n\n    # Item Size Consideration (adaptive weighting)\n    item_size_weight = item / max_bin_cap  # Normalize item size\n    priorities[can_fit] *= (1 + item_size_weight * 0.5)  # Larger items get higher priority\n\n    # Randomness (decaying)\n    randomness = np.random.rand(np.sum(can_fit)) * 0.01 * (1 - item_size_weight) # Less randomness for large items\n    priorities[can_fit] += randomness\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}