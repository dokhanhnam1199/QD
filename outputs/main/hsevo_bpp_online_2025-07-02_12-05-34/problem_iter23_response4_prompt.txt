{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines waste minimization, adaptive penalty/bonus, and controlled randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    bin_capacity = np.max(bins_remain_cap)\n\n    # Waste Minimization (Best-Fit)\n    waste = bins_remain_cap[can_fit] - item\n    priorities[can_fit] = 1.0 / (1e-6 + waste)\n\n    # Adaptive Near-Full Management: Item Size-Dependent\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = bins_remain_cap[can_fit] < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8 * (item / bin_capacity), 0.0)\n    priorities[valid_bins] += near_full_penalty\n\n    # Small item bonus\n    small_item_threshold = 0.2 * bin_capacity\n    if item < small_item_threshold:\n      almost_full_threshold = 0.1 * bin_capacity\n      almost_full_valid_bins = bins_remain_cap[can_fit] < almost_full_threshold + item\n      almost_full_indices = np.where(can_fit)[0][almost_full_valid_bins]\n      priorities[almost_full_indices] += 0.2\n\n    # Controlled Randomness (decaying with item size and remaining capacity)\n    randomness_scale = 0.01 * (1 - item/bin_capacity) * (bins_remain_cap[can_fit] / bin_capacity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n    priorities[can_fit] += randomness\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Enhanced heuristic: adaptive weights, dynamic near-full, item size considerations, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization: Prioritize bins that minimize remaining space relative to item size\n    waste_ratio = remaining_after / item\n    waste_priority = np.exp(-5 * waste_ratio)  # Exponentially decreasing priority with increasing waste\n\n    # Target Fill Level: Reward bins close to a target fill level, but adapt the target\n    # based on item size.  Smaller items shift the target higher.\n    target_fill_level = 0.8 * bin_capacity - 0.1 * item\n    fill_level_diff = np.abs(bins_remain_cap[can_fit] - target_fill_level)\n    fill_level_priority = np.exp(-fill_level_diff / (bin_capacity * 0.2))\n\n    # Near-Full Management: Penalize bins that become *very* near full, but only if the\n    # item isn't tiny.  Tiny items can top off bins.\n    near_full_threshold = 0.08 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full & (item > 0.1 * bin_capacity), -0.9, 0.0)\n\n    # Small Item Bonus: Significantly reward bins that can be nearly filled by small items.\n    small_item_threshold = 0.2 * bin_capacity\n    if item < small_item_threshold:\n        almost_full_threshold = 0.05 * bin_capacity\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Large Item Penalty: Penalize bins where a large item will leave very little space,\n    # especially if that space is smaller than the average item size seen so far.\n    large_item_threshold = 0.7 * bin_capacity\n    if item > large_item_threshold:\n        small_space_threshold = 0.15 * bin_capacity #was 0.1\n        small_space_penalty = np.where(remaining_after < small_space_threshold, -0.8, 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Anticipatory Penalty: Penalize bins that will lead to highly fragmented space\n    # (multiple small spaces).  This requires a simplified simulation.\n    fragmentation_penalty = np.zeros_like(remaining_after)\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization) if bins_utilization.size > 0 else 0.0\n\n    waste_weight = 0.3 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.3 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.1\n    small_item_weight = 0.15\n    large_item_weight = 0.15\n\n    # Strategic Randomness:  Introduce randomness proportional to the *uncertainty*\n    # in the current state (high uncertainty when bins are similar, low when\n    # one bin is clearly better).\n    priority_range = np.max([waste_priority.max(), fill_level_priority.max(), 0.1]) - np.min([waste_priority.min(), fill_level_priority.min(), -0.1]) #Avoid empty sequence\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor) * priority_range\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (waste_weight * waste_priority +\n                               fill_weight * fill_level_priority +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness +\n                               fragmentation_penalty)\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), we see that they are identical.\nComparing (3rd) vs (4th), we see the 3rd has \"Anticipatory Near-Full Penalty (Stronger penalty, scaled by item size)\" and \"Strategic Randomness (Controlled, decays slower for smaller items)\", while the 4th does not. The 4th uses item size and bin utilization in adaptive weighting, while the 3rd only uses item size.\nComparing (2nd worst) vs (worst), we see the worst one uses much more hyperparameter and `scipy`, `random`, `math`, `torch`, which may not be necessary and cause overhead.\nComparing (1st) vs (11th), we see the 1st has many considerations like waste minimization, target fill level, and near-full management, while the 11th is just the start of the function.\nComparing (19th) vs (20th), the 20th enhanced heuristic focuses on a range of target fill levels, using Gaussian penalties for both underfill and overfill, and includes an anticipatory penalty based on average item size and an item fit score. The 19th does not.\nOverall: Top heuristics combine waste minimization, target fill level, dynamic penalties (near full, smaller item bonus, larger item penalty), adaptive weighting (item size, utilization), and strategic randomness. The weights are often made adaptive with learning rate to further enhance the performance. High-performing heuristics often include mechanisms to reduce fragmentation, like an anticipatory penalty or an item fit score. Less effective heuristics either lack key components, use simpler calculations, or fail to adapt to item sizes. Over-parameterization also lead to low performance.\n- \nOkay, let's redefine \"Current self-reflection\" to design better bin packing heuristics, while avoiding the pitfalls of \"Ineffective self-reflection.\" Here's a breakdown:\n\n*   **Keywords:** Adaptive weighting, dynamic penalties/bonuses, target fill, stochasticity, item characteristics, bin state.\n\n*   **Advice:** Focus on *how* to make these elements adaptive and dynamic. Develop clear, measurable metrics for bin utilization and item characteristics to drive adaptation. Implement decaying randomness.\n\n*   **Avoid:** Overly complex rules, focusing solely on individual factors in isolation, and premature optimization (code duplication before concept validation).\n\n*   **Explanation:** Shift from *what* factors to consider (waste minimization, etc.) to *how* they interact dynamically. The key is creating a feedback loop where item properties and bin states influence weighting, penalties, and randomness. Simpler core logic with sophisticated adaptation is preferred.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}