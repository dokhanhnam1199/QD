```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Enhanced heuristic: adaptive weights, dynamic near-full, item size considerations, and randomness,
       with improved waste management and exploration.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    can_fit = bins_remain_cap >= item

    if not np.any(can_fit):
        return np.full_like(priorities, -1.0)

    valid_bins = np.where(can_fit)[0]
    remaining_after = bins_remain_cap[can_fit] - item
    bin_capacity = bins_remain_cap.max()
    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity

    # Waste Minimization: Exponential scaling to penalize large waste more severely
    waste = remaining_after
    waste_penalty = np.exp(waste / bin_capacity)

    # Target Fill Level: Gaussian target for a soft preference
    target_fill_level = 0.8 * bin_capacity
    fill_level = bins_remain_cap[can_fit]
    fill_diff = (fill_level - target_fill_level)
    fill_score = np.exp(-(fill_diff**2) / (2 * (bin_capacity * 0.1)**2))  # Gaussian

    # Dynamic Near-Full Management: Contextual penalty
    near_full_threshold = 0.15 * bin_capacity
    is_near_full = remaining_after < near_full_threshold
    near_full_penalty = np.where(is_near_full, -0.9 * (item / bin_capacity) * (1 - bins_utilization), 0.0)

    # Smaller Item Bonus: Consider bins close to full, proportional to item size
    small_item_threshold = bin_capacity * 0.3
    if item < small_item_threshold:
        almost_full_threshold = bin_capacity * 0.1
        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001)) * (item / small_item_threshold)
    else:
        almost_full_bonus = 0.0

    # Larger Item Penalty: Only if it leads to very low bin utilization
    large_item_threshold = bin_capacity * 0.7
    if item > large_item_threshold:
        small_space_threshold = 0.15 * bin_capacity  # Increased threshold
        small_space_penalty = np.where(remaining_after < small_space_threshold, -0.8 * (item / bin_capacity) * (1 + bins_utilization), 0.0)
    else:
        small_space_penalty = 0.0
    
    # Encourage balanced bin utilization
    balance_bonus = -np.abs(bins_utilization - np.mean(bins_utilization))

    # Adaptive Weighting: Enhanced sensitivity
    item_size_factor = item / bin_capacity
    utilization_factor = np.mean(bins_utilization)

    waste_weight = 0.30 * (1 - item_size_factor) * (1 + utilization_factor)
    fill_weight = 0.30 * (1 + item_size_factor) * (1 - utilization_factor)
    near_full_weight = 0.15
    small_item_weight = 0.075
    large_item_weight = 0.075
    balance_weight = 0.1

    # Stochasticity: Adjusted scaling for better exploration, reduced for very large items
    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor) * (1 - (item > 0.9 * bin_capacity)) # Reduced for large items
    randomness = np.random.normal(0, randomness_scale, len(valid_bins))

    priorities[valid_bins] = (waste_weight / waste_penalty +
                               fill_weight * fill_score +
                               near_full_weight * near_full_penalty +
                               small_item_weight * almost_full_bonus +
                               large_item_weight * small_space_penalty +
                               balance_weight * balance_bonus +
                               randomness)

    return priorities
```
