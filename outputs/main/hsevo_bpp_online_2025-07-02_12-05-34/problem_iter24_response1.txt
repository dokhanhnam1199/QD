```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Enhanced heuristic with adaptive weighting, dynamic penalties/bonuses,
    target fill, decaying stochasticity, and item/bin state awareness.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    can_fit = bins_remain_cap >= item

    if not np.any(can_fit):
        return np.full_like(priorities, -1.0)

    valid_bins = np.where(can_fit)[0]
    remaining_after = bins_remain_cap[can_fit] - item
    bin_capacity = bins_remain_cap.max()
    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity

    # 1. Waste Minimization with Adaptive Tightness
    waste = remaining_after
    base_tightness = 1 / (waste + 0.0001)
    # Adapt tightness based on item size: smaller items benefit more from tight fits.
    item_size_factor = item / bin_capacity
    tightness = base_tightness * (1 + (1 - item_size_factor))  # Boost tightness for small items


    # 2. Target Fill Level with Dynamic Target
    # Adjust target fill based on average bin utilization: if bins are filling up, aim higher.
    avg_utilization = np.mean(bins_utilization)
    target_fill_level = (0.65 + 0.2 * avg_utilization) * bin_capacity #was 0.75
    fill_level = bins_remain_cap[can_fit]
    fill_diff = np.abs(fill_level - target_fill_level)
    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))

    # 3. Dynamic Near-Full Management
    near_full_threshold = 0.12 * bin_capacity
    is_near_full = remaining_after < near_full_threshold
    # Adaptive penalty: larger penalty if the item is also large relative to bin capacity
    near_full_penalty = np.where(is_near_full, -0.7 * (item/bin_capacity) * (1+bins_utilization), 0.0)

    # 4. Smaller Item Bonus (if item fits nearly perfectly into a near-full bin)
    small_item_threshold = bin_capacity * 0.25
    if item < small_item_threshold:
        almost_full_threshold = bin_capacity * 0.1
        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))
    else:
        almost_full_bonus = 0.0

    # 5. Larger Item Penalty (if placing it leaves very little space)
    large_item_threshold = bin_capacity * 0.75
    if item > large_item_threshold:
        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6 * (item/bin_capacity), 0.0) #was 0.7
    else:
        small_space_penalty = 0.0

    # 6. Adaptive Weighting: item size & bin utilization
    #   - Emphasis on tightness when item is small and bins aren't fully utilized
    #   - Emphasis on fill when item is large or bins are highly utilized
    tightness_weight = 0.35 * (1.2 - item_size_factor) * (1.1 - avg_utilization) #was (1 - item_size_factor) * (1 + utilization_factor)
    fill_weight = 0.35 * (0.8 + item_size_factor) * (0.9 + avg_utilization) #was (1 + item_size_factor) * (1 - utilization_factor)
    near_full_weight = 0.15
    small_item_weight = 0.075
    large_item_weight = 0.075

    # 7. Decaying Stochasticity
    #   - Reduce randomness as bins fill up to stabilize the packing
    randomness_scale = 0.015 * (1 + item_size_factor) * (1 - avg_utilization) #was 0.015 * (1 + item_size_factor) * (1 - utilization_factor)
    randomness = np.random.normal(0, randomness_scale, len(valid_bins))

    priorities[valid_bins] = (tightness_weight * tightness +
                               fill_weight * fill_score +
                               near_full_weight * near_full_penalty +
                               small_item_weight * almost_full_bonus +
                               large_item_weight * small_space_penalty +
                               randomness)

    return priorities
```
