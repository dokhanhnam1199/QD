{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines waste minimization, target fill, adaptive weighting,\n    edge case handling, and stochasticity for improved bin packing.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0) # Significantly penalize no-fit situation\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization (Tightness)\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)  # Avoid division by zero\n\n    # Target Fill Level (Adaptive based on item size)\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty (Adjusted threshold)\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.7, 0.0)\n\n    # Small Item Bonus (Adaptive bonus)\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0\n\n    # Large Item Penalty - discourage placing large items in bins with little space\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6, 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting (Dynamically adjust based on item size and bin states)\n    item_size_factor = item / bin_capacity  # Normalize item size\n    tightness_weight = 0.4 #* (1 - item_size_factor) # Smaller items, prioritize tightness\n    fill_weight = 0.3 #* (1 + item_size_factor)   # Larger items, prioritize target fill\n    near_full_weight = 0.2\n    small_item_weight = 0.1\n    large_item_weight = 0.1\n\n    # Stochasticity (Add slight randomness to break ties)\n    randomness = np.random.normal(0, 0.01, len(valid_bins))\n\n    # Combine scores with weights\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines wasted space minimization, target fill and nearly full bin penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    fit_within_capacity = bins_remain_cap >= item\n    nearly_full_threshold = 0.1\n    nearly_full_penalty = 0.5\n\n    if np.any(fit_within_capacity):\n        # Wasted space minimization (primary objective)\n        wasted_space = bins_remain_cap[fit_within_capacity] - item\n        priorities[fit_within_capacity] = 1.0 / (1e-6 + wasted_space)\n\n        # Target fill ratio (secondary objective)\n        fill_ratios = item / bins_remain_cap[fit_within_capacity]\n        target_fill = 0.8\n        fill_ratio_priority = -np.abs(fill_ratios - target_fill)\n        priorities[fit_within_capacity] += fill_ratio_priority * 0.1\n\n        # Penalize nearly full bins to avoid creating tiny fragments\n        nearly_full = bins_remain_cap < nearly_full_threshold * np.max(bins_remain_cap)\n        priorities[nearly_full] *= (1 - nearly_full_penalty)\n\n        # Add a bit of randomness to escape local optima\n        randomness = np.random.rand(np.sum(fit_within_capacity)) * 0.01\n        priorities[fit_within_capacity] += randomness\n    else:\n        priorities = -np.inf * np.ones_like(priorities)\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the 1st implementation focuses on carefully tuned weights for various factors (tightness, fill level, near-full penalty, small/large item bonuses) and incorporates stochasticity, while the 20th implementation introduces many parameters as arguments with specific default values and has a more intricate structure. This suggests that adaptive weighting and careful parameter tuning are important.\n\nComparing (1st) vs (5th), we see the 1st version includes an additional adjustment: 'large item penalty' that discourages placing large items in bins with little space. This considers the item size. 5th version introduce more sophisticated adaptive weighting and scaling penalties based on item size. It also has an empty bin prioritization for large items.  The 1st also has stochasticity.\n\nComparing (2nd best) vs (2nd worst) (2nd vs 19th), we see version 2nd include target fill level. Comparing (3rd) vs (4th), there are identical. Comparing (second worst) vs (worst) (19th vs 20th), we see 20th takes many arguments.\n\nOverall:\nThe better heuristics seem to focus on a combination of factors, including waste minimization, target fill levels, near-full penalties, and bonuses for certain item sizes. They also incorporate adaptive weighting strategies based on item size and bin states, and often include a degree of stochasticity to promote exploration and avoid local optima. The worst heuristics have lack adaptive weighting strategies.\n- \nOkay, I'm ready to refine \"Current self-reflection\" to design better heuristics, focusing on actionable insights and avoiding common pitfalls. Let's aim for that $999K heuristic! Here's my take:\n\n*   **Keywords:** Objective function landscape, adaptive learning, multi-objective optimization, exploration-exploitation balance.\n\n*   **Advice:** Analyze the objective function landscape to inform exploration strategies. Use adaptive learning to dynamically adjust weights and parameters based on feedback during the search. Explicitly define and manage the exploration-exploitation trade-off.\n\n*   **Avoid:** Vague statements about \"fine-tuning\" or \"balancing.\" Don't rely solely on trial-and-error; base adjustments on observed performance and understanding of the problem structure.\n\n*   **Explanation:** Instead of just saying \"tune weights,\" focus on *how* to tune them. Track performance metrics (e.g., waste, fill level, time) and use these to guide weight adjustments. Adaptive learning algorithms (e.g., reinforcement learning) can automate this process. Understanding the objective function landscape helps design more effective exploration strategies (e.g., biased sampling towards promising regions).\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}