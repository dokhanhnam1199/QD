```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines waste minimization, target fill, adaptive weighting,
    edge case handling, and stochasticity for improved bin packing.
    Improves upon v1 by incorporating bin diversity and a dynamic penalty
    for exceeding a target number of bins used. Also utilizes a decaying
    randomness factor.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    can_fit = bins_remain_cap >= item

    if not np.any(can_fit):
        return np.full_like(priorities, -1.0)

    valid_bins = np.where(can_fit)[0]
    remaining_after = bins_remain_cap[can_fit] - item
    bin_capacity = bins_remain_cap.max()
    num_bins = len(bins_remain_cap)

    # Waste Minimization
    waste = remaining_after
    tightness = 1 / (waste + 0.0001)

    # Target Fill Level
    target_fill_level = 0.75 * bin_capacity
    fill_level = bins_remain_cap[can_fit]
    fill_diff = np.abs(fill_level - target_fill_level)
    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))

    # Near-Full Penalty
    near_full_threshold = 0.1 * bin_capacity
    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.7, 0.0)

    # Small Item Bonus
    small_item_threshold = bin_capacity * 0.2
    if item < small_item_threshold:
        almost_full_threshold = bin_capacity * 0.1
        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))
    else:
        almost_full_bonus = 0

    # Large Item Penalty
    large_item_threshold = bin_capacity * 0.8
    if item > large_item_threshold:
        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6, 0.0)
    else:
        small_space_penalty = 0.0

    # Adaptive Weighting (Dynamically adjust based on item size and bin states)
    item_size_factor = item / bin_capacity  # Normalize item size
    tightness_weight = 0.4 * (1 - item_size_factor) # Smaller items, prioritize tightness
    fill_weight = 0.3 * (1 + item_size_factor)   # Larger items, prioritize target fill
    near_full_weight = 0.2
    small_item_weight = 0.1
    large_item_weight = 0.1

    # Bin Diversity Encouragement: Prioritize bins with different fill levels
    fill_std = np.std(bins_remain_cap)
    diversity_bonus = fill_std / bin_capacity  # Normalize diversity

    # Dynamic Bin Count Penalty: Encourage packing into fewer bins
    bins_used = np.sum(bins_remain_cap < bin_capacity)
    target_bins = int(np.ceil(np.sum(item) / bin_capacity)) if isinstance(item,float) else int(np.ceil(np.sum(item)/bin_capacity))
    over_bins = max(0, bins_used - target_bins)
    bin_count_penalty = -0.1 * over_bins

    # Decaying Stochasticity: Reduce randomness over time (simulated)
    # This would ideally be managed externally to track the "packing progress".
    # Here, we approximate it using the mean remaining capacity
    packing_progress = np.mean(bins_remain_cap) / bin_capacity
    randomness_strength = max(0.0, 0.01 * (1 - packing_progress))  # Reduced randomness
    randomness = np.random.normal(0, randomness_strength, len(valid_bins))

    priorities[valid_bins] = (tightness_weight * tightness +
                               fill_weight * fill_score +
                               near_full_weight * near_full_penalty +
                               small_item_weight * almost_full_bonus +
                               large_item_weight * small_space_penalty +
                               diversity_bonus +
                               bin_count_penalty+
                               randomness)

    return priorities
```
