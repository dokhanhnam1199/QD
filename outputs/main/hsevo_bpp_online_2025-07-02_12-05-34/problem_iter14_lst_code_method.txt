{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines waste minimization, target fill, adaptive weighting,\n    edge case handling, stochasticity, and bin diversity for improved bin packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.7, 0.0)\n\n    # Small Item Bonus\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0\n\n    # Large Item Penalty\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6, 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting (Dynamically adjust based on item size and bin states)\n    item_size_factor = item / bin_capacity  # Normalize item size\n    tightness_weight = 0.4 * (1 - item_size_factor) # Smaller items, prioritize tightness\n    fill_weight = 0.3 * (1 + item_size_factor)   # Larger items, prioritize target fill\n    near_full_weight = 0.2\n    small_item_weight = 0.1\n    large_item_weight = 0.1\n\n    # Bin Diversity Encouragement: Penalize bins with similar fill levels to promote variance\n    fill_level_std = np.std(bins_remain_cap)\n    diversity_bonus = np.exp(-np.abs(bins_remain_cap[can_fit] - np.mean(bins_remain_cap)) / (fill_level_std + 0.0001)) if fill_level_std > 0.01 else 0.0\n    diversity_weight = 0.05\n\n    # Stochasticity (Reduced for more stability, but still present)\n    randomness = np.random.normal(0, 0.005, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               diversity_weight * diversity_bonus +\n                               randomness)\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines waste minimization, target fill, adaptive weighting,\n    edge case handling, stochasticity, and bin diversity for improved bin packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.7, 0.0)\n\n    # Small Item Bonus\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0\n\n    # Large Item Penalty\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6, 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting (Dynamically adjust based on item size and bin states)\n    item_size_factor = item / bin_capacity  # Normalize item size\n    tightness_weight = 0.4 * (1 - item_size_factor) # Smaller items, prioritize tightness\n    fill_weight = 0.3 * (1 + item_size_factor)   # Larger items, prioritize target fill\n    near_full_weight = 0.2\n    small_item_weight = 0.1\n    large_item_weight = 0.1\n\n    # Bin Diversity Encouragement: Penalize bins with similar fill levels to promote variance\n    fill_level_std = np.std(bins_remain_cap)\n    diversity_bonus = np.exp(-np.abs(bins_remain_cap[can_fit] - np.mean(bins_remain_cap)) / (fill_level_std + 0.0001)) if fill_level_std > 0.01 else 0.0\n    diversity_weight = 0.05\n\n    # Stochasticity (Reduced for more stability, but still present)\n    randomness = np.random.normal(0, 0.005, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               diversity_weight * diversity_bonus +\n                               randomness)\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines waste minimization, target fill, adaptive weighting,\n    edge case handling, and stochasticity for improved bin packing.\n    Improves upon v1 by incorporating bin diversity and a dynamic penalty\n    for exceeding a target number of bins used. Also utilizes a decaying\n    randomness factor.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    num_bins = len(bins_remain_cap)\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.7, 0.0)\n\n    # Small Item Bonus\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0\n\n    # Large Item Penalty\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6, 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting (Dynamically adjust based on item size and bin states)\n    item_size_factor = item / bin_capacity  # Normalize item size\n    tightness_weight = 0.4 * (1 - item_size_factor) # Smaller items, prioritize tightness\n    fill_weight = 0.3 * (1 + item_size_factor)   # Larger items, prioritize target fill\n    near_full_weight = 0.2\n    small_item_weight = 0.1\n    large_item_weight = 0.1\n\n    # Bin Diversity Encouragement: Prioritize bins with different fill levels\n    fill_std = np.std(bins_remain_cap)\n    diversity_bonus = fill_std / bin_capacity  # Normalize diversity\n\n    # Dynamic Bin Count Penalty: Encourage packing into fewer bins\n    bins_used = np.sum(bins_remain_cap < bin_capacity)\n    target_bins = int(np.ceil(np.sum(item) / bin_capacity)) if isinstance(item,float) else int(np.ceil(np.sum(item)/bin_capacity))\n    over_bins = max(0, bins_used - target_bins)\n    bin_count_penalty = -0.1 * over_bins\n\n    # Decaying Stochasticity: Reduce randomness over time (simulated)\n    # This would ideally be managed externally to track the \"packing progress\".\n    # Here, we approximate it using the mean remaining capacity\n    packing_progress = np.mean(bins_remain_cap) / bin_capacity\n    randomness_strength = max(0.0, 0.01 * (1 - packing_progress))  # Reduced randomness\n    randomness = np.random.normal(0, randomness_strength, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               diversity_bonus +\n                               bin_count_penalty+\n                               randomness)\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines waste minimization, target fill, adaptive weighting,\n    edge case handling, and stochasticity for improved bin packing.\n    Improves upon v1 by incorporating bin diversity and a dynamic penalty\n    for exceeding a target number of bins used. Also utilizes a decaying\n    randomness factor.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    num_bins = len(bins_remain_cap)\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.7, 0.0)\n\n    # Small Item Bonus\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0\n\n    # Large Item Penalty\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6, 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting (Dynamically adjust based on item size and bin states)\n    item_size_factor = item / bin_capacity  # Normalize item size\n    tightness_weight = 0.4 * (1 - item_size_factor) # Smaller items, prioritize tightness\n    fill_weight = 0.3 * (1 + item_size_factor)   # Larger items, prioritize target fill\n    near_full_weight = 0.2\n    small_item_weight = 0.1\n    large_item_weight = 0.1\n\n    # Bin Diversity Encouragement: Prioritize bins with different fill levels\n    fill_std = np.std(bins_remain_cap)\n    diversity_bonus = fill_std / bin_capacity  # Normalize diversity\n\n    # Dynamic Bin Count Penalty: Encourage packing into fewer bins\n    bins_used = np.sum(bins_remain_cap < bin_capacity)\n    target_bins = int(np.ceil(np.sum(item) / bin_capacity)) if isinstance(item,float) else int(np.ceil(np.sum(item)/bin_capacity))\n    over_bins = max(0, bins_used - target_bins)\n    bin_count_penalty = -0.1 * over_bins\n\n    # Decaying Stochasticity: Reduce randomness over time (simulated)\n    # This would ideally be managed externally to track the \"packing progress\".\n    # Here, we approximate it using the mean remaining capacity\n    packing_progress = np.mean(bins_remain_cap) / bin_capacity\n    randomness_strength = max(0.0, 0.01 * (1 - packing_progress))  # Reduced randomness\n    randomness = np.random.normal(0, randomness_strength, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               diversity_bonus +\n                               bin_count_penalty+\n                               randomness)\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines waste minimization, target fill, adaptive weighting,\n    edge case handling, and stochasticity for improved bin packing.\n    Improves upon v1 by incorporating bin diversity and a dynamic penalty\n    for exceeding a target number of bins used. Also utilizes a decaying\n    randomness factor.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    num_bins = len(bins_remain_cap)\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.7, 0.0)\n\n    # Small Item Bonus\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0\n\n    # Large Item Penalty\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6, 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting (Dynamically adjust based on item size and bin states)\n    item_size_factor = item / bin_capacity  # Normalize item size\n    tightness_weight = 0.4 * (1 - item_size_factor) # Smaller items, prioritize tightness\n    fill_weight = 0.3 * (1 + item_size_factor)   # Larger items, prioritize target fill\n    near_full_weight = 0.2\n    small_item_weight = 0.1\n    large_item_weight = 0.1\n\n    # Bin Diversity Encouragement: Prioritize bins with different fill levels\n    fill_std = np.std(bins_remain_cap)\n    diversity_bonus = fill_std / bin_capacity  # Normalize diversity\n\n    # Dynamic Bin Count Penalty: Encourage packing into fewer bins\n    bins_used = np.sum(bins_remain_cap < bin_capacity)\n    target_bins = int(np.ceil(np.sum(item) / bin_capacity)) if isinstance(item,float) else int(np.ceil(np.sum(item)/bin_capacity))\n    over_bins = max(0, bins_used - target_bins)\n    bin_count_penalty = -0.1 * over_bins\n\n    # Decaying Stochasticity: Reduce randomness over time (simulated)\n    # This would ideally be managed externally to track the \"packing progress\".\n    # Here, we approximate it using the mean remaining capacity\n    packing_progress = np.mean(bins_remain_cap) / bin_capacity\n    randomness_strength = max(0.0, 0.01 * (1 - packing_progress))  # Reduced randomness\n    randomness = np.random.normal(0, randomness_strength, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               diversity_bonus +\n                               bin_count_penalty+\n                               randomness)\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines waste minimization, target fill, near-full penalty, \n    adaptive weighting and stochasticity. Item-size aware.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.5, 0.0)\n\n    # Adaptive Weighting based on item size\n    item_size_factor = item / bin_capacity\n    tightness_weight = 0.5 * (1 - item_size_factor)\n    fill_weight = 0.3 * (1 + item_size_factor)\n    near_full_weight = 0.2\n\n    # Stochasticity\n    randomness = np.random.normal(0, 0.01, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, near-full penalty, and item size bonus.\n    Adaptive weights are used.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, 0.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n\n    # Waste minimization: Prioritize tighter fits\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target fill level (e.g., 75%): Reward bins closer to target\n    target_fill_level = 0.75 * bins_remain_cap.max()\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bins_remain_cap.max() * 0.2))\n\n    # Near-full penalty\n    near_full_threshold = 0.1 * bins_remain_cap.max()\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.5, 0.0)\n\n    # Small item bonus\n    small_item_threshold = bins_remain_cap.max() * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bins_remain_cap.max() * 0.1\n        almost_full_bonus = (bins_remain_cap[can_fit] > item) * np.exp(-remaining_after / almost_full_threshold)\n    else:\n        almost_full_bonus = 0\n\n    # Adaptive weights based on item size\n    if item < bins_remain_cap.max() * 0.1:\n        tightness_weight = 0.3\n        fill_weight = 0.4\n        near_full_weight = 0.1\n        small_item_weight = 0.2\n    elif item > bins_remain_cap.max() * 0.5:\n        tightness_weight = 0.5\n        fill_weight = 0.2\n        near_full_weight = 0.2\n        small_item_weight = 0.1\n    else:\n        tightness_weight = 0.4\n        fill_weight = 0.3\n        near_full_weight = 0.2\n        small_item_weight = 0.1\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus)\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, near-full penalty, and adaptive weights.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n\n    # Waste minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target fill level\n    target_fill_level = 0.75 * bins_remain_cap.max()\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bins_remain_cap.max() * 0.2))\n\n    # Near-full penalty\n    near_full_threshold = 0.1 * bins_remain_cap.max()\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -1.0 * (item / bins_remain_cap.max()), 0.0)\n\n    # Adaptive Weighting\n    item_size_ratio = item / bins_remain_cap.max()\n    tightness_weight = 0.5 - 0.2 * item_size_ratio\n    fill_weight = 0.2 + 0.2 * item_size_ratio\n    near_full_weight = 0.2 + 0.1 * item_size_ratio\n\n    tightness_weight = np.clip(tightness_weight, 0.1, 0.5)\n    fill_weight = np.clip(fill_weight, 0.1, 0.4)\n    near_full_weight = np.clip(near_full_weight, 0.1, 0.3)\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty)\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Enhanced heuristic combining waste minimization, target fill,\n    adaptive weighting based on bin utilization and item size,\n    dynamic near-full management, and a refined stochastic component.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.15))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.15 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8, 0.0)  # Stronger penalty\n\n    # Smaller Item Bonus\n    small_item_threshold = bin_capacity * 0.25\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty\n    large_item_threshold = bin_capacity * 0.75\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.7, 0.0) #Increased penalty\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting: Reacting to bin utilization & item size\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization) #Global view\n\n    # Adjust weights based on item size AND overall bin utilization.\n    tightness_weight = 0.35 * (1 - item_size_factor) * (1+utilization_factor)\n    fill_weight = 0.35 * (1 + item_size_factor) * (1-utilization_factor)\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # Refined Stochasticity: scaled by item size and bin utilization\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Enhanced heuristic combining waste minimization, target fill,\n    adaptive weighting based on bin utilization and item size,\n    dynamic near-full management, and a refined stochastic component.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.15))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.15 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8, 0.0)  # Stronger penalty\n\n    # Smaller Item Bonus\n    small_item_threshold = bin_capacity * 0.25\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty\n    large_item_threshold = bin_capacity * 0.75\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.7, 0.0) #Increased penalty\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting: Reacting to bin utilization & item size\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization) #Global view\n\n    # Adjust weights based on item size AND overall bin utilization.\n    tightness_weight = 0.35 * (1 - item_size_factor) * (1+utilization_factor)\n    fill_weight = 0.35 * (1 + item_size_factor) * (1-utilization_factor)\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # Refined Stochasticity: scaled by item size and bin utilization\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, near-full penalty, and randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    # Waste minimization\n    waste = bins_remain_cap[can_fit] - item\n    priorities[can_fit] = 1.0 / (1e-6 + waste)\n\n    # Target fill level\n    max_bin_cap = np.max(bins_remain_cap)\n    target_fill = 0.8 * max_bin_cap\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / max_bin_cap)\n    priorities[can_fit] += fill_priority * 0.1\n\n    # Near-full penalty\n    nearly_full_threshold = 0.1 * max_bin_cap\n    nearly_full = bins_remain_cap < nearly_full_threshold\n    priorities[nearly_full] *= 0.5\n\n    # Randomness\n    randomness = np.random.rand(np.sum(can_fit)) * 0.01\n    priorities[can_fit] += randomness\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, near-full penalty, and randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    # Waste minimization\n    waste = bins_remain_cap[can_fit] - item\n    priorities[can_fit] = 1.0 / (1e-6 + waste)\n\n    # Target fill level\n    max_bin_cap = np.max(bins_remain_cap)\n    target_fill = 0.8 * max_bin_cap\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / max_bin_cap)\n    priorities[can_fit] += fill_priority * 0.1\n\n    # Near-full penalty\n    nearly_full_threshold = 0.1 * max_bin_cap\n    nearly_full = bins_remain_cap < nearly_full_threshold\n    priorities[nearly_full] *= 0.5\n\n    # Randomness\n    randomness = np.random.rand(np.sum(can_fit)) * 0.01\n    priorities[can_fit] += randomness\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, near-full penalty, and randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    # Waste minimization\n    waste = bins_remain_cap[can_fit] - item\n    priorities[can_fit] = 1.0 / (1e-6 + waste)\n\n    # Target fill level\n    max_bin_cap = np.max(bins_remain_cap)\n    target_fill = 0.8 * max_bin_cap\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / max_bin_cap)\n    priorities[can_fit] += fill_priority * 0.1\n\n    # Near-full penalty\n    nearly_full_threshold = 0.1 * max_bin_cap\n    nearly_full = bins_remain_cap < nearly_full_threshold\n    priorities[nearly_full] *= 0.5\n\n    # Randomness\n    randomness = np.random.rand(np.sum(can_fit)) * 0.01\n    priorities[can_fit] += randomness\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, near-full penalty, and randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    # Waste minimization\n    waste = bins_remain_cap[can_fit] - item\n    priorities[can_fit] = 1.0 / (1e-6 + waste)\n\n    # Target fill level\n    max_bin_cap = np.max(bins_remain_cap)\n    target_fill = 0.8 * max_bin_cap\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / max_bin_cap)\n    priorities[can_fit] += fill_priority * 0.1\n\n    # Near-full penalty\n    nearly_full_threshold = 0.1 * max_bin_cap\n    nearly_full = bins_remain_cap < nearly_full_threshold\n    priorities[nearly_full] *= 0.5\n\n    # Randomness\n    randomness = np.random.rand(np.sum(can_fit)) * 0.01\n    priorities[can_fit] += randomness\n\n    return priorities\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins using tightness, target fill, waste, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        priorities[:] = np.random.rand(len(priorities)) * 0.0001\n        return priorities\n\n    remaining_space = bins_remain_cap[valid_bins] - item\n    fit_score = 1.0 / (remaining_space + 0.0001)\n\n    target_fill = bins_remain_cap.max() * 0.75\n    fill_level_diff = np.abs(bins_remain_cap[valid_bins] - target_fill)\n    fill_level_score = 1.0 / (fill_level_diff + 0.0001)\n\n    waste_threshold = bins_remain_cap.max() * 0.25\n    waste_score = np.where(remaining_space > waste_threshold, 0.1, 1.0)\n\n    num_valid = np.sum(valid_bins)\n    if num_valid > 5:\n        fit_weight = 0.6\n        fill_weight = 0.3\n        waste_weight = 0.1\n    else:\n        fit_weight = 0.4\n        fill_weight = 0.4\n        waste_weight = 0.2\n\n    combined_score = (fit_weight * fit_score + fill_weight * fill_level_score + waste_weight * waste_score)\n\n    priorities[valid_bins] = combined_score\n    priorities[valid_bins] += np.random.rand(np.sum(valid_bins)) * 0.1\n\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, near-full penalty, randomness, and item size consideration.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float) - np.inf\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        # Waste minimization\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] = -waste\n\n        # Target fill level\n        target_capacity = 0.75 * bins_remain_cap.max()\n        capacity_diff = np.abs(bins_remain_cap[valid_bins] - target_capacity)\n        priorities[valid_bins] += 0.5 / (capacity_diff + 0.0001)\n\n        # Near-full penalty\n        remaining_after_add = bins_remain_cap[valid_bins] - item\n        near_full_penalty = np.where(remaining_after_add < (0.1*bins_remain_cap.max()), -0.5, 0.0)\n        priorities[valid_bins] += near_full_penalty\n\n        # Randomness\n        priorities[valid_bins] += np.random.rand(np.sum(valid_bins)) * 0.01\n\n         # Fill percentage bonus\n        fill_percentage = item / bins_remain_cap[valid_bins]\n        priorities[valid_bins] += fill_percentage\n    \n        # Item Size Consideration: Penalize placing large items in bins with little extra space\n        large_item_threshold = 0.5 * bins_remain_cap.max()\n        if item > large_item_threshold:\n            small_space_penalty = np.where(bins_remain_cap[valid_bins] < (item + 0.1 * bins_remain_cap.max()), -0.2, 0.0)\n            priorities[valid_bins] += small_space_penalty\n\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, target fill, near-full penalty, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float) - np.inf\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        # Best fit - Minimize waste\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] = -waste\n\n        # Target fill level\n        target_capacity = 0.75 * bins_remain_cap.max()\n        capacity_diff = np.abs(bins_remain_cap[valid_bins] - target_capacity)\n        priorities[valid_bins] += 0.5 / (capacity_diff + 0.0001)\n\n        # Near-full penalty\n        remaining_after_add = bins_remain_cap[valid_bins] - item\n        near_full_penalty = np.where(remaining_after_add < (0.1*bins_remain_cap.max()), -0.5, 0.0)\n        priorities[valid_bins] += near_full_penalty\n\n        # Randomness\n        priorities[valid_bins] += np.random.rand(np.sum(valid_bins)) * 0.01\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, target fill, near-full penalty, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float) - np.inf\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        # Best fit - Minimize waste\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] = -waste\n\n        # Target fill level\n        target_capacity = 0.75 * bins_remain_cap.max()\n        capacity_diff = np.abs(bins_remain_cap[valid_bins] - target_capacity)\n        priorities[valid_bins] += 0.5 / (capacity_diff + 0.0001)\n\n        # Near-full penalty\n        remaining_after_add = bins_remain_cap[valid_bins] - item\n        near_full_penalty = np.where(remaining_after_add < (0.1*bins_remain_cap.max()), -0.5, 0.0)\n        priorities[valid_bins] += near_full_penalty\n\n        # Randomness\n        priorities[valid_bins] += np.random.rand(np.sum(valid_bins)) * 0.01\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, target fill, near-full penalty, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float) - np.inf\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        # Best fit - Minimize waste\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] = -waste\n\n        # Target fill level\n        target_capacity = 0.75 * bins_remain_cap.max()\n        capacity_diff = np.abs(bins_remain_cap[valid_bins] - target_capacity)\n        priorities[valid_bins] += 0.5 / (capacity_diff + 0.0001)\n\n        # Near-full penalty\n        remaining_after_add = bins_remain_cap[valid_bins] - item\n        near_full_penalty = np.where(remaining_after_add < (0.1*bins_remain_cap.max()), -0.5, 0.0)\n        priorities[valid_bins] += near_full_penalty\n\n        # Randomness\n        priorities[valid_bins] += np.random.rand(np.sum(valid_bins)) * 0.01\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines best-fit, target fill, near-full penalty, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float) - np.inf\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        # Best fit - Minimize waste\n        waste = bins_remain_cap[valid_bins] - item\n        priorities[valid_bins] = -waste\n\n        # Target fill level\n        target_capacity = 0.75 * bins_remain_cap.max()\n        capacity_diff = np.abs(bins_remain_cap[valid_bins] - target_capacity)\n        priorities[valid_bins] += 0.5 / (capacity_diff + 0.0001)\n\n        # Near-full penalty\n        remaining_after_add = bins_remain_cap[valid_bins] - item\n        near_full_penalty = np.where(remaining_after_add < (0.1*bins_remain_cap.max()), -0.5, 0.0)\n        priorities[valid_bins] += near_full_penalty\n\n        # Randomness\n        priorities[valid_bins] += np.random.rand(np.sum(valid_bins)) * 0.01\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}