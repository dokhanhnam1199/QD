{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines best-fit, target fill, waste minimization, and randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        priorities[:] = np.random.rand(len(priorities)) * 0.0001\n        return priorities\n\n    remaining_space = bins_remain_cap[valid_bins] - item\n    fit_score = 1.0 / (remaining_space + 0.0001)\n\n    target_fill = bins_remain_cap.max() * 0.75\n    fill_level_diff = np.abs(bins_remain_cap[valid_bins] - target_fill)\n    fill_level_score = 1.0 / (fill_level_diff + 0.0001)\n\n    waste_threshold = bins_remain_cap.max() * 0.25\n    waste_score = np.where(remaining_space > waste_threshold, 0.1, 1.0)\n\n    num_valid = np.sum(valid_bins)\n    if num_valid > 5:\n        fit_weight = 0.6\n        fill_weight = 0.3\n        waste_weight = 0.1\n    else:\n        fit_weight = 0.4\n        fill_weight = 0.4\n        waste_weight = 0.2\n\n    combined_score = (fit_weight * fit_score + fill_weight * fill_level_score + waste_weight * waste_score)\n\n    priorities[valid_bins] = combined_score\n    priorities[valid_bins] += np.random.rand(np.sum(valid_bins)) * 0.1\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins based on tightness, target fill, and waste.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        priorities[:] = np.random.rand(len(priorities)) * 0.0001\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n\n    # Tightness score\n    tightness = 1 / (remaining_after + 0.0001)\n\n    # Target fill level score\n    target_fill = bins_remain_cap.max() * 0.75\n    fill_level_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_level_score = 1 / (fill_level_diff + 0.0001)\n\n    # Waste minimization score\n    waste_threshold = bins_remain_cap.max() * 0.25\n    waste_score = np.where(remaining_after > waste_threshold, 0.1, 1.0)\n\n    # Adaptive weighting based on the number of valid bins\n    num_valid = np.sum(can_fit)\n    if num_valid > 5:\n        tightness_weight = 0.6\n        fill_weight = 0.3\n        waste_weight = 0.1\n    else:\n        tightness_weight = 0.4\n        fill_weight = 0.4\n        waste_weight = 0.2\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_level_score +\n                               waste_weight * waste_score)\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the 1st implementation focuses on carefully tuned weights for various factors (tightness, fill level, near-full penalty, small/large item bonuses) and incorporates stochasticity, while the 20th implementation introduces many parameters as arguments with specific default values and has a more intricate structure. This suggests that adaptive weighting and careful parameter tuning are important.\n\nComparing (1st) vs (5th), we see the 1st version includes an additional adjustment: 'large item penalty' that discourages placing large items in bins with little space. This considers the item size. 5th version introduce more sophisticated adaptive weighting and scaling penalties based on item size. It also has an empty bin prioritization for large items.  The 1st also has stochasticity.\n\nComparing (2nd best) vs (2nd worst) (2nd vs 19th), we see version 2nd include target fill level. Comparing (3rd) vs (4th), there are identical. Comparing (second worst) vs (worst) (19th vs 20th), we see 20th takes many arguments.\n\nOverall:\nThe better heuristics seem to focus on a combination of factors, including waste minimization, target fill levels, near-full penalties, and bonuses for certain item sizes. They also incorporate adaptive weighting strategies based on item size and bin states, and often include a degree of stochasticity to promote exploration and avoid local optima. The worst heuristics have lack adaptive weighting strategies.\n- \nOkay, I'm ready to refine \"Current self-reflection\" to design better heuristics, focusing on actionable insights and avoiding common pitfalls. Let's aim for that $999K heuristic! Here's my take:\n\n*   **Keywords:** Objective function landscape, adaptive learning, multi-objective optimization, exploration-exploitation balance.\n\n*   **Advice:** Analyze the objective function landscape to inform exploration strategies. Use adaptive learning to dynamically adjust weights and parameters based on feedback during the search. Explicitly define and manage the exploration-exploitation trade-off.\n\n*   **Avoid:** Vague statements about \"fine-tuning\" or \"balancing.\" Don't rely solely on trial-and-error; base adjustments on observed performance and understanding of the problem structure.\n\n*   **Explanation:** Instead of just saying \"tune weights,\" focus on *how* to tune them. Track performance metrics (e.g., waste, fill level, time) and use these to guide weight adjustments. Adaptive learning algorithms (e.g., reinforcement learning) can automate this process. Understanding the objective function landscape helps design more effective exploration strategies (e.g., biased sampling towards promising regions).\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}