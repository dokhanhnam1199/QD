[
  {
    "stdout_filepath": "problem_iter20_response0.txt_stdout.txt",
    "code_path": "problem_iter20_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, adaptive penalty/bonus, and controlled randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    bin_capacity = np.max(bins_remain_cap)\n\n    # Waste Minimization (Best-Fit)\n    waste = bins_remain_cap[can_fit] - item\n    priorities[can_fit] = 1.0 / (1e-6 + waste)\n\n    # Adaptive Near-Full Management: Item Size-Dependent\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = bins_remain_cap[can_fit] < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8 * (item / bin_capacity), 0.0)\n    priorities[valid_bins] += near_full_penalty\n\n    # Small item bonus\n    small_item_threshold = 0.2 * bin_capacity\n    if item < small_item_threshold:\n      almost_full_threshold = 0.1 * bin_capacity\n      almost_full_valid_bins = bins_remain_cap[can_fit] < almost_full_threshold + item\n      almost_full_indices = np.where(can_fit)[0][almost_full_valid_bins]\n      priorities[almost_full_indices] += 0.2\n\n    # Controlled Randomness (decaying with item size and remaining capacity)\n    randomness_scale = 0.01 * (1 - item/bin_capacity) * (bins_remain_cap[can_fit] / bin_capacity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n    priorities[can_fit] += randomness\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.5073793378540135,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response1.txt_stdout.txt",
    "code_path": "problem_iter20_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weighting, near-full management, learning rate, & bin diversity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level (Dynamic)\n    current_utilization = np.mean((bin_capacity - bins_remain_cap) / bin_capacity)\n    target_fill_level = 0.7 + 0.1 * current_utilization\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level * bin_capacity)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8 * (item/bin_capacity), 0.0)\n\n    # Adaptive Weighting: item size & bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n    remaining_capacity_factor = np.mean(bins_remain_cap[can_fit] / bin_capacity)\n\n\n    tightness_weight = 0.3 * (1 - item_size_factor) * (1 + utilization_factor) * (1 + remaining_capacity_factor)\n    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor) * (1 - remaining_capacity_factor)\n    near_full_weight = 0.15\n\n\n    # Stochasticity scaled by item size and bin utilization\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor) * (1 + remaining_capacity_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # Learning Rate and Bin Diversity Reward\n    learning_rate = 0.01\n    bin_diversity_reward = (1 / (np.std(bins_remain_cap[can_fit]) + 0.0001)) * learning_rate\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness + bin_diversity_reward)\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 17.471080973274837,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response2.txt_stdout.txt",
    "code_path": "problem_iter20_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weights, dynamic penalties, and strategic randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.15 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0)\n\n    # Smaller Item Bonus\n    small_item_threshold = bin_capacity * 0.3\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty\n    large_item_threshold = bin_capacity * 0.7\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.15 * bin_capacity), -0.8 * (item/bin_capacity), 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n    remaining_capacity_factor = np.mean(bins_remain_cap[can_fit] / bin_capacity)\n\n    tightness_weight = 0.3 * (1 - item_size_factor) * (1 + utilization_factor) * (1 + remaining_capacity_factor)\n    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor) * (1 - remaining_capacity_factor)\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # Strategic Randomness (Tie-breaking)\n    num_valid_bins = len(valid_bins)\n    if num_valid_bins > 1:\n        best_priority = np.max((tightness_weight * tightness +\n                                   fill_weight * fill_score +\n                                   near_full_weight * near_full_penalty +\n                                   small_item_weight * almost_full_bonus +\n                                   large_item_weight * small_space_penalty))\n\n        potential_bins = valid_bins[np.isclose((tightness_weight * tightness +\n                                   fill_weight * fill_score +\n                                   near_full_weight * near_full_penalty +\n                                   small_item_weight * almost_full_bonus +\n                                   large_item_weight * small_space_penalty), best_priority)]\n        if len(potential_bins) > 1:\n             chosen_bin = np.random.choice(potential_bins)\n             #Assign high probability to selected bin, so that it will be packed\n             randomness = np.zeros(len(valid_bins))\n             chosen_idx = np.where(valid_bins == chosen_bin)[0]\n             randomness[chosen_idx] = 0.01\n        else:\n            randomness = np.zeros(len(valid_bins))\n    else:\n         randomness = np.zeros(len(valid_bins))\n\n    # Learning Rate (Bin Diversity Reward)\n    learning_rate = 0.01\n    bin_diversity_reward = (1 / (np.std(bins_remain_cap[can_fit]) + 0.0001)) * learning_rate\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness + bin_diversity_reward)\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 2.991623454327882,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response3.txt_stdout.txt",
    "code_path": "problem_iter20_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive weights, strategic randomness, problem-specific objectives by adaptive\n    exploration vs exploitation.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.15 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0)\n\n    # Smaller Item Bonus\n    small_item_threshold = bin_capacity * 0.3\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty\n    large_item_threshold = bin_capacity * 0.7\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.15 * bin_capacity), -0.8 * (item/bin_capacity), 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n    remaining_capacity_factor = np.mean(bins_remain_cap[can_fit] / bin_capacity)\n\n    tightness_weight = 0.3 * (1 - item_size_factor) * (1 + utilization_factor) * (1 + remaining_capacity_factor)\n    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor) * (1 - remaining_capacity_factor)\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # Strategic Randomness\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor) * (1 + remaining_capacity_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # Learning Rate & bin diversity reward\n    learning_rate = 0.01\n    bin_diversity_reward = (1 / (np.std(bins_remain_cap[can_fit]) + 0.0001)) * learning_rate\n\n    #Adaptive exploration vs exploitation\n    exploration_prob = 0.1  # Probability of exploration\n\n    if np.random.rand() < exploration_prob: #Explore by reducing the weight\n        tightness_weight *= (1 - learning_rate)\n        fill_weight *= (1 + learning_rate)\n    else: # Exploit by increasing the weight\n       tightness_weight *= (1 + learning_rate)\n       fill_weight *= (1 - learning_rate)\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness + bin_diversity_reward)\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 21.81890706023135,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response4.txt_stdout.txt",
    "code_path": "problem_iter20_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, dynamic penalties, adaptive weighting, and decaying randomness based on item size and bin utilization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0)\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n    learning_rate = 0.1\n\n    tightness_weight = 0.35\n    fill_weight = 0.35\n    near_full_weight = 0.15\n    random_weight = 0.15\n\n\n    tightness_weight += learning_rate * (1 - item_size_factor) * (1 + utilization_factor) - tightness_weight\n    fill_weight += learning_rate * (1 + item_size_factor) * (1 - utilization_factor) - fill_weight\n\n    # Decaying Randomness based on item size and bin utilization\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               random_weight * randomness)\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 0.8775428799361856,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response5.txt_stdout.txt",
    "code_path": "problem_iter20_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weights, waste minimization, and strategic randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization (Best-Fit)\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target fill level\n    target_fill = 0.8 * bin_capacity\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / bin_capacity)\n\n    # Near-full penalty, scaled by item size\n    nearly_full_threshold = 0.1 * bin_capacity\n    nearly_full_valid_bins = remaining_after < nearly_full_threshold\n    near_full_penalty = np.where(nearly_full_valid_bins, -0.7 * (item / bin_capacity), 0.0)\n\n    # Adaptive Weighting: item size & bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.4 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.2\n\n    # Decaying Stochasticity:\n    randomness_scale = 0.015 * (1 - item/bin_capacity) * (np.mean(bins_remain_cap[can_fit]) / bin_capacity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_priority +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 1.4459513362584764,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response6.txt_stdout.txt",
    "code_path": "problem_iter20_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive weights, near-empty/full, and strategic randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization (Tightness)\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level (Adaptive)\n    current_utilization = np.mean((bin_capacity - bins_remain_cap) / bin_capacity)\n    target_fill_level = 0.7 + 0.1 * current_utilization\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill_level * bin_capacity)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Empty Bonus\n    near_empty_threshold = 0.9 * bin_capacity\n    is_near_empty = bins_remain_cap[can_fit] > near_empty_threshold\n    near_empty_bonus = np.where(is_near_empty, 0.2 * (1 - item / bin_capacity), 0.0)\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8 * (item / bin_capacity), 0.0)\n\n    # Adaptive Weighting: Item size and Bin Utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.4 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_empty_weight = 0.1\n    near_full_weight = 0.1\n\n    # Strategic Randomness (Decaying) - Tie Breaking + Perturbation\n    if not hasattr(priority_v2, \"time_step\"):\n        priority_v2.time_step = 1\n    else:\n        priority_v2.time_step += 1\n    exploration_factor = np.exp(-priority_v2.time_step / 1000.0)\n    randomness_scale = 0.01 * (1 + item_size_factor) * exploration_factor\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_empty_weight * near_empty_bonus +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 2.7822098125249393,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response7.txt_stdout.txt",
    "code_path": "problem_iter20_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive fill, waste minimization, decaying randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization - Prefer bins where the item fits tightly\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n    priorities[valid_bins] += tightness * 0.5\n\n    # Adaptive Target fill level\n    target_fill = 0.75 * bin_capacity\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / bin_capacity)\n    priorities[valid_bins] += fill_priority * 0.4\n\n    # Near-full penalty\n    nearly_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < nearly_full_threshold, -0.5, 0.0)\n    priorities[valid_bins] += near_full_penalty\n\n    # Decaying randomness\n    item_size_weight = item / bin_capacity\n    randomness = np.random.rand(len(valid_bins)) * 0.02 * (1 - item_size_weight)\n    priorities[valid_bins] += randomness\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 2.961707219784608,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter20_response8.txt_stdout.txt",
    "code_path": "problem_iter20_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weighting, waste minimization, and targeted fill.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    max_bin_cap = bins_remain_cap.max()\n    bins_utilization = (max_bin_cap - bins_remain_cap[can_fit]) / max_bin_cap\n\n    # Waste minimization\n    waste = remaining_after\n    tightness = 1.0 / (1e-6 + waste)\n    item_size_factor = item / max_bin_cap\n    utilization_factor = np.mean(bins_utilization)\n    tightness_weight = 0.4 * (1 - item_size_factor) * (1 + utilization_factor)\n\n\n    # Target fill level\n    target_fill = 0.75 * max_bin_cap\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / max_bin_cap)\n    fill_weight = 0.3 * (1 + item_size_factor) * (1 - utilization_factor)\n\n    # Near-full penalty\n    nearly_full_threshold = 0.1 * max_bin_cap\n    near_full_penalty = np.where(remaining_after < nearly_full_threshold, -0.5, 0.0)\n    penalty_weight = 0.2\n\n    # Item size consideration (adaptive randomness)\n    randomness_scale = 0.01 * (1 - item_size_weight)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n    random_weight = 0.1\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                              fill_weight * fill_priority +\n                              penalty_weight * near_full_penalty +\n                              random_weight * randomness)\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 37, in priority_v2\n    tightness_weight = 0.4\nNameError: name 'item_size_weight' is not defined\n"
  },
  {
    "stdout_filepath": "problem_iter20_response9.txt_stdout.txt",
    "code_path": "problem_iter20_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weighting, strategic randomness, and anticipatory penalties.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization (Focus on tightness)\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level (Emphasis on achieving target)\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Anticipatory Near-Full Penalty (Stronger penalty, scaled by item size)\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.95 * (item / bin_capacity), 0.0)\n\n    # Adaptive Weighting (Item size & utilization)\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n    learning_rate = 0.1\n\n    tightness_weight = 0.4\n    fill_weight = 0.35\n    near_full_weight = 0.25\n\n    tightness_weight += learning_rate * (1 - item_size_factor) * (1 + utilization_factor) - tightness_weight\n    fill_weight += learning_rate * (1 + item_size_factor) * (1 - utilization_factor) - fill_weight\n\n    # Strategic Randomness (Controlled, decays slower for smaller items)\n    randomness_scale = 0.015 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 1.126844834463509,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response0.txt_stdout.txt",
    "code_path": "problem_iter21_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Enhanced heuristic for online bin packing: adaptive weights, dynamic near-full,\n    item size considerations, strategic randomness, and anticipatory penalties.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization (focus on volume of unused space)\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level (aim for at least 80% full before opening new bin)\n    target_fill_level = 0.80 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management (penalize based on specific amount of space)\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (1 - (remaining_after / near_full_threshold)) * (item/bin_capacity), 0.0)  # Stronger penalty when closer to near_full\n\n    # Smaller Item Bonus (if item fits nearly perfectly into a near-full bin)\n    small_item_threshold = bin_capacity * 0.25\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08  # More aggressive almost_full_threshold\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty (if placing it leaves very little space, anticipatory)\n    large_item_threshold = bin_capacity * 0.75\n    if item > large_item_threshold:\n        small_space_threshold = 0.1 * bin_capacity # more aggressive small space threshold\n        small_space_penalty = np.where(remaining_after < small_space_threshold, -0.8 * (item/bin_capacity) * (1 - (remaining_after/small_space_threshold)), 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Anticipatory penalty: Check if remaining space is useless for smaller items\n    useless_space_threshold = bin_capacity * 0.05\n    potential_waste = np.where((remaining_after > 0) & (remaining_after < useless_space_threshold), -0.5 * (remaining_after / bin_capacity), 0.0) # only penalize if reaminder is > 0\n    # Adaptive Weighting (based on item size, bin utilization, and a global fill ratio)\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n    global_fill_ratio = np.mean((bin_capacity - bins_remain_cap) / bin_capacity)  # Track overall fill level\n\n    tightness_weight = 0.35 * (1 - item_size_factor) * (1 + utilization_factor) * (1 + global_fill_ratio)\n    fill_weight = 0.30 * (1 + item_size_factor) * (1 - utilization_factor) * (1 - global_fill_ratio)\n    near_full_weight = 0.15\n    small_item_weight = 0.1\n    large_item_weight = 0.05\n    waste_space_weight = 0.05\n\n    # Strategic Randomness (tie-breaking and score perturbation, scaled adaptively)\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor) * (1-global_fill_ratio)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # Prioritize bins with identical scores randomly\n    identical_score_indices = np.where(np.isclose(np.std(bins_remain_cap[can_fit]), 0))[0]\n    if len(identical_score_indices) > 1:\n        random_choice = np.random.choice(identical_score_indices)\n        priorities[valid_bins[random_choice]] += 0.01\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               waste_space_weight * potential_waste +\n                               randomness)\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 71, in priority_v2\n    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor) #* packing_success\nValueError: Calling nonzero on 0d arrays is not allowed. Use np.atleast_1d(scalar).nonzero() instead. If the context of this error is of the form `arr[nonzero(cond)]`, just use `arr[cond]`.\n"
  },
  {
    "stdout_filepath": "problem_iter21_response1.txt_stdout.txt",
    "code_path": "problem_iter21_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Advanced heuristic for online bin packing:\n    - Adaptive weights based on item size, bin utilization, and packing success.\n    - Strategic randomness injection for exploration.\n    - Anticipatory penalties for decisions leading to future waste.\n    - Dynamic adjustment of parameters based on problem characteristics.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level - dynamically adjusted\n    target_fill_level = 0.7 * bin_capacity  # Initial target, can be tuned\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.25))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0)\n\n    # Smaller Item Bonus (if item fits nearly perfectly into a near-full bin)\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty (if placing it leaves very little space)\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.08 * bin_capacity), -0.8 * (item/bin_capacity), 0.0)\n    else:\n        small_space_penalty = 0.0\n\n   # Anticipatory Waste Penalty\n    # Penalize bins that, after placing the item, will have remaining space\n    # smaller than a reasonable minimum item size.  This encourages filling\n    # bins with more usable space.\n\n    min_future_item_size = bin_capacity * 0.15 # Tune this value\n    anticipatory_penalty = np.where(remaining_after < min_future_item_size,\n                                    -0.2 * (min_future_item_size - remaining_after) / bin_capacity,\n                                    0.0)\n\n    # Adaptive Weighting: item size & bin utilization & packing success\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    # Packing success metric (Placeholder - needs external tracking/update)\n    #packing_success = 0.7  # Example, should be updated dynamically based on solution quality\n\n    tightness_weight = 0.4 * (1 - item_size_factor) * (1 + utilization_factor) # * packing_success\n    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor) #* packing_success\n    near_full_weight = 0.1\n    small_item_weight = 0.05\n    large_item_weight = 0.05\n    anticipatory_weight = 0.1  # Weight for the anticipatory penalty\n\n    # Stochasticity scaled by item size and bin utilization\n    randomness_scale = 0.01 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # Prioritize bins with close to the mean remaining capacity (reduce variance)\n    mean_remaining_capacity = np.mean(bins_remain_cap[can_fit])\n    capacity_similarity = np.exp(-np.abs(remaining_after - mean_remaining_capacity) / (bin_capacity * 0.3))\n    capacity_similarity_weight = 0.05\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               anticipatory_weight * anticipatory_penalty +\n                               capacity_similarity_weight * capacity_similarity +\n                               randomness)\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 1.9445552453131232,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response2.txt_stdout.txt",
    "code_path": "problem_iter21_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Enhanced heuristic for online bin packing, focusing on waste minimization,\n    target fill levels, dynamic adjustments, and strategic randomness.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization: Emphasize smaller waste\n    waste = remaining_after\n    tightness = np.exp(-5 * waste / bin_capacity)  # Exponential to favor smaller waste\n\n    # Target Fill Level: Aim for a range, penalize both under and over\n    target_fill_level_low = 0.70 * bin_capacity\n    target_fill_level_high = 0.90 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n\n    fill_score = np.where(\n        fill_level < target_fill_level_low,\n        np.exp(-((fill_level - target_fill_level_low)**2) / (2 * (bin_capacity * 0.1)**2)),  # Gaussian penalty for underfill\n        np.where(\n            fill_level > target_fill_level_high,\n            np.exp(-((fill_level - target_fill_level_high)**2) / (2 * (bin_capacity * 0.1)**2)),  # Gaussian penalty for overfill\n            1.0  # Ideal: within target range\n        )\n    )\n\n    # Dynamic Near-Full Management: Stronger penalty, adaptive threshold\n    near_full_threshold = 0.15 * bin_capacity  # Slightly larger threshold\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item / bin_capacity), 0.0)  # Stronger penalty\n\n    # Anticipatory Penalty: If remaining space is too small for common items\n    avg_item_size = 0.2 * bin_capacity  # Estimate average item size\n    anticipatory_penalty = np.where(remaining_after < (0.5 * avg_item_size), -0.5, 0.0)  # Penalize if too small\n\n    # Item Size Consideration: Reward fitting larger items well\n    item_fit_score = np.exp(-np.abs(remaining_after - (0.1 * bin_capacity)) / (bin_capacity * 0.2)) if item > (0.5 * bin_capacity) else 0.0\n\n    # Adaptive Weighting: Based on item size and average bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.4 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.3 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.15\n    anticipatory_weight = 0.1\n    item_fit_weight = 0.05\n\n    # Strategic Randomness: Scaled by item size and decreased over time\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # Introduce a decay factor over time (simulated by a global variable or function)\n    # decay_factor = get_decay_factor()  # Retrieve a decay factor that decreases over time\n    # randomness *= decay_factor\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               anticipatory_weight * anticipatory_penalty +\n                               item_fit_weight * item_fit_score +\n                               randomness)\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 40.25727961707221,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter21_response3.txt_stdout.txt",
    "code_path": "problem_iter21_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Advanced heuristic for online bin packing, incorporating adaptive weighting,\n    strategic randomness, and anticipatory penalties/bonuses.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization: Emphasize bins with minimal remaining space after packing\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level: Encourage bins to reach a target utilization\n    target_fill_level = 0.8 * bin_capacity  # Adjusted target fill\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.15))  # Tighter fill target\n\n    # Dynamic Near-Full Management: Discourage filling near-full bins unless the item fits perfectly\n    near_full_threshold = 0.15 * bin_capacity  # Adjusted near-full threshold\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0)  # Stronger penalty\n\n    # Smaller Item Bonus: Reward placing small items into almost full bins\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty: Discourage placing large items that leave very little space\n    large_item_threshold = bin_capacity * 0.7\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.15 * bin_capacity), -0.8 * (item/bin_capacity), 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Anticipatory Penalty: Penalize placements that lead to unusable fragments\n    fragment_penalty = np.zeros_like(remaining_after)\n    for i in range(len(remaining_after)):\n        if 0 < remaining_after[i] < 0.05 * bin_capacity:\n            fragment_penalty[i] = -0.5 * (item / bin_capacity)\n\n    # Adaptive Weighting: Dynamically adjust weights based on item size and bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.4 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.125\n    small_item_weight = 0.05\n    large_item_weight = 0.05\n    fragment_weight = 0.025  # Weight for the fragment penalty\n\n    # Strategic Randomness Injection: Introduce randomness scaled by item size and bin utilization\n    randomness_scale = 0.01 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               fragment_weight * fragment_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.999972120000166 seconds"
  },
  {
    "stdout_filepath": "problem_iter21_response4.txt_stdout.txt",
    "code_path": "problem_iter21_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced heuristic: adaptive weights, dynamic near-full, item size considerations, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization: Prioritize bins that minimize remaining space relative to item size\n    waste_ratio = remaining_after / item\n    waste_priority = np.exp(-5 * waste_ratio)  # Exponentially decreasing priority with increasing waste\n\n    # Target Fill Level: Reward bins close to a target fill level, but adapt the target\n    # based on item size.  Smaller items shift the target higher.\n    target_fill_level = 0.8 * bin_capacity - 0.1 * item\n    fill_level_diff = np.abs(bins_remain_cap[can_fit] - target_fill_level)\n    fill_level_priority = np.exp(-fill_level_diff / (bin_capacity * 0.2))\n\n    # Near-Full Management: Penalize bins that become *very* near full, but only if the\n    # item isn't tiny.  Tiny items can top off bins.\n    near_full_threshold = 0.08 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full & (item > 0.1 * bin_capacity), -0.9, 0.0)\n\n    # Small Item Bonus: Significantly reward bins that can be nearly filled by small items.\n    small_item_threshold = 0.2 * bin_capacity\n    if item < small_item_threshold:\n        almost_full_threshold = 0.05 * bin_capacity\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Large Item Penalty: Penalize bins where a large item will leave very little space,\n    # especially if that space is smaller than the average item size seen so far.\n    large_item_threshold = 0.7 * bin_capacity\n    if item > large_item_threshold:\n        small_space_threshold = 0.15 * bin_capacity #was 0.1\n        small_space_penalty = np.where(remaining_after < small_space_threshold, -0.8, 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Anticipatory Penalty: Penalize bins that will lead to highly fragmented space\n    # (multiple small spaces).  This requires a simplified simulation.\n    fragmentation_penalty = np.zeros_like(remaining_after)\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization) if bins_utilization.size > 0 else 0.0\n\n    waste_weight = 0.3 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.3 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.1\n    small_item_weight = 0.15\n    large_item_weight = 0.15\n\n    # Strategic Randomness:  Introduce randomness proportional to the *uncertainty*\n    # in the current state (high uncertainty when bins are similar, low when\n    # one bin is clearly better).\n    priority_range = np.max([waste_priority.max(), fill_level_priority.max(), 0.1]) - np.min([waste_priority.min(), fill_level_priority.min(), -0.1]) #Avoid empty sequence\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor) * priority_range\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (waste_weight * waste_priority +\n                               fill_weight * fill_level_priority +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness +\n                               fragmentation_penalty)\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 12.026326286398099,
    "exec_success": true
  }
]