{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines waste minimization, target fill ratio, and randomness for bin selection.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float) - np.inf\n    can_fit = bins_remain_cap >= item\n\n    if np.any(can_fit):\n        wasted_space = bins_remain_cap[can_fit] - item\n        priorities[can_fit] = -wasted_space  # Minimize waste\n\n        fill_ratio = (bins_remain_cap[can_fit] - wasted_space) / bins_remain_cap[can_fit]\n        target_ratio = 0.6\n        priorities[can_fit] += 5.0 * np.exp(-((fill_ratio - target_ratio)**2) / 0.02) # gaussian curve for target fill\n\n        # Add small randomness to avoid local optima\n        priorities[can_fit] += np.random.normal(0, 0.01, size=np.sum(can_fit))\n\n        # Penalize bins that become nearly full.\n        remaining_after_add = bins_remain_cap[can_fit] - item\n        near_full_penalty = np.where(remaining_after_add < (0.1*bins_remain_cap.max()), -0.5, 0.0)\n        priorities[can_fit] += near_full_penalty\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines waste minimization, target fill, randomness, and near-full penalty.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -np.inf)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    \n    # Waste minimization: Prioritize tighter fits\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target fill level (e.g., 75%): Reward bins closer to target\n    target_fill_level = 0.75 * bins_remain_cap.max()\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = 1 / (fill_diff + 0.0001)\n\n    # Near-full penalty\n    near_full_threshold = 0.1 * bins_remain_cap.max()\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.5, 0.0)  # Stronger penalty\n\n    # Randomness to escape local optima\n    randomness = np.random.rand(len(valid_bins)) * 0.05\n\n    # Combine scores with weights\n    priorities[valid_bins] = (0.5 * tightness) + (0.3 * fill_score) + near_full_penalty + randomness\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the 1st implementation uses a penalty for bins becoming nearly full and a randomness factor, while the 20th prioritizes waste minimization, target fill level, and penalizes near-full bins, also adding randomness; (2nd best) vs (second worst) ... the second has a different, possibly more sophisticated, way to balance multiple factors by assigning weights and considering a small item bonus. Comparing (1st) vs (2nd), we see the first one target fill level while the second uses target fill level and gaussian-like score. (3rd) vs (4th) ... we see the 3rd uses tightness, fullness and balance score. the 4th is about wasted space minimization, fill target and randomness. Comparing (second worst) vs (worst), we see the 19th has waste minimization, target fill, penalty for near-full, and randomness factors. The 20th has the same factors. Overall: The better heuristics incorporate multiple factors (waste minimization, target fill, penalties, randomness) and often use weighting or more complex scoring functions to balance these factors. Poorer heuristics may oversimplify or lack specific handling for edge cases (e.g., nearly full bins).\n- \nOkay, let's refine \"Current self-reflection\" to make it more effective for designing better heuristics, addressing the shortcomings of \"Ineffective self-reflection.\"\n\nHere's a revised perspective:\n\n*   **Keywords:** Objective balancing, adaptive weighting, edge case handling, stochasticity, performance tuning, vectorized operations, local optima avoidance.\n\n*   **Advice:** Rigorously define objectives. Implement adaptive weighting schemes for factors *grounded in problem characteristics*. Design specific responses (bonuses/penalties) for edge cases *after thorough analysis*. Systematically test stochastic elements. Optimize for speed.\n\n*   **Avoid:** Vague objectives, premature simplification, solely intuition-based weighting, and neglecting implementation efficiency.\n\n*   **Explanation:** Effective heuristic design requires a structured approach: explicitly defining objectives, adapting strategies based on problem dynamics, addressing exceptions thoughtfully, and empirically validating the heuristic's performance and robustness.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}