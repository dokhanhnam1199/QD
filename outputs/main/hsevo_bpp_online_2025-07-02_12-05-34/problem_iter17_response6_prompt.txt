{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines waste minimization, target fill, adaptive weighting, and stochasticity.\n    Improved by adding small item bonus and dynamic bin count penalty.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    num_bins = len(bins_remain_cap)\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty (Slightly reduced penalty)\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.6, 0.0)\n\n    # Small Item Bonus\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    tightness_weight = 0.5 * (1 - item_size_factor)\n    fill_weight = 0.4 * (1 + item_size_factor)\n    near_full_weight = 0.1\n\n    # Dynamic Bin Count Penalty\n    bins_used = np.sum(bins_remain_cap < bin_capacity)\n    target_bins = int(np.ceil(np.sum(item) / bin_capacity)) if isinstance(item, float) else int(np.ceil(np.sum(item)/bin_capacity))\n\n    over_bins = max(0, bins_used - target_bins)\n    bin_count_penalty = -0.05 * over_bins\n    # Randomness\n    randomness = np.random.rand(len(valid_bins)) * 0.01\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               almost_full_bonus * 0.2 +\n                               bin_count_penalty +\n                               randomness)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines waste minimization, target fill, near-full/empty penalties, and adaptive randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    # Waste minimization (Best-Fit)\n    waste = bins_remain_cap[can_fit] - item\n    priorities[can_fit] = 1.0 / (1e-6 + waste)\n\n    # Target fill level\n    max_bin_cap = np.max(bins_remain_cap)\n    target_fill = 0.75 * max_bin_cap\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / max_bin_cap)\n    priorities[can_fit] += fill_priority * 0.1\n\n    # Near-full penalty\n    nearly_full_threshold = 0.1 * max_bin_cap\n    nearly_full = bins_remain_cap < nearly_full_threshold\n    priorities[nearly_full] *= 0.5\n\n     # Nearly-empty bonus\n    nearly_empty_threshold = 0.9 * max_bin_cap\n    nearly_empty_valid = (bins_remain_cap[can_fit] > nearly_empty_threshold)\n    nearly_empty_indices = np.where(can_fit)[0][nearly_empty_valid]\n\n    priorities[nearly_empty_indices] += 0.05 # Small bonus for using empty bins.\n\n    # Adaptive Randomness (decaying with item size)\n    randomness = np.random.rand(np.sum(can_fit)) * 0.01 * (1 - item/max_bin_cap) # Reduce randomness for large items\n    priorities[can_fit] += randomness\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), we see no difference; (second best) vs (second worst) also has no difference, which is suspicious. Comparing (3rd) vs (4th), the key difference lies in the stochasticity. Heuristic 3 scales randomness by remaining bin capacity, while Heuristic 4 uses a decaying randomness based on item size. Heuristic 3's approach seems more context-aware. Comparing (second worst) vs (worst), no difference either. Comparing (7th) vs (8th), no difference. Comparing (9th) vs (10th) vs (11th) vs (12th), still no difference.\n\nComparing (1st) vs (3rd), Heuristic 1 has more detailed considerations: dynamic near-full management, smaller item bonus, larger item penalty, adaptive weighting considers both item size and bin utilization, and randomness scales with both item size and bin utilization. Heuristic 3 simplifies this to adaptive weighting based on item size and randomness scaled by remaining capacity.\n\nComparing (3rd) vs (5th), Heuristic 3 includes stochasticity scaled by remaining capacity, while Heuristic 5 uses decaying randomness based on item size. Also no difference between heuristics 4th and 5th.\n\nComparing (7th) vs (18th), Heuristic 7 uses small item bonus and dynamic bin count penalty, whereas Heuristic 18 uses a near-empty bonus and decaying randomness with item size.\n\nOverall: The better heuristics incorporate more context-aware parameters, such as bin utilization and item size, when calculating weights, penalties, bonuses, and stochasticity. More advanced ones dynamically adjust target fill levels and learning rates. Penalizing \"near-full\" bins and rewarding \"near-empty\" bins seems like a good idea. The decaying randomness is a good pattern.\n- \nOkay, here's a redefinition of \"Current Self-Reflection\" for designing better heuristics, focusing on actionable insights and avoiding pitfalls, plus the breakdown you requested:\n\n*   **Keywords:** Adaptive weighting, dynamic penalties/bonuses, stochasticity, problem state.\n*   **Advice:** Design heuristics that adapt to problem state using dynamic weights, penalties/bonuses based on bin and item characteristics. Introduce controlled randomness for exploration.\n*   **Avoid:** Static parameters, over-complexity, purely deterministic approaches, ignoring problem state information.\n*   **Explanation:** Emphasize adaptability. Heuristics should *react* to the unfolding problem, rather than following fixed rules. Introduce randomness *strategically* to explore better solutions while avoiding local optima.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}