{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weights, dynamic penalties, and strategic randomness based on item size.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0)\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n    learning_rate = 0.1\n\n    tightness_weight = 0.35\n    fill_weight = 0.35\n    near_full_weight = 0.15\n    random_weight = 0.15\n\n\n    tightness_weight += learning_rate * (1 - item_size_factor) * (1 + utilization_factor) - tightness_weight\n    fill_weight += learning_rate * (1 + item_size_factor) * (1 - utilization_factor) - fill_weight\n\n    # Decaying Randomness based on item size and bin utilization\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               random_weight * randomness)\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weights, dynamic penalties, and strategic randomness based on item size.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0)\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n    learning_rate = 0.1\n\n    tightness_weight = 0.35\n    fill_weight = 0.35\n    near_full_weight = 0.15\n    random_weight = 0.15\n\n\n    tightness_weight += learning_rate * (1 - item_size_factor) * (1 + utilization_factor) - tightness_weight\n    fill_weight += learning_rate * (1 + item_size_factor) * (1 - utilization_factor) - fill_weight\n\n    # Decaying Randomness based on item size and bin utilization\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               random_weight * randomness)\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines target fill, waste minimization, and adaptive penalty.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n\n    # Waste Minimization: Prioritize bins with smaller remaining space.\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level: Encourage bins to reach a target fill level.\n    target_fill_level = 0.8 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Adaptive Penalty for Near-Full Bins: Discourage filling bins that are already near full.\n    near_full_threshold = 0.15 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item / bin_capacity), 0.0)\n\n    # Combine Scores with Weights\n    tightness_weight = 0.4\n    fill_weight = 0.4\n    near_full_weight = 0.2\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty)\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining waste minimization, target fill, and stochasticity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization (Best-Fit)\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target fill level\n    target_fill = 0.75 * bin_capacity\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-full penalty, scaled by item size\n    nearly_full_threshold = 0.1 * bin_capacity\n    nearly_full_valid_bins = remaining_after < nearly_full_threshold\n    near_full_penalty = np.where(nearly_full_valid_bins, -0.95 * (item / bin_capacity), 0.0)\n\n    # Adaptive Weighting: item size & bin utilization, with learning\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n    learning_rate = 0.1\n\n    tightness_weight = 0.4\n    fill_weight = 0.35\n    near_full_weight = 0.25\n\n    tightness_weight += learning_rate * (1 - item_size_factor) * (1 + utilization_factor) - tightness_weight\n    fill_weight += learning_rate * (1 + item_size_factor) * (1 - utilization_factor) - fill_weight\n\n\n    # Strategic Randomness: Decays slower for smaller items, adjusts to utilization\n    randomness_scale = 0.015 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_priority +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining waste minimization, target fill, and stochasticity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization (Best-Fit)\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target fill level\n    target_fill = 0.75 * bin_capacity\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-full penalty, scaled by item size\n    nearly_full_threshold = 0.1 * bin_capacity\n    nearly_full_valid_bins = remaining_after < nearly_full_threshold\n    near_full_penalty = np.where(nearly_full_valid_bins, -0.95 * (item / bin_capacity), 0.0)\n\n    # Adaptive Weighting: item size & bin utilization, with learning\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n    learning_rate = 0.1\n\n    tightness_weight = 0.4\n    fill_weight = 0.35\n    near_full_weight = 0.25\n\n    tightness_weight += learning_rate * (1 - item_size_factor) * (1 + utilization_factor) - tightness_weight\n    fill_weight += learning_rate * (1 + item_size_factor) * (1 - utilization_factor) - fill_weight\n\n\n    # Strategic Randomness: Decays slower for smaller items, adjusts to utilization\n    randomness_scale = 0.015 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_priority +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill, waste minimization, and decaying randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n    priorities[valid_bins] += tightness * 0.5\n\n    # Adaptive Target fill level\n    target_fill = 0.75 * bin_capacity\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / bin_capacity)\n    priorities[valid_bins] += fill_priority * 0.4\n\n    # Near-full penalty\n    nearly_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < nearly_full_threshold, -0.5 * (item/bin_capacity), 0.0)  #scaled penalty by item size\n    priorities[valid_bins] += near_full_penalty\n\n    # Decaying randomness\n    item_size_weight = item / bin_capacity\n    randomness = np.random.rand(len(valid_bins)) * 0.02 * (1 - item_size_weight) # decay slower for smaller items\n    priorities[valid_bins] += randomness\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill, waste minimization, and decaying randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n    priorities[valid_bins] += tightness * 0.5\n\n    # Adaptive Target fill level\n    target_fill = 0.75 * bin_capacity\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / bin_capacity)\n    priorities[valid_bins] += fill_priority * 0.4\n\n    # Near-full penalty\n    nearly_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < nearly_full_threshold, -0.5 * (item/bin_capacity), 0.0)  #scaled penalty by item size\n    priorities[valid_bins] += near_full_penalty\n\n    # Decaying randomness\n    item_size_weight = item / bin_capacity\n    randomness = np.random.rand(len(valid_bins)) * 0.02 * (1 - item_size_weight) # decay slower for smaller items\n    priorities[valid_bins] += randomness\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins using waste, target fill, near-full penalty, & adaptive randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n    priorities[valid_bins] += tightness * 0.5\n\n    # Adaptive Target Fill\n    target_fill = 0.8 * bin_capacity - 0.1 * item\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / bin_capacity)\n    priorities[valid_bins] += fill_priority * 0.4\n\n    # Near-Full Penalty (only for larger items)\n    near_full_threshold = 0.08 * bin_capacity\n    near_full_penalty = np.where((remaining_after < near_full_threshold) & (item > 0.1 * bin_capacity), -0.5, 0.0)\n    priorities[valid_bins] += near_full_penalty\n    \n    #Decaying Randomness\n    item_size_weight = item / bin_capacity\n    randomness = np.random.rand(len(valid_bins)) * 0.02 * (1 - item_size_weight)\n    priorities[valid_bins] += randomness\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins using waste, target fill, near-full penalty, & adaptive randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n    priorities[valid_bins] += tightness * 0.5\n\n    # Adaptive Target Fill\n    target_fill = 0.8 * bin_capacity - 0.1 * item\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / bin_capacity)\n    priorities[valid_bins] += fill_priority * 0.4\n\n    # Near-Full Penalty (only for larger items)\n    near_full_threshold = 0.08 * bin_capacity\n    near_full_penalty = np.where((remaining_after < near_full_threshold) & (item > 0.1 * bin_capacity), -0.5, 0.0)\n    priorities[valid_bins] += near_full_penalty\n    \n    #Decaying Randomness\n    item_size_weight = item / bin_capacity\n    randomness = np.random.rand(len(valid_bins)) * 0.02 * (1 - item_size_weight)\n    priorities[valid_bins] += randomness\n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins using waste, target fill, near-full penalty, & adaptive randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n    priorities[valid_bins] += tightness * 0.5\n\n    # Adaptive Target Fill\n    target_fill = 0.8 * bin_capacity - 0.1 * item\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / bin_capacity)\n    priorities[valid_bins] += fill_priority * 0.4\n\n    # Near-Full Penalty (only for larger items)\n    near_full_threshold = 0.08 * bin_capacity\n    near_full_penalty = np.where((remaining_after < near_full_threshold) & (item > 0.1 * bin_capacity), -0.5, 0.0)\n    priorities[valid_bins] += near_full_penalty\n    \n    #Decaying Randomness\n    item_size_weight = item / bin_capacity\n    randomness = np.random.rand(len(valid_bins)) * 0.02 * (1 - item_size_weight)\n    priorities[valid_bins] += randomness\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Enhanced heuristic with adaptive weighting, dynamic penalties/bonuses,\n    target fill, decaying stochasticity, and item/bin state awareness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # 1. Waste Minimization with Adaptive Tightness\n    waste = remaining_after\n    base_tightness = 1 / (waste + 0.0001)\n    # Adapt tightness based on item size: smaller items benefit more from tight fits.\n    item_size_factor = item / bin_capacity\n    tightness = base_tightness * (1 + (1 - item_size_factor))  # Boost tightness for small items\n\n\n    # 2. Target Fill Level with Dynamic Target\n    # Adjust target fill based on average bin utilization: if bins are filling up, aim higher.\n    avg_utilization = np.mean(bins_utilization)\n    target_fill_level = (0.65 + 0.2 * avg_utilization) * bin_capacity #was 0.75\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # 3. Dynamic Near-Full Management\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    # Adaptive penalty: larger penalty if the item is also large relative to bin capacity\n    near_full_penalty = np.where(is_near_full, -0.7 * (item/bin_capacity) * (1+bins_utilization), 0.0)\n\n    # 4. Smaller Item Bonus (if item fits nearly perfectly into a near-full bin)\n    small_item_threshold = bin_capacity * 0.25\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # 5. Larger Item Penalty (if placing it leaves very little space)\n    large_item_threshold = bin_capacity * 0.75\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6 * (item/bin_capacity), 0.0) #was 0.7\n    else:\n        small_space_penalty = 0.0\n\n    # 6. Adaptive Weighting: item size & bin utilization\n    #   - Emphasis on tightness when item is small and bins aren't fully utilized\n    #   - Emphasis on fill when item is large or bins are highly utilized\n    tightness_weight = 0.35 * (1.2 - item_size_factor) * (1.1 - avg_utilization) #was (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.35 * (0.8 + item_size_factor) * (0.9 + avg_utilization) #was (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # 7. Decaying Stochasticity\n    #   - Reduce randomness as bins fill up to stabilize the packing\n    randomness_scale = 0.015 * (1 + item_size_factor) * (1 - avg_utilization) #was 0.015 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Enhanced heuristic with adaptive weighting, dynamic penalties/bonuses,\n    target fill, decaying stochasticity, and item/bin state awareness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # 1. Waste Minimization with Adaptive Tightness\n    waste = remaining_after\n    base_tightness = 1 / (waste + 0.0001)\n    # Adapt tightness based on item size: smaller items benefit more from tight fits.\n    item_size_factor = item / bin_capacity\n    tightness = base_tightness * (1 + (1 - item_size_factor))  # Boost tightness for small items\n\n\n    # 2. Target Fill Level with Dynamic Target\n    # Adjust target fill based on average bin utilization: if bins are filling up, aim higher.\n    avg_utilization = np.mean(bins_utilization)\n    target_fill_level = (0.65 + 0.2 * avg_utilization) * bin_capacity #was 0.75\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # 3. Dynamic Near-Full Management\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    # Adaptive penalty: larger penalty if the item is also large relative to bin capacity\n    near_full_penalty = np.where(is_near_full, -0.7 * (item/bin_capacity) * (1+bins_utilization), 0.0)\n\n    # 4. Smaller Item Bonus (if item fits nearly perfectly into a near-full bin)\n    small_item_threshold = bin_capacity * 0.25\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # 5. Larger Item Penalty (if placing it leaves very little space)\n    large_item_threshold = bin_capacity * 0.75\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6 * (item/bin_capacity), 0.0) #was 0.7\n    else:\n        small_space_penalty = 0.0\n\n    # 6. Adaptive Weighting: item size & bin utilization\n    #   - Emphasis on tightness when item is small and bins aren't fully utilized\n    #   - Emphasis on fill when item is large or bins are highly utilized\n    tightness_weight = 0.35 * (1.2 - item_size_factor) * (1.1 - avg_utilization) #was (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.35 * (0.8 + item_size_factor) * (0.9 + avg_utilization) #was (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # 7. Decaying Stochasticity\n    #   - Reduce randomness as bins fill up to stabilize the packing\n    randomness_scale = 0.015 * (1 + item_size_factor) * (1 - avg_utilization) #was 0.015 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid heuristic: Adaptive fill target, near-full/small-item bonuses, and decaying randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization (Tightness)\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level (Adaptive)\n    current_utilization = np.mean((bin_capacity - bins_remain_cap) / bin_capacity)\n    target_fill_level = 0.7 + 0.1 * current_utilization\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill_level * bin_capacity)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8 * (item / bin_capacity), 0.0)\n\n    # Smaller Item Bonus\n    small_item_threshold = bin_capacity * 0.3\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Adaptive Weighting: Item size and Bin Utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.3 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n\n    # Strategic Randomness (Decaying)\n    if not hasattr(priority_v2, \"time_step\"):\n        priority_v2.time_step = 1\n    else:\n        priority_v2.time_step += 1\n    exploration_factor = np.exp(-priority_v2.time_step / 1000.0)\n    randomness_scale = 0.01 * (1 + item_size_factor) * exploration_factor\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus+\n                               randomness)\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float,\n                bins_remain_cap: np.ndarray,\n                target_fill_level_ratio: float = 0.9221462247756516,\n                fill_level_deviation_ratio: float = 0.1713448674075636,\n                near_full_threshold_ratio: float = 0.16803777971854475,\n                near_full_penalty_scale: float = 0.8607925481753331,\n                learning_rate: float = 0.18698329902302885,\n                tightness_weight: float = 0.3502576865020792,\n                fill_weight: float = 0.34546294713703984,\n                near_full_weight: float = 0.18439088964679867,\n                random_weight: float = 0.19313490230268088,\n                randomness_scale_factor: float = 0.018529630773417054,\n                waste_epsilon: float = 0.0008545898773918969) -> np.ndarray:\n    \"\"\"Combines adaptive weights, dynamic penalties, and strategic randomness based on item size.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n[Heuristics 15th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, adaptive penalty, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    bin_capacity = np.max(bins_remain_cap)\n\n    # Waste Minimization\n    waste = bins_remain_cap[can_fit] - item\n    priorities[can_fit] = 1.0 / (1e-6 + waste)\n\n    # Adaptive Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = bins_remain_cap[can_fit] < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8 * (item / bin_capacity), 0.0)\n    priorities[valid_bins] += near_full_penalty\n\n    # Small item bonus\n    small_item_threshold = 0.2 * bin_capacity\n    if item < small_item_threshold:\n      almost_full_threshold = 0.1 * bin_capacity\n      almost_full_valid_bins = bins_remain_cap[can_fit] < almost_full_threshold + item\n      almost_full_indices = np.where(can_fit)[0][almost_full_valid_bins]\n      priorities[almost_full_indices] += 0.2\n\n    # Adaptive Weighting and Randomness (dependent on item size and remaining capacity)\n    item_size_factor = item / bin_capacity\n    randomness_scale = 0.01 * (1 - item_size_factor) * (bins_remain_cap[can_fit] / bin_capacity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n    priorities[can_fit] += randomness\n    return priorities\n\n[Heuristics 16th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, adaptive penalty, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    bin_capacity = np.max(bins_remain_cap)\n\n    # Waste Minimization\n    waste = bins_remain_cap[can_fit] - item\n    priorities[can_fit] = 1.0 / (1e-6 + waste)\n\n    # Adaptive Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = bins_remain_cap[can_fit] < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8 * (item / bin_capacity), 0.0)\n    priorities[valid_bins] += near_full_penalty\n\n    # Small item bonus\n    small_item_threshold = 0.2 * bin_capacity\n    if item < small_item_threshold:\n      almost_full_threshold = 0.1 * bin_capacity\n      almost_full_valid_bins = bins_remain_cap[can_fit] < almost_full_threshold + item\n      almost_full_indices = np.where(can_fit)[0][almost_full_valid_bins]\n      priorities[almost_full_indices] += 0.2\n\n    # Adaptive Weighting and Randomness (dependent on item size and remaining capacity)\n    item_size_factor = item / bin_capacity\n    randomness_scale = 0.01 * (1 - item_size_factor) * (bins_remain_cap[can_fit] / bin_capacity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n    priorities[can_fit] += randomness\n    return priorities\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, dynamic near-full, adaptive weighting based on item and bin.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization: Prioritize bins that minimize remaining space relative to item size\n    waste_ratio = remaining_after / item\n    waste_priority = np.exp(-5 * waste_ratio)\n\n    # Target Fill Level: Reward bins close to a target fill level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level_diff = np.abs(bins_remain_cap[can_fit] - target_fill_level)\n    fill_level_priority = np.exp(-fill_level_diff / (bin_capacity * 0.2))\n\n    # Near-Full Management: Penalize bins that become very near full\n    near_full_threshold = 0.08 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9, 0.0)\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization) if bins_utilization.size > 0 else 0.0\n\n    waste_weight = 0.3 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.3 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.1\n\n    # Strategic Randomness\n    priority_range = np.max([waste_priority.max(), fill_level_priority.max(), 0.1]) - np.min([waste_priority.min(), fill_level_priority.min(), -0.1]) #Avoid empty sequence\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor) * priority_range\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (waste_weight * waste_priority +\n                               fill_weight * fill_level_priority +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, dynamic near-full, adaptive weighting based on item and bin.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization: Prioritize bins that minimize remaining space relative to item size\n    waste_ratio = remaining_after / item\n    waste_priority = np.exp(-5 * waste_ratio)\n\n    # Target Fill Level: Reward bins close to a target fill level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level_diff = np.abs(bins_remain_cap[can_fit] - target_fill_level)\n    fill_level_priority = np.exp(-fill_level_diff / (bin_capacity * 0.2))\n\n    # Near-Full Management: Penalize bins that become very near full\n    near_full_threshold = 0.08 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9, 0.0)\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization) if bins_utilization.size > 0 else 0.0\n\n    waste_weight = 0.3 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.3 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.1\n\n    # Strategic Randomness\n    priority_range = np.max([waste_priority.max(), fill_level_priority.max(), 0.1]) - np.min([waste_priority.min(), fill_level_priority.min(), -0.1]) #Avoid empty sequence\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor) * priority_range\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (waste_weight * waste_priority +\n                               fill_weight * fill_level_priority +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, dynamic near-full, adaptive weighting based on item and bin.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization: Prioritize bins that minimize remaining space relative to item size\n    waste_ratio = remaining_after / item\n    waste_priority = np.exp(-5 * waste_ratio)\n\n    # Target Fill Level: Reward bins close to a target fill level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level_diff = np.abs(bins_remain_cap[can_fit] - target_fill_level)\n    fill_level_priority = np.exp(-fill_level_diff / (bin_capacity * 0.2))\n\n    # Near-Full Management: Penalize bins that become very near full\n    near_full_threshold = 0.08 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9, 0.0)\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization) if bins_utilization.size > 0 else 0.0\n\n    waste_weight = 0.3 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.3 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.1\n\n    # Strategic Randomness\n    priority_range = np.max([waste_priority.max(), fill_level_priority.max(), 0.1]) - np.min([waste_priority.min(), fill_level_priority.min(), -0.1]) #Avoid empty sequence\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor) * priority_range\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (waste_weight * waste_priority +\n                               fill_weight * fill_level_priority +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines waste minimization, target fill, and dynamic adjustments with strategic randomness.\n    Adaptive weights respond to item size and bin utilization.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = np.exp(-5 * waste / bin_capacity)\n\n    # Target Fill Level\n    target_fill_level_low = 0.70 * bin_capacity\n    target_fill_level_high = 0.90 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n\n    fill_score = np.where(\n        fill_level < target_fill_level_low,\n        np.exp(-((fill_level - target_fill_level_low)**2) / (2 * (bin_capacity * 0.1)**2)),\n        np.where(\n            fill_level > target_fill_level_high,\n            np.exp(-((fill_level - target_fill_level_high)**2) / (2 * (bin_capacity * 0.1)**2)),\n            1.0\n        )\n    )\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.15 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item / bin_capacity), 0.0)\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.4 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.3 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.15\n\n    # Strategic Randomness\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}