[
  {
    "stdout_filepath": "problem_iter17_response0.txt_stdout.txt",
    "code_path": "problem_iter17_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weights, dynamic penalties, and decaying randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.78 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.7 * (item / bin_capacity), 0.0)\n\n    # Adaptive Weighting: item size & bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.4 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.2\n\n    # Decaying Stochasticity:\n    randomness_scale = 0.015 / (1 + item_size_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 0.8276824890307208,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response1.txt_stdout.txt",
    "code_path": "problem_iter17_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weights, dynamic near-full penalty, and decaying randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0)\n\n    # Adaptive Weighting: item size & bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.5 * (1 - item_size_factor)\n    fill_weight = 0.5 * (1 + item_size_factor)\n    near_full_weight = 0.2\n\n    # Decaying randomness scaled by item size and remaining capacity\n    randomness_scale = 0.01 * (1 + item_size_factor) * (1 + bins_remain_cap[can_fit] / bin_capacity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 4.437574790586359,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response2.txt_stdout.txt",
    "code_path": "problem_iter17_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive weights, near-empty bonus, decaying randomness, and dynamic fill target.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level (Dynamic)\n    current_utilization = np.mean((bin_capacity - bins_remain_cap) / bin_capacity)\n    target_fill_level = 0.7 + 0.1 * current_utilization # Adjust dynamically\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level * bin_capacity)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Empty Bonus (Encourage initial bin use)\n    near_empty_threshold = 0.9 * bin_capacity\n    is_near_empty = bins_remain_cap[can_fit] > near_empty_threshold\n    near_empty_bonus = np.where(is_near_empty, 0.2 * (1 - item/bin_capacity), 0.0)\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8 * (item/bin_capacity), 0.0)\n\n    # Adaptive Weighting: item size & bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.4 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.4 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_empty_weight = 0.1\n    near_full_weight = 0.1\n\n    # Decaying Randomness\n    if not hasattr(priority_v2, \"time_step\"):\n        priority_v2.time_step = 1\n    else:\n        priority_v2.time_step += 1\n    exploration_factor = np.exp(-priority_v2.time_step / 1000.0)\n    randomness_scale = 0.01 * (1 + item_size_factor) * exploration_factor # Decay over time\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_empty_weight * near_empty_bonus +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 2.762265656162749,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response3.txt_stdout.txt",
    "code_path": "problem_iter17_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic: Combines dynamic fill target, near-full penalty, and intelligent stochasticity based on item size and bin utilization.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Dynamic Target Fill Level: Adaptive to Item Size\n    item_size_ratio = item / bin_capacity\n    dynamic_target_fill = 0.75 * bin_capacity * (1 - 0.2 * item_size_ratio)\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - dynamic_target_fill)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Management with Dynamic Penalty:\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity) * (1 + item_size_ratio), 0.0)\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Intelligent Stochasticity:\n    bin_similarity = np.std(bins_utilization)\n    randomness_scale = 0.01 * (1 + item_size_ratio) * (1 - bin_similarity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n    \n    #Adaptive Weights\n    tightness_weight = 0.40\n    fill_weight = 0.30\n    near_full_weight = 0.15\n    randomness_weight = 0.15\n\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness_weight * randomness)\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 2.712405265257284,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response4.txt_stdout.txt",
    "code_path": "problem_iter17_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill, near-empty bonus, and decaying randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Target fill level (adaptive)\n    target_fill = 0.75 * bin_capacity\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / bin_capacity)\n    priorities[valid_bins] += fill_priority * 0.4  # Increased weight\n\n    # Near-full/Near-empty\n    nearly_full_threshold = 0.1 * bin_capacity\n    nearly_empty_threshold = 0.9 * bin_capacity\n\n    near_full_penalty = np.where(remaining_after < nearly_full_threshold, -0.5, 0.0)\n    near_empty_bonus = np.where(bins_remain_cap[can_fit] > nearly_empty_threshold, 0.2, 0.0)  # Increase bonus\n    priorities[valid_bins] += near_full_penalty + near_empty_bonus\n\n    # Decaying randomness based on item size\n    item_size_weight = item / bin_capacity\n    randomness = np.random.rand(len(valid_bins)) * 0.02 * (1 - item_size_weight)\n    priorities[valid_bins] += randomness\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 146.94854407658556,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response5.txt_stdout.txt",
    "code_path": "problem_iter17_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weighting and dynamic elements with decaying randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0)\n\n    # Smaller Item Bonus\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.08\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.05 * bin_capacity), -0.8 * (item/bin_capacity), 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n    learning_rate = 0.1\n\n    tightness_weight = 0.35\n    fill_weight = 0.35\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    tightness_weight += learning_rate * (1 - item_size_factor) * (1 + utilization_factor) - tightness_weight\n    fill_weight += learning_rate * (1 + item_size_factor) * (1 - utilization_factor) - fill_weight\n\n    # Decaying Randomness based on item size and bin utilization\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 6.352213801356207,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response6.txt_stdout.txt",
    "code_path": "problem_iter17_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, adaptive bonuses/penalties, and decaying randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    # Waste minimization (Best-Fit)\n    waste = bins_remain_cap[can_fit] - item\n    priorities[can_fit] = 1.0 / (1e-6 + waste)\n\n    # Target fill level\n    max_bin_cap = np.max(bins_remain_cap)\n    target_fill = 0.8 * max_bin_cap\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / max_bin_cap)\n    priorities[can_fit] += fill_priority * 0.1\n\n    # Near-full penalty, scaled by item size\n    nearly_full_threshold = 0.1 * max_bin_cap\n    nearly_full = bins_remain_cap < nearly_full_threshold\n    priorities[nearly_full] -= 0.4 * (item / max_bin_cap) #Larger items get bigger penalty.\n\n    # Small item bonus to almost full bins\n    small_item_threshold = 0.2 * max_bin_cap\n    if item < small_item_threshold:\n      almost_full_threshold = 0.1 * max_bin_cap\n      almost_full_valid_bins = bins_remain_cap[can_fit] < almost_full_threshold + item\n      almost_full_indices = np.where(can_fit)[0][almost_full_valid_bins]\n      priorities[almost_full_indices] += 0.2\n\n    # Adaptive Randomness (decaying with item size and remaining capacity)\n    randomness = np.random.rand(np.sum(can_fit)) * 0.01 * (1 - item/max_bin_cap) * (bins_remain_cap[can_fit] / max_bin_cap)\n    priorities[can_fit] += randomness\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response7.txt_stdout.txt",
    "code_path": "problem_iter17_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, dynamic target fill, near-full penalty, and intelligent stochasticity.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Dynamic Target Fill Level\n    item_size_ratio = item / bin_capacity\n    dynamic_target_fill = 0.75 * bin_capacity * (1 - 0.2 * item_size_ratio)\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - dynamic_target_fill)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity) , 0.0)\n\n    # Intelligent Stochasticity\n    bin_similarity = np.std(bins_utilization)\n    randomness_scale = 0.01 * (1 + item_size_ratio) * (1 - bin_similarity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # Adaptive Weighting (tuned)\n    tightness_weight = 0.40\n    fill_weight = 0.30\n    near_full_weight = 0.15\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 2.0941364180295174,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response8.txt_stdout.txt",
    "code_path": "problem_iter17_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, dynamic penalties, and adaptive randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    max_bin_cap = bins_remain_cap.max()\n    bins_utilization = (max_bin_cap - bins_remain_cap[can_fit]) / max_bin_cap\n\n    # Waste minimization\n    waste = remaining_after\n    tightness = 1.0 / (1e-6 + waste)\n    tightness_weight = 0.4\n\n    # Target fill level\n    target_fill = 0.75 * max_bin_cap\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / max_bin_cap)\n    fill_weight = 0.3\n\n    # Near-full penalty and near-empty bonus\n    nearly_full_threshold = 0.1 * max_bin_cap\n    nearly_empty_threshold = 0.9 * max_bin_cap\n    near_full_penalty = np.where(remaining_after < nearly_full_threshold, -0.5, 0.0)\n    near_empty_bonus = np.where(bins_remain_cap[can_fit] > nearly_empty_threshold, 0.1, 0.0)\n    penalty_weight = 0.2\n\n    # Item size consideration (adaptive randomness)\n    item_size_weight = item / max_bin_cap\n    randomness_scale = 0.01 * (1 - item_size_weight)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n    random_weight = 0.1\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                              fill_weight * fill_priority +\n                              penalty_weight * (near_full_penalty + near_empty_bonus) +\n                              random_weight * randomness)\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 1.6753091344236206,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter17_response9.txt_stdout.txt",
    "code_path": "problem_iter17_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weighting, dynamic target fill, and intelligent stochasticity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # 1. Waste Minimization\n    waste = remaining_after\n    inverse_waste = 1 / (waste + 0.0001)\n    tightness = inverse_waste\n\n    # 2. Dynamic Target Fill Level\n    item_size_ratio = item / bin_capacity\n    dynamic_target_fill = 0.75 * bin_capacity * (1 - 0.2 * item_size_ratio)\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - dynamic_target_fill)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # 3. Near-Full Management with Dynamic Penalty\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0)\n\n    # 4. Intelligent Stochasticity\n    bin_similarity = np.std(bins_utilization)\n    randomness_scale = 0.01 * (1 + item_size_ratio) * (1 - bin_similarity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # 5. Adaptive Weighting\n    tightness_weight = 0.40\n    fill_weight = 0.30\n    near_full_weight = 0.30 # Increased weight\n    \n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 1.705225368966895,
    "exec_success": true
  }
]