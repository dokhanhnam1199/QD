{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines waste minimization, target fill, adaptive weighting,\n    edge case handling, stochasticity, and bin diversity for improved bin packing.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.7, 0.0)\n\n    # Small Item Bonus\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0\n\n    # Large Item Penalty\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6, 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting (Dynamically adjust based on item size and bin states)\n    item_size_factor = item / bin_capacity  # Normalize item size\n    tightness_weight = 0.4 * (1 - item_size_factor) # Smaller items, prioritize tightness\n    fill_weight = 0.3 * (1 + item_size_factor)   # Larger items, prioritize target fill\n    near_full_weight = 0.2\n    small_item_weight = 0.1\n    large_item_weight = 0.1\n\n    # Bin Diversity Encouragement: Penalize bins with similar fill levels to promote variance\n    fill_level_std = np.std(bins_remain_cap)\n    diversity_bonus = np.exp(-np.abs(bins_remain_cap[can_fit] - np.mean(bins_remain_cap)) / (fill_level_std + 0.0001)) if fill_level_std > 0.01 else 0.0\n    diversity_weight = 0.05\n\n    # Stochasticity (Reduced for more stability, but still present)\n    randomness = np.random.normal(0, 0.005, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               diversity_weight * diversity_bonus +\n                               randomness)\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines waste minimization, target fill, adaptive weighting,\n    edge case handling, and stochasticity for improved bin packing.\n    Improves upon v1 by incorporating bin diversity and a dynamic penalty\n    for exceeding a target number of bins used. Also utilizes a decaying\n    randomness factor.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    num_bins = len(bins_remain_cap)\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.7, 0.0)\n\n    # Small Item Bonus\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0\n\n    # Large Item Penalty\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6, 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting (Dynamically adjust based on item size and bin states)\n    item_size_factor = item / bin_capacity  # Normalize item size\n    tightness_weight = 0.4 * (1 - item_size_factor) # Smaller items, prioritize tightness\n    fill_weight = 0.3 * (1 + item_size_factor)   # Larger items, prioritize target fill\n    near_full_weight = 0.2\n    small_item_weight = 0.1\n    large_item_weight = 0.1\n\n    # Bin Diversity Encouragement: Prioritize bins with different fill levels\n    fill_std = np.std(bins_remain_cap)\n    diversity_bonus = fill_std / bin_capacity  # Normalize diversity\n\n    # Dynamic Bin Count Penalty: Encourage packing into fewer bins\n    bins_used = np.sum(bins_remain_cap < bin_capacity)\n    target_bins = int(np.ceil(np.sum(item) / bin_capacity)) if isinstance(item,float) else int(np.ceil(np.sum(item)/bin_capacity))\n    over_bins = max(0, bins_used - target_bins)\n    bin_count_penalty = -0.1 * over_bins\n\n    # Decaying Stochasticity: Reduce randomness over time (simulated)\n    # This would ideally be managed externally to track the \"packing progress\".\n    # Here, we approximate it using the mean remaining capacity\n    packing_progress = np.mean(bins_remain_cap) / bin_capacity\n    randomness_strength = max(0.0, 0.01 * (1 - packing_progress))  # Reduced randomness\n    randomness = np.random.normal(0, randomness_strength, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               diversity_bonus +\n                               bin_count_penalty+\n                               randomness)\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the best heuristic incorporates waste minimization, target fill level, near-full penalty, adaptive weighting (based on item size and bin states), bin diversity encouragement, and stochasticity. The worst combines best-fit, target fill, near-full penalty, and randomness, but lacks adaptive weighting, bin diversity, small/large item handling and decaying stochasticity.\n(2nd best) vs (second worst) are identical, indicating the ranking is not consistent or is based on factors not apparent in the code alone.\nComparing (1st) vs (2nd), we see they are identical which suggests the ranking is based on some factors that are not present in the code.\n(3rd) vs (4th) are also identical.\nComparing (second worst) vs (worst), we see the second worst includes Fill percentage bonus, Item Size Consideration while the worst one does not.\nOverall: The better heuristics attempt to balance multiple factors by using adaptive weights and considering item sizes, bin diversity, and global bin utilization, while the worse heuristics only focus on a few basic strategies and lack dynamic adjustments.\n- \nOkay, I will help you redefine 'Current self-reflection' to design better heuristics, avoiding the pitfalls of 'Ineffective self-reflection' and aiming for actionable insights.\n\nHere's a refined perspective:\n\n*   **Keywords:** Adaptive weighting, stochasticity, multi-objective, parameter tuning, dynamic penalties/bonuses, item characteristics, bin state.\n\n*   **Advice:** Design heuristics that dynamically adjust their behavior based on item features and current bin configurations. Employ stochastic elements for broader exploration and fine-tune parameters through experimentation.\n\n*   **Avoid:** Overly simplistic approaches. Don't neglect the balance between exploration and exploitation.\n\n*   **Explanation:** Focus on creating flexible heuristics that respond intelligently to the problem's state. Parameter tuning is crucial to get optimal results. The system should learn during the process.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}