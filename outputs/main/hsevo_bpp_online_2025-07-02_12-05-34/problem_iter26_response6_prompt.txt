{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Combines adaptive fill, waste minimization, and decaying randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n    priorities[valid_bins] += tightness * 0.5\n\n    # Adaptive Target fill level\n    target_fill = 0.75 * bin_capacity\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / bin_capacity)\n    priorities[valid_bins] += fill_priority * 0.4\n\n    # Near-full penalty\n    nearly_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < nearly_full_threshold, -0.5 * (item/bin_capacity), 0.0)  #scaled penalty by item size\n    priorities[valid_bins] += near_full_penalty\n\n    # Decaying randomness\n    item_size_weight = item / bin_capacity\n    randomness = np.random.rand(len(valid_bins)) * 0.02 * (1 - item_size_weight) # decay slower for smaller items\n    priorities[valid_bins] += randomness\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"Prioritizes bins using waste, target fill, near-full penalty, & adaptive randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n    priorities[valid_bins] += tightness * 0.5\n\n    # Adaptive Target Fill\n    target_fill = 0.8 * bin_capacity - 0.1 * item\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / bin_capacity)\n    priorities[valid_bins] += fill_priority * 0.4\n\n    # Near-Full Penalty (only for larger items)\n    near_full_threshold = 0.08 * bin_capacity\n    near_full_penalty = np.where((remaining_after < near_full_threshold) & (item > 0.1 * bin_capacity), -0.5, 0.0)\n    priorities[valid_bins] += near_full_penalty\n    \n    #Decaying Randomness\n    item_size_weight = item / bin_capacity\n    randomness = np.random.rand(len(valid_bins)) * 0.02 * (1 - item_size_weight)\n    priorities[valid_bins] += randomness\n\n    return priorities\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), we see no difference. Comparing (1st) vs (20th), we observe that the best heuristic incorporates a learning rate to adapt the weights of tightness and fill, strategic randomness that decays based on item size and bin utilization, and a dynamic near-full management system. The 20th heuristic uses a simpler static weighting and a different approach to target fill levels, using a combination of low and high thresholds. Comparing (2nd) vs (3rd), (1st) uses adaptive weighting and randomness while (3rd) uses static weighting. Comparing (3rd) vs (4th), (4th) has adaptive weighting and strategic randomness. Comparing (second worst) vs (worst), the second worst incorporates a small item bonus and adaptive weighting, while the worst only focuses on waste minimization and adaptive penalties without dynamically adjusting the weights or utilizing any bonus system for small items. Comparing (11th) vs (12th), we see no difference. Comparing (1st) vs (11th), the key difference is that (11th) introduces small and large item bonuses and penalties and adjusts target fill based on average bin utilization. Overall: the better heuristics incorporate adaptive weighting based on item size and bin utilization, strategic randomness, dynamic penalties and bonuses based on item size and bin state, and adaptive target fill levels. They also tend to have more sophisticated methods for waste minimization.\n- \nOkay, I understand. Let's redefine \"Current self-reflection\" to make it more effective for designing better bin packing heuristics, while explicitly avoiding the pitfalls of \"Ineffective self-reflection.\"\n\nHere's a breakdown to guide the process:\n\n*   **Keywords:** Adaptive learning, dynamic adjustment, multi-objective balancing, stochastic exploration, performance feedback.\n\n*   **Advice:** Focus on learning from past packing outcomes to dynamically adjust parameters like target fill levels, penalty/bonus weights, and the degree of randomness. Use a multi-objective approach that explicitly models different performance goals (waste, fill, balance).\n\n*   **Avoid:** Broad, generic statements like \"simpler is better\" or \"consider multiple factors.\" Avoid feature repetition and focusing on static configurations of heuristics.\n\n*   **Explanation:** Effective heuristics need to learn and adapt. A system for tracking performance and feeding that back into heuristic parameter adjustment is key. The learning should adjust the balance between conflicting objectives. Instead of just saying \"use randomness,\" focus on strategies like decaying randomness or randomness driven by performance.\n\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}