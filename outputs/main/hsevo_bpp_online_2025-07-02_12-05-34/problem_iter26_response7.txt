```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """Combines adaptive waste minimization, fill target, and randomness with learning."""
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    can_fit = bins_remain_cap >= item
    bin_capacity = bins_remain_cap.max()

    if not np.any(can_fit):
        return np.full_like(priorities, -1.0)

    valid_bins = np.where(can_fit)[0]
    remaining_after = bins_remain_cap[can_fit] - item
    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity

    # Waste Minimization (Best-Fit)
    waste = remaining_after
    tightness = 1 / (waste + 0.0001)

    # Target fill level
    target_fill = 0.75 * bin_capacity
    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)
    fill_priority = np.exp(-fill_diff / (bin_capacity * 0.2))

    # Near-full penalty, scaled by item size
    nearly_full_threshold = 0.1 * bin_capacity
    nearly_full_valid_bins = remaining_after < nearly_full_threshold
    near_full_penalty = np.where(nearly_full_valid_bins, -0.95 * (item / bin_capacity), 0.0)

    # Small item bonus
    small_item_threshold = 0.2 * bin_capacity
    if item < small_item_threshold:
      almost_full_threshold = 0.1 * bin_capacity
      almost_full_valid_bins = bins_remain_cap[can_fit] < almost_full_threshold + item
      almost_full_indices = np.where(can_fit)[0][almost_full_valid_bins]
      priorities[almost_full_indices] += 0.2

    # Adaptive Weighting: item size & bin utilization, with learning
    item_size_factor = item / bin_capacity
    utilization_factor = np.mean(bins_utilization)
    learning_rate = 0.1

    tightness_weight = 0.4
    fill_weight = 0.35
    near_full_weight = 0.25

    tightness_weight += learning_rate * (1 - item_size_factor) * (1 + utilization_factor) - tightness_weight
    fill_weight += learning_rate * (1 + item_size_factor) * (1 - utilization_factor) - fill_weight


    # Strategic Randomness: Decays slower for smaller items, adjusts to utilization
    randomness_scale = 0.015 * (1 + item_size_factor) * (1 - utilization_factor)
    randomness = np.random.normal(0, randomness_scale, len(valid_bins))

    priorities[valid_bins] = (tightness_weight * tightness +
                               fill_weight * fill_priority +
                               near_full_weight * near_full_penalty +
                               randomness)

    return priorities
```
