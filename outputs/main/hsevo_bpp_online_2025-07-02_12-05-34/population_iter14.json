[
  {
    "stdout_filepath": "problem_iter14_response0.txt_stdout.txt",
    "code_path": "problem_iter14_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, adaptive weighting, and stochasticity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.7, 0.0)\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    tightness_weight = 0.4 * (1 - item_size_factor)\n    fill_weight = 0.3 * (1 + item_size_factor)\n    near_full_weight = 0.2\n\n    # Stochasticity\n    randomness = np.random.normal(0, 0.005, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    # Item Size Consideration: Penalize placing large items in bins with little extra space\n    large_item_threshold = 0.5 * bin_capacity\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.2, 0.0)\n        priorities[valid_bins] += small_space_penalty\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 1.0071798962903893,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response1.txt_stdout.txt",
    "code_path": "problem_iter14_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, near-full penalty, item size.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.5, 0.0)\n\n    # Adaptive Weighting based on item size\n    item_size_factor = item / bin_capacity\n    tightness_weight = 0.5 * (1 - item_size_factor)\n    fill_weight = 0.3 * (1 + item_size_factor)\n    near_full_weight = 0.2\n\n    # Stochasticity (Decaying)\n    randomness = np.random.normal(0, 0.01 / (1 + item_size_factor), len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 1.0670123653769492,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response2.txt_stdout.txt",
    "code_path": "problem_iter14_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid heuristic: Adaptive weighting, target fill, and stochasticity.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.15))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.5, 0.0)\n\n    # Item size consideration\n    item_size_factor = item / bin_capacity\n    tightness_weight = 0.5 * (1 - item_size_factor)\n    fill_weight = 0.5 * (1 + item_size_factor)\n    near_full_weight = 0.2\n    \n    # Stochasticity - scaled by remaining capacity\n    randomness_scale = 0.01 * (1 + bins_remain_cap[can_fit] / bin_capacity)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 0.9074591144794598,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response3.txt_stdout.txt",
    "code_path": "problem_iter14_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining waste minimization, target fill, and dynamic penalties.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    # Waste minimization\n    waste = bins_remain_cap[can_fit] - item\n    priorities[can_fit] = 1.0 / (1e-6 + waste)\n\n    # Target fill level\n    max_bin_cap = np.max(bins_remain_cap)\n    target_fill = 0.75 * max_bin_cap\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / max_bin_cap)\n    priorities[can_fit] += fill_priority * 0.2\n\n    # Near-full/Near-empty penalty (dynamic)\n    remaining_after_add = bins_remain_cap[can_fit] - item\n    nearly_full_threshold = 0.1 * max_bin_cap\n    nearly_empty_threshold = 0.9 * max_bin_cap  # Encourage bin utilization\n\n    near_full_penalty = np.where(remaining_after_add < nearly_full_threshold, -0.5, 0.0)\n    near_empty_bonus = np.where(bins_remain_cap[can_fit] > nearly_empty_threshold, 0.1, 0.0) # Small bonus\n    priorities[can_fit] += near_full_penalty + near_empty_bonus\n\n    # Item Size Consideration (adaptive weighting)\n    item_size_weight = item / max_bin_cap  # Normalize item size\n    priorities[can_fit] *= (1 + item_size_weight * 0.5)  # Larger items get higher priority\n\n    # Randomness (decaying)\n    randomness = np.random.rand(np.sum(can_fit)) * 0.01 * (1 - item_size_weight) # Less randomness for large items\n    priorities[can_fit] += randomness\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 82.13003589948147,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response4.txt_stdout.txt",
    "code_path": "problem_iter14_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Hybrid heuristic: Combines tightness, target fill, and adaptive item-based bonuses.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        priorities[:] = np.random.rand(len(priorities)) * 0.0001 # Add some randomness to deal with no-fit situation\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n\n    # Tightness score\n    tightness = 1 / (remaining_after + 0.0001)\n\n    # Target fill score\n    target_fill_level = 0.75 * bins_remain_cap.max()\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bins_remain_cap.max() * 0.2))\n\n    # Adaptive weights based on item size\n    if item < bins_remain_cap.max() * 0.1:\n        tightness_weight = 0.3\n        fill_weight = 0.4\n        small_item_bonus_weight = 0.3\n        # Apply small item bonus when the item is quite small\n        almost_full_threshold = bins_remain_cap.max() * 0.1\n        almost_full_bonus = (bins_remain_cap[can_fit] > item) * np.exp(-remaining_after / almost_full_threshold)\n\n    elif item > bins_remain_cap.max() * 0.5:\n        tightness_weight = 0.6\n        fill_weight = 0.3\n        small_item_bonus_weight = 0.1\n        almost_full_bonus = 0 # No bonus\n    else:\n        tightness_weight = 0.4\n        fill_weight = 0.4\n        small_item_bonus_weight = 0.2\n        almost_full_bonus = 0 # No bonus\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               small_item_bonus_weight * almost_full_bonus)\n\n    priorities[valid_bins] += np.random.rand(np.sum(valid_bins)) * 0.1 # Add small randomness\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 48, in priority_v2\n    fill_weight = 0.3 * (1 + item_size_factor)\nValueError: operands could not be broadcast together with shapes (5000,) (12497500,) (5000,) \n"
  },
  {
    "stdout_filepath": "problem_iter14_response5.txt_stdout.txt",
    "code_path": "problem_iter14_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, adaptive weighting, and stochasticity.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill_level)\n    fill_score = np.exp(-fill_diff / bin_capacity)\n\n    # Near-Full Penalty (moved outside can_fit)\n    nearly_full_threshold = 0.1 * bin_capacity\n    nearly_full = bins_remain_cap < nearly_full_threshold\n    priorities[nearly_full] -= 0.2\n\n    #Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    tightness_weight = 0.5 * (1-item_size_factor)\n    fill_weight = 0.5 * (1+ item_size_factor)\n\n\n    # Stochasticity\n    randomness = np.random.rand(len(valid_bins)) * 0.01\n\n    priorities[valid_bins] = (tightness_weight * tightness + fill_weight*fill_score + randomness)\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 1.4559234144395714,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response6.txt_stdout.txt",
    "code_path": "problem_iter14_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, near-full/empty penalties, and adaptive randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    # Waste minimization (Best-Fit)\n    waste = bins_remain_cap[can_fit] - item\n    priorities[can_fit] = 1.0 / (1e-6 + waste)\n\n    # Target fill level\n    max_bin_cap = np.max(bins_remain_cap)\n    target_fill = 0.75 * max_bin_cap\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / max_bin_cap)\n    priorities[can_fit] += fill_priority * 0.1\n\n    # Near-full penalty\n    nearly_full_threshold = 0.1 * max_bin_cap\n    nearly_full = bins_remain_cap < nearly_full_threshold\n    priorities[nearly_full] *= 0.5\n\n     # Nearly-empty bonus\n    nearly_empty_threshold = 0.9 * max_bin_cap\n    nearly_empty_valid = (bins_remain_cap[can_fit] > nearly_empty_threshold)\n    nearly_empty_indices = np.where(can_fit)[0][nearly_empty_valid]\n\n    priorities[nearly_empty_indices] += 0.05 # Small bonus for using empty bins.\n\n    # Adaptive Randomness (decaying with item size)\n    randomness = np.random.rand(np.sum(can_fit)) * 0.01 * (1 - item/max_bin_cap) # Reduce randomness for large items\n    priorities[can_fit] += randomness\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 42.76027124052652,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response7.txt_stdout.txt",
    "code_path": "problem_iter14_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive weighting, bin diversity, and dynamic bin count penalty for BPP.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    num_bins = len(bins_remain_cap)\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.7, 0.0)\n\n    # Small Item Bonus\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0\n\n    # Large Item Penalty\n    large_item_threshold = bin_capacity * 0.8\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6, 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    tightness_weight = 0.4 * (1 - item_size_factor)\n    fill_weight = 0.3 * (1 + item_size_factor)\n    near_full_weight = 0.2\n    small_item_weight = 0.1\n    large_item_weight = 0.1\n\n    # Bin Diversity\n    fill_std = np.std(bins_remain_cap)\n    diversity_bonus = np.exp(-np.abs(bins_remain_cap[can_fit] - np.mean(bins_remain_cap)) / (fill_std + 0.0001)) if fill_std > 0.01 else 0.0\n\n    diversity_weight = 0.05\n\n    # Dynamic Bin Count Penalty\n    bins_used = np.sum(bins_remain_cap < bin_capacity)\n    target_bins = int(np.ceil(np.sum(item) / bin_capacity)) if isinstance(item,float) else int(np.ceil(np.sum(item)/bin_capacity))\n    over_bins = max(0, bins_used - target_bins)\n    bin_count_penalty = -0.1 * over_bins\n\n    # Stochasticity\n    packing_progress = np.mean(bins_remain_cap) / bin_capacity\n    randomness_strength = max(0.0, 0.01 * (1 - packing_progress))\n    randomness = np.random.normal(0, randomness_strength, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               diversity_weight*diversity_bonus +\n                               bin_count_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 0.9972078181092939,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response8.txt_stdout.txt",
    "code_path": "problem_iter14_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Enhanced heuristic: adaptive weights, dynamic near-full, item size considerations, and randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.75 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8 * (item/bin_capacity), 0.0)\n\n    # Smaller Item Bonus (if item fits nearly perfectly into a near-full bin)\n    small_item_threshold = bin_capacity * 0.25\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # Larger Item Penalty (if placing it leaves very little space)\n    large_item_threshold = bin_capacity * 0.75\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.7 * (item/bin_capacity), 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # Adaptive Weighting: item size & bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.35 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.35 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # Stochasticity scaled by item size and bin utilization\n    randomness_scale = 0.015 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 0.7977662544874352,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter14_response9.txt_stdout.txt",
    "code_path": "problem_iter14_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, adaptive weighting, and stochasticity.\n    Improved by adding small item bonus and dynamic bin count penalty.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    num_bins = len(bins_remain_cap)\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level\n    target_fill_level = 0.8 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-Full Penalty (Slightly reduced penalty)\n    near_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < near_full_threshold, -0.6, 0.0)\n\n    # Small Item Bonus\n    small_item_threshold = bin_capacity * 0.2\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    tightness_weight = 0.5 * (1 - item_size_factor)\n    fill_weight = 0.4 * (1 + item_size_factor)\n    near_full_weight = 0.1\n\n    # Dynamic Bin Count Penalty\n    bins_used = np.sum(bins_remain_cap < bin_capacity)\n    target_bins = int(np.ceil(np.sum(item) / bin_capacity)) if isinstance(item, float) else int(np.ceil(np.sum(item)/bin_capacity))\n\n    over_bins = max(0, bins_used - target_bins)\n    bin_count_penalty = -0.05 * over_bins\n    # Randomness\n    randomness = np.random.rand(len(valid_bins)) * 0.01\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               almost_full_bonus * 0.2 +\n                               bin_count_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 1.4160351017152022,
    "exec_success": true
  }
]