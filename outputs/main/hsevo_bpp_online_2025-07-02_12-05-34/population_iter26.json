[
  {
    "stdout_filepath": "problem_iter26_response0.txt_stdout.txt",
    "code_path": "problem_iter26_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, target fill, and adaptive weighting with strategic randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = np.exp(-5 * waste / bin_capacity)\n\n    # Target Fill Level\n    target_fill_level_low = 0.70 * bin_capacity\n    target_fill_level_high = 0.90 * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n\n    fill_score = np.where(\n        fill_level < target_fill_level_low,\n        np.exp(-((fill_level - target_fill_level_low)**2) / (2 * (bin_capacity * 0.1)**2)),\n        np.where(\n            fill_level > target_fill_level_high,\n            np.exp(-((fill_level - target_fill_level_high)**2) / (2 * (bin_capacity * 0.1)**2)),\n            1.0\n        )\n    )\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.15 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item / bin_capacity), 0.0)\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization) if bins_utilization.size > 0 else 0.0\n\n    tightness_weight = 0.3 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.3 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.15\n\n    # Strategic Randomness\n    priority_range = np.max([tightness.max(), fill_score.max(), 0.1]) - np.min([tightness.min(), fill_score.min(), -0.1])\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor) * priority_range\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 48.12524930195454,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter26_response1.txt_stdout.txt",
    "code_path": "problem_iter26_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines waste minimization, adaptive penalty, small item bonus, randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    bin_capacity = np.max(bins_remain_cap)\n    remaining_after = bins_remain_cap[can_fit] - item\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1.0 / (1e-6 + waste)\n    priorities[valid_bins] += tightness * 0.5\n\n    # Adaptive Near-Full Penalty\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8 * (item / bin_capacity), 0.0)\n    priorities[valid_bins] += near_full_penalty\n\n    # Small item bonus\n    small_item_threshold = 0.2 * bin_capacity\n    if item < small_item_threshold:\n      almost_full_threshold = 0.1 * bin_capacity\n      almost_full_valid_bins = remaining_after < almost_full_threshold\n      almost_full_indices = valid_bins[almost_full_valid_bins]\n      priorities[almost_full_indices] += 0.2\n      \n    #Decaying Randomness\n    item_size_weight = item / bin_capacity\n    randomness = np.random.rand(len(valid_bins)) * 0.02 * (1 - item_size_weight)\n    priorities[valid_bins] += randomness\n\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "obj": 5.065815715995209,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter26_response2.txt_stdout.txt",
    "code_path": "problem_iter26_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive weights, dynamic penalties, and strategic randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target Fill Level - adapt based on utilization\n    avg_utilization = np.mean(bins_utilization)\n    target_fill_level = (0.7 + 0.1 * avg_utilization) * bin_capacity # Adjust target\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.1 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.9 * (item/bin_capacity), 0.0)\n\n    # Adaptive Weighting\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n    learning_rate = 0.1\n\n    tightness_weight = 0.35\n    fill_weight = 0.35\n    near_full_weight = 0.15\n    random_weight = 0.15\n\n    tightness_weight += learning_rate * (1 - item_size_factor) * (1 + utilization_factor) - tightness_weight\n    fill_weight += learning_rate * (1 + item_size_factor) * (1 - utilization_factor) - fill_weight\n\n    # Decaying Randomness based on item size and bin utilization\n    randomness_scale = 0.02 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    # Small Item Bonus\n    small_item_bonus = np.where(item_size_factor < 0.2, 0.1, 0.0)\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               random_weight * randomness +\n                               small_item_bonus)\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 2.293577981651376,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter26_response3.txt_stdout.txt",
    "code_path": "problem_iter26_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill, waste minimization, decaying randomness, and item-size awareness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization with Item-Size Awareness\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n    priorities[valid_bins] += tightness * 0.5 * (1 - 0.3 * (item/bin_capacity))  # Smaller items get a tightness boost\n\n    # Adaptive Target fill level\n    target_fill = 0.75 * bin_capacity\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / bin_capacity)\n    priorities[valid_bins] += fill_priority * 0.4\n\n    # Near-full penalty, scaled by item size\n    nearly_full_threshold = 0.1 * bin_capacity\n    near_full_penalty = np.where(remaining_after < nearly_full_threshold, -0.5 * (item/bin_capacity), 0.0)\n    priorities[valid_bins] += near_full_penalty\n\n    # Decaying randomness, biased towards emptier bins for larger items\n    item_size_weight = item / bin_capacity\n    emptiness_factor = bins_remain_cap[valid_bins] / bin_capacity\n    randomness = np.random.rand(len(valid_bins)) * 0.02 * (1 - item_size_weight) * emptiness_factor # more random on emptier bins\n    priorities[valid_bins] += randomness\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 2.114080574391708,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter26_response4.txt_stdout.txt",
    "code_path": "problem_iter26_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive weights, dynamic penalties, strategic randomness based on item & bin state.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization\n    waste_ratio = remaining_after / item\n    waste_priority = np.exp(-5 * waste_ratio)\n\n    # Target Fill Level\n    target_fill_level = 0.78 * bin_capacity  # Adjusted target\n    fill_level_diff = np.abs(bins_remain_cap[can_fit] - target_fill_level)\n    fill_level_priority = np.exp(-fill_level_diff / (bin_capacity * 0.2))\n\n    # Dynamic Near-Full Management\n    near_full_threshold = 0.09 * bin_capacity # Adjusted threshold\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.8, 0.0)  #Reduced penalty\n\n    # Adaptive Weighting (combined approaches)\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization) if bins_utilization.size > 0 else 0.0\n\n    waste_weight = 0.32 * (1 - item_size_factor) * (1 + utilization_factor)\n    fill_weight = 0.32 * (1 + item_size_factor) * (1 - utilization_factor)\n    near_full_weight = 0.1\n\n    # Strategic Randomness (scaled to priorities)\n    priority_range = np.max([waste_priority.max(), fill_level_priority.max(), 0.1]) - np.min([waste_priority.min(), fill_level_priority.min(), -0.1])\n    randomness_scale = 0.015 * (1 + item_size_factor) * (1 - utilization_factor) * priority_range # Reduced scale\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (waste_weight * waste_priority +\n                               fill_weight * fill_level_priority +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "obj": 10.201435979258074,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter26_response5.txt_stdout.txt",
    "code_path": "problem_iter26_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic with dynamic weights and decaying randomness.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n    avg_utilization = np.mean(bins_utilization)\n\n    # 1. Waste Minimization (Tightness)\n    waste = remaining_after\n    base_tightness = 1 / (waste + 0.0001)\n    item_size_factor = item / bin_capacity\n    tightness = base_tightness * (1 + (1 - item_size_factor))\n\n    # 2. Target Fill Level (Adaptive)\n    target_fill_level = (0.65 + 0.2 * avg_utilization) * bin_capacity\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # 3. Dynamic Near-Full Management\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.7 * (item/bin_capacity) * (1+bins_utilization), 0.0)\n\n    # 4. Smaller Item Bonus\n    small_item_threshold = bin_capacity * 0.25\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n    \n    # 5. Larger Item Penalty\n    large_item_threshold = bin_capacity * 0.75\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6 * (item/bin_capacity), 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # 6. Adaptive Weighting\n    tightness_weight = 0.35 * (1.2 - item_size_factor) * (1.1 - avg_utilization)\n    fill_weight = 0.35 * (0.8 + item_size_factor) * (0.9 + avg_utilization)\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # 7. Decaying Stochasticity\n    randomness_scale = 0.015 * (1 + item_size_factor) * (1 - avg_utilization)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty+\n                               randomness)\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 3.0614280015955373,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter26_response6.txt_stdout.txt",
    "code_path": "problem_iter26_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive fill, waste minimization, dynamic penalty and decaying randomness.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return priorities\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n\n    # Waste Minimization\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n    priorities[valid_bins] += tightness * 0.5\n\n    # Adaptive Target Fill with item size adjustment\n    target_fill = 0.8 * bin_capacity - 0.1 * item\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / bin_capacity)\n    priorities[valid_bins] += fill_priority * 0.4\n\n    # Near-Full Penalty (larger items)\n    near_full_threshold = 0.08 * bin_capacity\n    near_full_penalty = np.where((remaining_after < near_full_threshold) & (item > 0.1 * bin_capacity), -0.5, 0.0)\n    priorities[valid_bins] += near_full_penalty\n\n    # Decaying Randomness (item size)\n    item_size_weight = item / bin_capacity\n    randomness = np.random.rand(len(valid_bins)) * 0.02 * (1 - item_size_weight)\n    priorities[valid_bins] += randomness\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 2.8619864379736786,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter26_response7.txt_stdout.txt",
    "code_path": "problem_iter26_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines adaptive waste minimization, fill target, and randomness with learning.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization (Best-Fit)\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Target fill level\n    target_fill = 0.75 * bin_capacity\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # Near-full penalty, scaled by item size\n    nearly_full_threshold = 0.1 * bin_capacity\n    nearly_full_valid_bins = remaining_after < nearly_full_threshold\n    near_full_penalty = np.where(nearly_full_valid_bins, -0.95 * (item / bin_capacity), 0.0)\n\n    # Small item bonus\n    small_item_threshold = 0.2 * bin_capacity\n    if item < small_item_threshold:\n      almost_full_threshold = 0.1 * bin_capacity\n      almost_full_valid_bins = bins_remain_cap[can_fit] < almost_full_threshold + item\n      almost_full_indices = np.where(can_fit)[0][almost_full_valid_bins]\n      priorities[almost_full_indices] += 0.2\n\n    # Adaptive Weighting: item size & bin utilization, with learning\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n    learning_rate = 0.1\n\n    tightness_weight = 0.4\n    fill_weight = 0.35\n    near_full_weight = 0.25\n\n    tightness_weight += learning_rate * (1 - item_size_factor) * (1 + utilization_factor) - tightness_weight\n    fill_weight += learning_rate * (1 + item_size_factor) * (1 - utilization_factor) - fill_weight\n\n\n    # Strategic Randomness: Decays slower for smaller items, adjusts to utilization\n    randomness_scale = 0.015 * (1 + item_size_factor) * (1 - utilization_factor)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_priority +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 1.1767052253689738,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter26_response8.txt_stdout.txt",
    "code_path": "problem_iter26_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Adaptive heuristic combining waste, fill, near-full, and learning.\"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bin_capacity = bins_remain_cap.max()\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n    avg_utilization = np.mean(bins_utilization)\n\n    # 1. Waste Minimization: Prioritize bins that minimize remaining space.\n    waste = remaining_after\n    base_tightness = 1 / (waste + 0.0001)\n    item_size_factor = item / bin_capacity\n    tightness = base_tightness * (1 + (1 - item_size_factor))  # Boost tightness for small items\n\n    # 2. Target Fill Level: Reward bins close to a dynamic target fill level.\n    target_fill_level = (0.65 + 0.2 * avg_utilization) * bin_capacity\n    fill_level = bins_remain_cap[can_fit]\n    fill_diff = np.abs(fill_level - target_fill_level)\n    fill_score = np.exp(-fill_diff / (bin_capacity * 0.2))\n\n    # 3. Near-Full Management: Penalize bins that become very near full.\n    near_full_threshold = 0.12 * bin_capacity\n    is_near_full = remaining_after < near_full_threshold\n    near_full_penalty = np.where(is_near_full, -0.7 * (item / bin_capacity) * (1 + bins_utilization), 0.0)\n\n    # 4. Smaller Item Bonus: if item fits nearly perfectly into a near-full bin\n    small_item_threshold = bin_capacity * 0.25\n    if item < small_item_threshold:\n        almost_full_threshold = bin_capacity * 0.1\n        almost_full_bonus = np.exp(-remaining_after / (almost_full_threshold + 0.0001))\n    else:\n        almost_full_bonus = 0.0\n\n    # 5. Larger Item Penalty (if placing it leaves very little space)\n    large_item_threshold = bin_capacity * 0.75\n    if item > large_item_threshold:\n        small_space_penalty = np.where(bins_remain_cap[can_fit] < (item + 0.1 * bin_capacity), -0.6 * (item / bin_capacity), 0.0)\n    else:\n        small_space_penalty = 0.0\n\n    # 6. Adaptive Weighting: item size & bin utilization\n    tightness_weight = 0.35 * (1.2 - item_size_factor) * (1.1 - avg_utilization)\n    fill_weight = 0.35 * (0.8 + item_size_factor) * (0.9 + avg_utilization)\n    near_full_weight = 0.15\n    small_item_weight = 0.075\n    large_item_weight = 0.075\n\n    # 7. Decaying Stochasticity\n    randomness_scale = 0.015 * (1 + item_size_factor) * (1 - avg_utilization)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_score +\n                               near_full_weight * near_full_penalty +\n                               small_item_weight * almost_full_bonus +\n                               large_item_weight * small_space_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 3.031511767052263,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter26_response9.txt_stdout.txt",
    "code_path": "problem_iter26_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Adaptive heuristic with learning for waste, fill, and randomness.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    can_fit = bins_remain_cap >= item\n    bin_capacity = bins_remain_cap.max()\n\n    if not np.any(can_fit):\n        return np.full_like(priorities, -1.0)\n\n    valid_bins = np.where(can_fit)[0]\n    remaining_after = bins_remain_cap[can_fit] - item\n    bins_utilization = (bin_capacity - bins_remain_cap[can_fit]) / bin_capacity\n\n    # Waste Minimization (Best-Fit)\n    waste = remaining_after\n    tightness = 1 / (waste + 0.0001)\n\n    # Adaptive Target Fill\n    target_fill = 0.8 * bin_capacity - 0.1 * item\n    fill_diff = np.abs(bins_remain_cap[can_fit] - target_fill)\n    fill_priority = np.exp(-fill_diff / bin_capacity)\n\n    # Near-Full Penalty (larger items only)\n    near_full_threshold = 0.08 * bin_capacity\n    near_full_penalty = np.where((remaining_after < near_full_threshold) & (item > 0.1 * bin_capacity), -0.5, 0.0)\n\n    # Adaptive Weighting: item size & bin utilization\n    item_size_factor = item / bin_capacity\n    utilization_factor = np.mean(bins_utilization)\n\n    tightness_weight = 0.4\n    fill_weight = 0.4\n    near_full_weight = 0.2\n\n    #Decaying Randomness\n    item_size_weight = item / bin_capacity\n    randomness_scale = 0.02 * (1 - item_size_weight)\n    randomness = np.random.normal(0, randomness_scale, len(valid_bins))\n\n    priorities[valid_bins] = (tightness_weight * tightness +\n                               fill_weight * fill_priority +\n                               near_full_weight * near_full_penalty +\n                               randomness)\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 1.5556441962505008,
    "exec_success": true
  }
]