{"system": "You are an expert in the domain of optimization heuristics. Your task is to provide useful advice based on analysis to design better heuristics.\n", "user": "### List heuristics\nBelow is a list of design heuristics ranked from best to worst.\n[Heuristics 1st]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit (tightest fit) with an epsilon-greedy exploration strategy.\n    Prioritizes bins that leave the smallest remaining capacity after packing,\n    with a small chance of picking any suitable bin to encourage exploration.\n    \"\"\"\n    epsilon = 0.05  # Probability of exploration\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n    suitable_bins_indices = np.where(suitable_bins_mask)[0]\n\n    if suitable_bins_indices.size == 0:\n        return priorities  # No bin can fit the item\n\n    # Exploration phase: with probability epsilon, pick a random suitable bin\n    if np.random.rand() < epsilon:\n        chosen_bin_index = np.random.choice(suitable_bins_indices)\n        priorities[chosen_bin_index] = 1.0\n    else:\n        # Exploitation phase: Best Fit strategy\n        suitable_bins_capacities = bins_remain_cap[suitable_bins_indices]\n        # Calculate the 'gap' or remaining capacity after fitting the item\n        gaps = suitable_bins_capacities - item\n        \n        # Find the index within the 'suitable_bins_indices' array that has the minimum gap\n        best_fit_in_suitable_idx = np.argmin(gaps)\n        # Get the original index of this best-fitting bin\n        best_fit_original_idx = suitable_bins_indices[best_fit_in_suitable_idx]\n        priorities[best_fit_original_idx] = 1.0\n\n    return priorities\n\n[Heuristics 2nd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit (tightest fit) with an epsilon-greedy exploration strategy.\n    Prioritizes bins that leave the smallest remaining capacity after packing,\n    with a small chance of picking any suitable bin to encourage exploration.\n    \"\"\"\n    epsilon = 0.05  # Probability of exploration\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n    suitable_bins_indices = np.where(suitable_bins_mask)[0]\n\n    if suitable_bins_indices.size == 0:\n        return priorities  # No bin can fit the item\n\n    # Exploration phase: with probability epsilon, pick a random suitable bin\n    if np.random.rand() < epsilon:\n        chosen_bin_index = np.random.choice(suitable_bins_indices)\n        priorities[chosen_bin_index] = 1.0\n    else:\n        # Exploitation phase: Best Fit strategy\n        suitable_bins_capacities = bins_remain_cap[suitable_bins_indices]\n        # Calculate the 'gap' or remaining capacity after fitting the item\n        gaps = suitable_bins_capacities - item\n        \n        # Find the index within the 'suitable_bins_indices' array that has the minimum gap\n        best_fit_in_suitable_idx = np.argmin(gaps)\n        # Get the original index of this best-fitting bin\n        best_fit_original_idx = suitable_bins_indices[best_fit_in_suitable_idx]\n        priorities[best_fit_original_idx] = 1.0\n\n    return priorities\n\n[Heuristics 3rd]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines tight-fit preference with adaptive penalty for large bins,\n    favoring bins that are neither too full nor too empty relative to item size.\n    Uses score normalization for robust comparison.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # Tightness score: Higher for bins leaving less space after packing.\n    # This is equivalent to prioritizing bins closer to 'item' size from below.\n    tightness_score = 1.0 / (fitting_bins_remain_cap - item + epsilon)\n\n    # Adaptive penalty for \"empty\" or overly large bins:\n    # Penalize bins whose remaining capacity is significantly larger than the item size.\n    # We want to reduce the priority of bins that are \"too empty\" for the current item.\n    # A simple way is to use an inverse relationship with the initial remaining capacity.\n    # The factor penalizes bins with large remaining capacities, favoring those already somewhat utilized.\n    # This is analogous to prioritizing bins that are not \"too empty\".\n    penalty_weight = 0.3\n    penalty_score = 1.0 / (1.0 + penalty_weight * fitting_bins_remain_cap)\n\n    # Combine tightness and penalty. A higher combined score means a bin is both a tight fit\n    # and not excessively large (i.e., not \"too empty\").\n    combined_score = tightness_score * penalty_score\n\n    # Normalize scores to a 0-1 range for stable comparison across different item/bin states.\n    max_score = np.max(combined_score)\n    if max_score > 0:\n        priorities[can_fit_mask] = combined_score / max_score\n\n    return priorities\n\n[Heuristics 4th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines the tightness preference with an adaptive \"fill level\" bonus\n    and a sophisticated exploration strategy inspired by multi-armed bandits.\n    Prioritizes tight fits while encouraging the use of partially filled bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    # Mask for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit, return all zeros\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # --- Exploitation Strategy: Combined Tightness and Fill Bonus ---\n\n    # Tightness score: Inverse of remaining capacity after packing. Higher is better.\n    # This favors bins that leave minimal slack.\n    tightness_score = np.zeros_like(bins_remain_cap, dtype=float)\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_packing = fitting_bins_remain_cap - item\n    tightness_score[can_fit_mask] = 1.0 / (remaining_after_packing + epsilon)\n\n    # Fill Level Bonus: Rewards bins that are already more utilized.\n    # We approximate utilization by penalizing bins with large remaining capacity.\n    # A simple inverse of the current remaining capacity (for fitting bins) serves as a bonus.\n    # This encourages using bins that are already partially filled, rather than always\n    # picking a \"tight fit\" in a nearly empty bin.\n    fill_bonus = np.zeros_like(bins_remain_cap, dtype=float)\n    # Bonus is higher for bins with less remaining capacity (i.e., more filled)\n    fill_bonus[can_fit_mask] = 1.0 / (fitting_bins_remain_cap + epsilon)\n\n    # Combine tightness and fill bonus. Multiplication allows the fill bonus to\n    # modulate the tightness score. A bin that is both tight and already somewhat full\n    # gets a higher combined score.\n    combined_exploitation_score = tightness_score * (1.0 + 0.3 * fill_bonus) # 0.3 is a tunable weight\n\n    # Normalize exploitation scores to the range [0, 1]\n    max_exploitation_score = np.max(combined_exploitation_score)\n    if max_exploitation_score > 0:\n        normalized_exploitation_scores = combined_exploitation_score / max_exploitation_score\n    else:\n        normalized_exploitation_scores = np.zeros_like(combined_exploitation_score)\n\n    # --- Exploration Strategy: Adaptive Exploration (Simplified Bandit-like) ---\n\n    # We want to explore bins that are currently less prioritized to discover\n    # potentially better packing options or to balance load.\n    # A simple adaptive strategy: If a bin has a low exploitation score,\n    # it's a candidate for exploration. We'll assign a small, uniform exploration\n    # priority to all bins that can fit the item. The degree of exploration\n    # can be tied to the number of available fitting bins.\n\n    num_fitting_bins = np.sum(can_fit_mask)\n    exploration_weight = 0.15 # Base weight for exploration\n\n    # Increase exploration tendency if there are many options, decrease if few\n    if num_fitting_bins > 5:\n        exploration_weight *= 1.2\n    elif num_fitting_bins < 3:\n        exploration_weight *= 0.8\n\n    # Create exploration scores. For simplicity here, we'll give a small boost\n    # to all fitting bins, meaning any fitting bin has a chance.\n    # A more advanced approach would use a UCB-like strategy.\n    exploration_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    exploration_scores[can_fit_mask] = exploration_weight / num_fitting_bins\n\n    # --- Final Priority: Blend Exploitation and Exploration ---\n    # A simple blending: priorities = exploitation_scores + exploration_scores\n    # This gives a base priority based on exploitation and adds a small chance\n    # to any fitting bin via exploration.\n    priorities[can_fit_mask] = normalized_exploitation_scores[can_fit_mask] + exploration_scores[can_fit_mask]\n\n    # Ensure no negative priorities and normalize the final output to [0, 1]\n    priorities = np.maximum(0, priorities)\n    max_final_priority = np.max(priorities)\n    if max_final_priority > 0:\n        priorities /= max_final_priority\n\n    return priorities\n\n[Heuristics 5th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines the tightness preference with an adaptive \"fill level\" bonus\n    and a sophisticated exploration strategy inspired by multi-armed bandits.\n    Prioritizes tight fits while encouraging the use of partially filled bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    # Mask for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit, return all zeros\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # --- Exploitation Strategy: Combined Tightness and Fill Bonus ---\n\n    # Tightness score: Inverse of remaining capacity after packing. Higher is better.\n    # This favors bins that leave minimal slack.\n    tightness_score = np.zeros_like(bins_remain_cap, dtype=float)\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_packing = fitting_bins_remain_cap - item\n    tightness_score[can_fit_mask] = 1.0 / (remaining_after_packing + epsilon)\n\n    # Fill Level Bonus: Rewards bins that are already more utilized.\n    # We approximate utilization by penalizing bins with large remaining capacity.\n    # A simple inverse of the current remaining capacity (for fitting bins) serves as a bonus.\n    # This encourages using bins that are already partially filled, rather than always\n    # picking a \"tight fit\" in a nearly empty bin.\n    fill_bonus = np.zeros_like(bins_remain_cap, dtype=float)\n    # Bonus is higher for bins with less remaining capacity (i.e., more filled)\n    fill_bonus[can_fit_mask] = 1.0 / (fitting_bins_remain_cap + epsilon)\n\n    # Combine tightness and fill bonus. Multiplication allows the fill bonus to\n    # modulate the tightness score. A bin that is both tight and already somewhat full\n    # gets a higher combined score.\n    combined_exploitation_score = tightness_score * (1.0 + 0.3 * fill_bonus) # 0.3 is a tunable weight\n\n    # Normalize exploitation scores to the range [0, 1]\n    max_exploitation_score = np.max(combined_exploitation_score)\n    if max_exploitation_score > 0:\n        normalized_exploitation_scores = combined_exploitation_score / max_exploitation_score\n    else:\n        normalized_exploitation_scores = np.zeros_like(combined_exploitation_score)\n\n    # --- Exploration Strategy: Adaptive Exploration (Simplified Bandit-like) ---\n\n    # We want to explore bins that are currently less prioritized to discover\n    # potentially better packing options or to balance load.\n    # A simple adaptive strategy: If a bin has a low exploitation score,\n    # it's a candidate for exploration. We'll assign a small, uniform exploration\n    # priority to all bins that can fit the item. The degree of exploration\n    # can be tied to the number of available fitting bins.\n\n    num_fitting_bins = np.sum(can_fit_mask)\n    exploration_weight = 0.15 # Base weight for exploration\n\n    # Increase exploration tendency if there are many options, decrease if few\n    if num_fitting_bins > 5:\n        exploration_weight *= 1.2\n    elif num_fitting_bins < 3:\n        exploration_weight *= 0.8\n\n    # Create exploration scores. For simplicity here, we'll give a small boost\n    # to all fitting bins, meaning any fitting bin has a chance.\n    # A more advanced approach would use a UCB-like strategy.\n    exploration_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    exploration_scores[can_fit_mask] = exploration_weight / num_fitting_bins\n\n    # --- Final Priority: Blend Exploitation and Exploration ---\n    # A simple blending: priorities = exploitation_scores + exploration_scores\n    # This gives a base priority based on exploitation and adds a small chance\n    # to any fitting bin via exploration.\n    priorities[can_fit_mask] = normalized_exploitation_scores[can_fit_mask] + exploration_scores[can_fit_mask]\n\n    # Ensure no negative priorities and normalize the final output to [0, 1]\n    priorities = np.maximum(0, priorities)\n    max_final_priority = np.max(priorities)\n    if max_final_priority > 0:\n        priorities /= max_final_priority\n\n    return priorities\n\n[Heuristics 6th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines tightest fit with a penalty for under-utilized bins,\n    using a novel exploration strategy to balance exploitation and exploration.\n    \"\"\"\n    epsilon = 1e-9\n    exploration_factor = 0.2  # Controls the degree of exploration\n\n    # Mask for bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # --- Exploitation Component: Tightest Fit ---\n    # Prioritize bins that leave minimal remaining capacity after packing.\n    # Higher score for smaller remaining space.\n    remaining_after_packing = fitting_bins_remain_cap - item\n    tight_fit_scores = 1.0 / (remaining_after_packing + epsilon)\n\n    # --- Exploitation Component: Utilization Penalty ---\n    # Penalize bins that are significantly under-utilized (i.e., have a lot of remaining capacity).\n    # This encourages filling existing bins before opening new ones.\n    # We use the inverse of the *initial* remaining capacity as a proxy for utilization.\n    # Higher utilization (less remaining capacity) gets a higher score.\n    utilization_scores = 1.0 / (fitting_bins_remain_cap + epsilon)\n\n    # --- Combine Exploitation Scores ---\n    # Weighted sum of tight fit and utilization scores.\n    # Giving slightly more weight to tight fit as it's the primary goal of BPP.\n    combined_exploitation_scores = 0.6 * tight_fit_scores + 0.4 * utilization_scores\n\n    # Normalize exploitation scores to [0, 1]\n    max_exploitation_score = np.max(combined_exploitation_scores)\n    if max_exploitation_score > epsilon:\n        normalized_exploitation_scores = combined_exploitation_scores / max_exploitation_score\n    else:\n        normalized_exploitation_scores = np.zeros_like(combined_exploitation_scores)\n\n    # --- Exploration Component: Adaptive Exploration ---\n    # We want to explore bins that are not necessarily the best according to exploitation.\n    # Instead of random choice, we will boost the scores of bins that are \"average\" or slightly below average\n    # in terms of exploitation, giving them a chance.\n    num_fitting_bins = len(fitting_bins_remain_cap)\n    \n    # Calculate a baseline score (e.g., mean exploitation score)\n    mean_exploitation_score = np.mean(normalized_exploitation_scores)\n    \n    # Create exploration scores: higher for bins closer to the mean exploitation score.\n    # This aims to explore \"promising but not top\" candidates.\n    # We add a small constant to ensure even the lowest scores get some exploration boost if needed.\n    exploration_scores = np.exp(-((normalized_exploitation_scores - mean_exploitation_score) / (mean_exploitation_score + epsilon))**2)\n    \n    # Apply the exploration factor to blend exploitation and exploration\n    # The final priority is a mix:\n    # (1 - exploration_factor) * exploitation_scores + exploration_factor * exploration_scores\n    # This ensures that exploration never completely overrides exploitation,\n    # and also that exploitation still has a significant impact.\n    final_priorities_unnormalized = (1 - exploration_factor) * normalized_exploitation_scores + exploration_factor * exploration_scores\n\n    # Normalize final priorities for the fitting bins\n    sum_final_priorities = np.sum(final_priorities_unnormalized)\n    if sum_final_priorities > epsilon:\n        priorities[can_fit_mask] = final_priorities_unnormalized / sum_final_priorities\n    else:\n        # If all scores are zero, distribute probability equally among fitting bins\n        priorities[can_fit_mask] = 1.0 / num_fitting_bins\n\n    return priorities\n\n[Heuristics 7th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines the tightness preference with an adaptive \"fill level\" bonus\n    and a sophisticated exploration strategy inspired by multi-armed bandits.\n    Prioritizes tight fits while encouraging the use of partially filled bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    # Mask for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit, return all zeros\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # --- Exploitation Strategy: Combined Tightness and Fill Bonus ---\n\n    # Tightness score: Inverse of remaining capacity after packing. Higher is better.\n    # This favors bins that leave minimal slack.\n    tightness_score = np.zeros_like(bins_remain_cap, dtype=float)\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_packing = fitting_bins_remain_cap - item\n    tightness_score[can_fit_mask] = 1.0 / (remaining_after_packing + epsilon)\n\n    # Fill Level Bonus: Rewards bins that are already more utilized.\n    # We approximate utilization by penalizing bins with large remaining capacity.\n    # A simple inverse of the current remaining capacity (for fitting bins) serves as a bonus.\n    # This encourages using bins that are already partially filled, rather than always\n    # picking a \"tight fit\" in a nearly empty bin.\n    fill_bonus = np.zeros_like(bins_remain_cap, dtype=float)\n    # Bonus is higher for bins with less remaining capacity (i.e., more filled)\n    fill_bonus[can_fit_mask] = 1.0 / (fitting_bins_remain_cap + epsilon)\n\n    # Combine tightness and fill bonus. Multiplication allows the fill bonus to\n    # modulate the tightness score. A bin that is both tight and already somewhat full\n    # gets a higher combined score.\n    combined_exploitation_score = tightness_score * (1.0 + 0.3 * fill_bonus) # 0.3 is a tunable weight\n\n    # Normalize exploitation scores to the range [0, 1]\n    max_exploitation_score = np.max(combined_exploitation_score)\n    if max_exploitation_score > 0:\n        normalized_exploitation_scores = combined_exploitation_score / max_exploitation_score\n    else:\n        normalized_exploitation_scores = np.zeros_like(combined_exploitation_score)\n\n    # --- Exploration Strategy: Adaptive Exploration (Simplified Bandit-like) ---\n\n    # We want to explore bins that are currently less prioritized to discover\n    # potentially better packing options or to balance load.\n    # A simple adaptive strategy: If a bin has a low exploitation score,\n    # it's a candidate for exploration. We'll assign a small, uniform exploration\n    # priority to all bins that can fit the item. The degree of exploration\n    # can be tied to the number of available fitting bins.\n\n    num_fitting_bins = np.sum(can_fit_mask)\n    exploration_weight = 0.15 # Base weight for exploration\n\n    # Increase exploration tendency if there are many options, decrease if few\n    if num_fitting_bins > 5:\n        exploration_weight *= 1.2\n    elif num_fitting_bins < 3:\n        exploration_weight *= 0.8\n\n    # Create exploration scores. For simplicity here, we'll give a small boost\n    # to all fitting bins, meaning any fitting bin has a chance.\n    # A more advanced approach would use a UCB-like strategy.\n    exploration_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    exploration_scores[can_fit_mask] = exploration_weight / num_fitting_bins\n\n    # --- Final Priority: Blend Exploitation and Exploration ---\n    # A simple blending: priorities = exploitation_scores + exploration_scores\n    # This gives a base priority based on exploitation and adds a small chance\n    # to any fitting bin via exploration.\n    priorities[can_fit_mask] = normalized_exploitation_scores[can_fit_mask] + exploration_scores[can_fit_mask]\n\n    # Ensure no negative priorities and normalize the final output to [0, 1]\n    priorities = np.maximum(0, priorities)\n    max_final_priority = np.max(priorities)\n    if max_final_priority > 0:\n        priorities /= max_final_priority\n\n    return priorities\n\n[Heuristics 8th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines the tightness preference with an adaptive \"fill level\" bonus\n    and a sophisticated exploration strategy inspired by multi-armed bandits.\n    Prioritizes tight fits while encouraging the use of partially filled bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    # Mask for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    # If no bins can fit, return all zeros\n    if not np.any(can_fit_mask):\n        return priorities\n\n    # --- Exploitation Strategy: Combined Tightness and Fill Bonus ---\n\n    # Tightness score: Inverse of remaining capacity after packing. Higher is better.\n    # This favors bins that leave minimal slack.\n    tightness_score = np.zeros_like(bins_remain_cap, dtype=float)\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_packing = fitting_bins_remain_cap - item\n    tightness_score[can_fit_mask] = 1.0 / (remaining_after_packing + epsilon)\n\n    # Fill Level Bonus: Rewards bins that are already more utilized.\n    # We approximate utilization by penalizing bins with large remaining capacity.\n    # A simple inverse of the current remaining capacity (for fitting bins) serves as a bonus.\n    # This encourages using bins that are already partially filled, rather than always\n    # picking a \"tight fit\" in a nearly empty bin.\n    fill_bonus = np.zeros_like(bins_remain_cap, dtype=float)\n    # Bonus is higher for bins with less remaining capacity (i.e., more filled)\n    fill_bonus[can_fit_mask] = 1.0 / (fitting_bins_remain_cap + epsilon)\n\n    # Combine tightness and fill bonus. Multiplication allows the fill bonus to\n    # modulate the tightness score. A bin that is both tight and already somewhat full\n    # gets a higher combined score.\n    combined_exploitation_score = tightness_score * (1.0 + 0.3 * fill_bonus) # 0.3 is a tunable weight\n\n    # Normalize exploitation scores to the range [0, 1]\n    max_exploitation_score = np.max(combined_exploitation_score)\n    if max_exploitation_score > 0:\n        normalized_exploitation_scores = combined_exploitation_score / max_exploitation_score\n    else:\n        normalized_exploitation_scores = np.zeros_like(combined_exploitation_score)\n\n    # --- Exploration Strategy: Adaptive Exploration (Simplified Bandit-like) ---\n\n    # We want to explore bins that are currently less prioritized to discover\n    # potentially better packing options or to balance load.\n    # A simple adaptive strategy: If a bin has a low exploitation score,\n    # it's a candidate for exploration. We'll assign a small, uniform exploration\n    # priority to all bins that can fit the item. The degree of exploration\n    # can be tied to the number of available fitting bins.\n\n    num_fitting_bins = np.sum(can_fit_mask)\n    exploration_weight = 0.15 # Base weight for exploration\n\n    # Increase exploration tendency if there are many options, decrease if few\n    if num_fitting_bins > 5:\n        exploration_weight *= 1.2\n    elif num_fitting_bins < 3:\n        exploration_weight *= 0.8\n\n    # Create exploration scores. For simplicity here, we'll give a small boost\n    # to all fitting bins, meaning any fitting bin has a chance.\n    # A more advanced approach would use a UCB-like strategy.\n    exploration_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    exploration_scores[can_fit_mask] = exploration_weight / num_fitting_bins\n\n    # --- Final Priority: Blend Exploitation and Exploration ---\n    # A simple blending: priorities = exploitation_scores + exploration_scores\n    # This gives a base priority based on exploitation and adds a small chance\n    # to any fitting bin via exploration.\n    priorities[can_fit_mask] = normalized_exploitation_scores[can_fit_mask] + exploration_scores[can_fit_mask]\n\n    # Ensure no negative priorities and normalize the final output to [0, 1]\n    priorities = np.maximum(0, priorities)\n    max_final_priority = np.max(priorities)\n    if max_final_priority > 0:\n        priorities /= max_final_priority\n\n    return priorities\n\n[Heuristics 9th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with a utilization-aware exploration strategy.\n    Prioritizes tight fits and encourages exploration of less utilized bins.\n    \"\"\"\n    epsilon = 0.05  # Exploration probability\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    suitable_bins_mask = bins_remain_cap >= item\n    suitable_bins_indices = np.where(suitable_bins_mask)[0]\n\n    if suitable_bins_indices.size == 0:\n        return priorities\n\n    # Calculate a \"tightness\" score (how much space is left after packing)\n    tightness_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    if suitable_bins_indices.size > 0:\n        remaining_after_packing = bins_remain_cap[suitable_bins_indices] - item\n        # Higher score for smaller remaining capacity (tighter fit)\n        # Add a small constant to avoid division by zero and ensure positive scores\n        tightness_scores[suitable_bins_indices] = 1.0 / (remaining_after_packing + 1e-9)\n\n    # Calculate a \"utilization\" score (favoring bins that are already more full)\n    # We use the inverse of remaining capacity *before* packing.\n    utilization_scores = np.zeros_like(bins_remain_cap, dtype=float)\n    if suitable_bins_indices.size > 0:\n        # Higher score for less remaining capacity (more utilized bin)\n        utilization_scores[suitable_bins_indices] = 1.0 / (bins_remain_cap[suitable_bins_indices] + 1e-9)\n\n    # Combine scores: prioritize tightness, with a bonus for utilization\n    combined_scores = tightness_scores + 0.5 * utilization_scores # Weight utilization less than tightness\n\n    # Normalize scores for the suitable bins to a 0-1 range\n    suitable_scores = combined_scores[suitable_bins_indices]\n    if suitable_scores.size > 0:\n        max_score = np.max(suitable_scores)\n        if max_score > 0:\n            normalized_scores = suitable_scores / max_score\n            priorities[suitable_bins_indices] = normalized_scores\n\n    # Epsilon-greedy exploration: with probability epsilon, pick a random suitable bin\n    if np.random.rand() < epsilon:\n        chosen_bin_index = np.random.choice(suitable_bins_indices)\n        priorities = np.zeros_like(bins_remain_cap, dtype=float) # Reset priorities\n        priorities[chosen_bin_index] = 1.0 # Assign full priority to the random bin\n    else:\n        # Exploitation: Use the calculated priorities (based on combined scores)\n        # The `priorities` array already holds the normalized scores\n        pass \n\n    return priorities\n\n[Heuristics 10th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines tight-fit preference with adaptive bin utilization and dynamic exploration.\n    Prioritizes bins that minimize waste and are more utilized, with exploration\n    favoring less utilized bins based on a dynamically adjusted probability.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    # Mask for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    available_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    available_bin_indices = np.where(can_fit_mask)[0]\n\n    # --- Core Heuristic Components ---\n\n    # 1. Tight Fitting (Minimize Waste): Score is inverse of remaining space after packing.\n    remaining_after_packing = available_bins_remain_cap - item\n    tight_fit_scores = 1.0 / (remaining_after_packing + epsilon)\n\n    # 2. Adaptive Bin Utilization: Score based on how \"full\" the bin is.\n    # Prefer bins that have less remaining capacity relative to the item size.\n    # This can be approximated by `item / available_bins_remain_cap` or similar.\n    # Let's use a score that is higher for bins that are less empty (i.e., lower remaining capacity).\n    # A simple approach is `1.0 / (available_bins_remain_cap + epsilon)`.\n    # To make it more adaptive, we can consider the *average* remaining capacity of fitting bins.\n    avg_fitting_remain_cap = np.mean(available_bins_remain_cap) if available_bins_remain_cap.size > 0 else 1.0\n    # Prefer bins with remaining capacity closer to the item or lower than average.\n    # Let's try a score that is high when remaining capacity is low (closer to item).\n    utilization_scores = 1.0 / (available_bins_remain_cap + epsilon)\n\n    # Combine the two heuristic scores. A weighted sum is a common approach.\n    # Let's give equal weight for now.\n    combined_core_scores = 0.5 * tight_fit_scores + 0.5 * utilization_scores\n\n    # Normalize core scores to be between 0 and 1.\n    max_core_score = np.max(combined_core_scores)\n    if max_core_score > epsilon:\n        normalized_core_scores = combined_core_scores / max_core_score\n    else:\n        normalized_core_scores = np.zeros_like(combined_core_scores)\n\n    # --- Dynamic Epsilon-Greedy Exploration ---\n    num_available_bins = available_bins_remain_cap.size\n\n    # Determine exploration probability adaptively.\n    # A common strategy is to increase exploration when there are many bins,\n    # to encourage trying out different options. Or, explore less if bins are very full.\n    # Let's use a simple inverse relationship with the number of available bins to explore more\n    # when there are fewer options, which can be counter-intuitive.\n    # A better approach: explore more when there are *many* bins to choose from, to diversify.\n    # Or, explore less when bins are already quite full, and more when they are mostly empty.\n\n    # A simple dynamic probability: decrease exploration as the number of available bins decreases.\n    # Or, use the inverse of the average utilization as a proxy for how \"challenging\" the packing is.\n    # Let's use a probability that decreases with the tightness of the fit (smaller remaining_after_packing).\n    # This means we explore more when the fits are not tight.\n    \n    # Heuristic from analysis: dynamic exploration favoring less utilized bins.\n    # We want to explore bins that are NOT among the top-ranked by core heuristics.\n    # The probability of exploration for a bin could be inversely related to its normalized core score.\n\n    # Simple dynamic exploration probability: higher when many bins, lower when few.\n    # Or, a fixed probability for simplicity if dynamic is too complex to implement robustly here.\n    # Given the prompt's goal of combining elements, let's use a fixed epsilon-greedy\n    # but slightly modified based on utilization to influence *which* bins are explored.\n\n    exploration_prob = 0.15 # Base exploration probability\n\n    # We want to assign exploration scores to a subset of bins.\n    # Instead of random scores, let's boost scores of bins that are less utilized.\n    # A simple way to select bins for \"exploration\" (or a modified score):\n    # bins with higher `utilization_scores` (meaning they are more utilized)\n    # should be less likely to be perturbed by random exploration.\n    # So, bins with lower `utilization_scores` are more prone to exploration.\n\n    # Create a probability mask for exploration, favoring less utilized bins.\n    # Let's sort bins by utilization_scores (ascending) and pick a fraction.\n    # A simple approach: assign a higher 'random' score to bins that are less utilized.\n    \n    # Let's stick to a blended approach inspired by Heuristic 11, where exploration\n    # contributes to the final score.\n    \n    # For the exploration component, we can generate random scores.\n    # To bias exploration towards less utilized bins, we can scale these random scores.\n    # If `utilization_scores` is low (meaning bin is less utilized), we want a higher random score.\n    # We can achieve this by multiplying `random_scores` by `(1.0 / (utilization_scores + epsilon))`.\n    \n    random_exploration_scores = np.random.rand(num_available_bins)\n    \n    # Scale random scores: boost scores for less utilized bins (low utilization_scores).\n    # Higher `boost_factor` means more boost for less utilized bins.\n    boost_factor = 2.0 # Control how much less utilized bins are favored in exploration\n    scaled_random_scores = random_exploration_scores * (1.0 + boost_factor * (1.0 - utilization_scores))\n    \n    # Normalize these scaled random scores to keep them in a comparable range.\n    max_scaled_random_score = np.max(scaled_random_scores)\n    if max_scaled_random_score > epsilon:\n        normalized_exploration_scores = scaled_random_scores / max_scaled_random_score\n    else:\n        normalized_exploration_scores = np.zeros_like(scaled_random_scores)\n\n    # Blend the deterministic (core) scores with the exploration scores.\n    # Use the `exploration_prob` to decide the mixing weight.\n    alpha = exploration_prob\n    final_scores = (1 - alpha) * normalized_core_scores + alpha * normalized_exploration_scores\n\n    # Re-normalize the final blended scores to ensure they are in a 0-1 range.\n    max_final_score = np.max(final_scores)\n    if max_final_score > epsilon:\n        priorities[can_fit_mask] = final_scores / max_final_score\n    else:\n        # Fallback if all scores are zero or near-zero\n        priorities[can_fit_mask] = final_scores\n\n    # Ensure priorities are non-negative.\n    priorities[priorities < 0] = 0\n\n    return priorities\n\n[Heuristics 11th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines tight-fit preference with adaptive bin utilization and dynamic exploration.\n    Prioritizes bins that minimize waste and are more utilized, with exploration\n    favoring less utilized bins based on a dynamically adjusted probability.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    # Mask for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    available_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    available_bin_indices = np.where(can_fit_mask)[0]\n\n    # --- Core Heuristic Components ---\n\n    # 1. Tight Fitting (Minimize Waste): Score is inverse of remaining space after packing.\n    remaining_after_packing = available_bins_remain_cap - item\n    tight_fit_scores = 1.0 / (remaining_after_packing + epsilon)\n\n    # 2. Adaptive Bin Utilization: Score based on how \"full\" the bin is.\n    # Prefer bins that have less remaining capacity relative to the item size.\n    # This can be approximated by `item / available_bins_remain_cap` or similar.\n    # Let's use a score that is higher for bins that are less empty (i.e., lower remaining capacity).\n    # A simple approach is `1.0 / (available_bins_remain_cap + epsilon)`.\n    # To make it more adaptive, we can consider the *average* remaining capacity of fitting bins.\n    avg_fitting_remain_cap = np.mean(available_bins_remain_cap) if available_bins_remain_cap.size > 0 else 1.0\n    # Prefer bins with remaining capacity closer to the item or lower than average.\n    # Let's try a score that is high when remaining capacity is low (closer to item).\n    utilization_scores = 1.0 / (available_bins_remain_cap + epsilon)\n\n    # Combine the two heuristic scores. A weighted sum is a common approach.\n    # Let's give equal weight for now.\n    combined_core_scores = 0.5 * tight_fit_scores + 0.5 * utilization_scores\n\n    # Normalize core scores to be between 0 and 1.\n    max_core_score = np.max(combined_core_scores)\n    if max_core_score > epsilon:\n        normalized_core_scores = combined_core_scores / max_core_score\n    else:\n        normalized_core_scores = np.zeros_like(combined_core_scores)\n\n    # --- Dynamic Epsilon-Greedy Exploration ---\n    num_available_bins = available_bins_remain_cap.size\n\n    # Determine exploration probability adaptively.\n    # A common strategy is to increase exploration when there are many bins,\n    # to encourage trying out different options. Or, explore less if bins are very full.\n    # Let's use a simple inverse relationship with the number of available bins to explore more\n    # when there are fewer options, which can be counter-intuitive.\n    # A better approach: explore more when there are *many* bins to choose from, to diversify.\n    # Or, explore less when bins are already quite full, and more when they are mostly empty.\n\n    # A simple dynamic probability: decrease exploration as the number of available bins decreases.\n    # Or, use the inverse of the average utilization as a proxy for how \"challenging\" the packing is.\n    # Let's use a probability that decreases with the tightness of the fit (smaller remaining_after_packing).\n    # This means we explore more when the fits are not tight.\n    \n    # Heuristic from analysis: dynamic exploration favoring less utilized bins.\n    # We want to explore bins that are NOT among the top-ranked by core heuristics.\n    # The probability of exploration for a bin could be inversely related to its normalized core score.\n\n    # Simple dynamic exploration probability: higher when many bins, lower when few.\n    # Or, a fixed probability for simplicity if dynamic is too complex to implement robustly here.\n    # Given the prompt's goal of combining elements, let's use a fixed epsilon-greedy\n    # but slightly modified based on utilization to influence *which* bins are explored.\n\n    exploration_prob = 0.15 # Base exploration probability\n\n    # We want to assign exploration scores to a subset of bins.\n    # Instead of random scores, let's boost scores of bins that are less utilized.\n    # A simple way to select bins for \"exploration\" (or a modified score):\n    # bins with higher `utilization_scores` (meaning they are more utilized)\n    # should be less likely to be perturbed by random exploration.\n    # So, bins with lower `utilization_scores` are more prone to exploration.\n\n    # Create a probability mask for exploration, favoring less utilized bins.\n    # Let's sort bins by utilization_scores (ascending) and pick a fraction.\n    # A simple approach: assign a higher 'random' score to bins that are less utilized.\n    \n    # Let's stick to a blended approach inspired by Heuristic 11, where exploration\n    # contributes to the final score.\n    \n    # For the exploration component, we can generate random scores.\n    # To bias exploration towards less utilized bins, we can scale these random scores.\n    # If `utilization_scores` is low (meaning bin is less utilized), we want a higher random score.\n    # We can achieve this by multiplying `random_scores` by `(1.0 / (utilization_scores + epsilon))`.\n    \n    random_exploration_scores = np.random.rand(num_available_bins)\n    \n    # Scale random scores: boost scores for less utilized bins (low utilization_scores).\n    # Higher `boost_factor` means more boost for less utilized bins.\n    boost_factor = 2.0 # Control how much less utilized bins are favored in exploration\n    scaled_random_scores = random_exploration_scores * (1.0 + boost_factor * (1.0 - utilization_scores))\n    \n    # Normalize these scaled random scores to keep them in a comparable range.\n    max_scaled_random_score = np.max(scaled_random_scores)\n    if max_scaled_random_score > epsilon:\n        normalized_exploration_scores = scaled_random_scores / max_scaled_random_score\n    else:\n        normalized_exploration_scores = np.zeros_like(scaled_random_scores)\n\n    # Blend the deterministic (core) scores with the exploration scores.\n    # Use the `exploration_prob` to decide the mixing weight.\n    alpha = exploration_prob\n    final_scores = (1 - alpha) * normalized_core_scores + alpha * normalized_exploration_scores\n\n    # Re-normalize the final blended scores to ensure they are in a 0-1 range.\n    max_final_score = np.max(final_scores)\n    if max_final_score > epsilon:\n        priorities[can_fit_mask] = final_scores / max_final_score\n    else:\n        # Fallback if all scores are zero or near-zero\n        priorities[can_fit_mask] = final_scores\n\n    # Ensure priorities are non-negative.\n    priorities[priorities < 0] = 0\n\n    return priorities\n\n[Heuristics 12th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines tightest fit with a utilization bonus and an adaptive exploration strategy.\n    Favors bins that result in minimal slack after packing, with a bonus for bins\n    that are already partially filled, and a probabilistic chance to explore less-used bins.\n    \"\"\"\n    epsilon = 1e-9\n    exploration_prob = 0.1\n\n    # Mask for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    # --- Component 1: Tightest Fit ---\n    # Prioritize bins that leave minimal remaining capacity after packing (minimize slack).\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_packing = fitting_bins_remain_cap - item\n    # Score is inverse of slack; higher score for smaller slack.\n    tightness_score = 1.0 / (remaining_after_packing + epsilon)\n\n    # --- Component 2: Utilization Bonus ---\n    # Prefer bins that are already partially filled.\n    # A simple proxy for utilization: higher score for bins with less remaining capacity.\n    # This encourages using bins that are already in use.\n    # Score is inverse of remaining capacity *before* packing.\n    utilization_bonus = 1.0 / (fitting_bins_remain_cap + epsilon)\n\n    # --- Combining Exploitation Scores ---\n    # Combine tightness and utilization bonus. A weighted sum is used.\n    # Tightness is the primary driver, utilization adds a bonus.\n    # We normalize the utilization bonus to prevent it from overpowering the tightness score.\n    # A simple normalization: divide by the maximum possible utilization score (1/epsilon if a bin is empty).\n    # A more stable approach: normalize by the maximum utilization bonus among fitting bins.\n    max_utilization_bonus = np.max(utilization_bonus)\n    normalized_utilization_bonus = utilization_bonus / (max_utilization_bonus + epsilon)\n\n    # The combined exploitation score weighs tightness more heavily.\n    exploitation_score = tightness_score + 0.3 * normalized_utilization_bonus\n\n    # Normalize exploitation scores to be between 0 and 1\n    max_exploitation_score = np.max(exploitation_score)\n    if max_exploitation_score > epsilon:\n        normalized_exploitation_scores = exploitation_score / max_exploitation_score\n    else:\n        normalized_exploitation_scores = np.zeros_like(exploitation_score)\n\n    # --- Component 3: Adaptive Exploration (Epsilon-Greedy) ---\n    # Introduce a small probability to explore less optimal bins.\n    num_fitting_bins = len(fitting_bins_remain_cap)\n    exploration_scores = np.zeros_like(normalized_exploitation_scores)\n\n    # Determine how many bins to \"explore\"\n    num_to_explore = int(np.floor(exploration_prob * num_fitting_bins))\n\n    if num_to_explore > 0:\n        # Select random indices for exploration\n        explore_indices = np.random.choice(num_fitting_bins, size=num_to_explore, replace=False)\n        # Give explored bins a baseline high priority, slightly boosted to ensure consideration.\n        # This ensures some randomness without completely overriding good exploitation choices.\n        exploration_scores[explore_indices] = 0.5\n\n    # --- Final Priority Calculation ---\n    # Combine exploitation scores with exploration scores.\n    # The exploration scores add a boost to randomly selected bins.\n    final_scores_unnormalized = normalized_exploitation_scores + exploration_scores\n\n    # Normalize final scores so that the highest priority is 1.0.\n    max_final_score = np.max(final_scores_unnormalized)\n    if max_final_score > epsilon:\n        priorities[can_fit_mask] = final_scores_unnormalized / max_final_score\n    else:\n        # Fallback: if all scores are near zero, assign uniform probability to fitting bins.\n        priorities[can_fit_mask] = 1.0 / num_fitting_bins\n\n    return priorities\n\n[Heuristics 13th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines tightest fit with a utilization bonus and an adaptive exploration strategy.\n    Favors bins that result in minimal slack after packing, with a bonus for bins\n    that are already partially filled, and a probabilistic chance to explore less-used bins.\n    \"\"\"\n    epsilon = 1e-9\n    exploration_prob = 0.1\n\n    # Mask for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    # --- Component 1: Tightest Fit ---\n    # Prioritize bins that leave minimal remaining capacity after packing (minimize slack).\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_packing = fitting_bins_remain_cap - item\n    # Score is inverse of slack; higher score for smaller slack.\n    tightness_score = 1.0 / (remaining_after_packing + epsilon)\n\n    # --- Component 2: Utilization Bonus ---\n    # Prefer bins that are already partially filled.\n    # A simple proxy for utilization: higher score for bins with less remaining capacity.\n    # This encourages using bins that are already in use.\n    # Score is inverse of remaining capacity *before* packing.\n    utilization_bonus = 1.0 / (fitting_bins_remain_cap + epsilon)\n\n    # --- Combining Exploitation Scores ---\n    # Combine tightness and utilization bonus. A weighted sum is used.\n    # Tightness is the primary driver, utilization adds a bonus.\n    # We normalize the utilization bonus to prevent it from overpowering the tightness score.\n    # A simple normalization: divide by the maximum possible utilization score (1/epsilon if a bin is empty).\n    # A more stable approach: normalize by the maximum utilization bonus among fitting bins.\n    max_utilization_bonus = np.max(utilization_bonus)\n    normalized_utilization_bonus = utilization_bonus / (max_utilization_bonus + epsilon)\n\n    # The combined exploitation score weighs tightness more heavily.\n    exploitation_score = tightness_score + 0.3 * normalized_utilization_bonus\n\n    # Normalize exploitation scores to be between 0 and 1\n    max_exploitation_score = np.max(exploitation_score)\n    if max_exploitation_score > epsilon:\n        normalized_exploitation_scores = exploitation_score / max_exploitation_score\n    else:\n        normalized_exploitation_scores = np.zeros_like(exploitation_score)\n\n    # --- Component 3: Adaptive Exploration (Epsilon-Greedy) ---\n    # Introduce a small probability to explore less optimal bins.\n    num_fitting_bins = len(fitting_bins_remain_cap)\n    exploration_scores = np.zeros_like(normalized_exploitation_scores)\n\n    # Determine how many bins to \"explore\"\n    num_to_explore = int(np.floor(exploration_prob * num_fitting_bins))\n\n    if num_to_explore > 0:\n        # Select random indices for exploration\n        explore_indices = np.random.choice(num_fitting_bins, size=num_to_explore, replace=False)\n        # Give explored bins a baseline high priority, slightly boosted to ensure consideration.\n        # This ensures some randomness without completely overriding good exploitation choices.\n        exploration_scores[explore_indices] = 0.5\n\n    # --- Final Priority Calculation ---\n    # Combine exploitation scores with exploration scores.\n    # The exploration scores add a boost to randomly selected bins.\n    final_scores_unnormalized = normalized_exploitation_scores + exploration_scores\n\n    # Normalize final scores so that the highest priority is 1.0.\n    max_final_score = np.max(final_scores_unnormalized)\n    if max_final_score > epsilon:\n        priorities[can_fit_mask] = final_scores_unnormalized / max_final_score\n    else:\n        # Fallback: if all scores are near zero, assign uniform probability to fitting bins.\n        priorities[can_fit_mask] = 1.0 / num_fitting_bins\n\n    return priorities\n\n[Heuristics 14th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 0.4564181975005053, exploration_factor: float = 0.9106476870042141, tight_fit_weight: float = 0.7574395180925119, utilization_weight: float = 0.24567190977130593) -> np.ndarray:\n    \"\"\"\n    Combines tightest fit with a penalty for under-utilized bins,\n    using a novel exploration strategy to balance exploitation and exploration.\n    \"\"\"\n\n    # Mask for bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n[Heuristics 15th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 0.4564181975005053, exploration_factor: float = 0.9106476870042141, tight_fit_weight: float = 0.7574395180925119, utilization_weight: float = 0.24567190977130593) -> np.ndarray:\n    \"\"\"\n    Combines tightest fit with a penalty for under-utilized bins,\n    using a novel exploration strategy to balance exploitation and exploration.\n    \"\"\"\n\n    # Mask for bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n[Heuristics 16th]\nimport numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray, epsilon: float = 0.4564181975005053, exploration_factor: float = 0.9106476870042141, tight_fit_weight: float = 0.7574395180925119, utilization_weight: float = 0.24567190977130593) -> np.ndarray:\n    \"\"\"\n    Combines tightest fit with a penalty for under-utilized bins,\n    using a novel exploration strategy to balance exploitation and exploration.\n    \"\"\"\n\n    # Mask for bins that can accommodate the item\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n[Heuristics 17th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines tightest fit with a utilization bonus and adaptive exploration.\n    Favors bins that minimize remaining space, offering a bonus for less utilized bins,\n    and strategically explores less optimal bins.\n    \"\"\"\n    epsilon = 1e-9\n    exploration_prob = 0.15  # Slightly higher exploration to balance\n\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    valid_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    # --- Heuristic Component 1: Tightest Fit ---\n    # Prioritize bins that leave minimal remaining capacity after packing.\n    remaining_after_packing = valid_bins_remain_cap - item\n    tight_fit_scores = 1.0 / (remaining_after_packing + epsilon)\n\n    # --- Heuristic Component 2: Utilization Bonus ---\n    # Prefer bins that are currently less utilized (more empty space).\n    # This encourages spreading items across more bins initially.\n    # A simple score: higher for bins with less current remaining capacity.\n    # Using a base of 1 to avoid making already partially full bins *too* dominant.\n    fill_score_bonus = 0.3 * (1.0 / (valid_bins_remain_cap + epsilon))\n    \n    # Combine tightness and utilization bonus: multiplicative effect\n    # This rewards bins that are both tight and already have some items\n    combined_exploitation_scores = tight_fit_scores * (1.0 + fill_score_bonus)\n\n    # Normalize exploitation scores to be between 0 and 1\n    max_exploitation_score = np.max(combined_exploitation_scores)\n    if max_exploitation_score > epsilon:\n        normalized_exploitation_scores = combined_exploitation_scores / max_exploitation_score\n    else:\n        normalized_exploitation_scores = np.zeros_like(combined_exploitation_scores)\n\n    # --- Adaptive Exploration ---\n    # With a certain probability, give a boost to randomly selected fitting bins\n    # to explore less optimal choices and avoid getting stuck in local optima.\n    num_fitting_bins = len(valid_bins_remain_cap)\n    exploration_boost = np.zeros_like(normalized_exploitation_scores)\n    \n    # Determine how many bins to \"boost\" for exploration\n    num_to_explore = max(1, int(np.floor(exploration_prob * num_fitting_bins))) # Ensure at least one bin is explored if possible\n    \n    # Select indices to explore randomly from the fitting bins\n    # Using np.random.choice with replace=False to ensure unique bins are selected for exploration boost\n    explore_indices = np.random.choice(num_fitting_bins, size=num_to_explore, replace=False)\n    \n    # Assign a uniform high exploration score to these bins, relative to the normalized exploitation scores.\n    # This ensures exploration bins are considered, but their exact priority is context-dependent on overall exploitation scores.\n    exploration_boost[explore_indices] = 1.0 \n\n    # --- Final Priority Calculation ---\n    # Combine exploitation and exploration scores.\n    # Adding exploration boost means these bins will have a higher chance of selection.\n    # The `1 - exploration_prob` for exploitation is implicitly handled by not boosting all bins.\n    final_scores_unnormalized = normalized_exploitation_scores + exploration_boost\n    \n    # Ensure all priorities are non-negative and normalize them for the fitting bins\n    final_scores_unnormalized[final_scores_unnormalized < 0] = 0\n    sum_final_scores = np.sum(final_scores_unnormalized)\n    \n    if sum_final_scores > epsilon:\n        priorities[can_fit_mask] = final_scores_unnormalized / sum_final_scores\n    else:\n        # Fallback to uniform probability if all scores are zero (e.g., due to epsilon issues)\n        priorities[can_fit_mask] = 1.0 / num_fitting_bins\n        \n    return priorities\n\n[Heuristics 18th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines tightest fit with a utilization bonus and adaptive exploration.\n    Favors bins that minimize remaining space, offering a bonus for less utilized bins,\n    and strategically explores less optimal bins.\n    \"\"\"\n    epsilon = 1e-9\n    exploration_prob = 0.15  # Slightly higher exploration to balance\n\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    valid_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    # --- Heuristic Component 1: Tightest Fit ---\n    # Prioritize bins that leave minimal remaining capacity after packing.\n    remaining_after_packing = valid_bins_remain_cap - item\n    tight_fit_scores = 1.0 / (remaining_after_packing + epsilon)\n\n    # --- Heuristic Component 2: Utilization Bonus ---\n    # Prefer bins that are currently less utilized (more empty space).\n    # This encourages spreading items across more bins initially.\n    # A simple score: higher for bins with less current remaining capacity.\n    # Using a base of 1 to avoid making already partially full bins *too* dominant.\n    fill_score_bonus = 0.3 * (1.0 / (valid_bins_remain_cap + epsilon))\n    \n    # Combine tightness and utilization bonus: multiplicative effect\n    # This rewards bins that are both tight and already have some items\n    combined_exploitation_scores = tight_fit_scores * (1.0 + fill_score_bonus)\n\n    # Normalize exploitation scores to be between 0 and 1\n    max_exploitation_score = np.max(combined_exploitation_scores)\n    if max_exploitation_score > epsilon:\n        normalized_exploitation_scores = combined_exploitation_scores / max_exploitation_score\n    else:\n        normalized_exploitation_scores = np.zeros_like(combined_exploitation_scores)\n\n    # --- Adaptive Exploration ---\n    # With a certain probability, give a boost to randomly selected fitting bins\n    # to explore less optimal choices and avoid getting stuck in local optima.\n    num_fitting_bins = len(valid_bins_remain_cap)\n    exploration_boost = np.zeros_like(normalized_exploitation_scores)\n    \n    # Determine how many bins to \"boost\" for exploration\n    num_to_explore = max(1, int(np.floor(exploration_prob * num_fitting_bins))) # Ensure at least one bin is explored if possible\n    \n    # Select indices to explore randomly from the fitting bins\n    # Using np.random.choice with replace=False to ensure unique bins are selected for exploration boost\n    explore_indices = np.random.choice(num_fitting_bins, size=num_to_explore, replace=False)\n    \n    # Assign a uniform high exploration score to these bins, relative to the normalized exploitation scores.\n    # This ensures exploration bins are considered, but their exact priority is context-dependent on overall exploitation scores.\n    exploration_boost[explore_indices] = 1.0 \n\n    # --- Final Priority Calculation ---\n    # Combine exploitation and exploration scores.\n    # Adding exploration boost means these bins will have a higher chance of selection.\n    # The `1 - exploration_prob` for exploitation is implicitly handled by not boosting all bins.\n    final_scores_unnormalized = normalized_exploitation_scores + exploration_boost\n    \n    # Ensure all priorities are non-negative and normalize them for the fitting bins\n    final_scores_unnormalized[final_scores_unnormalized < 0] = 0\n    sum_final_scores = np.sum(final_scores_unnormalized)\n    \n    if sum_final_scores > epsilon:\n        priorities[can_fit_mask] = final_scores_unnormalized / sum_final_scores\n    else:\n        # Fallback to uniform probability if all scores are zero (e.g., due to epsilon issues)\n        priorities[can_fit_mask] = 1.0 / num_fitting_bins\n        \n    return priorities\n\n[Heuristics 19th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines tightest fit with a utilization bonus and adaptive exploration.\n    Favors bins that minimize remaining space, offering a bonus for less utilized bins,\n    and strategically explores less optimal bins.\n    \"\"\"\n    epsilon = 1e-9\n    exploration_prob = 0.15  # Slightly higher exploration to balance\n\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    valid_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    # --- Heuristic Component 1: Tightest Fit ---\n    # Prioritize bins that leave minimal remaining capacity after packing.\n    remaining_after_packing = valid_bins_remain_cap - item\n    tight_fit_scores = 1.0 / (remaining_after_packing + epsilon)\n\n    # --- Heuristic Component 2: Utilization Bonus ---\n    # Prefer bins that are currently less utilized (more empty space).\n    # This encourages spreading items across more bins initially.\n    # A simple score: higher for bins with less current remaining capacity.\n    # Using a base of 1 to avoid making already partially full bins *too* dominant.\n    fill_score_bonus = 0.3 * (1.0 / (valid_bins_remain_cap + epsilon))\n    \n    # Combine tightness and utilization bonus: multiplicative effect\n    # This rewards bins that are both tight and already have some items\n    combined_exploitation_scores = tight_fit_scores * (1.0 + fill_score_bonus)\n\n    # Normalize exploitation scores to be between 0 and 1\n    max_exploitation_score = np.max(combined_exploitation_scores)\n    if max_exploitation_score > epsilon:\n        normalized_exploitation_scores = combined_exploitation_scores / max_exploitation_score\n    else:\n        normalized_exploitation_scores = np.zeros_like(combined_exploitation_scores)\n\n    # --- Adaptive Exploration ---\n    # With a certain probability, give a boost to randomly selected fitting bins\n    # to explore less optimal choices and avoid getting stuck in local optima.\n    num_fitting_bins = len(valid_bins_remain_cap)\n    exploration_boost = np.zeros_like(normalized_exploitation_scores)\n    \n    # Determine how many bins to \"boost\" for exploration\n    num_to_explore = max(1, int(np.floor(exploration_prob * num_fitting_bins))) # Ensure at least one bin is explored if possible\n    \n    # Select indices to explore randomly from the fitting bins\n    # Using np.random.choice with replace=False to ensure unique bins are selected for exploration boost\n    explore_indices = np.random.choice(num_fitting_bins, size=num_to_explore, replace=False)\n    \n    # Assign a uniform high exploration score to these bins, relative to the normalized exploitation scores.\n    # This ensures exploration bins are considered, but their exact priority is context-dependent on overall exploitation scores.\n    exploration_boost[explore_indices] = 1.0 \n\n    # --- Final Priority Calculation ---\n    # Combine exploitation and exploration scores.\n    # Adding exploration boost means these bins will have a higher chance of selection.\n    # The `1 - exploration_prob` for exploitation is implicitly handled by not boosting all bins.\n    final_scores_unnormalized = normalized_exploitation_scores + exploration_boost\n    \n    # Ensure all priorities are non-negative and normalize them for the fitting bins\n    final_scores_unnormalized[final_scores_unnormalized < 0] = 0\n    sum_final_scores = np.sum(final_scores_unnormalized)\n    \n    if sum_final_scores > epsilon:\n        priorities[can_fit_mask] = final_scores_unnormalized / sum_final_scores\n    else:\n        # Fallback to uniform probability if all scores are zero (e.g., due to epsilon issues)\n        priorities[can_fit_mask] = 1.0 / num_fitting_bins\n        \n    return priorities\n\n[Heuristics 20th]\nimport numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines tightest fit with a utilization bonus and adaptive exploration.\n    Favors bins that minimize remaining space, offering a bonus for less utilized bins,\n    and strategically explores less optimal bins.\n    \"\"\"\n    epsilon = 1e-9\n    exploration_prob = 0.15  # Slightly higher exploration to balance\n\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    valid_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    # --- Heuristic Component 1: Tightest Fit ---\n    # Prioritize bins that leave minimal remaining capacity after packing.\n    remaining_after_packing = valid_bins_remain_cap - item\n    tight_fit_scores = 1.0 / (remaining_after_packing + epsilon)\n\n    # --- Heuristic Component 2: Utilization Bonus ---\n    # Prefer bins that are currently less utilized (more empty space).\n    # This encourages spreading items across more bins initially.\n    # A simple score: higher for bins with less current remaining capacity.\n    # Using a base of 1 to avoid making already partially full bins *too* dominant.\n    fill_score_bonus = 0.3 * (1.0 / (valid_bins_remain_cap + epsilon))\n    \n    # Combine tightness and utilization bonus: multiplicative effect\n    # This rewards bins that are both tight and already have some items\n    combined_exploitation_scores = tight_fit_scores * (1.0 + fill_score_bonus)\n\n    # Normalize exploitation scores to be between 0 and 1\n    max_exploitation_score = np.max(combined_exploitation_scores)\n    if max_exploitation_score > epsilon:\n        normalized_exploitation_scores = combined_exploitation_scores / max_exploitation_score\n    else:\n        normalized_exploitation_scores = np.zeros_like(combined_exploitation_scores)\n\n    # --- Adaptive Exploration ---\n    # With a certain probability, give a boost to randomly selected fitting bins\n    # to explore less optimal choices and avoid getting stuck in local optima.\n    num_fitting_bins = len(valid_bins_remain_cap)\n    exploration_boost = np.zeros_like(normalized_exploitation_scores)\n    \n    # Determine how many bins to \"boost\" for exploration\n    num_to_explore = max(1, int(np.floor(exploration_prob * num_fitting_bins))) # Ensure at least one bin is explored if possible\n    \n    # Select indices to explore randomly from the fitting bins\n    # Using np.random.choice with replace=False to ensure unique bins are selected for exploration boost\n    explore_indices = np.random.choice(num_fitting_bins, size=num_to_explore, replace=False)\n    \n    # Assign a uniform high exploration score to these bins, relative to the normalized exploitation scores.\n    # This ensures exploration bins are considered, but their exact priority is context-dependent on overall exploitation scores.\n    exploration_boost[explore_indices] = 1.0 \n\n    # --- Final Priority Calculation ---\n    # Combine exploitation and exploration scores.\n    # Adding exploration boost means these bins will have a higher chance of selection.\n    # The `1 - exploration_prob` for exploitation is implicitly handled by not boosting all bins.\n    final_scores_unnormalized = normalized_exploitation_scores + exploration_boost\n    \n    # Ensure all priorities are non-negative and normalize them for the fitting bins\n    final_scores_unnormalized[final_scores_unnormalized < 0] = 0\n    sum_final_scores = np.sum(final_scores_unnormalized)\n    \n    if sum_final_scores > epsilon:\n        priorities[can_fit_mask] = final_scores_unnormalized / sum_final_scores\n    else:\n        # Fallback to uniform probability if all scores are zero (e.g., due to epsilon issues)\n        priorities[can_fit_mask] = 1.0 / num_fitting_bins\n        \n    return priorities\n\n\n### Guide\n- Keep in mind, list of design heuristics ranked from best to worst. Meaning the first function in the list is the best and the last function in the list is the worst.\n- The response in Markdown style and nothing else has the following structure:\n\"**Analysis:**\n**Experience:**\"\nIn there:\n+ Meticulously analyze comments, docstrings and source code of several pairs (Better code - Worse code) in List heuristics to fill values for **Analysis:**.\nExample: \"Comparing (best) vs (worst), we see ...;  (second best) vs (second worst) ...; Comparing (1st) vs (2nd), we see ...; (3rd) vs (4th) ...; Comparing (second worst) vs (worst), we see ...; Overall:\"\n\n+ Self-reflect to extract useful experience for design better heuristics and fill to **Experience:** (<60 words).\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}