{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines tight-fit preference with adaptive penalty for large bins,\n    favoring bins that are neither too full nor too empty relative to item size.\n    Uses score normalization for robust comparison.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n\n    # Tightness score: Higher for bins leaving less space after packing.\n    # This is equivalent to prioritizing bins closer to 'item' size from below.\n    tightness_score = 1.0 / (fitting_bins_remain_cap - item + epsilon)\n\n    # Adaptive penalty for \"empty\" or overly large bins:\n    # Penalize bins whose remaining capacity is significantly larger than the item size.\n    # We want to reduce the priority of bins that are \"too empty\" for the current item.\n    # A simple way is to use an inverse relationship with the initial remaining capacity.\n    # The factor penalizes bins with large remaining capacities, favoring those already somewhat utilized.\n    # This is analogous to prioritizing bins that are not \"too empty\".\n    penalty_weight = 0.3\n    penalty_score = 1.0 / (1.0 + penalty_weight * fitting_bins_remain_cap)\n\n    # Combine tightness and penalty. A higher combined score means a bin is both a tight fit\n    # and not excessively large (i.e., not \"too empty\").\n    combined_score = tightness_score * penalty_score\n\n    # Normalize scores to a 0-1 range for stable comparison across different item/bin states.\n    max_score = np.max(combined_score)\n    if max_score > 0:\n        priorities[can_fit_mask] = combined_score / max_score\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines tightest fit with a utilization bonus and an adaptive exploration strategy.\n    Favors bins that result in minimal slack after packing, with a bonus for bins\n    that are already partially filled, and a probabilistic chance to explore less-used bins.\n    \"\"\"\n    epsilon = 1e-9\n    exploration_prob = 0.1\n\n    # Mask for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if not np.any(can_fit_mask):\n        return priorities  # No bin can fit the item\n\n    # --- Component 1: Tightest Fit ---\n    # Prioritize bins that leave minimal remaining capacity after packing (minimize slack).\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    remaining_after_packing = fitting_bins_remain_cap - item\n    # Score is inverse of slack; higher score for smaller slack.\n    tightness_score = 1.0 / (remaining_after_packing + epsilon)\n\n    # --- Component 2: Utilization Bonus ---\n    # Prefer bins that are already partially filled.\n    # A simple proxy for utilization: higher score for bins with less remaining capacity.\n    # This encourages using bins that are already in use.\n    # Score is inverse of remaining capacity *before* packing.\n    utilization_bonus = 1.0 / (fitting_bins_remain_cap + epsilon)\n\n    # --- Combining Exploitation Scores ---\n    # Combine tightness and utilization bonus. A weighted sum is used.\n    # Tightness is the primary driver, utilization adds a bonus.\n    # We normalize the utilization bonus to prevent it from overpowering the tightness score.\n    # A simple normalization: divide by the maximum possible utilization score (1/epsilon if a bin is empty).\n    # A more stable approach: normalize by the maximum utilization bonus among fitting bins.\n    max_utilization_bonus = np.max(utilization_bonus)\n    normalized_utilization_bonus = utilization_bonus / (max_utilization_bonus + epsilon)\n\n    # The combined exploitation score weighs tightness more heavily.\n    exploitation_score = tightness_score + 0.3 * normalized_utilization_bonus\n\n    # Normalize exploitation scores to be between 0 and 1\n    max_exploitation_score = np.max(exploitation_score)\n    if max_exploitation_score > epsilon:\n        normalized_exploitation_scores = exploitation_score / max_exploitation_score\n    else:\n        normalized_exploitation_scores = np.zeros_like(exploitation_score)\n\n    # --- Component 3: Adaptive Exploration (Epsilon-Greedy) ---\n    # Introduce a small probability to explore less optimal bins.\n    num_fitting_bins = len(fitting_bins_remain_cap)\n    exploration_scores = np.zeros_like(normalized_exploitation_scores)\n\n    # Determine how many bins to \"explore\"\n    num_to_explore = int(np.floor(exploration_prob * num_fitting_bins))\n\n    if num_to_explore > 0:\n        # Select random indices for exploration\n        explore_indices = np.random.choice(num_fitting_bins, size=num_to_explore, replace=False)\n        # Give explored bins a baseline high priority, slightly boosted to ensure consideration.\n        # This ensures some randomness without completely overriding good exploitation choices.\n        exploration_scores[explore_indices] = 0.5\n\n    # --- Final Priority Calculation ---\n    # Combine exploitation scores with exploration scores.\n    # The exploration scores add a boost to randomly selected bins.\n    final_scores_unnormalized = normalized_exploitation_scores + exploration_scores\n\n    # Normalize final scores so that the highest priority is 1.0.\n    max_final_score = np.max(final_scores_unnormalized)\n    if max_final_score > epsilon:\n        priorities[can_fit_mask] = final_scores_unnormalized / max_final_score\n    else:\n        # Fallback: if all scores are near zero, assign uniform probability to fitting bins.\n        priorities[can_fit_mask] = 1.0 / num_fitting_bins\n\n    return priorities\n\n### Analyze & experience\n- Comparing (Heuristics 1st) vs (Heuristics 2nd), they are identical.\n\nComparing (Heuristics 3rd) vs (Heuristics 4th), Heuristics 4th introduces a \"Fill Level Bonus\" and a more complex exploration strategy. The fill level bonus (penalizing large remaining capacities) in Heuristics 4th is a good addition for utilization. The exploration strategy in Heuristics 4th, while more complex, aims for a more nuanced exploration by adapting to the number of fitting bins, which is a step up.\n\nComparing (Heuristics 4th) vs (Heuristics 5th), they are identical.\n\nComparing (Heuristics 5th) vs (Heuristics 6th), Heuristics 5th uses a simpler exploration (uniform boost to all fitting bins with probability). Heuristics 6th attempts a more sophisticated exploration by boosting bins closer to the mean exploitation score, aiming to explore \"promising but not top\" candidates. This seems more targeted than uniform boosting. Heuristics 6th also uses a weighted sum of tightness and utilization, which is a reasonable way to combine objectives.\n\nComparing (Heuristics 6th) vs (Heuristics 7th), Heuristics 7th is identical to Heuristics 5th. This indicates a lack of progression or differentiation in the provided list for these specific entries.\n\nComparing (Heuristics 7th) vs (Heuristics 8th), they are identical.\n\nComparing (Heuristics 8th) vs (Heuristics 9th), Heuristics 8th has a complex exploration that scales randomly. Heuristics 9th uses a simple epsilon-greedy with a random pick for exploration. Heuristics 9th's combined score (tightness + 0.5 * utilization) is simpler than Heuristics 8th's multiplicative approach. The normalization in 9th is also simpler.\n\nComparing (Heuristics 9th) vs (Heuristics 10th), Heuristics 10th introduces a \"Dynamic Epsilon-Greedy Exploration\" and a more adaptive utilization score, attempting to boost scores of less utilized bins. This is more sophisticated than the simple epsilon-greedy in Heuristics 9th. Heuristics 10th's approach to combining scores and exploring seems more nuanced.\n\nComparing (Heuristics 10th) vs (Heuristics 11th), they are identical.\n\nComparing (Heuristics 11th) vs (Heuristics 12th), Heuristics 11th uses a fixed exploration probability with a scaled random score favoring less utilized bins. Heuristics 12th uses a fixed `exploration_prob` to select a *number* of bins to boost uniformly. Heuristics 12th's combination of tightness and utilization seems more balanced with normalized utilization bonus. The exploration in 12th is simpler (uniform boost) but ensures at least one bin is explored if possible.\n\nComparing (Heuristics 12th) vs (Heuristics 13th), they are identical.\n\nComparing (Heuristics 13th) vs (Heuristics 14th), Heuristics 14th has significantly different imports (random, math, scipy, torch) and unused parameters, indicating it's an incomplete or placeholder heuristic, making direct comparison difficult and marking it as worse due to lack of implementation and unnecessary complexity.\n\nComparing (Heuristics 14th) vs (Heuristics 15th), they are identical and incomplete.\n\nComparing (Heuristics 15th) vs (Heuristics 16th), they are identical and incomplete.\n\nComparing (Heuristics 16th) vs (Heuristics 17th), Heuristics 17th is a complete heuristic with a clear strategy, unlike the incomplete Heuristics 16th. Heuristics 17th has a multiplicative combination of tightness and utilization bonus, and its exploration boosts specific bins.\n\nComparing (Heuristics 17th) vs (Heuristics 18th), they are identical.\n\nComparing (Heuristics 18th) vs (Heuristics 19th), they are identical.\n\nComparing (Heuristics 19th) vs (Heuristics 20th), they are identical.\n\nOverall: Heuristics 1st-2nd and 5th-8th and 11th-13th and 17th-20th are largely identical and represent a solid base combining tightness, utilization bonus, and basic exploration. Heuristics 3rd and 4th/5th introduce more sophisticated utilization bonuses. Heuristics 6th tries a more advanced exploration. Heuristics 10th/11th attempt dynamic exploration. Heuristics 12th/13th offer a structured exploration boost. The most distinct and potentially improved approaches seem to be those in Heuristics 4th/5th (more nuanced utilization), 6th (smarter exploration targeting), and 10th/11th (dynamic exploration). However, due to extensive duplication, the progression is unclear. The latter group of identical heuristics (17th-20th) represents a reasonable, albeit unoriginal, approach. Heuristics 14th-16th are clearly worse due to incompleteness.\n- \nHere's a refined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Multi-objective, Normalization, Adaptive Exploration, Robustness.\n*   **Advice:** Focus on designing heuristics that explicitly manage trade-offs between competing objectives using techniques like normalized weighted sums or Pareto-based selection. Implement sophisticated exploration strategies that dynamically adjust based on search progress, such as Thompson sampling or Upper Confidence Bound (UCB).\n*   **Avoid:** Blindly combining objectives with fixed weights that might not generalize. Using brittle or ad-hoc handling of edge cases without a clear fallback strategy. Over-reliance on simple epsilon-greedy for exploration, which can be inefficient.\n*   **Explanation:** This approach emphasizes principled methods for handling multi-objective optimization and exploration, ensuring heuristics are adaptable, less prone to local optima, and better at managing complexity without becoming overly brittle.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}