```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines a refined Best Fit strategy with a dynamic exploration mechanism
    that favors bins that are "almost full" to encourage packing larger items
    into fewer bins, while also considering "almost empty" bins for small items.
    It uses a sigmoid-like scaling to create smoother priority transitions.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    suitable_bins_mask = bins_remain_cap >= item
    suitable_bins_indices = np.where(suitable_bins_mask)[0]

    if suitable_bins_indices.size == 0:
        return priorities

    suitable_bins_capacities = bins_remain_cap[suitable_bins_indices]
    gaps = suitable_bins_capacities - item

    # Calculate a "closeness" score for each suitable bin.
    # This score is higher for bins that leave a small gap (good for Best Fit)
    # and also for bins that are already quite full (to group items).
    # We use a scaled inverse gap, with a bias towards larger remaining capacities
    # for exploration.
    
    # Normalize capacities to have a value between 0 and 1 for the sigmoid.
    # Add a small epsilon to avoid division by zero if a bin has exactly the item's size.
    normalized_remaining_cap = suitable_bins_capacities / (np.max(bins_remain_cap) + 1e-9)
    
    # Use a sigmoid-like function to map gaps to priorities.
    # A smaller gap should result in a higher priority.
    # We invert the gap to make smaller gaps correspond to larger sigmoid inputs.
    # A scaling factor `alpha` controls the steepness of the sigmoid.
    alpha = 10.0
    closeness_score = 1 / (1 + np.exp(-alpha * (1 - (gaps / (item + 1e-9)))))

    # Introduce a factor that prefers bins with more remaining capacity (less full bins)
    # to encourage spreading smaller items if available, using a scaled inverse
    # of the remaining capacity.
    # Add small value to avoid division by zero for bins with 0 remaining capacity if they exist.
    space_utilization_score = (bins_remain_cap[suitable_bins_indices] + 1e-9) / (np.max(bins_remain_cap) + 1e-9)
    
    # Combine scores: lean towards closeness (Best Fit) but also consider space utilization
    # which implicitly favors larger remaining capacities for exploration of these slots.
    # A weighted sum: 70% closeness, 30% space utilization.
    combined_scores = 0.7 * closeness_score + 0.3 * space_utilization_score

    # Apply a small exploration factor by slightly perturbing the best bin's score.
    # This is a deterministic way to add a little noise without a fixed epsilon.
    # We find the index of the highest score and add a small bonus to it,
    # but also slightly boost other high-scoring bins to avoid always picking the absolute top.
    
    sorted_indices_by_score = np.argsort(combined_scores)[::-1]
    
    # Assign priorities based on the combined scores, with a slight boost to the top few.
    # The highest score gets a priority of 1.0, the next highest gets 0.9, etc.
    # This provides a relative ordering and reduces reliance on absolute gap values.
    for i, idx_in_suitable in enumerate(sorted_indices_by_score):
        original_idx = suitable_bins_indices[idx_in_suitable]
        priority_value = max(0, 1.0 - (i * 0.1)) # Give decreasing priority
        priorities[original_idx] = priority_value

    # Ensure the highest priority is exactly 1.0 for the best bin
    if suitable_bins_indices.size > 0:
        best_bin_in_suitable_idx = np.argmax(combined_scores)
        best_bin_original_idx = suitable_bins_indices[best_bin_in_suitable_idx]
        priorities[best_bin_original_idx] = 1.0

    return priorities
```
