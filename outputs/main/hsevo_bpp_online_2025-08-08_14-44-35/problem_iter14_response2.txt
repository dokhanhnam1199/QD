```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines tight fitting preference with an adaptive exploration strategy
    that balances exploitation and exploration more effectively.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    epsilon = 0.1  # Base exploration rate
    alpha = 0.5    # Weight for utilization bonus

    # Mask for bins that can fit the item
    can_fit_mask = bins_remain_cap >= item

    if not np.any(can_fit_mask):
        return priorities

    # --- Exploitation Score: Tightness + Utilization Bonus ---

    # Tightness: Prioritize bins with less remaining capacity after packing
    tightness_scores = np.zeros_like(bins_remain_cap, dtype=float)
    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]
    remaining_after_packing = fitting_bins_remain_cap - item
    tightness_scores[can_fit_mask] = 1.0 / (remaining_after_packing + 1e-9)

    # Utilization Bonus: Reward bins that are already more full (less remaining capacity)
    utilization_scores = np.zeros_like(bins_remain_cap, dtype=float)
    utilization_scores[can_fit_mask] = 1.0 / (fitting_bins_remain_cap + 1e-9)

    # Combine scores: weighted sum
    combined_exploitation_score = tightness_scores + alpha * utilization_scores

    # Normalize exploitation scores for fitting bins to [0, 1]
    normalized_exploitation_scores = np.zeros_like(combined_exploitation_score, dtype=float)
    if np.any(can_fit_mask):
        fitting_scores = combined_exploitation_score[can_fit_mask]
        max_score = np.max(fitting_scores)
        if max_score > 0:
            normalized_exploitation_scores[can_fit_mask] = fitting_scores / max_score

    # --- Adaptive Exploration: Epsilon-Greedy with Targeted Exploration ---
    # With probability epsilon, choose a random fitting bin.
    # Otherwise, use the exploitation scores.
    # We can also add a slight uniform boost to all fitting bins to encourage
    # exploration without completely overriding good exploitation choices.

    exploration_boost = epsilon / (np.sum(can_fit_mask) + 1e-9)
    exploration_scores = np.zeros_like(bins_remain_cap, dtype=float)
    exploration_scores[can_fit_mask] = exploration_boost

    # Final priorities: blend normalized exploitation and exploration boost
    priorities[can_fit_mask] = normalized_exploitation_scores[can_fit_mask] + exploration_scores[can_fit_mask]

    # Ensure no negative priorities and re-normalize if necessary
    priorities = np.maximum(0, priorities)
    max_final_priority = np.max(priorities)
    if max_final_priority > 0:
        priorities /= max_final_priority

    return priorities
```
