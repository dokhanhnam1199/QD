```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines a robust Best Fit strategy with an adaptive penalty for slack.
    Prioritizes bins that offer the tightest fit, with a penalty for
    bins that leave excessive remaining capacity, encouraging better space utilization.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    suitable_bins_mask = bins_remain_cap >= item
    suitable_bins_indices = np.where(suitable_bins_mask)[0]

    if suitable_bins_indices.size == 0:
        return priorities

    suitable_bins_capacities = bins_remain_cap[suitable_bins_indices]

    # Calculate the gap for best fit (lower is better)
    gaps = suitable_bins_capacities - item

    # Calculate a penalty for bins with large remaining capacity (slack).
    # We want to penalize larger gaps to encourage tighter packing.
    # A simple penalty could be the gap itself, so we want to MINIMIZE gap.
    # To convert to a priority score (higher is better), we can use 1 / (gap + epsilon).
    # However, if we want to PENALIZE large gaps, we can subtract the gap from a base value
    # or use a function that decreases with gap size.
    # Let's consider a score where we want to MAXIMIZE `-(gap)^2` to favor small gaps.
    # A simpler approach for penalizing large gaps is to ensure the priority decreases
    # as the gap increases.
    # Let's use a scoring system that directly favors smaller gaps.
    # Score = 1 / (gap + epsilon) aims to maximize preference for smallest gap.

    # Let's introduce a penalty for bins that have *too much* remaining capacity.
    # This "too much" can be relative. A bin with capacity 100 and item 10 has gap 90.
    # A bin with capacity 20 and item 10 has gap 10.
    # The gap of 10 is better for tight fit.
    # If we want to penalize the gap of 90, we can use a function that decreases rapidly.
    # A linear penalty might be `penalty_weight * gap`.
    # Let's try to score bins by `(some_value - gap)`.
    # A common approach is to use the negative of the gap, or `1/(gap + epsilon)`.

    # Let's combine Best Fit (minimize gap) with an incentive to not leave too much space.
    # This can be achieved by rewarding bins that have a remaining capacity closer to the item size.
    # Maximize `-(gap)^2` is one way to do this.
    # Or, let's consider the inverse of the remaining capacity after packing.
    # We want to maximize the *fullness* of the bin after packing.
    # This would mean maximizing `1 / (gap + epsilon)`.
    # This is essentially Best Fit.

    # What if we want to penalize bins that have a *very* large gap?
    # For example, if `gap > item * threshold`.
    # Let's consider a score that heavily favors small gaps but also slightly penalizes very large gaps.
    # A function like `1 / (gap + 1)` would give higher scores to smaller gaps.
    # To penalize large gaps, we can ensure the score doesn't increase linearly with `1/gap`.
    # Let's consider the efficiency: `item / bins_remain_cap[i]`. Maximize this.
    # This is equivalent to minimizing `bins_remain_cap[i] / item`.
    # And thus, minimizing `bins_remain_cap[i] - item`.

    # A good heuristic might be to prioritize bins that have a small gap,
    # but not necessarily the absolute smallest if that leaves very little room.
    # Let's try to combine Best Fit (minimize gap) with a factor that
    # penalizes large gaps.
    # We want to maximize a score that is high for small gaps.
    # Score: `1.0 / (gaps + 1e-6)` is a strong Best Fit.
    # To penalize large gaps, we can apply a discount to this score for large gaps.
    # Or, consider `-(gaps)`. Maximizing this means minimizing gaps.

    # Let's use the gap as the primary driver and add a slight adjustment for very large gaps.
    # Consider a score that is inversely proportional to the gap, but caps out or decreases for extremely large gaps.
    # A simple penalty for large gaps can be achieved by subtracting a term proportional to the gap itself.
    # Score = C - gap, where C is a large constant. This still favors minimum gap.

    # Let's define the score for each suitable bin as:
    # `priority_score = 1.0 / (gap + 1e-6)`  (favors tightest fit)
    # This is standard Best Fit.

    # To add a penalty for excessive slack (large gaps), we can subtract a term related to the gap.
    # Let's consider the "waste" created. `waste = gap`.
    # We want to minimize waste.
    # Let's define a score that is higher for lower waste.
    # Score = -waste = -(bins_remain_capacities - item). Maximizing this means minimizing waste.

    # Let's try a combined score: prioritize small gaps, but penalize very large gaps.
    # Consider the reciprocal of the *normalized* gap.
    # Normalized gap: `gaps / item`.
    # Score = `1.0 / (gaps / item + 1e-6)` ? No, this amplifies small item sizes.

    # Let's go back to the idea of penalizing large remaining capacity.
    # The residual capacity after packing is `gap`.
    # We want to maximize `1 / (gap + epsilon)`.
    # However, if `gap` is very large, this score might still be relatively high,
    # which is not ideal if we want to penalize large remaining spaces.

    # Let's introduce a penalty term that grows with the gap.
    # Score = `(1.0 / (gaps + 1e-6)) - penalty_weight * gaps`
    # This might over-penalize.

    # A more direct way to penalize large remaining capacity:
    # Consider the "fullness" after packing, which is `1 - (item / bins_remain_cap)`.
    # This is related to `1 - item / (gap + item) = gap / (gap + item)`.
    # We want to maximize this ratio.
    # So, `score = gaps / (gaps + 1e-6)`. This aims to maximize slack.

    # Let's combine Best Fit (minimize gap) and a factor that discourages large gaps.
    # We want to maximize a value that is high for small gaps.
    # Consider `1 / (gap + 1)` as a base score.
    # To penalize large gaps, we can subtract a term proportional to the gap.
    # Example: `priority = 100 - gap`. This favors small gaps.
    # Let's make it more dynamic.

    # Let's consider a score that balances tight fitting and leaving moderate space.
    # Best Fit component: `1.0 / (gaps + 1e-6)`
    # A component that penalizes large gaps: `1.0 / (gaps**2 + 1e-6)`
    # This amplifies the penalty for larger gaps.
    # Or, simply subtract `gaps`.

    # Let's use the inverse of the remaining capacity after packing as a measure of how full the bin is.
    # We want to maximize this: `1.0 / (gaps + 1e-6)`. This IS Best Fit.

    # A strategy that penalizes "too much" remaining capacity could be:
    # prioritize bins where `gap` is small, but not excessively small if it leads to very large gaps.
    # This is tricky.

    # Let's simplify: prioritize tightest fit, but add a small penalty to bins with very large slack.
    # Consider the score `1 / (gap + 1)`.
    # If gap > item, apply a discount.
    # This means a bin that is almost full (small gap) is preferred.
    # A bin that is much larger than needed (large gap) is less preferred.

    # Let's define the priority score for each suitable bin as:
    # `score = 1.0 / (gaps + 1e-6)`
    # This directly implements Best Fit.

    # To add a penalty for excessive slack (large gaps), we can modify this.
    # If a bin has `gap > SOME_THRESHOLD`, reduce its score.
    # What's a good threshold? Maybe related to `item` or average `bins_remain_cap`.
    # Let's use `item` as a reference. If `gap > item`, the bin is more than twice the size needed.

    # Let's assign a score that favors small gaps, and decreases for larger gaps.
    # `score = 1.0 / (gaps + 1e-6)`  -- This is best fit.
    # To penalize large gaps, let's subtract a term proportional to the gap.
    # `score = (1.0 / (gaps + 1e-6)) - (0.1 * gaps)`
    # The `0.1` is a tunable parameter.

    # Let's try a different formulation. We want to maximize remaining space after packing,
    # but not excessively.
    # Consider the score that prioritizes bins where `bins_remain_cap` is *just* large enough.
    # This means `bins_remain_cap` is close to `item`.
    # We want to maximize `bins_remain_cap` among suitable bins, which is "Worst Fit".

    # Let's try to combine Best Fit with a penalty for "too empty" bins.
    # For a suitable bin, the remaining capacity is `gap`.
    # If `gap` is very large, it's "too empty".
    # We want to prioritize small `gap`.
    # Consider `score = -gap`. Maximizing this minimizes `gap`.
    # Let's add a slight bonus for bins that are not excessively empty.
    # If `gap < item * tolerance`, give a bonus.

    # Let's use a scoring function that is derived from Best Fit, but with a modification for large gaps.
    # Base score (Best Fit): `1.0 / (gaps + 1e-6)`
    # Penalty for large gaps: Let's make the score decrease faster for larger gaps.
    # Consider `1.0 / (gaps + 1e-6)`. If gap is large, this value is small.
    # What if we try to maximize `(bins_remain_cap[i] - item)` but subject to `bins_remain_cap[i] - item` being small?

    # Let's define the score for each suitable bin as:
    # `score = 1.0 / (gaps + 1e-6)`  # High score for small gaps (tight fit)
    # To penalize large gaps (excessive slack), we can add a term that subtracts from the score as gap increases.
    # Let's use a penalty proportional to the gap itself.
    # `penalty = 0.1 * gaps`
    # `final_score = (1.0 / (gaps + 1e-6)) - (0.1 * gaps)`

    # This might penalize too aggressively.
    # Let's try a simpler approach: favor bins that have remaining capacity that is "just enough" or slightly more.
    # This means we want to MAXIMIZE `bins_remain_cap` among suitable bins, subject to `bins_remain_cap` not being excessively large.
    # Let's prioritize bins that have a reasonable amount of capacity remaining after packing.
    # This means maximizing `gap`. This is the opposite of Best Fit.

    # Let's stick to Best Fit but modify the scoring to penalize large gaps.
    # We want a score that is high for small gaps and decreases as gaps grow.
    # Consider `score = exp(-gaps / some_scale)`. This is good but potentially non-linear.

    # Let's use a score that is `1.0 / (gap + 1)` and apply a discount if `gap` is large.
    # For example, if `gap > item`, apply a penalty.
    # `score = 1.0 / (gaps + 1e-6)`
    # `penalty_factor = np.where(gaps > item, 0.5, 1.0)`
    # `final_scores = score * penalty_factor`

    # Let's try a more direct approach using the negative gap, but with a penalty for large gaps.
    # We want to maximize `(-gaps)` which means minimizing gaps.
    # To penalize large gaps, we can subtract a term that grows with gaps.
    # `score = -gaps - (0.1 * gaps**2)`
    # This will heavily penalize large gaps.

    # Let's define the score based on minimizing the gap and penalizing its size.
    # We want to maximize `-(gap + a*gap^2)` where 'a' is a penalty factor.
    # For simplicity, let's use `score = -gaps`. This is just Best Fit.

    # Let's reconsider the penalty for large gaps.
    # If `gap` is large, the bin is very empty after packing.
    # This is generally okay, but if there are many such bins, it might not be optimal.
    # Let's try a score that is `1 / (gap + 1)` and a penalty for `gap > item`.
    # This promotes Best Fit but discourages very loose fits.

    # Let's implement a score that favors tight fits, with a penalty for excessive remaining capacity.
    # The penalty will be proportional to the remaining capacity after packing.
    # Score for each suitable bin `i`:
    # `remaining_after_packing = bins_remain_cap[i] - item`
    # `base_score = 1.0 / (remaining_after_packing + 1e-6)` (favors small remaining capacity)
    # `penalty = 0.1 * remaining_after_packing` (penalizes large remaining capacity)
    # `final_score = base_score - penalty`
    # This attempts to combine tight fit with a disincentive for very loose fits.

    final_scores = np.zeros_like(suitable_bins_capacities, dtype=float)
    for i, bin_idx in enumerate(suitable_bins_indices):
        remaining_after_packing = suitable_bins_capacities[i] - item
        
        # Base score: favors smaller remaining capacity (tightest fit)
        # Add a small epsilon to avoid division by zero.
        base_score = 1.0 / (remaining_after_packing + 1e-6)
        
        # Penalty: discourages bins with excessively large remaining capacity.
        # This penalty increases linearly with the remaining capacity after packing.
        # The coefficient (0.1) is a tunable parameter.
        penalty = 0.1 * remaining_after_packing
        
        final_scores[i] = base_score - penalty

    if final_scores.size > 0:
        best_fit_in_suitable_idx = np.argmax(final_scores)
        best_fit_original_idx = suitable_bins_indices[best_fit_in_suitable_idx]
        priorities[best_fit_original_idx] = 1.0

    return priorities
```
