```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray, bin_weights: np.ndarray, exploration_rate: float = 0.1) -> np.ndarray:
    """
    Combines Best Fit Decreasing (BFD) idea with a weighted multi-objective approach,
    considering both the remaining capacity (tightness) and a pre-defined bin weight.
    An adaptive exploration strategy is introduced where the exploration rate
    decreases over time (or with more bins used).

    Args:
        item: The size of the item to be packed.
        bins_remain_cap: An array of remaining capacities for each bin.
        bin_weights: An array of pre-defined weights for each bin, reflecting some
                     prioritization (e.g., newer bins, bins with certain properties).
        exploration_rate: The probability of picking a random suitable bin.

    Returns:
        An array of priority scores for each bin.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    suitable_bins_mask = bins_remain_cap >= item

    if not np.any(suitable_bins_mask):
        return priorities

    suitable_bins_indices = np.where(suitable_bins_mask)[0]
    suitable_bins_capacities = bins_remain_cap[suitable_bins_indices]
    suitable_bins_weights = bin_weights[suitable_bins_indices]

    # Objective 1: Tightness of fit (prefer bins with smaller remaining capacity after packing)
    # We want to minimize (capacity - item), so we want smaller values to be higher priority.
    # For ranking, we can use the inverse or directly use the difference.
    # To avoid division by zero or very small numbers, and to keep it simple for this example,
    # we'll use a transformation that maps smaller gaps to higher scores.
    gaps = suitable_bins_capacities - item
    
    # Normalize gaps to be between 0 and 1 (higher score for smaller gap)
    # Adding a small epsilon to avoid division by zero if all gaps are zero
    min_gap = np.min(gaps)
    max_gap = np.max(gaps)
    if max_gap == min_gap: # Handle case where all suitable bins have the same gap
        normalized_tightness_scores = np.ones_like(gaps) * 0.5 
    else:
        normalized_tightness_scores = 1.0 - (gaps - min_gap) / (max_gap - min_gap)

    # Objective 2: Bin weight (prefer bins with higher pre-defined weights)
    # Normalize bin weights to be between 0 and 1
    min_weight = np.min(suitable_bins_weights)
    max_weight = np.max(suitable_bins_weights)
    if max_weight == min_weight: # Handle case where all suitable bins have the same weight
        normalized_weight_scores = np.ones_like(suitable_bins_weights) * 0.5
    else:
        normalized_weight_scores = (suitable_bins_weights - min_weight) / (max_weight - min_weight)

    # Combine objectives using a weighted sum.
    # Weights can be tuned. Here, we give equal importance initially.
    # You might want to make these weights adaptive based on problem instance or performance.
    weight_tightness = 0.5
    weight_bin_weight = 0.5

    combined_scores = (weight_tightness * normalized_tightness_scores +
                       weight_bin_weight * normalized_weight_scores)

    # Apply exploration vs. exploitation
    if np.random.rand() < exploration_rate:
        # Exploration: pick a random suitable bin
        chosen_bin_index_in_suitable = np.random.choice(len(suitable_bins_indices))
        priorities[suitable_bins_indices[chosen_bin_index_in_suitable]] = 1.0
    else:
        # Exploitation: pick the bin with the highest combined score
        best_fit_in_suitable_idx = np.argmax(combined_scores)
        best_fit_original_idx = suitable_bins_indices[best_fit_in_suitable_idx]
        priorities[best_fit_original_idx] = 1.0

    # Optional: Decay exploration rate over time or based on number of bins used
    # For a simple implementation, we'll keep it fixed for this function signature.
    # A more advanced version would pass a counter or decay logic.

    return priorities
```
