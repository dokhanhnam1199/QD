```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines tight-fit preference with an adaptive penalty for unused bins.
    Favors bins that leave minimal remaining space, with a bonus for bins
    that have already been utilized to some extent.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    epsilon = 1e-9

    # Mask for bins that can fit the item
    can_fit_mask = bins_remain_cap >= item

    # Calculate tightness score: inverse of remaining capacity after packing
    # Higher score for bins that leave less remaining space (closer to zero slack)
    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]
    remaining_after_packing = fitting_bins_remain_cap - item
    tightness_score = np.zeros_like(bins_remain_cap, dtype=float)
    tightness_score[can_fit_mask] = 1.0 / (remaining_after_packing + epsilon)

    # Adaptive penalty for "empty" or less utilized bins:
    # Penalize bins with high remaining capacity more significantly.
    # This encourages using bins that are already partially filled.
    # We use a logistic-like function (sigmoid inverse) for a smooth penalty.
    # Bins with very high remaining capacity get a score close to 0.5.
    # Bins with remaining capacity close to the item size get a score closer to 1.0.
    
    # To make it adaptive, let's consider the distribution of remaining capacities.
    # A simple approach is to normalize the remaining capacities relative to the maximum.
    # However, a direct penalty on large remaining capacity is more straightforward.
    
    # Let's use a penalty factor that is inversely proportional to the remaining capacity
    # after packing, but smoothed.
    
    # The idea is to combine the "tightest fit" with a preference for bins that are
    # not "too empty". A bin that leaves a lot of space after packing is less desirable.
    # The slack `remaining_after_packing` is what we want to minimize.
    
    # Let's introduce a bonus for bins that have already been used, which we can infer
    # from `bins_remain_cap` being significantly less than some assumed max capacity.
    # Without knowing the initial capacity, we can penalize bins whose current `bins_remain_cap`
    # is large relative to the item.
    
    # Let's define a "fill level" score for each bin that *can* fit the item.
    # Higher score means more "filled" (less remaining capacity).
    # A simple fill score could be `1.0 - (bins_remain_cap / MAX_CAPACITY)`.
    # Without MAX_CAPACITY, we can normalize by the max *available* capacity.
    
    # Let's combine the `tightness_score` with a penalty that discourages bins
    # that still have a lot of capacity *after* the item is packed.
    
    # Heuristic 4's core: minimize slack.
    # The "penalty for empty bins" can be interpreted as: if we have a choice
    # between a nearly empty bin and a partially filled bin with similar slack,
    # prefer the partially filled one.
    
    # Let's use a composite score:
    # Score = Tightness * Utilization_Bonus
    
    # Tightness: 1 / (slack + epsilon)
    # Utilization_Bonus: How "full" is the bin *before* packing?
    # A simple proxy for utilization without knowing initial capacity:
    # If `bins_remain_cap` is large, it's less utilized.
    # Let's create a bonus that increases as `bins_remain_cap` decreases.
    
    # Calculate a "fill fraction" for fitting bins.
    # A larger fraction means the bin is more "used".
    # We need a reference for "fully empty" vs "full".
    # Let's use the maximum remaining capacity among fitting bins as a reference point for "emptiness".
    # This is not ideal as it's adaptive to the current state.
    
    # A more robust "penalty for empty bins" is to give a bonus to bins that are
    # already partially occupied.
    
    # Let's use a combined score: Tightness + Utilization_Bonus
    # Tightness: `1 / (slack + epsilon)`
    # Utilization_Bonus: Let's say, a small constant *if* the bin is not "empty".
    # How to define "empty"? If `bins_remain_cap` is close to the maximum possible bin capacity.
    # Without knowing MAX_CAPACITY, let's use a relative measure.
    
    # Let's implement a score that rewards tightness and also provides a bonus
    # for bins that have already been used.
    
    # The `tightness_score` is good. Let's call it `score_tightness`.
    score_tightness = np.zeros_like(bins_remain_cap, dtype=float)
    score_tightness[can_fit_mask] = 1.0 / (bins_remain_cap[can_fit_mask] - item + epsilon)

    # Now, add a bonus for bins that are not "empty".
    # We can define "not empty" as having `bins_remain_cap` below a certain threshold.
    # A simpler approach is to give a bonus based on how *little* remaining capacity there is.
    # This bonus should be smaller than the primary tightness score.
    
    # Let's define a "fill_score" which is higher for bins with less remaining capacity.
    # For fitting bins: `fill_score = 1.0 / (bins_remain_cap[can_fit_mask] + epsilon)`
    # This rewards bins that are already quite full.
    
    # Combine `score_tightness` and `fill_score`.
    # A multiplicative approach: `priority = score_tightness * (1 + fill_score * bonus_weight)`
    # This rewards bins that are both tight AND already quite full.
    
    bonus_weight = 0.2 # Weight for the fill score bonus
    
    fill_score = np.zeros_like(bins_remain_cap, dtype=float)
    fill_score[can_fit_mask] = 1.0 / (bins_remain_cap[can_fit_mask] + epsilon)
    
    combined_score = score_tightness * (1.0 + fill_score * bonus_weight)
    
    # Normalize scores so the highest priority is 1.0
    max_score = np.max(combined_score)
    if max_score > 0:
        priorities[can_fit_mask] = combined_score[can_fit_mask] / max_score
        
    return priorities
```
