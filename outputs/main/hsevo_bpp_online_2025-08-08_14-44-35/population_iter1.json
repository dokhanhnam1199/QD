[
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns priority with which we want to add item to each bin using a modified First Fit strategy.\n    Priority is higher for bins that can accommodate the item and have less remaining capacity\n    after packing, aiming to fill bins more tightly.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Consider bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate remaining capacity after packing the item\n    remaining_after_packing = bins_remain_cap[can_fit_mask] - item\n    \n    # Assign higher priority to bins with less remaining capacity after packing\n    # This encourages tighter packing.\n    # We use the inverse of remaining capacity (plus a small epsilon to avoid division by zero\n    # if an item perfectly fills a bin) to ensure higher priority for tighter fits.\n    epsilon = 1e-9\n    priorities[can_fit_mask] = 1.0 / (remaining_after_packing + epsilon)\n    \n    # Normalize priorities so the maximum priority is 1.0 (optional, but good practice)\n    if np.max(priorities) > 0:\n        priorities /= np.max(priorities)\n        \n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 9.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.9999662170012 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response2.txt_stdout.txt",
    "code_path": "problem_iter1_code2.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    suitable_bins = bins_remain_cap >= item\n    if not np.any(suitable_bins):\n        return np.zeros_like(bins_remain_cap)\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    \n    worst_fit_candidates = bins_remain_cap[suitable_bins]\n    \n    \n    min_remaining_capacity = np.min(worst_fit_candidates)\n    \n    \n    priorities[suitable_bins] = (worst_fit_candidates - min_remaining_capacity)\n    \n    \n    priorities[bins_remain_cap < item] = -np.inf\n    \n    \n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 22, in priority_v2\n    \nOverflowError: cannot convert float infinity to integer\n10\n2\n"
  },
  {
    "stdout_filepath": "problem_iter1_response3.txt_stdout.txt",
    "code_path": "problem_iter1_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Almost Full Fit strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Identify bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n    \n    # Calculate the \"emptiness\" of suitable bins\n    # We want to prioritize bins that are almost full, meaning they have less remaining capacity\n    # The less remaining capacity, the higher the priority\n    suitable_bins_capacity = bins_remain_cap[suitable_bins_mask]\n    \n    # The priority is inversely proportional to the remaining capacity.\n    # A small positive constant is added to avoid division by zero and to ensure non-zero priorities for non-empty bins.\n    # A larger constant can be used to penalize empty bins more heavily, effectively prioritizing bins that already have items.\n    # Here, we use a penalty that is greater than any possible item size.\n    penalty_for_empty = 1000.0 \n    \n    priorities[suitable_bins_mask] = penalty_for_empty - suitable_bins_capacity\n    \n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.9999684850045 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response5.txt_stdout.txt",
    "code_path": "problem_iter1_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Inverse Distance strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    available_bins_mask = bins_remain_cap >= item\n    available_bins_cap = bins_remain_cap[available_bins_mask]\n    \n    if available_bins_cap.size == 0:\n        return np.zeros_like(bins_remain_cap)\n\n    # Inverse distance (proximity fit) strategy: prioritize bins that are almost full but can still fit the item\n    # Calculate the \"waste\" if the item is placed in a bin\n    waste = available_bins_cap - item\n    \n    # Higher priority for bins with less waste (closer fit)\n    # Add a small epsilon to avoid division by zero if an exact fit is found (waste is 0)\n    priorities = 1.0 / (waste + 1e-9)\n    \n    # Create a full-size priority array and fill in the priorities for available bins\n    full_priorities = np.zeros_like(bins_remain_cap)\n    full_priorities[available_bins_mask] = priorities\n    \n    return full_priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 10.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response6.txt_stdout.txt",
    "code_path": "problem_iter1_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    available_bins_mask = bins_remain_cap >= item\n    available_bins_cap = bins_remain_cap[available_bins_mask]\n    \n    if available_bins_cap.size == 0:\n        return np.zeros_like(bins_remain_cap)\n    \n    \n    fit_ratios = available_bins_cap / item\n    \n    \n    priorities = 1 / (1 + np.exp(- (fit_ratios - 1.5))) \n    \n    \n    final_priorities = np.zeros_like(bins_remain_cap)\n    final_priorities[available_bins_mask] = priorities\n    \n    return final_priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 10.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    fits = bins_remain_cap >= item\n    priorities[fits] = bins_remain_cap[fits] - item\n    priorities[priorities < 0] = 0\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response8.txt_stdout.txt",
    "code_path": "problem_iter1_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Epsilon-Greedy.\n\n    This strategy prioritizes bins that have just enough space for the item\n    (minimizing wasted space) but also considers bins that have significant\n    remaining space to encourage filling them up later. The epsilon-greedy\n    approach introduces randomness to explore different bin choices.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    epsilon = 0.2\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    suitable_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(suitable_bins_mask):\n        return np.zeros_like(bins_remain_cap)\n\n    suitable_bins_remain_cap = bins_remain_cap[suitable_bins_remain_cap]\n\n    \n    exact_fit_score = 1.0 / (1.0 + np.abs(suitable_bins_remain_cap - item))\n    \n    large_capacity_score = suitable_bins_remain_cap / np.max(suitable_bins_remain_cap)\n    \n    combined_score = 0.7 * exact_fit_score + 0.3 * large_capacity_score\n    \n    priorities[bins_remain_cap >= item] = combined_score\n\n    \n    if np.random.rand() < epsilon:\n        random_index = np.random.choice(np.where(suitable_bins_mask)[0])\n        priorities = np.zeros_like(bins_remain_cap, dtype=float)\n        priorities[random_index] = 1.0\n    else:\n        max_priority = np.max(priorities)\n        priorities[priorities < max_priority] = priorities[priorities < max_priority] * 0.8\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 26, in priority_v2\n    # We want to prioritize bins where the difference is small (good fit).\nUnboundLocalError: local variable 'suitable_bins_remain_cap' referenced before assignment\n19\n3\n"
  },
  {
    "stdout_filepath": "problem_iter1_response9.txt_stdout.txt",
    "code_path": "problem_iter1_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculates priorities for packing an item into bins using a Softmax-Based Fit strategy.\n\n    This strategy assigns higher priority to bins that are a good fit for the item,\n    meaning bins with remaining capacity close to the item's size. A smaller\n    difference between bin capacity and item size results in a higher score.\n    Softmax is used to convert these scores into probabilities (priorities).\n\n    Args:\n        item: The size of the item to be packed.\n        bins_remain_cap: A NumPy array representing the remaining capacity of each bin.\n\n    Returns:\n        A NumPy array of the same size as bins_remain_cap, where each element\n        is the priority score for placing the item into the corresponding bin.\n    \"\"\"\n    # Calculate the difference between remaining capacity and item size.\n    # We are interested in bins where remaining capacity is >= item size.\n    # For bins where remaining capacity is less than item size, the difference will be negative.\n    # Adding a small epsilon to avoid issues with log(0) if capacity is exactly item size.\n    differences = bins_remain_cap - item + 1e-9\n\n    # We want to prioritize bins where the difference is small (good fit).\n    # A larger difference means a worse fit. We can use the negative difference\n    # to effectively treat smaller positive differences as \"more positive\".\n    # We'll filter out bins where capacity < item size by making their score very low.\n    # A large negative number will result in a very small exponent in softmax.\n    scores = np.where(differences >= 0, -differences, -1e9)\n\n    # Apply the softmax function to convert scores into probabilities (priorities)\n    # Softmax: exp(score_i) / sum(exp(score_j))\n    # This will naturally give higher probabilities to bins with smaller (less negative) scores.\n    exp_scores = np.exp(scores)\n    priorities = exp_scores / np.sum(exp_scores)\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 6.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using First Fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    fits = bins_remain_cap >= item\n    priorities[fits] = 1.0\n    first_fit_index = np.argmax(fits.astype(int))\n    priorities[first_fit_index] = 2.0\n    return priorities",
    "response_id": 10,
    "tryHS": false,
    "obj": 4.487435181491823,
    "SLOC": 7.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response11.txt_stdout.txt",
    "code_path": "problem_iter1_code11.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1 / (bins_remain_cap[i] - item + 1e-9)\n    return priorities",
    "response_id": 11,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 6.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response12.txt_stdout.txt",
    "code_path": "problem_iter1_code12.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    eligible_bins = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n    if np.any(eligible_bins):\n        eligible_capacities = bins_remain_cap[eligible_bins]\n        priorities[eligible_bins] = 1.0 / (bins_remain_cap[eligible_bins] - item + 1e-9)\n    return priorities",
    "response_id": 12,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 7.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response13.txt_stdout.txt",
    "code_path": "problem_iter1_code13.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            priorities[i] = (cap - item) / cap\n    return priorities",
    "response_id": 13,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 6.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Exact Fit First strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Heuristic for Exact Fit First: Prioritize bins that are an exact fit\n    # or very close to an exact fit.\n    \n    # Calculate the difference between bin capacity and item size\n    diff = bins_remain_cap - item\n    \n    # Bins that are a perfect fit (diff == 0) get the highest priority.\n    # Bins that are a very close fit (small positive diff) get high priority.\n    # Bins that are not a good fit (larger diff or negative diff) get low priority.\n    \n    # Assign high priority to bins that can fit the item\n    can_fit = bins_remain_cap >= item\n    \n    # For bins that can fit, we want to prioritize those that result in the least remaining space.\n    # This encourages using up space efficiently.\n    # We can use a score inversely proportional to the remaining capacity after placing the item.\n    # A smaller remaining capacity means a higher score.\n    \n    # Calculate the remaining capacity if the item is placed in the bin\n    remaining_capacity_after_fit = bins_remain_cap - item\n    \n    # Avoid division by zero or negative values if an item doesn't fit\n    # For bins that can fit, assign a priority score.\n    # We want bins that have just enough space to be prioritized.\n    # A good heuristic is to give a high score when `remaining_capacity_after_fit` is close to 0.\n    # A simple approach is to use `1 / (1 + remaining_capacity_after_fit)` which maps\n    # 0 remaining space to a priority of 1, and larger remaining space to smaller priorities.\n    # We can add a small epsilon to avoid division by zero in edge cases, though `bins_remain_cap >= item` handles it.\n    \n    # Let's refine: higher priority for smaller remaining capacity.\n    # A score like `1.0 / (remaining_capacity_after_fit + 1e-6)` works, but can lead to\n    # very large numbers.\n    # A more stable approach is to invert the rank of remaining capacity or use a Gaussian-like function.\n    \n    # A simpler strategy for Exact Fit First:\n    # Prioritize bins where `bins_remain_cap - item` is minimized (but non-negative).\n    # Let's give a score of 1 if it's an exact fit, and a decreasing score based on how much\n    # \"extra\" space is left.\n    \n    # Option 1: Higher score for smaller difference (closer to 0)\n    # For bins that can fit: assign priority based on `bins_remain_cap - item`\n    # Higher priority for smaller `bins_remain_cap - item`\n    # We can use a function like `max_capacity - (bins_remain_cap - item)`\n    # or simply the negative of the difference if we normalize or cap scores.\n    \n    # Let's assign priorities:\n    # 1. Exact fits get the highest priority (e.g., a large constant).\n    # 2. Then, bins with the smallest positive remaining capacity.\n    # 3. Finally, bins that can fit but leave larger remaining capacity.\n    \n    # Let's try a scoring mechanism:\n    # For bins that can fit: priority = some_large_number - (bins_remain_cap - item)\n    # This rewards smaller remaining space.\n    \n    # Let's create a priority value for each bin that can fit the item.\n    # We want to prioritize bins that leave the LEAST amount of remaining space.\n    # So, a smaller `bins_remain_cap - item` should yield a higher priority.\n    # A simple way is to use `np.max(bins_remain_cap) - (bins_remain_cap - item)`\n    # or `1.0 / (bins_remain_cap - item + epsilon)`\n    \n    # Let's use the inverse of the remaining capacity after placing the item.\n    # Smallest remaining capacity gets highest score.\n    \n    # Calculate scores for bins that can accommodate the item.\n    # Add a small epsilon to avoid division by zero if `bins_remain_cap == item`.\n    # Although, exact fit (0 difference) is the primary goal.\n    \n    # To give the absolute highest priority to an exact fit:\n    # Assign a very high score for exact fits.\n    # Then, for non-exact fits, assign a score based on the remaining capacity.\n    \n    # Define a high score for exact fits\n    exact_fit_score = 1000.0\n    \n    # Calculate scores for bins that can fit the item\n    scores_for_fitting_bins = np.where(bins_remain_cap >= item, bins_remain_cap - item, np.inf)\n    \n    # Assign a very high score to bins that are an exact fit (difference is 0)\n    # For other fitting bins, the score is `bins_remain_cap - item`.\n    # We want smaller `bins_remain_cap - item` to be prioritized, so we should\n    # invert this relationship, e.g., `1 / (diff + epsilon)` or similar.\n    \n    # Let's use a score that is higher for smaller `bins_remain_cap - item`\n    # `max_possible_diff - diff` could work if we know max_possible_diff.\n    # Or, use `1.0 / (diff + 1)` where diff is `bins_remain_cap - item`.\n    # This maps diff=0 to priority 1, diff=1 to priority 0.5, etc.\n    \n    # Let's refine the priority:\n    # Exact fits are paramount.\n    # If no exact fit, choose the bin that leaves the least excess capacity.\n    \n    # Score for bins that can fit:\n    # For bins where `bins_remain_cap - item == 0`, assign highest priority.\n    # For bins where `bins_remain_cap - item > 0`, assign a priority based on `bins_remain_cap - item`.\n    # We want smaller positive differences to have higher priority.\n    \n    # Let's use the inverse of the remaining space as priority.\n    # priority = 1 / (remaining_space + 1) where remaining_space = bins_remain_cap - item\n    # This means a difference of 0 gives priority 1, difference of 1 gives 0.5, etc.\n    \n    # Consider a penalty for not being an exact fit.\n    # Or, assign a score based on the \"closeness\" to an exact fit.\n    \n    # Let's use a score that is high for exact fits, and then decreases as the remaining space increases.\n    \n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Condition for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # For bins that can fit, calculate the remaining capacity after placing the item\n    remaining_capacities_after_fit = bins_remain_cap[can_fit_mask] - item\n    \n    # Calculate priorities for these fitting bins.\n    # We want to prioritize bins with smaller remaining capacity.\n    # A good mapping is `1.0 / (remaining_capacities_after_fit + 1.0)` which results in values between 0 and 1.\n    # Exact fits (remaining_capacities_after_fit == 0) get a priority of 1.0.\n    # Other fits get values less than 1.0.\n    \n    # To make exact fits even more dominant, we can multiply by a large factor or add a bonus.\n    \n    # Let's use a simple heuristic:\n    # Priority = 1.0 if exact fit\n    # Priority = 1.0 / (remaining_capacity + 1.0) for other fitting bins\n    # Where remaining_capacity = bins_remain_cap - item\n    \n    # Assign priority of 0 initially to all bins\n    priorities[:] = 0.0\n    \n    # Identify bins that can fit the item\n    fitting_bins_indices = np.where(bins_remain_cap >= item)[0]\n    \n    # If there are fitting bins\n    if fitting_bins_indices.size > 0:\n        # Calculate remaining capacity for fitting bins\n        remaining_caps = bins_remain_cap[fitting_bins_indices] - item\n        \n        # Assign priorities:\n        # Exact fits get a higher priority (e.g., 1.0)\n        # For other fitting bins, assign a priority that is inversely related to the remaining capacity.\n        # Let's use 1.0 - (remaining_cap / some_max_cap_or_1.0) for a linear decrease.\n        # Or `1.0 / (remaining_cap + 1.0)` which is `1.0` for exact fit and decreases.\n        \n        # Let's try assigning a priority based on the inverse of the remaining capacity + 1\n        # Higher value means better fit.\n        # Exact fit (remaining_cap = 0) -> priority = 1.0\n        # Remaining cap = 1 -> priority = 0.5\n        # Remaining cap = 5 -> priority = 1/6\n        \n        # We want the \"best\" fit to be chosen.\n        # Let's consider the \"waste\" (remaining capacity). We want to minimize waste.\n        \n        # Heuristic: prioritize bins where `bins_remain_cap - item` is smallest non-negative.\n        \n        # Calculate the difference for all bins that can fit\n        diffs = bins_remain_cap[fitting_bins_indices] - item\n        \n        # Assign priorities:\n        # Higher priority for smaller differences.\n        # A simple inverse relationship: `1.0 / (diff + epsilon)` or a bounded value.\n        \n        # Let's assign priority:\n        # exact_fit_priority = 1.0\n        # general_fit_priority = 1.0 - (diff / max_possible_bin_size) (if max_possible_bin_size is known)\n        \n        # A robust way for exact fit first:\n        # Identify exact fits. Give them a high, unique priority.\n        # For non-exact fits, sort them by the smallest positive remaining capacity.\n        \n        # Let's combine these:\n        # Assign priority = -diff. The minimum diff will have the maximum priority.\n        # For exact fits (diff=0), this gives 0.\n        # For diffs > 0, these are negative.\n        # We want exact fits to be highest, so we can add a large constant.\n        \n        # Option: give exact fits priority 1.0, and other fits a priority < 1.0.\n        # For bins that fit:\n        # priority = (max_remaining_capacity_among_fitting_bins - (bins_remain_cap[i] - item)) / max_remaining_capacity_among_fitting_bins\n        # This normalizes priorities to be between 0 and 1.\n        \n        # Let's create a score that is higher for smaller remaining capacity.\n        # Score = 1 / (1 + remaining_capacity)\n        # For exact fits (remaining_capacity = 0), score is 1.0.\n        # For remaining_capacity = 1, score is 0.5.\n        # For remaining_capacity = 5, score is 1/6.\n        \n        # We can also consider how \"tight\" the fit is as a secondary criterion if exact fits aren't available.\n        \n        # Let's try this:\n        # If an exact fit exists, assign it the highest possible priority.\n        # If multiple exact fits exist, any of them is fine.\n        # If no exact fit, assign priorities based on how close the remaining capacity is to the item size.\n        \n        # Let's simplify: assign a priority to each bin.\n        # For each bin:\n        # If bin can fit the item:\n        #   Calculate remaining space `r = bins_remain_cap[i] - item`.\n        #   Assign a priority based on `r`. We want small `r` to have high priority.\n        #   Example: priority = 1.0 / (r + 1.0)\n        # Else (bin cannot fit):\n        #   priority = 0.0\n        \n        # To make \"exact fit first\" more pronounced:\n        # Priority = 1.0 for exact fits (r=0).\n        # Priority = 1.0 - (r / max_possible_remaining_capacity) for other fits.\n        \n        # Let's use a score that emphasizes exact fits strongly:\n        # A score that is 1.0 for exact fit and decreases as difference increases.\n        # Example: score = exp(-k * (bins_remain_cap[i] - item)) for some k.\n        # Or simply: score = 1.0 - (bins_remain_cap[i] - item) / MAX_CAPACITY.\n        \n        # Let's define a scoring function that prioritizes minimal non-negative difference.\n        # For bins that can fit: `priority = C - (bins_remain_cap - item)` where C is a large constant.\n        # This ensures smaller differences are ranked higher.\n        \n        # Let's assign priority values.\n        # For each bin that can fit:\n        # priority = 1.0 / (1.0 + (bins_remain_cap[i] - item))\n        # This gives a priority of 1.0 for exact fits, and values between 0 and 1 for others.\n        # Bins that cannot fit will have priority 0.\n        \n        priorities[fitting_bins_indices] = 1.0 / (1.0 + remaining_capacities_after_fit)\n        \n        # To ensure exact fits are strictly preferred if they exist, we can add a bonus to them.\n        # For instance, multiply the priority of exact fits by a large factor.\n        exact_fit_indices = fitting_bins_indices[remaining_capacities_after_fit == 0]\n        if exact_fit_indices.size > 0:\n            priorities[exact_fit_indices] *= 100.0 # Give a significant boost to exact fits\n            \n    return priorities",
    "response_id": 14,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 20.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins_mask = bins_remain_cap >= item\n    valid_bins_capacities = bins_remain_cap[valid_bins_mask]\n\n    if valid_bins_capacities.size > 0:\n        inverse_distances = 1.0 / (bins_remain_cap[valid_bins_mask] - item + 1e-9)\n        priorities[valid_bins_mask] = inverse_distances\n\n    return priorities",
    "response_id": 15,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 8.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    bins_can_fit = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    available_bins_cap = bins_remain_cap[bins_can_fit]\n    if available_bins_cap.size > 0:\n        ratios = available_bins_cap / item\n        sigmoids = 1 / (1 + np.exp(-ratios + 5))\n        priorities[bins_can_fit] = sigmoids\n    return priorities",
    "response_id": 16,
    "tryHS": false,
    "obj": 149.27203829278022,
    "SLOC": 9.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response17.txt_stdout.txt",
    "code_path": "problem_iter1_code17.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    available_bins_mask = bins_remain_cap >= item\n    available_bins_capacities = bins_remain_cap[available_bins_mask]\n\n    if available_bins_capacities.size > 0:\n        priorities[available_bins_mask] = available_bins_capacities - item\n        \n        # Introduce a bit of randomness for exploration, like nudging things around.\n        # The idea is to sometimes pick a slightly worse fit to see if it opens up better opportunities later.\n        # Not too much, just a gentle push. Think of it as trying out a slightly different path.\n        random_noise = np.random.normal(0, np.std(available_bins_capacities) * 0.05, available_bins_capacities.shape)\n        priorities[available_bins_mask] = priorities[available_bins_mask] + random_noise\n\n    return priorities",
    "response_id": 17,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 9.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response18.txt_stdout.txt",
    "code_path": "problem_iter1_code18.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-6)\n    return priorities",
    "response_id": 18,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 6.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Softmax-Based Fit.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    valid_bins_mask = bins_remain_cap >= item\n    valid_bins_remain_cap = bins_remain_cap[valid_bins_remain_cap]\n\n    if not valid_bins_remain_cap.size:\n        return np.zeros_like(bins_remain_cap)\n\n    # Calculate the \"fit\" metric: remaining capacity after placing the item\n    fits = valid_bins_remain_cap - item\n\n    # Use a Softmax-like function to convert fits into priorities.\n    # We want higher fits (more remaining capacity) to have higher priority.\n    # Adding a small epsilon to avoid numerical issues with exp(0) if all fits are 0.\n    # Scaling by a factor (e.g., 10) can make the differences more pronounced.\n    scaled_fits = fits * 10.0\n    exp_fits = np.exp(scaled_fits)\n    priorities = exp_fits / np.sum(exp_fits)\n\n    # Create the final priorities array, placing calculated priorities in valid bin slots\n    final_priorities = np.zeros_like(bins_remain_cap)\n    final_priorities[valid_bins_remain_cap >= item] = priorities\n\n    return final_priorities",
    "response_id": 19,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 14, in priority_v2\n    priorities[i] = 1.0 / (remaining_after_fit + 1e-6)\nUnboundLocalError: local variable 'valid_bins_remain_cap' referenced before assignment\n12\n2\n"
  },
  {
    "stdout_filepath": "problem_iter1_response20.txt_stdout.txt",
    "code_path": "problem_iter1_code20.py",
    "code": null,
    "response_id": 20,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Invalid response!"
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": null,
    "response_id": 21,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Invalid response!"
  },
  {
    "stdout_filepath": "problem_iter1_response22.txt_stdout.txt",
    "code_path": "problem_iter1_code22.py",
    "code": null,
    "response_id": 22,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Invalid response!"
  },
  {
    "stdout_filepath": "problem_iter1_response23.txt_stdout.txt",
    "code_path": "problem_iter1_code23.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            remaining_after_fit = cap - item\n            if remaining_after_fit == 0:\n                priorities[i] = 1.0\n            else:\n                priorities[i] = 1.0 / (remaining_after_fit + 1e-6)\n    return priorities",
    "response_id": 23,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 10.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response24.txt_stdout.txt",
    "code_path": "problem_iter1_code24.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = bins_remain_cap[i] - item\n        else:\n            priorities[i] = -float('inf')\n    return priorities",
    "response_id": 24,
    "tryHS": false,
    "obj": 149.30195452732352,
    "SLOC": 8.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response25.txt_stdout.txt",
    "code_path": "problem_iter1_code25.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    suitable_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[suitable_bins_mask] = 1.0 / (bins_remain_cap[suitable_bins_mask] - item + 1e-9)\n    return priorities",
    "response_id": 25,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 5.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response26.txt_stdout.txt",
    "code_path": "problem_iter1_code26.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    suitable_bins_mask = bins_remain_cap >= item\n    \n    suitable_bins_capacities = bins_remain_cap[suitable_bins_mask]\n    \n    if suitable_bins_capacities.size == 0:\n        return np.zeros_like(bins_remain_cap)\n    \n    gaps = suitable_bins_capacities - item\n    \n    scaled_gaps = 1 / (1 + np.exp(-gaps * 0.5)) \n    \n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[suitable_bins_mask] = scaled_gaps\n    \n    return priorities",
    "response_id": 26,
    "tryHS": false,
    "obj": 9.473474272038294,
    "SLOC": 10.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response27.txt_stdout.txt",
    "code_path": "problem_iter1_code27.py",
    "code": "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    priorities = np.zeros_like(bins_remain_cap)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            priorities[i] = 1.0 / (bins_remain_cap[i] - item + 1e-9)\n    return priorities",
    "response_id": 27,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 6.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response28.txt_stdout.txt",
    "code_path": "problem_iter1_code28.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Implements an epsilon-greedy strategy for online Bin Packing.\n    The priority function favors bins that can fit the item and\n    prioritizes those with less remaining capacity (Best Fit).\n    With probability epsilon, it randomly selects a bin that can fit the item.\n    \"\"\"\n    epsilon = 0.1  # Exploration probability\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    possible_bins = np.where(bins_remain_cap >= item)[0]\n\n    if len(possible_bins) == 0:\n        return priorities  # No bin can fit the item\n\n    if np.random.rand() < epsilon:\n        # Exploration: Randomly choose a bin that can fit the item\n        chosen_bin_index = np.random.choice(possible_bins)\n        priorities[chosen_bin_index] = 1.0\n    else:\n        # Exploitation: Best Fit strategy - prioritize bins with least remaining capacity\n        fitting_bins_capacities = bins_remain_cap[possible_bins]\n        # Calculate difference between capacity and item size for fitting bins\n        diffs = fitting_bins_capacities - item\n        # Find the index of the bin with the minimum difference among possible bins\n        best_fit_index_in_possible = np.argmin(diffs)\n        # Get the original index of this bin in the bins_remain_cap array\n        best_fit_original_index = possible_bins[best_fit_index_in_possible]\n        priorities[best_fit_original_index] = 1.0\n\n    return priorities",
    "response_id": 28,
    "tryHS": false,
    "obj": 4.198244914240141,
    "SLOC": 17.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin using Softmax-Based Fit strategy.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    valid_bins_mask = bins_remain_cap >= item\n    \n    if not np.any(valid_bins_mask):\n        return np.zeros_like(bins_remain_cap)\n\n    valid_bins_remain_cap = bins_remain_cap[valid_bins_remain_cap]\n    \n    # Softmax-Based Fit: Prioritize bins that are a good fit, but also consider those with more remaining space.\n    # A simple approach is to use the negative difference between capacity and item size as a \"desirability\" score.\n    # Smaller differences are more desirable (better fit).\n    desirability = -(valid_bins_remain_cap - item)\n    \n    # Apply softmax to turn desirability into probabilities (priorities)\n    # We can add a temperature parameter to control the \"greediness\" of the selection.\n    # A higher temperature leads to a more uniform distribution, a lower temperature to a more peaked distribution.\n    temperature = 1.0  # This could be a tunable parameter\n    \n    exp_desirability = np.exp(desirability / temperature)\n    probabilities = exp_desirability / np.sum(exp_desirability)\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    priorities[valid_bins_remain_cap >= item] = probabilities\n    \n    return priorities",
    "response_id": 29,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 18, in priority_v2\n    # Consider bins that can fit the item\nUnboundLocalError: local variable 'valid_bins_remain_cap' referenced before assignment\n12\n2\n"
  }
]