```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines tight-fit preference with a penalty for empty bins,
    favoring fuller bins and efficient space utilization.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    epsilon = 1e-9

    # Mask for bins that can fit the item
    can_fit_mask = bins_remain_cap >= item

    # Calculate tightness score: inverse of remaining capacity after packing
    # Higher score for bins that leave less remaining space
    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]
    remaining_after_packing = fitting_bins_remain_cap - item
    tightness_score = np.zeros_like(bins_remain_cap, dtype=float)
    tightness_score[can_fit_mask] = 1.0 / (remaining_after_packing + epsilon)

    # Calculate penalty for empty bins. This encourages using existing bins.
    # An empty bin is one whose remaining capacity is equal to the maximum possible bin capacity.
    # We need to find the actual maximum capacity across all bins if they are not uniform.
    # However, for simplicity and common BPP scenarios, we assume a standard bin capacity.
    # A robust approach would require bin capacity as an input or infer it.
    # For this example, let's assume `bins_remain_cap` reflects current state, and a bin with
    # capacity equal to its initial maximum (if known) or a very large remaining capacity
    # implies it's effectively "empty" in terms of prior usage.
    # A simpler proxy for "empty" is a very large remaining capacity compared to the item.
    # Let's use a large constant penalty for bins that are significantly underutilized relative to their max potential.
    # A more direct approach is to penalize bins that are still "full" (i.e., have not been used yet).
    # Let's assume an "empty" bin has a remaining capacity equal to the max seen in bins_remain_cap.
    
    # This logic aims to combine the "tight fit" of Heuristic 4 with the "penalty for empty bins" of Heuristic 17.
    # We prioritize bins that fit snugly, but if there's a tie or similar fit, we prefer bins that have already been used.
    
    # Penalty for bins that appear "empty" (e.g., have not been utilized).
    # A bin is considered "empty" if its remaining capacity is close to the maximum capacity.
    # Let's assume the maximum capacity of a bin is the largest value found in bins_remain_cap
    # for bins that can fit the item, or a known global bin capacity if provided.
    # For this implementation, we'll use a penalty for bins that are *not* significantly filled.
    # A simple proxy for "not significantly filled" is to consider bins that are still "very full".
    
    # Using the penalty from Heuristic 17: a large constant for empty bins.
    # We need to identify which of the `can_fit_mask` bins are also "empty".
    # A common definition of "empty" in BPP heuristics is a bin that has not yet received any items.
    # If we don't have explicit information about which bins are truly empty vs. just having high remaining capacity,
    # we can approximate it by looking for bins with remaining capacity that is very close to the maximum capacity found.
    
    # For simplicity, let's redefine "empty" as a bin that has *just* enough capacity for the item,
    # and we want to penalize these if better options exist.
    # Alternatively, we can directly apply a penalty to bins that are initially "full".
    # Let's go with a direct penalty for bins that are very close to being full (i.e., their remaining capacity is very large).
    
    # Instead of a fixed large penalty, let's make it relative.
    # We want to discourage packing into a "new" bin if an "existing" bin offers a similar tightness.
    # A heuristic that combines "tight fit" and a "penalty for empty bins" can be achieved by:
    # 1. Calculating tightness scores for all fitting bins.
    # 2. Identifying "empty" bins among the fitting ones (e.g., those with capacity close to the maximum).
    # 3. Reducing the priority of these "empty" bins by a certain factor or offset.
    
    # Let's try a simpler approach that is common: penalize bins that have a lot of remaining space.
    # This is implicitly handled by the inverse of remaining capacity.
    # The "penalty for empty bins" is often to ensure that if a bin has lots of space, we only use it
    # if other bins are not good fits.
    
    # Let's combine Heuristic 4 (tight fit) with a penalty for bins that have a lot of leftover space
    # after packing the item. This is similar to the `oversize_penalty` idea but perhaps simpler.
    
    # The 'tightness_score' already rewards bins with less remaining capacity.
    # The 'penalty for empty bins' is about preferring to fill existing bins.
    # If we consider bins with remaining_after_packing == 0 to be ideal, and larger values to be less ideal,
    # then the inverse already handles this.
    
    # Let's integrate the "penalty for empty bins" by reducing the score of bins that have
    # a large `remaining_after_packing`. This is contrary to the tight-fit idea.
    
    # A better combination: prioritize tight fits. For bins with similar tightness,
    # prefer those that are already partially filled.
    
    # Let's stick to the core idea of Heuristic 4 (tightest fit) and enhance it by
    # penalizing bins that are "too large", similar to the `oversize_penalty` in the `priority_v0` example.
    # This would mean prioritizing bins where `remaining_after_packing` is small.
    
    # Combining tight fit (inverse of remaining space) with a penalty for "excessive" remaining space.
    
    # Let's use the tightness score and add a penalty for bins that have a lot of slack.
    # If a bin has `R` remaining capacity, and item `I` is packed, the new remaining is `R-I`.
    # We want to minimize `R-I`.
    # The `tightness_score` does this: `1 / (R-I + epsilon)`.
    
    # For the "penalty for empty bins": This is meant to encourage using partially filled bins before new ones.
    # If we consider bins with `bins_remain_cap` close to some maximum capacity as "empty",
    # we should reduce their priority.
    
    # Let's define a threshold for "empty". A bin might be considered "empty" if its remaining capacity
    # is, say, more than 75% of the maximum capacity encountered.
    
    # Let's consider the combined logic of tight-fit and a penalty for bins that are
    # unnecessarily large for the item.
    
    # Recalculate tightness: higher for smaller remaining capacity after packing
    # This is good.
    
    # Consider a penalty for bins that are "overly large" for the item.
    # If `bins_remain_cap[i]` is much larger than `item`, we might want to penalize it.
    # For instance, if `bins_remain_cap[i] > 2 * item`, apply a penalty.
    
    oversize_penalty_factor = 2.0 # Penalize if bin capacity is more than twice the item size
    penalty_value = 0.5 # Reduce priority by this factor
    
    oversize_penalties = np.ones_like(bins_remain_cap, dtype=float)
    oversize_mask = (bins_remain_cap > oversize_penalty_factor * item) & can_fit_mask
    oversize_penalties[oversize_mask] = penalty_value
    
    # Combine tightness score with oversize penalty
    # We want to amplify tightness, and reduce for oversized bins.
    # A multiplicative approach seems suitable.
    
    combined_score = tightness_score * oversize_penalties
    
    # Normalize priorities to avoid extremely large values and ensure a fair comparison.
    max_score = np.max(combined_score)
    if max_score > 0:
        priorities[can_fit_mask] = combined_score[can_fit_mask] / max_score
        
    # Now, let's add the "penalty for empty bins".
    # This means if a bin is "empty" and also fits the item, reduce its priority.
    # Let's define "empty" as having remaining capacity equal to the *initial* capacity of that bin.
    # Without initial capacities, we can use a proxy: bins with remaining capacity above a certain threshold.
    # For instance, if remaining capacity is > 90% of the max capacity observed among fitting bins.
    
    # Let's use a simpler interpretation: "empty" bins are those that are initially full.
    # If we have no information about initial fill, we can use a proxy: bins that are currently
    # much larger than the item. This is already somewhat handled by `oversize_penalties`.
    
    # A more direct interpretation of "penalty for empty bins" from Heuristic 17:
    # Apply a significant reduction to bins that are still "full" (i.e., have high remaining capacity).
    # Let's consider bins with `bins_remain_cap >= item` as candidates.
    # Among these, identify those that are "empty".
    # A simple approach to identify "empty" bins is to look at bins whose remaining capacity
    # is very close to a common maximum bin capacity. If we don't know the max capacity,
    # we can use the maximum value in `bins_remain_cap` as a reference.
    
    # Let's implement a penalty that reduces the priority of bins that have
    # a large amount of slack *after* the item is placed. This is related to
    # minimizing waste.
    
    # Consider the "waste" as `bins_remain_cap - item` for fitting bins.
    # We want to minimize waste. The `tightness_score` already does this.
    
    # Let's focus on the explicit "penalty for empty bins".
    # A common interpretation is that if we have partially filled bins, we should
    # prefer them over completely new (empty) bins.
    # If `bins_remain_cap` represents the state, and we don't know initial states,
    # we can approximate "empty" bins as those with very large `bins_remain_cap`.
    
    # Let's combine Heuristic 4 (tight fit) with Heuristic 17 (penalty for empty bins).
    # Heuristic 4: `1.0 / (bins_remain_cap - item + epsilon)`
    # Heuristic 17: Penalize "empty" bins.
    
    # Let's define "empty" as `bins_remain_cap` being very close to some `MAX_CAPACITY`.
    # Without `MAX_CAPACITY`, we can use a relative measure: is `bins_remain_cap`
    # very large compared to `item`? The `oversize_penalties` handle this.
    
    # Let's refine the "penalty for empty bins" by considering bins that have
    # a large amount of *available* space for *future* items, relative to the current item.
    # This is about balancing immediate fit with future potential.
    
    # Combining "tight fit" (Heuristic 4) and "prefer partially filled bins"
    # (a common strategy for "penalty for empty bins").
    
    # Let's define a score based on how "full" the bin is *before* packing.
    # `fill_ratio = (BIN_CAPACITY - bins_remain_cap) / BIN_CAPACITY`. We'd need BIN_CAPACITY.
    # A proxy: `1 - (bins_remain_cap / MAX_REMAINING_CAP)`.
    
    # Alternative: Prioritize bins with small `bins_remain_cap` (tight fit) first.
    # Then, among those with similar tightness, prefer those that are *not* "empty".
    # "Empty" can mean `bins_remain_cap` is very large.
    
    # Let's go with the most direct combination of Heuristic 4 and the concept of
    # "penalty for empty bins" interpreted as penalizing bins with *large* remaining capacity.
    
    # 1. Calculate tightness score (inverse of slack).
    # 2. Apply a penalty to bins with large slack *after* packing.
    
    # The `tightness_score` already penalizes bins with large slack.
    # `tightness_score[can_fit_mask] = 1.0 / (bins_remain_cap[can_fit_mask] - item + epsilon)`
    
    # Now, add a penalty for bins that have a large *initial* remaining capacity.
    # Let's assume an "empty" bin is one with `bins_remain_cap` significantly larger than `item`.
    # This is similar to `oversize_penalty` but applied differently.
    
    # Let's use a penalty on the `tightness_score` itself.
    # If `bins_remain_cap[i]` is large, we want to reduce its priority.
    # A simple penalty: `1 / (1 + k * bins_remain_cap[i])`.
    
    penalty_factor_slack = 0.1 # Adjust this to control the penalty for slack
    slack_penalty = np.ones_like(bins_remain_cap, dtype=float)
    
    # Apply penalty to bins that can fit, based on their *initial* remaining capacity.
    # A larger initial remaining capacity gets a higher penalty (lower score).
    slack_penalty[can_fit_mask] = 1.0 / (1.0 + penalty_factor_slack * bins_remain_cap[can_fit_mask])
    
    # Combine tightness score and slack penalty.
    # We want high tightness, but also penalize large initial slack.
    # Multiplication is a good way to combine these:
    # `priority = tightness_score * slack_penalty`
    
    combined_score = tightness_score * slack_penalty
    
    # Normalize to ensure priorities are in a comparable range (e.g., 0 to 1)
    max_score = np.max(combined_score)
    if max_score > 0:
        priorities[can_fit_mask] = combined_score[can_fit_mask] / max_score
        
    # Ensure that bins that cannot fit have a priority of 0, which is already set.
    return priorities
```
