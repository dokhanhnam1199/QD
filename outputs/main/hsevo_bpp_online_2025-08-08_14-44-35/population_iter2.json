[
  {
    "stdout_filepath": "problem_iter2_response0.txt_stdout.txt",
    "code_path": "problem_iter2_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines the tight-fitting priority of inverse remaining capacity\n    with an epsilon-greedy exploration strategy for better bin packing.\n    \"\"\"\n    epsilon = 0.1  # Probability of exploring a random bin\n\n    # Calculate priorities based on tightest fit (inverse remaining capacity)\n    # Only consider bins that can fit the item\n    fit_mask = bins_remain_cap >= item\n    tight_fit_priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Add a small epsilon to avoid division by zero if remaining capacity == item\n    valid_capacities = bins_remain_cap[fit_mask] - item + 1e-9\n    tight_fit_priorities[fit_mask] = 1.0 / valid_capacities\n\n    # Normalize priorities so they sum to 1 (if no exploration)\n    sum_priorities = np.sum(tight_fit_priorities)\n    if sum_priorities > 0:\n        normalized_priorities = tight_fit_priorities / sum_priorities\n    else:\n        # If no bins can fit the item, assign equal probability to all (effectively a new bin)\n        normalized_priorities = np.ones_like(bins_remain_cap) / len(bins_remain_cap)\n\n    # Epsilon-greedy: explore randomly with probability epsilon\n    exploration_priorities = np.ones_like(bins_remain_cap) / len(bins_remain_cap)\n    \n    # Combine exploitation (tight fit) and exploration (random)\n    # With probability (1 - epsilon), choose the tight fit priority\n    # With probability epsilon, choose the exploration priority\n    combined_priorities = (1 - epsilon) * normalized_priorities + epsilon * exploration_priorities\n\n    # Ensure probabilities sum to 1 (due to potential floating point inaccuracies or edge cases)\n    final_priorities = combined_priorities / np.sum(combined_priorities)\n\n    return final_priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 15.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response1.txt_stdout.txt",
    "code_path": "problem_iter2_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines the inverse remaining capacity strategy with a sigmoid function for smoother prioritization.\n    It favors bins with smaller remaining capacity after placing the item, using a sigmoid to normalize scores.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i in range(len(bins_remain_cap)):\n        if bins_remain_cap[i] >= item:\n            remaining_capacity = bins_remain_cap[i] - item\n            # Use inverse of remaining capacity, scaled by sigmoid to smooth prioritization\n            # Adding a small epsilon to denominator to avoid division by zero\n            # Scaling factor (e.g., 5.0) can be tuned to control sensitivity\n            priorities[i] = 1 / (remaining_capacity + 1e-9)\n            \n    # Normalize priorities using sigmoid to create a smoother distribution and avoid extreme values\n    # The sigmoid function squashes values between 0 and 1\n    # We can scale the input to sigmoid to control the steepness of the transition\n    # Using a simple division by the maximum priority to prevent overflow and normalize\n    max_priority = np.max(priorities)\n    if max_priority > 0:\n        normalized_priorities = priorities / max_priority\n        # Apply sigmoid\n        return 1 / (1 + np.exp(-5.0 * (normalized_priorities - 0.5))) # Tunable steepness factor 5.0\n    else:\n        return np.zeros_like(bins_remain_cap, dtype=float)",
    "response_id": 1,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99996592500247 seconds"
  },
  {
    "stdout_filepath": "problem_iter2_response2.txt_stdout.txt",
    "code_path": "problem_iter2_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines the \"tightest fit\" priority of inverse remaining capacity with an\n    epsilon-greedy exploration strategy. Favors bins that leave minimal space\n    after packing, with a small chance of selecting a random suitable bin.\n    \"\"\"\n    suitable_bins_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if np.any(suitable_bins_mask):\n        suitable_bins_remain_cap = bins_remain_cap[suitable_bins_mask]\n        \n        # Prioritize bins with the tightest fit (inverse remaining capacity)\n        tight_fit_priorities = 1.0 / (suitable_bins_remain_cap - item + 1e-9)\n        \n        # Normalize tight fit priorities for a smoother distribution\n        normalized_tight_fit_priorities = (tight_fit_priorities - np.min(tight_fit_priorities)) / \\\n                                          (np.max(tight_fit_priorities) - np.min(tight_fit_priorities) + 1e-9)\n        \n        # Introduce epsilon-greedy exploration: a small chance to pick any suitable bin\n        epsilon = 0.1\n        random_priorities = np.random.rand(np.sum(suitable_bins_mask))\n        \n        # Combine tight fit and random exploration\n        combined_priorities = (1 - epsilon) * normalized_tight_fit_priorities + epsilon * random_priorities\n        \n        priorities[suitable_bins_mask] = combined_priorities\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 13.0,
    "cyclomatic_complexity": 2.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response3.txt_stdout.txt",
    "code_path": "problem_iter2_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines Best Fit with an adaptive exploration strategy.\n    It prioritizes bins with the tightest fit, but with a probability,\n    explores other fitting bins to avoid getting stuck in local optima.\n    \"\"\"\n    epsilon = 0.1  # Probability of exploration\n    n_bins = len(bins_remain_cap)\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    possible_bins_indices = np.where(bins_remain_cap >= item)[0]\n\n    if len(possible_bins_indices) == 0:\n        return priorities  # No bin can fit the item\n\n    # Exploration phase: with probability epsilon, choose a random fitting bin\n    if np.random.rand() < epsilon:\n        chosen_bin_index = np.random.choice(possible_bins_indices)\n        priorities[chosen_bin_index] = 1.0\n    else:\n        # Exploitation phase: Best Fit strategy\n        fitting_bins_capacities = bins_remain_cap[possible_bins_indices]\n        # Calculate the 'gap' or remaining capacity after fitting the item\n        gaps = fitting_bins_capacities - item\n        # Find the index within the 'possible_bins_indices' array that has the minimum gap\n        best_fit_in_possible_idx = np.argmin(gaps)\n        # Get the original index of this best-fitting bin\n        best_fit_original_idx = possible_bins_indices[best_fit_in_possible_idx]\n        priorities[best_fit_original_idx] = 1.0\n\n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.148384523334677,
    "SLOC": 17.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response4.txt_stdout.txt",
    "code_path": "problem_iter2_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines inverse remaining capacity with a penalty for empty bins,\n    favoring tighter fits while encouraging filling existing bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-6\n    \n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            remaining_after_fit = cap - item\n            \n            # Favor tighter fits (inverse remaining capacity)\n            priority_fit = 1.0 / (remaining_after_fit + epsilon)\n            \n            # Penalty for completely empty bins if not an exact fit\n            # This encourages using existing bins before opening new ones unless it's an exact fit\n            if cap > item and cap == bins_remain_cap[i]: # if bin was initially empty\n                priority_fit *= 0.8 # slight penalty for using an empty bin\n                \n            priorities[i] = priority_fit\n            \n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.9999738750048 seconds"
  },
  {
    "stdout_filepath": "problem_iter2_response5.txt_stdout.txt",
    "code_path": "problem_iter2_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins by favoring tighter fits (inverse remaining capacity) while adding a penalty for completely empty bins.\"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Identify bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n\n    # Calculate priorities for suitable bins: higher priority for less remaining capacity (tighter fit)\n    # Add a small epsilon to avoid division by zero if a bin is exactly full\n    epsilon = 1e-9\n    suitable_bins_capacity = bins_remain_cap[suitable_bins_mask]\n    priorities[suitable_bins_mask] = 1.0 / (suitable_bins_capacity - item + epsilon)\n\n    # Apply a penalty to bins that are completely empty to encourage packing into existing bins first.\n    # Bins with remaining capacity equal to the bin capacity are considered empty.\n    # This penalty is designed to be significantly larger than any priority value from the inverse capacity calculation.\n    empty_bins_mask = bins_remain_cap == np.max(bins_remain_cap) # Assuming max capacity is the bin size\n    \n    # Ensure we only penalize empty bins that are also suitable\n    empty_and_suitable_mask = empty_bins_mask & suitable_bins_mask\n    \n    # A large constant to penalize empty bins. This ensures they are considered only after non-empty bins are exhausted.\n    empty_bin_penalty = 1e6  \n    priorities[empty_and_suitable_mask] = empty_bin_penalty\n\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "obj": 86.58755484643,
    "SLOC": 11.0,
    "cyclomatic_complexity": 1.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response6.txt_stdout.txt",
    "code_path": "problem_iter2_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prioritizes bins by favoring tighter fits and incorporating a soft epsilon-greedy exploration.\n    Combines inverse remaining capacity with a small probability of choosing a random bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    suitable_bins_mask = bins_remain_cap >= item\n\n    suitable_bins_capacities = bins_remain_cap[suitable_bins_mask]\n\n    if suitable_bins_capacities.size > 0:\n        gaps = suitable_bins_capacities - item\n        \n        # Inverse remaining capacity for tightest fits\n        # Add a small epsilon to avoid division by zero and make priorities finite\n        inverse_gaps = 1.0 / (gaps + 1e-6)\n        \n        # Normalize priorities to be between 0 and 1 (similar to softmax idea but simpler)\n        # This rewards bins with smaller remaining capacity more\n        max_inverse_gap = np.max(inverse_gaps)\n        if max_inverse_gap > 0:\n            normalized_priorities = inverse_gaps / max_inverse_gap\n        else:\n            normalized_priorities = np.ones_like(inverse_gaps) # All bins have 0 gap after fit\n\n        priorities[suitable_bins_mask] = normalized_priorities\n        \n    # Introduce a small probability of choosing any suitable bin to encourage exploration\n    # This is a simplified epsilon-greedy approach.\n    epsilon = 0.05\n    num_suitable_bins = np.sum(suitable_bins_mask)\n    \n    if num_suitable_bins > 0:\n        # Assign a small, uniform probability to all suitable bins\n        exploration_prob = epsilon / num_suitable_bins\n        priorities[suitable_bins_mask] += exploration_prob\n\n        # Re-normalize to ensure the sum of probabilities for suitable bins is manageable\n        # This step ensures that exploration doesn't completely dominate exploitation\n        sum_priorities = np.sum(priorities[suitable_bins_mask])\n        if sum_priorities > 0:\n             priorities[suitable_bins_mask] /= sum_priorities\n\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 22.0,
    "cyclomatic_complexity": 5.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response7.txt_stdout.txt",
    "code_path": "problem_iter2_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Prioritizes bins by inverse remaining capacity with adaptive exploration.\n\n    Combines the tight-fit preference of inverse remaining capacity with\n    a controlled exploration mechanism similar to epsilon-greedy.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins_mask = bins_remain_cap >= item\n    valid_bins_capacities = bins_remain_cap[valid_bins_mask]\n\n    if valid_bins_capacities.size > 0:\n        # Primary heuristic: Prioritize bins with tighter fits (inverse remaining capacity)\n        inverse_distances = 1.0 / (bins_remain_cap[valid_bins_mask] - item + 1e-9)\n        priorities[valid_bins_mask] = inverse_distances\n\n        # Adaptive exploration: Introduce a small probability of choosing a non-best fit\n        # This helps prevent getting stuck in local optima.\n        # The exploration probability can be tuned. Here, we use a small fixed probability.\n        exploration_prob = 0.05\n        num_valid_bins = valid_bins_capacities.size\n        \n        if num_valid_bins > 1:\n            # Randomly select a subset of valid bins to give a small boost,\n            # simulating exploration. This is a simplified epsilon-greedy approach.\n            exploration_indices_in_valid = np.random.choice(num_valid_bins, \n                                                          size=max(1, int(num_valid_bins * exploration_prob)), \n                                                          replace=False)\n            \n            # Get the actual indices in the original bins_remain_cap array\n            exploration_indices_in_original = np.where(valid_bins_mask)[0][exploration_indices_in_valid]\n            \n            # Add a small, uniform boost to these bins to make them potentially selectable\n            # even if they are not the absolute tightest fit.\n            priorities[exploration_indices_in_original] += 1e-6 # A small boost\n\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "obj": 4.048663741523748,
    "SLOC": 16.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response8.txt_stdout.txt",
    "code_path": "problem_iter2_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Combines Inverse Distance with an epsilon-greedy strategy for exploration.\n\n    Prioritizes bins with a tighter fit (less waste) while occasionally\n    exploring other bins to avoid local optima.\n    \"\"\"\n    available_bins_mask = bins_remain_cap >= item\n    available_bins_cap = bins_remain_cap[available_bins_mask]\n\n    if available_bins_cap.size == 0:\n        return np.zeros_like(bins_remain_cap)\n\n    waste = available_bins_cap - item\n    priorities = 1.0 / (waste + 1e-9)\n\n    full_priorities = np.zeros_like(bins_remain_cap)\n    full_priorities[available_bins_mask] = priorities\n\n    epsilon = 0.1  # Exploration rate\n    num_available_bins = available_bins_mask.sum()\n\n    if num_available_bins > 0 and np.random.rand() < epsilon:\n        # Randomly select an available bin for exploration\n        random_indices = np.where(available_bins_mask)[0]\n        random_bin_index = np.random.choice(random_indices)\n        full_priorities[random_bin_index] = np.max(full_priorities) + 1.0 # Boost priority for exploration\n\n    return full_priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 5.434782608695652,
    "SLOC": 16.0,
    "cyclomatic_complexity": 4.0,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter2_response9.txt_stdout.txt",
    "code_path": "problem_iter2_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines the tight-fitting preference of inverse capacity with adaptive exploration.\n    Prioritizes bins that offer a tighter fit, with a controlled amount of randomness\n    to encourage exploration of potentially better, albeit slightly less optimal, fits.\n    \"\"\"\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Identify bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n    \n    suitable_bins_capacities = bins_remain_cap[suitable_bins_mask]\n    \n    if suitable_bins_capacities.size == 0:\n        return priorities\n    \n    # Calculate the \"gap\" for suitable bins (remaining capacity after placing item)\n    gaps = suitable_bins_capacities - item\n    \n    # Prioritize bins with smaller gaps (tighter fit). Using inverse of (1 + gap)\n    # to ensure a priority score that is higher for smaller gaps.\n    # Adding 1 to the denominator to avoid division by zero and a small epsilon\n    # for numerical stability if gaps can be zero.\n    fit_scores = 1.0 / (1.0 + gaps + 1e-9)\n    \n    # Introduce adaptive exploration: add a small amount of noise based on the std dev\n    # of the fit scores of the suitable bins. This nudges the selection slightly\n    # away from purely greedy choices, promoting exploration.\n    if fit_scores.size > 0:\n        std_dev_fit_scores = np.std(fit_scores)\n        random_noise = np.random.normal(0, std_dev_fit_scores * 0.05, fit_scores.shape)\n        priorities[suitable_bins_mask] = fit_scores + random_noise\n    \n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.307937774232155,
    "SLOC": 13.0,
    "cyclomatic_complexity": 3.0,
    "exec_success": true
  }
]