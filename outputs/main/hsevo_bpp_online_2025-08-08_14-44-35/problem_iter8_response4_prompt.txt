{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines tight packing (inverse remaining capacity after item) with an\n    epsilon-greedy exploration strategy for selecting bins.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    can_fit_mask = bins_remain_cap >= item\n    \n    if not np.any(can_fit_mask):\n        return priorities\n\n    available_bins_cap = bins_remain_cap[can_fit_mask]\n    \n    # Calculate tight fit score: higher for less remaining capacity after packing\n    epsilon = 1e-9\n    tight_fit_scores = 1.0 / (available_bins_cap - item + epsilon)\n    \n    # Normalize tight fit scores to be between 0 and 1\n    max_tight_fit = np.max(tight_fit_scores)\n    if max_tight_fit > 0:\n        normalized_tight_fit = tight_fit_scores / max_tight_fit\n    else:\n        normalized_tight_fit = np.zeros_like(tight_fit_scores)\n\n    # Epsilon-greedy exploration: \n    # With probability epsilon, pick a random fitting bin.\n    # Otherwise, pick the bin with the highest tight_fit_score.\n    epsilon = 0.1\n    \n    if np.random.rand() < epsilon:\n        # Exploration: Assign uniform high priority to all fitting bins\n        priorities[can_fit_mask] = 1.0\n    else:\n        # Exploitation: Use normalized tight fit scores\n        priorities[can_fit_mask] = normalized_tight_fit\n        \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines tightest fit with an epsilon-greedy exploration strategy.\n    Prioritizes bins with minimal remaining capacity after packing,\n    with a small chance to select a random fitting bin for exploration.\n    \"\"\"\n    epsilon = 0.1  # Probability of exploration\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    can_fit_mask = bins_remain_cap >= item\n    available_bins_cap = bins_remain_cap[can_fit_mask]\n    \n    if available_bins_cap.size == 0:\n        return priorities\n    \n    # Calculate tightest fit priority (higher for less remaining capacity)\n    waste = available_bins_cap - item\n    tight_fit_scores = 1.0 / (waste + 1e-9)\n    \n    # Apply exploration: with probability epsilon, choose a random fitting bin\n    if np.random.rand() < epsilon:\n        random_indices_in_subset = np.random.choice(len(available_bins_cap), size=1)\n        # Set priority for the randomly chosen bin to be the maximum possible tight fit score\n        # This effectively makes it the most preferred bin during exploration.\n        priorities[can_fit_mask][random_indices_in_subset] = np.max(tight_fit_scores) + 1.0 \n    else:\n        # Otherwise, use the tightest fit scores\n        priorities[can_fit_mask] = tight_fit_scores\n        \n    # Normalize priorities to be between 0 and 1\n    max_priority = np.max(priorities)\n    if max_priority > 0:\n        priorities /= max_priority\n        \n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1 (Epsilon-Greedy Best Fit) with Heuristic 6 (Epsilon-Greedy Best Fit, different normalization/combination), Heuristic 1 is simpler and more direct in its epsilon-greedy implementation by choosing either a random bin or the best fit. Heuristic 6's approach of normalizing and then applying weights and epsilon feels more complex and potentially less robust due to the normalization scaling.\n\nComparing Heuristic 7/8 (Epsilon-Greedy Best Fit, simple score) with Heuristic 12/13 (Epsilon-Greedy Best Fit, boosted random choice), Heuristics 12/13's approach of boosting the random choice's priority might make exploration too dominant, potentially hindering exploitation of good fits. Heuristics 7/8's direct use of normalized tight-fit scores in exploitation is cleaner.\n\nComparing Heuristic 9/10/11 (Multi-objective with adaptive utilization and boosted exploration) with Heuristic 18/19 (Multi-objective with adaptive weights based on available bins), Heuristics 18/19 have a more grounded adaptive weighting strategy based on bin availability, which is a better heuristic for adaptivity than the more generic \"boosted exploration\" in 9/10/11. However, the core objectives in 9/10/11 (tight fit + utilization) might be more generally applicable than the specific balancing in 18/19.\n\nComparing Heuristic 1 (simple epsilon-greedy Best Fit) with Heuristic 2/3/4/5 (complex combination of tight fit and \"penalty for empty bins\"), the latter heuristics attempt to incorporate more nuanced ideas like penalizing slack. However, their implementation is convoluted and the interpretation of \"penalty for empty bins\" is not clearly defined or consistently applied, leading to less straightforward logic. Heuristic 1's simplicity and clear strategy make it more robust.\n\nComparing Heuristic 20 (Worst Fit + Tightness bonus) with Heuristic 18/19 (adaptive multi-objective), Heuristic 20's approach is interesting but the combination of Worst Fit and Tightness bonus, along with the \"less used\" bonus, makes it complex and potentially contradictory in its goals. The adaptive weighting in 18/19 is a more coherent approach to balancing objectives.\n\nOverall, simpler heuristics that clearly define and combine strategies (like Heuristic 1) tend to be better than overly complex ones with ambiguously defined components (like 2-5, 18-20).\n- \nHere's a redefined approach to self-reflection for better heuristic design, focusing on actionable insights:\n\n*   **Keywords:** Performance, adaptability, interpretability, validation.\n*   **Advice:** Design heuristics with clear objectives and simple combination mechanisms. Incorporate adaptive exploration and consider smooth, non-linear scaling for fine-tuning. Prioritize vectorized operations for efficiency.\n*   **Avoid:** Ambiguity in objectives, overly complex components, and buggy implementations. Resist relying solely on linear or binary scaling without justification.\n*   **Explanation:** Focus on making heuristics understandable and maintainable. This clarity aids in identifying bottlenecks and opportunities for improvement through controlled experimentation and validation.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}