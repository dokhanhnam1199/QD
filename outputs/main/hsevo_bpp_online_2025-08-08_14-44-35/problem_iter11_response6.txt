```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines tight-fit preference with adaptive penalty for large bins,
    favoring bins that are neither too full nor too empty relative to item size.
    Uses score normalization for robust comparison.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    epsilon = 1e-9

    can_fit_mask = bins_remain_cap >= item

    if not np.any(can_fit_mask):
        return priorities

    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]

    # Tightness score: Higher for bins leaving less space after packing.
    # This is equivalent to prioritizing bins closer to 'item' size from below.
    tightness_score = 1.0 / (fitting_bins_remain_cap - item + epsilon)

    # Adaptive penalty for "empty" or overly large bins:
    # Penalize bins whose remaining capacity is significantly larger than the item size.
    # We want to reduce the priority of bins that are "too empty" for the current item.
    # A simple way is to use an inverse relationship with the initial remaining capacity.
    # The factor penalizes bins with large remaining capacities, favoring those already somewhat utilized.
    # This is analogous to prioritizing bins that are not "too empty".
    penalty_weight = 0.3
    penalty_score = 1.0 / (1.0 + penalty_weight * fitting_bins_remain_cap)

    # Combine tightness and penalty. A higher combined score means a bin is both a tight fit
    # and not excessively large (i.e., not "too empty").
    combined_score = tightness_score * penalty_score

    # Normalize scores to a 0-1 range for stable comparison across different item/bin states.
    max_score = np.max(combined_score)
    if max_score > 0:
        priorities[can_fit_mask] = combined_score / max_score

    return priorities
```
