```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines tight-fitting preference with adaptive bin utilization and a balanced exploration strategy.
    Prioritizes bins that minimize waste and are more utilized, with controlled random exploration.
    """
    priorities = np.zeros_like(bins_remain_cap, dtype=float)
    epsilon = 1e-9
    exploration_prob = 0.15  # Probability for epsilon-greedy exploration

    can_fit_mask = bins_remain_cap >= item
    
    if not np.any(can_fit_mask):
        return priorities

    available_bins_remain_cap = bins_remain_cap[can_fit_mask]
    
    # --- Heuristic Components ---

    # 1. Tight Fitting (Minimize Waste): Higher score for bins leaving less space.
    remaining_after_packing = available_bins_remain_cap - item
    # Add epsilon to avoid division by zero. Higher score for smaller remaining space.
    tight_fit_scores = 1.0 / (remaining_after_packing + epsilon)

    # 2. Adaptive Bin Utilization: Prefer bins that are already more full.
    # Normalize remaining capacity to reflect utilization. Higher score for less remaining capacity.
    # Avoid division by zero if all bins are empty.
    max_remaining_overall = np.max(bins_remain_cap) if np.any(bins_remain_cap > 0) else 1.0
    utilization_scores = (max_remaining_overall - available_bins_remain_cap + epsilon) / (max_remaining_overall + epsilon)

    # Combine core heuristic scores with equal weighting.
    combined_core_scores = 0.5 * tight_fit_scores + 0.5 * utilization_scores

    # Normalize core scores to be between 0 and 1.
    max_core_score = np.max(combined_core_scores)
    if max_core_score > epsilon:
        normalized_core_scores = combined_core_scores / max_core_score
    else:
        normalized_core_scores = np.zeros_like(combined_core_scores)

    # --- Epsilon-Greedy Exploration ---
    num_available_bins = available_bins_remain_cap.size
    
    # Generate random scores for exploration. The idea is to allow some randomness
    # to potentially discover better packing strategies over time, rather than
    # always picking the deterministically "best" based on current heuristics.
    # We want to give a chance to bins that might not be top-ranked by core heuristics.
    # We generate random numbers and then sort them to get a random permutation.
    random_exploration_scores = np.random.rand(num_available_bins)
    
    # Blend between the deterministic (core) score and the random exploration score.
    # With probability `exploration_prob`, the priority will lean towards the random score.
    # A simple linear interpolation is used: priority = (1-alpha)*core + alpha*random
    # where alpha is `exploration_prob` for some bins, and 0 for others.
    
    # Create a mask for exploration bins.
    is_exploration_bin = np.random.rand(num_available_bins) < exploration_prob
    
    # Calculate final scores: use core scores by default, and exploration scores for chosen bins.
    final_scores = np.where(is_exploration_bin, random_exploration_scores, normalized_core_scores)
    
    # Re-normalize the final scores to ensure they are within a comparable range (0 to 1).
    # This prevents extreme values from dominating due to the random component.
    max_final_score = np.max(final_scores)
    if max_final_score > epsilon:
        priorities[can_fit_mask] = final_scores / max_final_score
    else:
        priorities[can_fit_mask] = final_scores # Should not happen if there are fitting bins, but for safety.

    # Ensure priorities are non-negative (though they should be due to operations).
    priorities[priorities < 0] = 0

    return priorities
```
