{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority with which we want to add item to each bin using an adaptive\n    strategy that balances tight fitting with utilizing bins that are nearly full.\n    This version aims for better performance by considering both the immediate\n    benefit of tight packing and the long-term strategy of keeping larger bins\n    available.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # Identify bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n    \n    # Calculate remaining capacity after packing the item for bins that can fit\n    remaining_after_packing = bins_remain_cap[can_fit_mask] - item\n    \n    # --- Heuristic Design Principles ---\n    # 1. Adaptive Exploration: Dynamically adjust priorities.\n    # 2. Multi-objective Balancing: Combine \"tight fit\" with \"prefer nearly full\".\n    # 3. Dynamic Scaling: Use scaling factors based on context.\n    \n    # Objective 1: Encourage tight packing (similar to v1)\n    # Higher priority for bins that leave less remaining space.\n    # Add a small epsilon to avoid division by zero.\n    epsilon = 1e-9\n    tight_fit_score = 1.0 / (remaining_after_packing + epsilon)\n    \n    # Objective 2: Prefer bins that are already somewhat full but still have space.\n    # This helps in consolidating items and potentially leaving larger bins open for larger items.\n    # The score is higher for bins with less remaining capacity *before* packing.\n    # We use a sigmoid-like function to give a boost to bins that are moderately filled,\n    # not too empty and not completely full.\n    # A simple approach is to use inverse of current remaining capacity, but cap it.\n    # Let's normalize the current remaining capacity for bins that can fit the item.\n    normalized_current_remain_cap = bins_remain_cap[can_fit_mask] / np.max(bins_remain_cap[can_fit_mask] + epsilon) # Normalize by max capacity to keep it within [0, 1]\n    nearly_full_score = 1.0 - normalized_current_remain_cap # Higher score for smaller remaining capacity\n\n    # Combine scores. We can use a weighted sum.\n    # The weights can be thought of as dynamic parameters or set based on observed performance.\n    # For this example, let's give a slight preference to tight fitting, but also reward\n    # using bins that are already somewhat utilized.\n    \n    # Let's assign a weight to each objective.\n    # weight_tight_fit = 0.7\n    # weight_nearly_full = 0.3\n\n    # A more adaptive approach: The preference for tight fit vs. using a nearly full bin\n    # could depend on the item size itself. Smaller items might benefit more from tight fitting,\n    # while larger items might benefit from using bins that are already somewhat full to keep\n    # larger empty bins available.\n\n    # Let's scale the item size relative to the maximum bin capacity available.\n    max_possible_capacity = np.max(bins_remain_cap[can_fit_mask]) if np.any(can_fit_mask) else 1.0\n    relative_item_size = item / (max_possible_capacity + epsilon)\n    \n    # Dynamic weighting:\n    # If item is small (relative_item_size < 0.5), favor tight fit more.\n    # If item is large (relative_item_size >= 0.5), favor using nearly full bins more.\n    weight_tight_fit = 0.4 + 0.6 * (1.0 - relative_item_size) # Range: [0.4, 1.0]\n    weight_nearly_full = 0.6 + 0.4 * relative_item_size      # Range: [0.6, 1.0]\n    # Ensure weights sum to 1 (approximately, due to scaling factors)\n    total_weight = weight_tight_fit + weight_nearly_full\n    weight_tight_fit /= total_weight\n    weight_nearly_full /= total_weight\n    \n\n    combined_score = (weight_tight_fit * tight_fit_score) + (weight_nearly_full * nearly_full_score)\n\n    # Assign the combined scores to the bins that can fit the item\n    priorities[can_fit_mask] = combined_score\n    \n    # Normalize priorities to have a maximum of 1.0. This makes comparisons relative.\n    if np.max(priorities) > 0:\n        priorities /= np.max(priorities)\n        \n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines the tight-fitting preference of inverse capacity with adaptive exploration.\n    Prioritizes bins that offer a tighter fit, with a controlled amount of randomness\n    to encourage exploration of potentially better, albeit slightly less optimal, fits.\n    \"\"\"\n    \n    priorities = np.zeros_like(bins_remain_cap)\n    \n    # Identify bins that can accommodate the item\n    suitable_bins_mask = bins_remain_cap >= item\n    \n    suitable_bins_capacities = bins_remain_cap[suitable_bins_mask]\n    \n    if suitable_bins_capacities.size == 0:\n        return priorities\n    \n    # Calculate the \"gap\" for suitable bins (remaining capacity after placing item)\n    gaps = suitable_bins_capacities - item\n    \n    # Prioritize bins with smaller gaps (tighter fit). Using inverse of (1 + gap)\n    # to ensure a priority score that is higher for smaller gaps.\n    # Adding 1 to the denominator to avoid division by zero and a small epsilon\n    # for numerical stability if gaps can be zero.\n    fit_scores = 1.0 / (1.0 + gaps + 1e-9)\n    \n    # Introduce adaptive exploration: add a small amount of noise based on the std dev\n    # of the fit scores of the suitable bins. This nudges the selection slightly\n    # away from purely greedy choices, promoting exploration.\n    if fit_scores.size > 0:\n        std_dev_fit_scores = np.std(fit_scores)\n        random_noise = np.random.normal(0, std_dev_fit_scores * 0.05, fit_scores.shape)\n        priorities[suitable_bins_mask] = fit_scores + random_noise\n    \n    return priorities\n\n### Analyze & experience\n- Comparing Heuristic 1 (priority_v2) vs Heuristic 4 (priority_v2): Heuristic 1 attempts a more nuanced approach by considering both tight packing and current fullness, aiming for a balance. Heuristic 4 solely focuses on tight packing (inverse of remaining capacity after packing). Heuristic 1's attempt to balance objectives is potentially better, but its implementation has an error in calculating `filled_ratio` and the subsequent logic might not achieve its stated goals effectively. Heuristic 4 is simpler and directly implements the \"tightest fit\" idea.\n\nComparing Heuristic 1 (priority_v2) vs Heuristic 5 (priority_v2): Heuristic 5 introduces dynamic weighting based on item size relative to bin capacity, aiming to favor tight packing for small items and using fuller bins for larger items. This is a more sophisticated approach than Heuristic 1's fixed weights and static scores, but Heuristic 1's conceptual goal of balancing two factors is also valuable. Heuristic 5's complexity and dynamic weighting seem promising.\n\nComparing Heuristic 5 (priority_v2) vs Heuristic 6 (priority_v2): Heuristic 5 uses item size relative to max capacity for dynamic weighting. Heuristic 6 uses item size relative to average remaining capacity for dynamic weighting of tight fit. Both try to adapt. Heuristic 5's inclusion of a \"future accommodation\" score alongside \"tight fit\" and \"nearly full\" is more comprehensive than Heuristic 6's simpler \"tight fit\" and \"nearly full\" components.\n\nComparing Heuristic 4 (priority_v2) vs Heuristic 9 (priority_v2): These heuristics are identical, both implementing a simple \"tightest fit\" strategy (inverse remaining capacity after packing) and normalizing the results. They represent a baseline approach.\n\nComparing Heuristic 2 (priority_v2) vs Heuristic 10 (priority_v2): Both introduce exploration. Heuristic 2 uses a small fixed probability to add a boost to a random subset of valid bins. Heuristic 10 uses an epsilon-greedy approach: with probability epsilon, it picks a random fitting bin; otherwise, it picks the best fit. Heuristic 10's epsilon-greedy is a more standard and potentially effective exploration strategy for optimizing decisions.\n\nComparing Heuristic 7 (priority_v2) vs Heuristics 11, 12, 13, 14, 15, 16 (all priority_v2): Heuristic 7 combines inverse gaps with a uniform boost to all suitable bins (soft epsilon-greedy). Heuristics 11-16 are very similar, implementing a tight fit (inverse of waste/gap) and some form of exploration. Heuristic 11 uses Gaussian noise based on std dev. Heuristics 12-16 use an epsilon-greedy approach where a random available bin gets a significantly boosted priority. Heuristic 10's epsilon-greedy (select random fitting bin vs best fit) seems more direct than boosting a bin's priority. The implementation in 12-16, boosting a single bin's priority, is a very crude form of exploration. Heuristic 11's noise approach is also interesting.\n\nComparing Heuristic 17 (priority_v2) vs Heuristic 20 (priority_v2): Both prioritize tight fits and penalize empty bins. Heuristic 17 uses a fixed large penalty for empty bins. Heuristic 20 seems identical to 17. They focus on leveraging existing bins.\n\nComparing Heuristic 18 (priority_v2) vs Heuristic 19 (priority_v2): These heuristics are identical. They attempt to balance tight packing, future accommodation, and adaptive utilization with weighted scores. This multi-objective approach is conceptually strong.\n\nOverall: The best heuristics (1, 5, 6, 18/19) attempt to balance multiple objectives (tight fit, nearly full, future accommodation, adaptive utilization). Heuristics 2, 10, 11, 12-16 introduce exploration mechanisms. Heuristic 10's epsilon-greedy is a strong contender. Heuristic 18/19's multi-objective approach is also very promising. The simplest but functional approach is the tight-fit strategy (4, 9). The worst heuristics are those with clear bugs or conceptually flawed logic (like the initial attempt in Heuristic 1). The identical heuristics (4 vs 9, 18 vs 19) suggest redundancy or copy-pasting errors in the prompt's ranking. The cluster of identical \"Inverse Distance + epsilon-greedy\" heuristics (12-16) are simple but not as nuanced as others.\n- \nHere's a redefined approach to self-reflection for heuristic design:\n\n*   **Keywords:** Multi-objective optimization, adaptive search, problem decomposition, empirical validation.\n*   **Advice:** Focus on clear objective articulation and breaking down complex problems into manageable sub-problems. Design heuristics that explicitly address different facets of the problem, allowing for targeted improvements. Integrate mechanisms for systematic empirical testing and comparison against baselines.\n*   **Avoid:** Over-reliance on generic exploration strategies without understanding their impact on specific problem structures. Implementing overly complex or poorly understood scaling mechanisms before thoroughly validating simpler approaches.\n*   **Explanation:** True self-reflection involves deep understanding of the problem and tailored solutions. It's not about applying off-the-shelf meta-heuristics but about intelligently combining and adapting them based on empirical evidence and problem-specific insights.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}