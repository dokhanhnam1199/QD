The goal is to create a robust priority function by combining a strong exploitation strategy (tightest fit with utilization bonus) with a more intelligent exploration mechanism. We will adapt the approach from `priority_v0` (simple epsilon-greedy) and `priority_v6` (more targeted exploration based on deviation from mean).

Heuristics to combine:
1.  **Tightest Fit + Utilization Bonus:** This is a core aspect for good BPP performance. Bins that leave the smallest remaining capacity are preferred, and bins with less initial remaining capacity (more utilized) are also favored.
2.  **Targeted Exploration:** Instead of purely random exploration, we want to explore bins that are "good but not the best," offering a chance to discover better local optima. The idea from `priority_v6` of boosting bins closer to the mean exploitation score is a good starting point.

Let's refine this. We'll aim for a heuristic that:
*   Calculates a score based on "tightness" (remaining capacity after packing).
*   Calculates a score based on "utilization" (inverse of the initial remaining capacity).
*   Combines these exploitation scores.
*   Implements an exploration strategy that boosts scores of bins that are *not* the absolute best but are still good candidates. A slightly modified version of `priority_v6`'s exploration could work: instead of boosting based on deviation from the mean, we could simply boost the next N best bins, or bins within a certain percentile range of the top scores. A simpler, yet effective, exploration could be to give a small uniform boost to all suitable bins, making them all *potential* candidates if the main exploitation doesn't yield a clear winner, or if exploration is triggered.

Let's combine the Best Fit + Utilization from `priority_v6` with a slightly modified exploration strategy that is less complex than `priority_v6`'s Gaussian approach but more structured than `priority_v0`'s random choice. We'll use a fixed probability for exploration, and if exploration is triggered, we boost the scores of all *suitable* bins slightly, ensuring they have a chance, rather than picking just one random bin or targeting specific bins based on their relative merit. This provides a balance.

**Refined Plan:**
1.  **Exploitation Scores:**
    *   **Tightness:** `1 / (remaining_capacity_after_packing + epsilon)`
    *   **Utilization:** `1 / (initial_remaining_capacity + epsilon)`
    *   Combine these with weights.
2.  **Exploration Strategy:**
    *   Use an `epsilon` chance to trigger exploration.
    *   If exploration is triggered, add a small, constant boost to *all* suitable bins. This gives them an equal footing for a moment, encouraging diversity.
    *   If not exploring, apply the combined exploitation scores.
3.  **Normalization:** Ensure output priorities sum to 1 (or are scaled appropriately).

This hybrid approach should offer the benefits of both focused exploitation and a broader exploration that doesn't discard potentially good, but not optimal, bins.

```python
import numpy as np

def priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:
    """
    Combines tightest fit and utilization bonus for exploitation,
    with an epsilon-greedy strategy that slightly boosts all suitable bins for exploration.
    """
    epsilon = 0.05  # Probability of triggering exploration
    exploration_boost = 0.1 # Small boost for exploration phase
    epsilon_for_division = 1e-9 # Small value to prevent division by zero

    priorities = np.zeros_like(bins_remain_cap, dtype=float)

    # Mask for bins that can accommodate the item
    can_fit_mask = bins_remain_cap >= item
    suitable_bins_indices = np.where(can_fit_mask)[0]

    if suitable_bins_indices.size == 0:
        return priorities  # No bin can fit the item

    # --- Exploitation Component ---
    fitting_bins_remain_cap = bins_remain_cap[suitable_bins_indices]

    # 1. Tightest Fit Score: Lower remaining capacity after packing is better.
    remaining_after_packing = fitting_bins_remain_cap - item
    tightness_scores = 1.0 / (remaining_after_packing + epsilon_for_division)

    # 2. Utilization Score: Higher initial remaining capacity is worse (less utilized).
    # We want to penalize bins with very large remaining capacities.
    # So, higher score for smaller initial remaining capacity.
    utilization_scores = 1.0 / (fitting_bins_remain_cap + epsilon_for_division)

    # Combine exploitation scores with weights
    # Giving slightly more weight to tightness as it's a primary BPP goal.
    combined_exploitation_scores = 0.6 * tightness_scores + 0.4 * utilization_scores

    # Normalize exploitation scores to a [0, 1] range based on their current values
    max_exploitation_score = np.max(combined_exploitation_scores)
    if max_exploitation_score > epsilon_for_division:
        normalized_exploitation_scores = combined_exploitation_scores / max_exploitation_score
    else:
        normalized_exploitation_scores = np.zeros_like(combined_exploitation_scores)

    # --- Exploration Component ---
    if np.random.rand() < epsilon:
        # Exploration phase: Boost all suitable bins
        # Add a small, constant boost to all fitting bins' normalized scores
        exploration_scores = normalized_exploitation_scores + exploration_boost
        # Ensure scores don't exceed a reasonable upper bound if boost is too large
        exploration_scores = np.clip(exploration_scores, 0, 1.0 + exploration_boost)
        
        # Use these exploration scores as the final priorities
        final_priorities_unnormalized = exploration_scores
    else:
        # Exploitation phase: Use the combined exploitation scores
        final_priorities_unnormalized = normalized_exploitation_scores

    # --- Final Priority Calculation ---
    # Assign priorities to the original bins
    priorities[suitable_bins_indices] = final_priorities_unnormalized

    # Normalize priorities so they sum to 1, ensuring a valid probability distribution
    sum_priorities = np.sum(priorities)
    if sum_priorities > epsilon_for_division:
        priorities /= sum_priorities
    else:
        # If all scores somehow end up zero, distribute probability equally among suitable bins
        if suitable_bins_indices.size > 0:
            priorities[suitable_bins_indices] = 1.0 / suitable_bins_indices.size

    return priorities
```
