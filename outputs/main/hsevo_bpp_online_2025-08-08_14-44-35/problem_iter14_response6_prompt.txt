{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines tight-fit preference with adaptive bin utilization and dynamic exploration.\n    Prioritizes bins that minimize waste and are more utilized, with exploration\n    favoring less utilized bins based on a dynamically adjusted probability.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n\n    # Mask for bins that can fit the item\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    available_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    available_bin_indices = np.where(can_fit_mask)[0]\n\n    # --- Core Heuristic Components ---\n\n    # 1. Tight Fitting (Minimize Waste): Score is inverse of remaining space after packing.\n    remaining_after_packing = available_bins_remain_cap - item\n    tight_fit_scores = 1.0 / (remaining_after_packing + epsilon)\n\n    # 2. Adaptive Bin Utilization: Score based on how \"full\" the bin is.\n    # Prefer bins that have less remaining capacity relative to the item size.\n    # This can be approximated by `item / available_bins_remain_cap` or similar.\n    # Let's use a score that is higher for bins that are less empty (i.e., lower remaining capacity).\n    # A simple approach is `1.0 / (available_bins_remain_cap + epsilon)`.\n    # To make it more adaptive, we can consider the *average* remaining capacity of fitting bins.\n    avg_fitting_remain_cap = np.mean(available_bins_remain_cap) if available_bins_remain_cap.size > 0 else 1.0\n    # Prefer bins with remaining capacity closer to the item or lower than average.\n    # Let's try a score that is high when remaining capacity is low (closer to item).\n    utilization_scores = 1.0 / (available_bins_remain_cap + epsilon)\n\n    # Combine the two heuristic scores. A weighted sum is a common approach.\n    # Let's give equal weight for now.\n    combined_core_scores = 0.5 * tight_fit_scores + 0.5 * utilization_scores\n\n    # Normalize core scores to be between 0 and 1.\n    max_core_score = np.max(combined_core_scores)\n    if max_core_score > epsilon:\n        normalized_core_scores = combined_core_scores / max_core_score\n    else:\n        normalized_core_scores = np.zeros_like(combined_core_scores)\n\n    # --- Dynamic Epsilon-Greedy Exploration ---\n    num_available_bins = available_bins_remain_cap.size\n\n    # Determine exploration probability adaptively.\n    # A common strategy is to increase exploration when there are many bins,\n    # to encourage trying out different options. Or, explore less if bins are very full.\n    # Let's use a simple inverse relationship with the number of available bins to explore more\n    # when there are fewer options, which can be counter-intuitive.\n    # A better approach: explore more when there are *many* bins to choose from, to diversify.\n    # Or, explore less when bins are already quite full, and more when they are mostly empty.\n\n    # A simple dynamic probability: decrease exploration as the number of available bins decreases.\n    # Or, use the inverse of the average utilization as a proxy for how \"challenging\" the packing is.\n    # Let's use a probability that decreases with the tightness of the fit (smaller remaining_after_packing).\n    # This means we explore more when the fits are not tight.\n    \n    # Heuristic from analysis: dynamic exploration favoring less utilized bins.\n    # We want to explore bins that are NOT among the top-ranked by core heuristics.\n    # The probability of exploration for a bin could be inversely related to its normalized core score.\n\n    # Simple dynamic exploration probability: higher when many bins, lower when few.\n    # Or, a fixed probability for simplicity if dynamic is too complex to implement robustly here.\n    # Given the prompt's goal of combining elements, let's use a fixed epsilon-greedy\n    # but slightly modified based on utilization to influence *which* bins are explored.\n\n    exploration_prob = 0.15 # Base exploration probability\n\n    # We want to assign exploration scores to a subset of bins.\n    # Instead of random scores, let's boost scores of bins that are less utilized.\n    # A simple way to select bins for \"exploration\" (or a modified score):\n    # bins with higher `utilization_scores` (meaning they are more utilized)\n    # should be less likely to be perturbed by random exploration.\n    # So, bins with lower `utilization_scores` are more prone to exploration.\n\n    # Create a probability mask for exploration, favoring less utilized bins.\n    # Let's sort bins by utilization_scores (ascending) and pick a fraction.\n    # A simple approach: assign a higher 'random' score to bins that are less utilized.\n    \n    # Let's stick to a blended approach inspired by Heuristic 11, where exploration\n    # contributes to the final score.\n    \n    # For the exploration component, we can generate random scores.\n    # To bias exploration towards less utilized bins, we can scale these random scores.\n    # If `utilization_scores` is low (meaning bin is less utilized), we want a higher random score.\n    # We can achieve this by multiplying `random_scores` by `(1.0 / (utilization_scores + epsilon))`.\n    \n    random_exploration_scores = np.random.rand(num_available_bins)\n    \n    # Scale random scores: boost scores for less utilized bins (low utilization_scores).\n    # Higher `boost_factor` means more boost for less utilized bins.\n    boost_factor = 2.0 # Control how much less utilized bins are favored in exploration\n    scaled_random_scores = random_exploration_scores * (1.0 + boost_factor * (1.0 - utilization_scores))\n    \n    # Normalize these scaled random scores to keep them in a comparable range.\n    max_scaled_random_score = np.max(scaled_random_scores)\n    if max_scaled_random_score > epsilon:\n        normalized_exploration_scores = scaled_random_scores / max_scaled_random_score\n    else:\n        normalized_exploration_scores = np.zeros_like(scaled_random_scores)\n\n    # Blend the deterministic (core) scores with the exploration scores.\n    # Use the `exploration_prob` to decide the mixing weight.\n    alpha = exploration_prob\n    final_scores = (1 - alpha) * normalized_core_scores + alpha * normalized_exploration_scores\n\n    # Re-normalize the final blended scores to ensure they are in a 0-1 range.\n    max_final_score = np.max(final_scores)\n    if max_final_score > epsilon:\n        priorities[can_fit_mask] = final_scores / max_final_score\n    else:\n        # Fallback if all scores are zero or near-zero\n        priorities[can_fit_mask] = final_scores\n\n    # Ensure priorities are non-negative.\n    priorities[priorities < 0] = 0\n\n    return priorities\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines tightest fit with a utilization bonus and adaptive exploration.\n    Favors bins that minimize remaining space, offering a bonus for less utilized bins,\n    and strategically explores less optimal bins.\n    \"\"\"\n    epsilon = 1e-9\n    exploration_prob = 0.15  # Slightly higher exploration to balance\n\n    can_fit_mask = bins_remain_cap >= item\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    valid_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    \n    # --- Heuristic Component 1: Tightest Fit ---\n    # Prioritize bins that leave minimal remaining capacity after packing.\n    remaining_after_packing = valid_bins_remain_cap - item\n    tight_fit_scores = 1.0 / (remaining_after_packing + epsilon)\n\n    # --- Heuristic Component 2: Utilization Bonus ---\n    # Prefer bins that are currently less utilized (more empty space).\n    # This encourages spreading items across more bins initially.\n    # A simple score: higher for bins with less current remaining capacity.\n    # Using a base of 1 to avoid making already partially full bins *too* dominant.\n    fill_score_bonus = 0.3 * (1.0 / (valid_bins_remain_cap + epsilon))\n    \n    # Combine tightness and utilization bonus: multiplicative effect\n    # This rewards bins that are both tight and already have some items\n    combined_exploitation_scores = tight_fit_scores * (1.0 + fill_score_bonus)\n\n    # Normalize exploitation scores to be between 0 and 1\n    max_exploitation_score = np.max(combined_exploitation_scores)\n    if max_exploitation_score > epsilon:\n        normalized_exploitation_scores = combined_exploitation_scores / max_exploitation_score\n    else:\n        normalized_exploitation_scores = np.zeros_like(combined_exploitation_scores)\n\n    # --- Adaptive Exploration ---\n    # With a certain probability, give a boost to randomly selected fitting bins\n    # to explore less optimal choices and avoid getting stuck in local optima.\n    num_fitting_bins = len(valid_bins_remain_cap)\n    exploration_boost = np.zeros_like(normalized_exploitation_scores)\n    \n    # Determine how many bins to \"boost\" for exploration\n    num_to_explore = max(1, int(np.floor(exploration_prob * num_fitting_bins))) # Ensure at least one bin is explored if possible\n    \n    # Select indices to explore randomly from the fitting bins\n    # Using np.random.choice with replace=False to ensure unique bins are selected for exploration boost\n    explore_indices = np.random.choice(num_fitting_bins, size=num_to_explore, replace=False)\n    \n    # Assign a uniform high exploration score to these bins, relative to the normalized exploitation scores.\n    # This ensures exploration bins are considered, but their exact priority is context-dependent on overall exploitation scores.\n    exploration_boost[explore_indices] = 1.0 \n\n    # --- Final Priority Calculation ---\n    # Combine exploitation and exploration scores.\n    # Adding exploration boost means these bins will have a higher chance of selection.\n    # The `1 - exploration_prob` for exploitation is implicitly handled by not boosting all bins.\n    final_scores_unnormalized = normalized_exploitation_scores + exploration_boost\n    \n    # Ensure all priorities are non-negative and normalize them for the fitting bins\n    final_scores_unnormalized[final_scores_unnormalized < 0] = 0\n    sum_final_scores = np.sum(final_scores_unnormalized)\n    \n    if sum_final_scores > epsilon:\n        priorities[can_fit_mask] = final_scores_unnormalized / sum_final_scores\n    else:\n        # Fallback to uniform probability if all scores are zero (e.g., due to epsilon issues)\n        priorities[can_fit_mask] = 1.0 / num_fitting_bins\n        \n    return priorities\n\n### Analyze & experience\n- Comparing (Heuristics 1st) vs (Heuristics 2nd), they are identical.\n\nComparing (Heuristics 3rd) vs (Heuristics 4th), Heuristics 4th introduces a \"Fill Level Bonus\" and a more complex exploration strategy. The fill level bonus (penalizing large remaining capacities) in Heuristics 4th is a good addition for utilization. The exploration strategy in Heuristics 4th, while more complex, aims for a more nuanced exploration by adapting to the number of fitting bins, which is a step up.\n\nComparing (Heuristics 4th) vs (Heuristics 5th), they are identical.\n\nComparing (Heuristics 5th) vs (Heuristics 6th), Heuristics 5th uses a simpler exploration (uniform boost to all fitting bins with probability). Heuristics 6th attempts a more sophisticated exploration by boosting bins closer to the mean exploitation score, aiming to explore \"promising but not top\" candidates. This seems more targeted than uniform boosting. Heuristics 6th also uses a weighted sum of tightness and utilization, which is a reasonable way to combine objectives.\n\nComparing (Heuristics 6th) vs (Heuristics 7th), Heuristics 7th is identical to Heuristics 5th. This indicates a lack of progression or differentiation in the provided list for these specific entries.\n\nComparing (Heuristics 7th) vs (Heuristics 8th), they are identical.\n\nComparing (Heuristics 8th) vs (Heuristics 9th), Heuristics 8th has a complex exploration that scales randomly. Heuristics 9th uses a simple epsilon-greedy with a random pick for exploration. Heuristics 9th's combined score (tightness + 0.5 * utilization) is simpler than Heuristics 8th's multiplicative approach. The normalization in 9th is also simpler.\n\nComparing (Heuristics 9th) vs (Heuristics 10th), Heuristics 10th introduces a \"Dynamic Epsilon-Greedy Exploration\" and a more adaptive utilization score, attempting to boost scores of less utilized bins. This is more sophisticated than the simple epsilon-greedy in Heuristics 9th. Heuristics 10th's approach to combining scores and exploring seems more nuanced.\n\nComparing (Heuristics 10th) vs (Heuristics 11th), they are identical.\n\nComparing (Heuristics 11th) vs (Heuristics 12th), Heuristics 11th uses a fixed exploration probability with a scaled random score favoring less utilized bins. Heuristics 12th uses a fixed `exploration_prob` to select a *number* of bins to boost uniformly. Heuristics 12th's combination of tightness and utilization seems more balanced with normalized utilization bonus. The exploration in 12th is simpler (uniform boost) but ensures at least one bin is explored if possible.\n\nComparing (Heuristics 12th) vs (Heuristics 13th), they are identical.\n\nComparing (Heuristics 13th) vs (Heuristics 14th), Heuristics 14th has significantly different imports (random, math, scipy, torch) and unused parameters, indicating it's an incomplete or placeholder heuristic, making direct comparison difficult and marking it as worse due to lack of implementation and unnecessary complexity.\n\nComparing (Heuristics 14th) vs (Heuristics 15th), they are identical and incomplete.\n\nComparing (Heuristics 15th) vs (Heuristics 16th), they are identical and incomplete.\n\nComparing (Heuristics 16th) vs (Heuristics 17th), Heuristics 17th is a complete heuristic with a clear strategy, unlike the incomplete Heuristics 16th. Heuristics 17th has a multiplicative combination of tightness and utilization bonus, and its exploration boosts specific bins.\n\nComparing (Heuristics 17th) vs (Heuristics 18th), they are identical.\n\nComparing (Heuristics 18th) vs (Heuristics 19th), they are identical.\n\nComparing (Heuristics 19th) vs (Heuristics 20th), they are identical.\n\nOverall: Heuristics 1st-2nd and 5th-8th and 11th-13th and 17th-20th are largely identical and represent a solid base combining tightness, utilization bonus, and basic exploration. Heuristics 3rd and 4th/5th introduce more sophisticated utilization bonuses. Heuristics 6th tries a more advanced exploration. Heuristics 10th/11th attempt dynamic exploration. Heuristics 12th/13th offer a structured exploration boost. The most distinct and potentially improved approaches seem to be those in Heuristics 4th/5th (more nuanced utilization), 6th (smarter exploration targeting), and 10th/11th (dynamic exploration). However, due to extensive duplication, the progression is unclear. The latter group of identical heuristics (17th-20th) represents a reasonable, albeit unoriginal, approach. Heuristics 14th-16th are clearly worse due to incompleteness.\n- \nHere's a refined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Multi-objective, Normalization, Adaptive Exploration, Robustness.\n*   **Advice:** Focus on designing heuristics that explicitly manage trade-offs between competing objectives using techniques like normalized weighted sums or Pareto-based selection. Implement sophisticated exploration strategies that dynamically adjust based on search progress, such as Thompson sampling or Upper Confidence Bound (UCB).\n*   **Avoid:** Blindly combining objectives with fixed weights that might not generalize. Using brittle or ad-hoc handling of edge cases without a clear fallback strategy. Over-reliance on simple epsilon-greedy for exploration, which can be inefficient.\n*   **Explanation:** This approach emphasizes principled methods for handling multi-objective optimization and exploration, ensuring heuristics are adaptable, less prone to local optima, and better at managing complexity without becoming overly brittle.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}