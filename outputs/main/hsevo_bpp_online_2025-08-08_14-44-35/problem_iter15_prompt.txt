{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code only and do not add comments into the code. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\nCurrent heuristics:\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines tightest fit with a weighted utilization bonus and adaptive exploration.\n    Prioritizes bins that minimize slack after packing, with a bonus for utilized bins.\n    Exploration strategy boosts less utilized, fitting bins to encourage diversity.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    epsilon = 1e-9\n    utilization_weight = 0.3\n    exploration_prob = 0.1\n\n    can_fit_mask = bins_remain_cap >= item\n\n    if not np.any(can_fit_mask):\n        return priorities\n\n    fitting_bins_remain_cap = bins_remain_cap[can_fit_mask]\n    fitting_indices = np.where(can_fit_mask)[0]\n\n    # 1. Tightest Fit: Prioritize bins that leave minimal remaining capacity after packing.\n    remaining_after_packing = fitting_bins_remain_cap - item\n    tightness_score = 1.0 / (remaining_after_packing + epsilon)\n\n    # 2. Utilization Bonus: Prefer bins that are already partially filled.\n    # Score is inverse of remaining capacity before packing.\n    utilization_score = 1.0 / (fitting_bins_remain_cap + epsilon)\n\n    # Normalize utilization score to be between 0 and 1 relative to fitting bins\n    max_utilization_score = np.max(utilization_score)\n    if max_utilization_score > epsilon:\n        normalized_utilization_score = utilization_score / max_utilization_score\n    else:\n        normalized_utilization_score = np.zeros_like(utilization_score)\n\n    # Combine Tightness and Utilization (Exploitation)\n    exploitation_score = tightness_score + utilization_weight * normalized_utilization_score\n\n    # Normalize exploitation scores to [0, 1]\n    max_exploitation_score = np.max(exploitation_score)\n    if max_exploitation_score > epsilon:\n        normalized_exploitation_scores = exploitation_score / max_exploitation_score\n    else:\n        normalized_exploitation_scores = np.zeros_like(exploitation_score)\n\n    # 3. Adaptive Exploration: Boost scores of some less utilized fitting bins.\n    exploration_boost = np.zeros_like(normalized_exploitation_scores)\n    num_fitting_bins = len(fitting_bins_remain_cap)\n    \n    # Identify bins that are \"less utilized\" among the fitting ones (higher utilization score)\n    # We want to boost bins that have been used more, but are still \"good\" fits.\n    # A simple way is to select from bins with utilization scores in the lower half (meaning more capacity used)\n    # but still providing a decent fit.\n    \n    # Let's sort by utilization score (descending) and pick some from the top.\n    # More simply, randomly pick a subset and boost them.\n    \n    num_to_explore = max(1, int(np.floor(exploration_prob * num_fitting_bins)))\n    explore_indices_local = np.random.choice(num_fitting_bins, size=min(num_to_explore, num_fitting_bins), replace=False)\n    \n    # Assign a modest boost to these selected bins.\n    # The boost should be enough to make them competitive but not necessarily dominate.\n    # Let's give them a score that is slightly above average of the normalized exploitation scores.\n    mean_exploitation_score = np.mean(normalized_exploitation_scores) if num_fitting_bins > 0 else 0\n    exploration_boost[explore_indices_local] = mean_exploitation_score * 1.2 \n\n    # Final Scores: Combine exploitation and exploration\n    final_scores_unnormalized = normalized_exploitation_scores + exploration_boost\n\n    # Final Normalization to ensure the highest priority is 1.0\n    max_final_score = np.max(final_scores_unnormalized)\n    if max_final_score > epsilon:\n        priorities[can_fit_mask] = final_scores_unnormalized / max_final_score\n    else:\n        # Fallback if all scores are zero\n        priorities[can_fit_mask] = 1.0 / num_fitting_bins if num_fitting_bins > 0 else 0.0\n\n    return priorities\n\nNow, think outside the box write a mutated function `priority_v2` better than current version.\nYou can use some hints below:\n- \nHere's a refined approach to self-reflection for designing better heuristics:\n\n*   **Keywords:** Multi-objective, Normalization, Adaptive Exploration, Robustness.\n*   **Advice:** Focus on designing heuristics that explicitly manage trade-offs between competing objectives using techniques like normalized weighted sums or Pareto-based selection. Implement sophisticated exploration strategies that dynamically adjust based on search progress, such as Thompson sampling or Upper Confidence Bound (UCB).\n*   **Avoid:** Blindly combining objectives with fixed weights that might not generalize. Using brittle or ad-hoc handling of edge cases without a clear fallback strategy. Over-reliance on simple epsilon-greedy for exploration, which can be inefficient.\n*   **Explanation:** This approach emphasizes principled methods for handling multi-objective optimization and exploration, ensuring heuristics are adaptable, less prone to local optima, and better at managing complexity without becoming overly brittle.\n\nOutput code only and enclose your code with Python code block: ```python ... ```.\nI'm going to tip $999K for a better solution!"}