{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority scores for adding an item to each bin, \n    combining bin fullness and fit scores with tunable weights and normalization.\n    \"\"\"\n    # Calculate remaining capacity after adding the item\n    remaining_cap_after_addition = bins_remain_cap - item\n    \n    # Check if the bin has enough capacity\n    has_enough_capacity = remaining_cap_after_addition >= 0\n    \n    # Calculate bin fullness score\n    bin_fullness_score = np.where(has_enough_capacity, \n                                  1 - (remaining_cap_after_addition / (bins_remain_cap + 1e-6)), \n                                  -1)\n    \n    # Calculate fit score (rewarding bins with remaining capacity close to the item size)\n    remaining_cap_score = np.where(has_enough_capacity, \n                                   1 / (1 + np.abs(remaining_cap_after_addition - item) / (item + 1e-6)), \n                                   0)\n    \n    # Introduce a bias towards bins with smaller indices to break ties\n    index_bias = -np.arange(len(bins_remain_cap)) / len(bins_remain_cap)\n    \n    # Combine scores with tunable weights\n    weights = np.array([0.6, 0.3, 0.1])  # Weights for bin_fullness_score, remaining_cap_score, and index_bias\n    priority_scores = (weights[0] * bin_fullness_score + \n                       weights[1] * remaining_cap_score + \n                       weights[2] * index_bias)\n    \n    # Normalize priority scores using tanh\n    priority_scores = np.tanh(priority_scores)\n    \n    return priority_scores\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Combines bin fullness and item fit scores with tunable weights and normalization for robustness.\n    Rewards bins that are fuller and fit the item tightly.\n    \"\"\"\n    # Check if the bin has enough capacity for the item\n    has_enough_capacity = bins_remain_cap >= item\n    \n    # Calculate bin fullness score, rewarding fuller bins\n    bin_fullness_score = np.where(has_enough_capacity, bins_remain_cap / (bins_remain_cap.max() + 1e-6), -1)\n    \n    # Calculate a score that rewards bins where the remaining capacity after addition is close to zero (tight fit)\n    tight_fit_score = np.where(has_enough_capacity, 1 - np.abs(bins_remain_cap - item) / (item + 1e-6), 0)\n    \n    # Combine the two scores with tunable weights to get the final priority score\n    weights = np.array([0.6, 0.4])  # Tunable weights for bin_fullness_score and tight_fit_score\n    priority_scores = weights[0] * bin_fullness_score + weights[1] * tight_fit_score\n    \n    # Normalize the priority scores to improve robustness\n    priority_scores = (priority_scores - priority_scores.min()) / (priority_scores.max() - priority_scores.min() + 1e-6)\n    \n    return priority_scores\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that both heuristics combine bin fullness and item fit scores, but the 1st heuristic uses more complex scoring systems and has more nuanced weighting. (2nd) vs (19th) shows that the top heuristics often include additional parameters for tuning. Comparing (1st) vs (2nd), we see that the 2nd has more parameters to potentially overfit. Overall, top heuristics balance complexity with nuanced scoring.\n- \nTo design better heuristics, we need to analyze the given 'Current self-reflection' and 'Ineffective self-reflection'. Here's a step-by-step analysis:\n\n* Keywords: simplicity, tunable parameters, normalization, bin fullness, item fit.\n* Advice: \n    - Balance complexity and nuance in scoring systems.\n    - Focus on prioritizing bins based on how tightly they can fit the item.\n    - Consider normalization to avoid numerical issues.\n    - Simplify scoring systems while incorporating relevant factors.\n* Avoid: unnecessary complexity, redundant parameters, ineffective use of tunable weights.\n* Explanation: Effective heuristics require a balance between simplicity and nuance, considering factors like bin fullness and item fit while avoiding unnecessary complexity.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}