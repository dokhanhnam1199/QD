{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a priority function for Solving online Bin Packing Problem (BPP). BPP requires packing a set of items of various sizes into the smallest number of fixed-sized bins. Online BPP requires packing an item as soon as it is received.\nThe priority function takes as input an item and an array of bins_remain_cap (containing the remaining capacity of each bin) and returns a priority score for each bin. The bin with the highest priority score will be selected for the item.\n\n\n### Better code\ndef priority_v0(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n                epsilon: float = 0.0007172075845624779, \n                bin_fullness_weight: float = 0.6832967170748634, \n                fit_score_weight: float = 0.7408009259100935,\n                capacity_threshold: float = -0.8405607021260366,\n                tight_fit_epsilon: float = 9.703058604165807e-05) -> np.ndarray:\n    \"\"\"\n    Returns priority scores for each bin based on bin fullness and item fit.\n    Combines elements of top heuristics for effective bin prioritization.\n    \"\"\"\n    # Check if the bin has enough capacity for the item\n    has_enough_capacity = bins_remain_cap >= (item + capacity_threshold)\n    \n    # Calculate bin fullness score, rewarding bins that are fuller\n    bin_fullness_score = np.where(has_enough_capacity, \n                                  1 - (bins_remain_cap - item) / (bins_remain_cap + epsilon), \n                                  -1)\n    \n    # Calculate fit score, prioritizing bins that fit the item tightly\n    fit_score = np.where(has_enough_capacity, \n                         1 / (1 + np.abs(bins_remain_cap - item - item) / (item + tight_fit_epsilon)), \n                         0)\n    \n    # Combine the two scores to get the final priority score with weights\n    priority_scores = bin_fullness_weight * bin_fullness_score + fit_score_weight * fit_score\n    \n    return priority_scores\n\n### Worse code\ndef priority_v1(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n\n    \"\"\"\n    Returns priority scores for adding an item to each bin, \n    combining bin fullness and fit scores with tunable weights and normalization.\n    \"\"\"\n    # Calculate remaining capacity after adding the item\n    remaining_cap_after_addition = bins_remain_cap - item\n    \n    # Check if the bin has enough capacity\n    has_enough_capacity = remaining_cap_after_addition >= 0\n    \n    # Calculate bin fullness score\n    bin_fullness_score = np.where(has_enough_capacity, \n                                  1 - (remaining_cap_after_addition / (bins_remain_cap + 1e-6)), \n                                  -1)\n    \n    # Calculate fit score (rewarding bins with remaining capacity close to the item size)\n    remaining_cap_score = np.where(has_enough_capacity, \n                                   1 / (1 + np.abs(remaining_cap_after_addition - item) / (item + 1e-6)), \n                                   0)\n    \n    # Introduce a bias towards bins with smaller indices to break ties\n    index_bias = -np.arange(len(bins_remain_cap)) / len(bins_remain_cap)\n    \n    # Combine scores with tunable weights\n    weights = np.array([0.6, 0.3, 0.1])  # Weights for bin_fullness_score, remaining_cap_score, and index_bias\n    priority_scores = (weights[0] * bin_fullness_score + \n                       weights[1] * remaining_cap_score + \n                       weights[2] * index_bias)\n    \n    # Normalize priority scores using tanh\n    priority_scores = np.tanh(priority_scores)\n    \n    return priority_scores\n\n### Analyze & experience\n- Comparing the best heuristics (1st, 2nd,3rd) vs the worst (18th, 19th,20th), we see that top heuristics have simpler, more straightforward implementations without unnecessary import statements and focus on bin fullness and item fit. \nThe worst ones have additional parameters and normalization. \nComparing (4th) vs (9th), (10th) we see the difference in complexity due to parameters and normalization.\n(1st) vs (2nd) shows identical implementations, indicating potential redundancy.\nOverall: Top heuristics prioritize simplicity, focusing on bin fullness and item fit, while lower-ranked ones introduce more complexity with additional parameters and normalization.\n- \nTo design better heuristics, let's redefine 'Current self-reflection' while avoiding 'Ineffective self-reflection'. Here's a breakdown:\n\n* **Keywords**: Simplicity, Bin fullness, Item fit, Normalization\n* **Advice**: Focus on simplicity and prioritize bins based on item fit and bin fullness while ensuring normalization.\n* **Avoid**: Unnecessary complexity, Tunable parameters, Epsilon addition, Combining multiple scores with weights.\n* **Explanation**: Simplify the heuristics by focusing on key factors like bin fullness and item fit, and normalize scores to avoid numerical issues, thus avoiding overly complex and parameterized approaches.\n\nYour task is to write an improved function `priority_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}