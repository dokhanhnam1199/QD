[
  {
    "stdout_filepath": "problem_iter1_response0.txt_stdout.txt",
    "code_path": "problem_iter1_code0.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Find bins that can accommodate the item\n    feasible_bins = bins_remain_cap >= item\n\n    if np.any(feasible_bins):\n        # Calculate remaining capacity after placing item in feasible bins\n        remaining_capacities = bins_remain_cap[feasible_bins] - item\n\n        # Prioritize bins with smallest remaining capacity after placement (first-fit decreasing)\n        priorities[feasible_bins] = 1 / (remaining_capacities + 1e-9) # add a small constant to avoid division by zero\n\n        # Optionally, add a bonus for bins that are almost full\n        almost_full_threshold = 0.1  # e.g., bin is at least 90% full after placement\n        almost_full = remaining_capacities / bins_remain_cap[feasible_bins] < almost_full_threshold\n        priorities[feasible_bins][almost_full] *= 2  # Double the priority for almost full bins\n\n    else:\n        # If no feasible bins, penalize bins with low capacity\n        priorities = -1 / (bins_remain_cap + 1e-9) # Penalize the bins. Add small constant to avoid div by 0\n\n    return priorities",
    "response_id": 0,
    "tryHS": false,
    "obj": 4.198244914240141,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response1.txt_stdout.txt",
    "code_path": "problem_iter1_code1.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    A more nuanced approach considering both space utilization and avoidance of fragmentation.\n    Prioritizes bins that have enough space but not excessively so, aiming for efficient packing.\n    Also incorporates a slight preference for bins that are already somewhat full, to encourage consolidation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, remaining_capacity in enumerate(bins_remain_cap):\n        if item <= remaining_capacity:\n            # Calculate the fill ratio if the item were added\n            new_fill_ratio = (1 - (remaining_capacity - item))\n\n            # A factor based on how well the item fits, aiming for relatively full bins\n            fit_score = np.exp(-((remaining_capacity - item) / item)**2) # Gaussian centered at 0 (perfect fit)\n\n            # Slight bonus for bins that already have some content (avoiding excessive fragmentation)\n            existing_fill_penalty = 0.0\n            if remaining_capacity < 1.0: #if the bin is not empty\n                existing_fill_penalty = (1 - remaining_capacity) * 0.5\n\n            # Combine the factors to create the priority\n            priorities[i] = fit_score + existing_fill_penalty # removed new_fill_ratio as its almost always one.\n    return priorities",
    "response_id": 1,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99998443100776 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response2.txt_stdout.txt",
    "code_path": "problem_iter1_code2.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # 1. Feasibility: Only consider bins that can accommodate the item\n    feasible_bins = bins_remain_cap >= item\n    priorities[~feasible_bins] = -np.inf  # Mark infeasible bins with negative infinity\n\n    # 2. Remaining capacity as a priority: Smaller remaining capacity is better, but avoid perfect fits unless necessary\n    remaining_space = bins_remain_cap - item\n    \n    #Smallest feasible remaining space\n    smallest_remaining = np.min(remaining_space[feasible_bins]) if np.any(feasible_bins) else np.inf\n    \n    \n    # Penalize too tight of fits unless that is the best feasible bin\n    tight_fit_penalty = 0.1\n    near_perfect_fit = np.isclose(remaining_space,0) #Perfect fit means bin_remain_cap = item\n\n    #Perfect fit gives huge incentive\n    perfect_fit_bonus = 10\n\n    #Bins with near perfect fits should get a huge boost\n\n    priorities[near_perfect_fit] += perfect_fit_bonus\n\n    # 3. Normalize the remaining capacity scores so its on the scale of 0-1\n    normalized_remaining_space = remaining_space / np.max(bins_remain_cap)\n\n    #Bins with significant remaining space after placing item should be rewarded, we will reward by a log score\n    log_remaining_space = np.log(np.clip(1 - normalized_remaining_space, a_min = 0.001, a_max = 1.0))\n    \n    priorities[feasible_bins] +=  -log_remaining_space[feasible_bins]\n    \n    #If it is very tight fit, penalize if that bin is not the best feasible bin\n    almost_full = (remaining_space > 0) & (remaining_space < 0.1 * np.max(bins_remain_cap))\n\n    best_feasible_index = np.argmin(remaining_space[feasible_bins]) if np.any(feasible_bins) else -1\n\n    if best_feasible_index != -1:\n        #Determine index of best bin in full list\n        true_best_feasible_index = np.where(feasible_bins)[0][best_feasible_index]\n        \n        #Loop through each bin\n        for i, bin_is_almost_full in enumerate(almost_full):\n            #Determine if it is a tight fit\n            if bin_is_almost_full:\n                #If it is and it is not the best feasible bin, penalize it.\n                if i != true_best_feasible_index:\n                  priorities[i] -= tight_fit_penalty\n\n    return priorities",
    "response_id": 2,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 17, in priority_v2\n    infeasible = item > bins_remain_cap\nOverflowError: cannot convert float infinity to integer\n"
  },
  {
    "stdout_filepath": "problem_iter1_response3.txt_stdout.txt",
    "code_path": "problem_iter1_code3.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # First, penalize bins that are too small.  We strongly discourage putting items\n    # in bins where they will cause an overflow.\n    infeasible = item > bins_remain_cap\n    priorities[infeasible] = -np.inf  # Never pick if infeasible\n    \n    # For feasible bins, let's prioritize based on remaining capacity after placement.\n    # Bins closer to full are slightly favored.\n\n    feasible = item <= bins_remain_cap\n    remaining_capacity_after_placement = bins_remain_cap[feasible] - item\n    \n    # Prioritize bins with tighter fits using a non-linear function to avoid very small remaining space.\n    # The tighter the fit, the higher the priority.\n    # The specific formula (e.g., exp, inverse) can be experimented with to fine-tune behavior.\n    \n    priorities[feasible] = np.exp(-5 * remaining_capacity_after_placement / np.max(bins_remain_cap)) if np.max(bins_remain_cap) > 0 else 1  # use exp to emphasize small diff and prevent divide by zero\n\n    # If no bins are available, slightly penalize lower indexes to add to the end of list of empty bins.\n    if not np.any(feasible):\n        priorities = -np.arange(len(bins_remain_cap))\n        \n    return priorities",
    "response_id": 3,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response4.txt_stdout.txt",
    "code_path": "problem_iter1_code4.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Only consider bins that can actually hold the item.\n    valid_bins = bins_remain_cap >= item\n\n    priorities = np.zeros_like(bins_remain_cap)\n\n    if np.any(valid_bins):\n        # 1. Fill as much as possible\n        fill_ratios = item / bins_remain_cap[valid_bins]\n        priorities[valid_bins] = fill_ratios\n\n        # 2. Avoid fragmentation, prioritize bins that fill nearly completely.\n        # Use a Gaussian-like kernel centered around perfect fit.\n        ideal_fill_ratio = 1.0  # perfect fit\n        std_dev = 0.1  # adjust for sensitivity\n\n        fit_gaussian = np.exp(-((fill_ratios - ideal_fill_ratio) ** 2) / (2 * std_dev**2))\n        priorities[valid_bins] += 2.0 * fit_gaussian  # Add more weights for near perfect fits\n        \n        # 3. Try to maximize the remaining space to leave space for next big item.\n        remaining_space = bins_remain_cap[valid_bins] - item\n        # if there is at least one feasible bins\n        priorities[valid_bins] += 0.5 * (remaining_space / np.max(bins_remain_cap))\n\n\n    # Penalize bins that are not valid.  This helps prevent overflow / errors\n    priorities[~valid_bins] = -np.inf\n\n    return priorities",
    "response_id": 4,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 29, in priority_v2\n    return priorities\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n"
  },
  {
    "stdout_filepath": "problem_iter1_response5.txt_stdout.txt",
    "code_path": "problem_iter1_code5.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This function prioritizes bins that can accommodate the item with minimal wasted space,\n    but also introduces a small preference for using already partially filled bins\n    to consolidate items and reduce the overall number of bins used.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Give high priority to bins where the item fits without excessive wasted space.\n    # We'll use a capped inverse of the wasted space.  Bins that cannot fit the item receive a priority of -np.inf\n    wasted_space = bins_remain_cap - item\n    priorities = np.where(wasted_space >= 0, np.clip(1.0 / (1e-6 + wasted_space), 0, 100), -np.inf) #Small number avoids divide by 0. clip avoids extreme scores\n    \n    # Add a small bonus for bins that are already partially filled. This encourages filling bins that have been used before.\n    # The more filled a bin is, the slightly higher the bonus it gets. We are scaling remaining capacity now\n    partially_filled_bonus = (1 - (bins_remain_cap / bins_remain_cap.max())) * 0.1 #Avoids filling very full bins when it isn't a very good fit.\n    priorities = priorities + partially_filled_bonus\n    return priorities",
    "response_id": 5,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 29, in priority_v2\n    else:\nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n"
  },
  {
    "stdout_filepath": "problem_iter1_response6.txt_stdout.txt",
    "code_path": "problem_iter1_code6.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # First, consider bins where the item fits.\n    fit_indices = np.where(bins_remain_cap >= item)[0]\n    \n    if len(fit_indices) > 0:\n        # Try to minimize wasted space, while favoring fuller bins.\n        # Calculate wasted space for each bin where the item fits.\n        wasted_space = bins_remain_cap[fit_indices] - item\n        \n        #Prioritize bins based on: 1/wasted_space + fill ratio if item is added\n        fill_ratio_if_added = (bins_remain_cap[fit_indices] - wasted_space) / (bins_remain_cap[fit_indices] + item - wasted_space)\n        priorities[fit_indices] = (1 / (wasted_space + 1e-9)) + fill_ratio_if_added #add small number to avoid division by 0\n\n    # For bins where the item doesn't fit, assign a very low priority.\n    else:\n      priorities = -np.inf * np.ones_like(bins_remain_cap, dtype=float)\n\n\n    return priorities",
    "response_id": 6,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response7.txt_stdout.txt",
    "code_path": "problem_iter1_code7.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap)\n\n    # Give bins with sufficient capacity a base priority\n    sufficient_capacity = bins_remain_cap >= item\n    priorities[sufficient_capacity] += 1.0\n\n    # Prioritize bins with tighter fits (but still sufficient capacity). This aims to minimize wasted space.\n    # Using exponential to emphasize tighter fits. Scale with the item size to allow different sized items\n    # to find appropriate spots\n    fit_difference = bins_remain_cap[sufficient_capacity] - item\n    priorities[sufficient_capacity] += np.exp(-fit_difference / item)\n\n    # Introduce a stochastic element - this is like a 'quantum fluctuation'\n    # to explore other possibilities. Helps avoid getting stuck in local minima.\n    # Scale randomness with the number of bins\n    num_bins = len(bins_remain_cap)\n    priorities += 0.01 * np.random.rand(num_bins) / num_bins  # Scaled for stability\n\n\n    # Slightly favor bins that are less full. This encourages using more bins in initial phases.\n    # Prevents quickly filling a few bins up, leaving other bins largely empty\n    priorities += (1 - bins_remain_cap / np.max(bins_remain_cap)) * 0.05 #Scaled for effect\n    return priorities",
    "response_id": 7,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Traceback (most recent call last):\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 112, in <module>\n    avg_num_bins = -evaluate(dataset)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 55, in evaluate\n    _, bins_packed = online_binpack(items.astype(float), bins)\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/eval.py\", line 28, in online_binpack\n    priorities = priority(item, bins[valid_bin_indices])\n  File \"/home/dokhanhnam1199/QD/problems/bpp_online/gpt.py\", line 18, in priority_v2\n    \nnumpy._core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n"
  },
  {
    "stdout_filepath": "problem_iter1_response8.txt_stdout.txt",
    "code_path": "problem_iter1_code8.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that can accommodate the item without excessive waste,\n    but also avoids filling bins too early. It uses a combination of remaining capacity,\n    item size, and a waste factor to generate the priority. Bins that can't fit the item\n    receive a very low priority.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Give very low priority to bins that can't fit the item.\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf\n\n    # Calculate waste for bins that can fit.\n    feasible_bins = ~infeasible_bins\n    waste = bins_remain_cap[feasible_bins] - item\n\n    # Calculate a priority based on a combination of factors:\n    # - Inverse of waste: Less waste is better (higher priority).\n    #   We add a small constant to waste to avoid division by zero.\n    # - Remaining capacity: We want to use bins, but not fill them completely.\n\n    priorities[feasible_bins] = (1.0 / (waste + 0.01)) + (bins_remain_cap[feasible_bins] / np.sum(bins_remain_cap))\n    # Normalize the priorities to be between 0 and 1, making interpretation easier.\n    # This scaling helps to prevent large priority values dominating the decision-making.\n    priorities = (priorities - np.min(priorities)) / (np.max(priorities) - np.min(priorities) + 1e-9)  # add small value to avoid ZeroDivisionError\n\n    return priorities",
    "response_id": 8,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response9.txt_stdout.txt",
    "code_path": "problem_iter1_code9.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities with a default low value\n    priorities = np.zeros_like(bins_remain_cap, dtype=float) - np.inf\n\n    # Identify bins that can accommodate the item\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities # No bin can fit the item, return lowest possible priorities.\n\n    # Calculate waste if item is placed in the bin\n    waste = bins_remain_cap - item\n\n    # Prioritize bins based on different strategies:\n    # 1. Minimize waste (First-Fit Decreasing variant): Favor bins with less remaining space after placement\n    priorities[valid_bins] = -waste[valid_bins]  # Smaller waste = higher priority\n\n    # 2. Avoid fragmentation (Encourage filling bins as much as possible):\n    fill_ratios = item / bins_remain_cap\n    priorities[valid_bins] += 5 * fill_ratios[valid_bins] # Reward higher fill ratios\n\n    # 3. Avoid bins that are ALMOST full after adding the item (Leave enough room for future smaller items):\n    nearly_full = (waste > 0) & (waste < 0.1 * bins_remain_cap) # Bins with waste less than 10% of bin capacity\n    priorities[nearly_full] -= 10  # Penalize nearly full bins\n\n    # 4. Boost bins with nearly the same size remaining capacity as the item\n    same_size = np.isclose(bins_remain_cap, item)\n    priorities[same_size] += 20\n\n    # 5. Consider the amount of remaining capacity as a tie-breaker\n    priorities[valid_bins] += 0.01 * bins_remain_cap[valid_bins]  # Higher remaining capacity, slightly higher priority (as a tie-breaker)\n\n    return priorities",
    "response_id": 9,
    "tryHS": false,
    "obj": 4.417630634224167,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response10.txt_stdout.txt",
    "code_path": "problem_iter1_code10.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap)\n    for i, cap in enumerate(bins_remain_cap):\n        if item <= cap:\n            # Encourage filling bins as much as possible\n            fill_ratio = item / cap\n            \n            # Penalize leaving too much space, prefer bins closer to item size\n            waste_penalty = np.abs(cap - item) #Linear penalty\n            #waste_penalty = (cap - item)**2 #Quadratic penalty, stronger discouragement for leaving waste\n            # Scale the penalty to have a meaningful impact on the priority\n            waste_penalty_scaled = waste_penalty / np.max(bins_remain_cap + 1e-9)\n\n            # A small bonus for bins that are almost full\n            almost_full_bonus = 0.0\n            if cap > 0 and item > 0.0:\n                if item / cap > 0.9:\n                    almost_full_bonus = 0.1\n            \n\n            priorities[i] = fill_ratio + almost_full_bonus - waste_penalty_scaled #Original, seems stable\n        else:\n            priorities[i] = -np.inf  # Impossible to add, lowest priority\n    return priorities",
    "response_id": 10,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99999212000694 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response11.txt_stdout.txt",
    "code_path": "problem_iter1_code11.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Utilizes a combination of heuristics inspired by physics and a touch of 'divine intuition'.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # 1. Gravitational Attraction:\n    # Bins with capacity closer to the item's size have higher 'gravitational attraction'.\n    attraction = np.exp(-np.abs(bins_remain_cap - item) / (item + 1e-6))\n\n    # 2. Conservation of Energy (Bin Capacity):\n    # We don't want to 'overfill' the bin. Penalize bins that would be too full.\n    energy_potential = np.zeros_like(bins_remain_cap)\n    valid_bins = bins_remain_cap >= item\n    energy_potential[valid_bins] = (bins_remain_cap[valid_bins] - item) / bins_remain_cap[valid_bins]\n    energy_potential[~valid_bins] = -1  # Heavily penalize invalid bins\n    energy_potential = np.clip(energy_potential, -1, 1)  # Ensure values stay within a reasonable range\n\n\n    # 3. \"God Does Not Play Dice\":\n    # Preferentially use bins that are already partially filled. The more a bin is\n    # filled, the more likely it is to accept another item without wasting too much space\n    # \"Fullness\" factor -- encourages efficient space usage\n    fullness_factor = (1 - (bins_remain_cap / bins_remain_cap.max()))\n    fullness_factor = np.clip(fullness_factor, 0, 1) # Ensure values are non-negative\n\n    # 4. A touch of randomness for exploration. Add small Gaussian noise\n    noise = np.random.normal(0, 0.01, size=bins_remain_cap.shape)\n\n    # Combine these factors with carefully chosen weights.\n    priority = 0.5 * attraction + 0.3 * energy_potential + 0.2*fullness_factor + noise\n\n    return priority",
    "response_id": 11,
    "tryHS": false,
    "obj": 4.068607897885915,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response12.txt_stdout.txt",
    "code_path": "problem_iter1_code12.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    # Calculate the waste if the item is placed in each bin.\n    waste = bins_remain_cap - item\n\n    # Initialize priorities to a low value (e.g., -np.inf)\n    priorities = np.full(bins_remain_cap.shape, -np.inf)\n\n    # Identify bins that can accommodate the item (waste >= 0)\n    valid_bins_indices = waste >= 0\n\n    # Calculate a priority score for valid bins. This score encourages\n    # filling bins as much as possible without creating excessive waste.\n    # Prioritize bins with smaller waste (tighter fit) using a function\n    # inversely proportional to the waste. Adding a small constant (1e-6)\n    # avoids division by zero. We use an exponential decay to promote\n    # better fit.\n    if np.any(valid_bins_indices):\n        priorities[valid_bins_indices] = np.exp(-waste[valid_bins_indices] / item)\n\n\n    #Optionally, add another component to the priority that helps\n    #balance the bins by penalizing bins with very high fill levels\n    #or bins that are nearly full. This helps to avoid cases where a few bins\n    #are completely full and other bins are almost empty\n\n    #If all bins are larger than the item size assign default priorities of 1.0\n    if not np.any(valid_bins_indices):\n      priorities = np.ones(bins_remain_cap.shape)\n\n    return priorities",
    "response_id": 12,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response13.txt_stdout.txt",
    "code_path": "problem_iter1_code13.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Heuristic 1: First-Fit Decreasing adapted for priorities.  Prioritize bins where the item fits, with preference for bins where the remaining capacity is closer to the item size, but not too close (avoiding very small leftovers).\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, cap in enumerate(bins_remain_cap):\n        if item <= cap:\n            # Calculate \"closeness\" to item size, normalized by bin capacity.\n            closeness = 1 - abs(cap - item) / cap\n            # Penalize bins where the remaining space is too small (small leftover after packing).\n            leftover = cap - item\n            if leftover < 0.1:  # Adjust 0.1 based on problem scale\n                priorities[i] = -1  # Very low priority. Could also set to -np.inf\n            else:\n                priorities[i] = closeness\n        else:\n            priorities[i] = -np.inf  # Item doesn't fit; impossible assignment\n\n    # Heuristic 2: Add a small random component to break ties and explore the solution space.\n    priorities += np.random.rand(len(bins_remain_cap)) * 0.001\n\n    return priorities",
    "response_id": 13,
    "tryHS": false,
    "obj": 5.195452732349436,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response14.txt_stdout.txt",
    "code_path": "problem_iter1_code14.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # A bin is eligible only if it can contain the item\n    eligible_bins = bins_remain_cap >= item\n\n    if not np.any(eligible_bins):\n        return priorities # No bin can fit the item. All bins have zero priority.\n\n    # 1. First-Fit Decreasing Heuristic inspired - Consider remaining capacity\n    remaining_capacity_priority = bins_remain_cap - item # positive only if eligible\n\n    #Prioritize bins with smallest waste possible, but only when they can contain the item\n    remaining_capacity_priority[~eligible_bins] = -np.inf #make sure only consider possible candidates\n\n    priorities = remaining_capacity_priority\n\n\n    # 2. Try to avoid bins that are almost full if other bins are more empty.\n    # If the item fills the bin nearly entirely, that might be less efficient later.\n\n    nearly_full = (bins_remain_cap >= item) & (bins_remain_cap < 1.1*item) #tune parameters to your distribution, avoid bins just a bit larger than item\n    priorities[nearly_full] -= 0.1 #mild penalization. Adjust as needed.\n\n\n    # 3. If the item is really big, prioritize almost-full bins to not waste space. This handles large items separately. If the item is a relatively small fraction of bin size (e.g. <10% of bin capacity), then it makes sense to prefer more available capacity to allow for later large items that may come up, but we don't penalize \"filling up\" a bin as heavily. if item > 0.7, change strategy.\n    if item > 0.7 :\n        priorities = bins_remain_cap - item  # Focus on smallest waste for LARGE item\n        priorities[~eligible_bins] = -np.inf\n        priorities +=0.1 #slight boost\n\n\n    # 4. Prioritize bins according to how well the item \"fits\". This is good for general item sizes.\n    #    Want items where item/rem_cap is close to 1, but we already approximated that at step 1.\n\n    return priorities",
    "response_id": 14,
    "tryHS": false,
    "obj": 149.30195452732352,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response15.txt_stdout.txt",
    "code_path": "problem_iter1_code15.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that can accommodate the item closely,\n    avoiding excessive waste but also encouraging reuse of partially filled bins.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if not np.any(valid_bins):\n        return priorities  # No bin can fit the item\n\n    # Reward bins with smallest remaining capacity AFTER fitting the item (minimize waste)\n    remaining_after_fit = bins_remain_cap[valid_bins] - item\n    priorities[valid_bins] = -remaining_after_fit\n\n    # Also add a bonus for bins that are already somewhat full (encourage reuse)\n    priorities[valid_bins] += (1 - bins_remain_cap[valid_bins])\n\n\n    # Exponentiate the priorities to exaggerate the differences\n    priorities[valid_bins] = np.exp(priorities[valid_bins])\n    return priorities",
    "response_id": 15,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response16.txt_stdout.txt",
    "code_path": "problem_iter1_code16.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n       This version prioritizes bins that can fit the item snugly\n       while also discouraging near-full bins to avoid fragmentation.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Give a negative infinite score to bins that cannot fit the item.\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    # Calculate the waste if the item is placed in each feasible bin.\n    waste = bins_remain_cap - item\n    feasible_mask = ~infeasible_mask #redundant for clarity\n\n    # Prioritize bins that result in smaller waste (snug fit).  Also, avoid bins that are almost full after adding item.\n    priorities[feasible_mask] = np.exp(-10 * waste[feasible_mask] / bins_remain_cap.max()) - (item/bins_remain_cap[feasible_mask])  # Snug fit exponential with small negative item/cap term\n\n    # Add a bonus for bins with moderate remaining capacity to promote balanced utilization\n    moderate_cap_mask = (bins_remain_cap > item) & (bins_remain_cap < bins_remain_cap.max() / 2 + item)\n    priorities[moderate_cap_mask] += 0.5\n\n    # Small bonus for bins with enough space left in them\n    large_cap_mask = bins_remain_cap > (2*item)\n    priorities[large_cap_mask] += 0.1\n\n    return priorities",
    "response_id": 16,
    "tryHS": false,
    "obj": 4.637016354208217,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response17.txt_stdout.txt",
    "code_path": "problem_iter1_code17.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.  Inspired by energy minimization and probabilities.\n\n    This version attempts to mimic a simulated annealing or quantum annealing process, where better fits are\n    preferred with higher probability.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Calculate the wasted space if the item is placed in each bin\n    wasted_space = bins_remain_cap - item\n\n    # Bins that cannot accommodate the item get a very low priority\n    wasted_space[wasted_space < 0] = np.inf  #effectively exclude these\n\n    # Scale the wasted space to a reasonable range. Adding a small value to avoid zero division\n    scaled_wasted_space = wasted_space / (np.max(bins_remain_cap) + 1e-9)  #normalized\n\n    #Convert 'energy' to 'probability'-like measure, and normalize:\n    priorities = np.exp(-scaled_wasted_space)\n\n    # Normalize priorities to ensure sum is 1 (optional, but can be helpful)\n    priorities = priorities / np.sum(priorities)  #or just normalize to [0,1] by dividing by max(priorities)\n\n    # Small constant to prefer bins with some remaining capacity (exploration):\n    priorities += 1e-6 * bins_remain_cap/np.max(bins_remain_cap)\n    return priorities",
    "response_id": 17,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response18.txt_stdout.txt",
    "code_path": "problem_iter1_code18.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Idea:\n    # 1. Heavily penalize bins that cannot fit the item.\n    # 2. Prioritize bins where the item fills a significant portion of the bin\n    #    but avoid bins that will become too full (small remaining space).\n    # 3. Add a small random component to break ties and encourage exploration.\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Penalize bins that cannot fit the item\n    infeasible_mask = bins_remain_cap < item\n    priorities[infeasible_mask] = -np.inf\n\n    # Calculate remaining capacity after adding the item\n    remaining_after_add = bins_remain_cap - item\n\n    # Prioritize bins that can fit the item. Higher the percentage of item/bin size better it is\n    feasible_mask = bins_remain_cap >= item\n    fill_ratios = item / bins_remain_cap[feasible_mask]\n    priorities[feasible_mask] = fill_ratios # Favor bins that item fills well\n\n    # Moderate penalty for bins becoming near-full after adding the item\n    near_full_mask = (remaining_after_add > 0) & (remaining_after_add < 0.1) #remaining capacity less than 10%\n    priorities[near_full_mask] -= 0.2\n\n    # Slight boost for bins that will still have substantial remaining capacity. This is crucial.\n    substantial_remain_mask = (remaining_after_add >= 0.3)\n    priorities[substantial_remain_mask] += 0.1\n\n    # Add a small random number to break ties and explore\n    priorities += np.random.rand(len(bins_remain_cap)) * 0.01\n\n    return priorities",
    "response_id": 18,
    "tryHS": false,
    "obj": 4.487435181491823,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response19.txt_stdout.txt",
    "code_path": "problem_iter1_code19.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Give a higher priority to bins that can fit the item.\n            # Prioritize bins that leave less space after packing (First Fit Decreasing heuristic idea).\n            remaining_space = cap - item\n            # Give bonus to bins where the remaining space is small, but penalize too small space\n            if remaining_space > 0.0:\n              priorities[i] = (item / cap) + (1.0 / (remaining_space + 0.00001))  # avoid division by zero and encourage fitting well. The original item / cap prefers full bins regardless of fit, but 1/(remaining_space + small number) encourages snug fits instead.\n            else:\n                priorities[i] = -np.inf  # make this invalid; shouldn't happen, but just in case!\n        else:\n            # Very low priority to bins that cannot fit the item.\n            priorities[i] = -np.inf  # Ensure these bins are never considered unless all bins are too small.\n\n    # If no bin can fit the item, then equally penalize all bins\n    if np.all(priorities == -np.inf):\n        priorities = np.ones_like(bins_remain_cap) * -10\n    return priorities",
    "response_id": 19,
    "tryHS": false,
    "obj": 5.195452732349436,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response20.txt_stdout.txt",
    "code_path": "problem_iter1_code20.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    \n    # 1. Feasibility check: Disqualify bins that cannot fit the item.\n    infeasible_bins = bins_remain_cap < item\n    priorities[infeasible_bins] = -np.inf\n    \n    # 2. Remaining capacity after placing the item\n    remaining_capacities = bins_remain_cap - item\n    remaining_capacities[infeasible_bins] = np.inf  # Avoid errors from infeasible bins.\n\n    # 3. Prioritize bins based on fill ratio *after* placing the item. Higher fill ratio is better, but avoid overfilling\n    fill_ratios = 1 - (remaining_capacities / np.max(bins_remain_cap))\n    priorities[~infeasible_bins] = fill_ratios[~infeasible_bins]\n    \n    # 4. Add a small bonus for bins that were already partially filled, so we dont start new bins unnecessarily\n    already_filled = bins_remain_cap < np.max(bins_remain_cap)\n    priorities[already_filled & ~infeasible_bins] += 0.1\n\n    #5. If two bins are equal in fill ratio after the addition of an item prioritize the one with smallest remaining capacity\n    priorities[~infeasible_bins] -= 0.0001 * remaining_capacities[~infeasible_bins]\n\n    return priorities",
    "response_id": 20,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response21.txt_stdout.txt",
    "code_path": "problem_iter1_code21.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Employing a more nuanced approach, considering both the fit and the fullness\n    of the bin. We prioritize bins that can accommodate the item reasonably well\n    without leaving excessive unused space.  We add a bit of randomness to avoid\n    getting stuck in local minima, mimicking the inherent uncertainty of the\n    universe. Inspired by space-time distortion, where the item 'bends' the\n    bin capacity landscape.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Fit Score: Prioritize better fits, not just any fit\n            fit_score = np.exp(-((cap - item) / item)**2) # Gaussian-like preference for closer fits\n\n            # Fullness Score: Discourage excessive remaining space after packing\n            fullness_score = np.tanh(item / cap) # Reward bins nearing completion\n\n            # Space-Time Distortion - slightly modify the space to introduce variation\n            distortion = np.random.normal(0, 0.01) # add some randomness\n\n            priorities[i] = fit_score + fullness_score + distortion\n        else:\n            priorities[i] = -np.inf  # Cannot fit, extremely low priority\n\n    return priorities",
    "response_id": 21,
    "tryHS": false,
    "exec_success": false,
    "obj": Infinity,
    "traceback_msg": "Command '['python3', '-u', '/home/dokhanhnam1199/QD/problems/bpp_online/eval.py', '5000', '/home/dokhanhnam1199/QD', 'train']' timed out after 49.99998776000575 seconds"
  },
  {
    "stdout_filepath": "problem_iter1_response22.txt_stdout.txt",
    "code_path": "problem_iter1_code22.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Initialize priorities with a base value (e.g., 0).\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Give high priority to bins that can fit the item. If a bin cannot fit, the priority is zero\n    fit_indices = bins_remain_cap >= item\n    priorities[fit_indices] = 1.0\n\n    # Adjust priorities based on how well the item fits. Use a ratio of remaining capacity after fitting.\n    remaining_capacity = bins_remain_cap[fit_indices] - item\n    capacity_ratios = remaining_capacity / bins_remain_cap[fit_indices]\n\n    # A smaller remaining capacity should give a higher priority. The most full-like bin is thus prioritized\n    priorities[fit_indices] += (1.0 - capacity_ratios)**2  # Adding to the already existing '1'\n\n    #Bonus for almost full bin. If the bin can take the new item almost perfectly without leaving any considerable space, prioritize it\n    almost_full_indices = np.where((bins_remain_cap >= item) & (bins_remain_cap - item <= 0.1*bins_remain_cap ))[0]\n    priorities[almost_full_indices]+=1.0 #Bonus Score\n\n    return priorities",
    "response_id": 22,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response23.txt_stdout.txt",
    "code_path": "problem_iter1_code23.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that can fit the item snugly,\n    but also considers the absolute remaining capacity to avoid\n    filling bins too early with small items if larger items are expected.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n    valid_bins = bins_remain_cap >= item\n\n    if np.any(valid_bins):\n        # Calculate the wasted space if the item is placed in each valid bin\n        wasted_space = bins_remain_cap[valid_bins] - item\n\n        # Calculate a \"snugness\" score - lower wasted space is better\n        snugness = np.exp(-wasted_space)\n\n        #Give larger bins (more total capacity) a slightly better shot at fitting the items if there's space.\n        capacity_boost = bins_remain_cap[valid_bins]/np.max(bins_remain_cap) #boost score based on how full/empty bin is. Higher is more space remaining (better)\n\n        # Combine snugness and remaining capacity boost to make up priority\n        priorities[valid_bins] = snugness * capacity_boost\n\n    return priorities",
    "response_id": 23,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response24.txt_stdout.txt",
    "code_path": "problem_iter1_code24.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This priority function considers both the remaining capacity and how well\n    the item fills the bin. It favors bins that can accommodate the item\n    without excessive waste, while also penalizing near-full bins that\n    would become almost completely filled.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Define parameters to fine-tune the heuristic\n    capacity_threshold = 0.1  # Avoid bins with capacity below this ratio\n    fill_threshold = 0.9       # Reward bins that fill up to this ratio after adding the item\n    overfill_penalty = -1000   # Huge penalty for bins that can't hold item\n\n    for i, cap in enumerate(bins_remain_cap):\n        if item > cap:\n            priorities[i] = overfill_penalty  # Penalize bins that are too small\n        else:\n            fill_ratio = (item + cap) / (1 + cap) #approximating bin size = 1 to normalize\n\n            # Prefer bins that are well-filled without becoming excessively full\n            if cap > 0:\n                # prioritize near best fit but penalize near empty bins.\n                waste = cap - item\n                priority_add = -waste # linear penalty for wasted space.\n                fill_bonus = 0\n                if cap > 0 and item/cap > 0.8 and item/cap < 1.0:\n                   fill_bonus = 10\n\n                priorities[i] = priority_add + fill_bonus\n            else:\n                priorities[i] = -100\n\n    return priorities",
    "response_id": 24,
    "tryHS": false,
    "obj": 4.646988432389324,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response25.txt_stdout.txt",
    "code_path": "problem_iter1_code25.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Aimed at reducing bin fragmentation and overall bin count.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # 1. High priority for bins that can fit the item closely\n    fit_mask = bins_remain_cap >= item\n    priorities[fit_mask] = (bins_remain_cap[fit_mask] - item) / bins_remain_cap[fit_mask]  # Remaining capacity ratio - Smaller is better, so invert\n\n    priorities[fit_mask] = 1 - priorities[fit_mask] #higher number, higher priority\n\n    # 2. Very low priority for bins that can't fit (to discourage large item being crammed in tight spaces later.)\n    priorities[bins_remain_cap < item] = -1.0\n\n    # 3. Favor bins that are relatively empty (encourage use of partially filled bins before starting new ones).\n    # This term is weaker than the fit closeness to allow bins close in capacity to be filled faster.\n    normalized_capacity = bins_remain_cap / np.max(bins_remain_cap) if np.max(bins_remain_cap) > 0 else np.zeros_like(bins_remain_cap)\n    priorities += 0.1*normalized_capacity #add remaining capacity priority\n    return priorities",
    "response_id": 25,
    "tryHS": false,
    "obj": 4.058635819704831,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response26.txt_stdout.txt",
    "code_path": "problem_iter1_code26.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Heuristic 1: First-Fit Decreasing (FFD) inspired. Prioritize bins that can accommodate the item with minimal wasted space, but also\n    # encourage filling up bins rather than leaving many partially filled.\n\n    # Only consider bins that can actually fit the item\n    valid_bins = bins_remain_cap >= item\n    priority = np.zeros_like(bins_remain_cap, dtype=float) - np.inf # Initial priority of -inf\n\n    if np.any(valid_bins):\n        remaining_space = bins_remain_cap[valid_bins] - item\n        # Scale remaining space by item size. Helps prioritize based on relative waste.\n        scaled_waste = remaining_space / item\n\n        # Heuristic: smaller waste is generally better (first fit), but incentivize near-full bins.\n        priority[valid_bins] = -scaled_waste + (bins_remain_cap[valid_bins] / np.sum(bins_remain_cap))\n\n        #Boost priority of the fullest bins\n        priority[bins_remain_cap == np.max(bins_remain_cap)] += 0.000001\n\n    return priority",
    "response_id": 26,
    "tryHS": false,
    "obj": 4.048663741523748,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response27.txt_stdout.txt",
    "code_path": "problem_iter1_code27.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n    This version incorporates a \"near miss\" bonus and a penalty for bins that are too small.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Penalty for bins that cannot contain the item\n    priorities[bins_remain_cap < item] = -np.inf  # Or a very large negative number\n\n    # Calculate \"near miss\" bonus - bins only slightly larger than the item get high priority\n    near_miss_threshold = item * 1.2 #tuneable, percentage above item size to be \"near miss\"\n    near_miss_bonus = np.exp(-np.abs(bins_remain_cap - item) / (item*0.1))  # Gaussian-like bonus near item size.  0.1 is tunable.\n    near_miss_bonus[bins_remain_cap < item] = 0 # Avoid triggering near-miss for impossible fits\n    priorities += near_miss_bonus\n\n    # Fill rate priority- favors filling almost empty bins somewhat.\n    fill_rate_priority = (bins_remain_cap - item)/bins_remain_cap\n    fill_rate_priority[bins_remain_cap < item] = -np.inf\n    priorities += fill_rate_priority # Consider scaling if one influence is too strong\n\n    #Remaining capacity priority (modified first-fit)\n    priorities += bins_remain_cap / np.sum(bins_remain_cap)\n\n    return priorities",
    "response_id": 27,
    "tryHS": false,
    "obj": 80.86358197048266,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response28.txt_stdout.txt",
    "code_path": "problem_iter1_code28.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    # Heuristic 1: Avoid fragmentation by prioritizing bins that can fit the item snugly.\n    # Heuristic 2: Use a combination of remaining capacity and item size to calculate score.\n    # Heuristic 3: Prefer bins that are relatively full to avoid leaving too much empty space\n    # after placing the current item.\n\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    for i, cap in enumerate(bins_remain_cap):\n        if cap >= item:\n            # Base priority: Higher remaining capacity implies potentially better fit (less waste).\n            priorities[i] = cap\n\n            # Adjust for 'snugness': Smaller remaining space *after* packing increases the score\n            remaining_after_pack = cap - item\n            priorities[i] += 1.0 / (remaining_after_pack + 0.0001)  # Avoid division by zero\n\n            # Scale the score by how full the bin currently is.\n            current_fullness = 1.0 - (cap / (cap + item)) # Approximation\n            priorities[i] += current_fullness\n        else:\n            priorities[i] = -np.inf  # Item doesn't fit: Lowest priority\n\n    return priorities",
    "response_id": 28,
    "tryHS": false,
    "obj": 86.58755484643,
    "exec_success": true
  },
  {
    "stdout_filepath": "problem_iter1_response29.txt_stdout.txt",
    "code_path": "problem_iter1_code29.py",
    "code": "import numpy as np\n\ndef priority_v2(item: float, bins_remain_cap: np.ndarray) -> np.ndarray:\n    \"\"\"Returns priority with which we want to add item to each bin.\n\n    This version prioritizes bins that can fit the item closely,\n    but also adds a small bonus for bins that are emptier, to\n    encourage filling up partially empty bins. It also heavily penalizes bins that cannot fit the item.\n\n    Args:\n        item: Size of item to be added to the bin.\n        bins_remain_cap: Array of capacities for each bin.\n\n    Return:\n        Array of same size as bins_remain_cap with priority score of each bin.\n    \"\"\"\n    priorities = np.zeros_like(bins_remain_cap, dtype=float)\n\n    # Penalize bins that cannot fit the item *very* strongly.\n    infeasible = bins_remain_cap < item\n    priorities[infeasible] = -np.inf\n\n    # For bins that can fit the item, calculate a priority based on:\n    # 1. How closely the item fits (remaining capacity after adding)\n    # 2. A small bonus for the remaining capacity *before* adding the item.\n\n    feasible = bins_remain_cap >= item\n    remaining_after = bins_remain_cap[feasible] - item\n    \n    # The smaller remaining_after, the better.  Using reciprocal.\n    fit_priority = 1.0 / (remaining_after + 0.0001)  # add small constant to avoid division by zero if remaining_after is near zero\n\n    # Bonus for emptier bins. Using a logarithmic scale so as not to overpower the fit_priority.\n    empty_bonus = np.log(bins_remain_cap[feasible] + 1)\n\n    priorities[feasible] = fit_priority + 0.1 * empty_bonus  # weighted combination of fit priority and empty bonus\n\n    return priorities",
    "response_id": 29,
    "tryHS": false,
    "obj": 49.92022337455127,
    "exec_success": true
  }
]