{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling. CVRP requires finding the shortest path that visits all given nodes and returns to the starting node. Each node has a demand and each vehicle has a capacity. The total demand of the nodes visited by a vehicle cannot exceed the vehicle capacity. When the total demand exceeds the vehicle capacity, the vehicle must return to the starting node.\nThe `heuristics` function takes as input a distance matrix (shape: n by n), Euclidean coordinates of nodes (shape: n by 2), a vector of customer demands (shape: n), and the integer capacity of vehicle capacity. It returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the distance_matrix. The depot node is indexed by 0.\n\n\nCurrent heuristics:\ndef heuristics_v1(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"\n    Heuristics for solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling.\n\n    This version incorporates:\n    1. Distance: Edges with shorter distances are preferred.\n    2. Demand Feasibility: Penalizes edges that would immediately violate capacity constraints if used early in a route.\n    3. Depot Proximity: Prioritizes returning to the depot from nodes that are far from other customers and have high demand.\n    4. Gravitational Attraction: Mimics the gravitational attraction of black holes: Nodes with high demand and/or far from depot will \"attract\" closer nodes to form clusters.\n    5. Savings Heuristic Integration: Incorporates the savings heuristic to encourage merging routes.\n    6. Sparsification: Sets unpromising edges to zero to focus the search.\n\n    Args:\n        distance_matrix (np.ndarray): Distance matrix between nodes (shape: n x n).\n        coordinates (np.ndarray): Euclidean coordinates of nodes (shape: n x 2).\n        demands (np.ndarray): Vector of customer demands (shape: n). The demand of depot is demands[0].\n        capacity (int): Vehicle capacity.\n\n    Returns:\n        np.ndarray: Prior indicators of how promising it is to include each edge in a solution (shape: n x n).\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros((n, n))\n    epsilon = 1e-6\n\n    # 1. Distance component\n    distance_heuristic = 1 / (distance_matrix + epsilon)\n\n    # 2. Demand Feasibility\n    demand_heuristic = np.ones((n, n))\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                demand_heuristic[i, j] = 0\n            if demands[i] + demands[j] > capacity and i == 0:\n                demand_heuristic[i, j] = 0.1\n            elif demands[i] + demands[j] > capacity and j == 0:\n                demand_heuristic[i, j] = 0.1\n            elif i != 0 and demands[i] > capacity or j != 0 and demands[j] > capacity:\n                demand_heuristic[i,j] = 0.05\n\n    # 3. Depot Proximity\n    depot_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        avg_distance = np.sum(distance_matrix[i, 1:]) / (n - 2) if n > 2 else distance_matrix[i,0]\n        depot_preference = (avg_distance / np.max(distance_matrix)) * (demands[i] / capacity)\n        depot_heuristic[i, 0] = depot_preference\n        depot_heuristic[0, i] = depot_preference\n\n    # 4. Gravitational Attraction\n    gravitational_heuristic = np.zeros((n, n))\n    gravitational_constant = 1.0\n    for i in range(1, n):\n        for j in range(1, n):\n            mass_i = demands[i]\n            mass_j = demands[j]\n            if i == j:\n                gravitational_heuristic[i,j] = 0\n                continue\n            gravitational_heuristic[i, j] = gravitational_constant * (mass_i * mass_j) / (distance_matrix[i, j]**2 + epsilon)\n\n    # 5. Savings Heuristic\n    savings_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        for j in range(i + 1, n):\n            savings = distance_matrix[i, 0] + distance_matrix[0, j] - distance_matrix[i, j]\n            savings_heuristic[i, j] = savings\n            savings_heuristic[j, i] = savings  # Savings are symmetric\n\n    # Combine the heuristics with adaptive weights.  Weights could be tuned by a metaheuristic\n    alpha = 0.4\n    beta = 0.2\n    gamma = 0.15\n    delta = 0.15\n    eta = 0.1\n\n    heuristics = alpha * distance_heuristic * demand_heuristic + beta * depot_heuristic + gamma * gravitational_heuristic + delta * savings_heuristic\n\n    # 6. Sparsification\n    # Only keep edges with a heuristic value above a certain threshold or that are among the k-nearest neighbors.\n\n    k_nearest = 10 #consider only k-nearest neighbors.\n    threshold = np.percentile(heuristics[heuristics > 0], 30)  # Dynamic threshold (e.g., 30th percentile)\n\n    for i in range(n):\n        # Find k-nearest neighbors\n        nearest_neighbors = np.argsort(distance_matrix[i, :])[1:k_nearest+1] #excluding self loop and depot\n\n        for j in range(n):\n            if heuristics[i, j] < threshold and j not in nearest_neighbors:\n                heuristics[i, j] = 0\n\n    # Normalize to be between 0 and 1\n    max_val = np.max(heuristics)\n    if max_val > 0:\n        heuristics = heuristics / max_val\n\n    return heuristics\n\nNow, think outside the box write a mutated function `heuristics_v2` better than current version.\nYou can use some hints below:\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, here's a refined perspective on self-reflection to guide heuristic design, focusing on actionable insights:\n\n*   **Keywords:** Factor diversity, adaptive weighting, normalization, spatial relationships, sparsification, problem characteristics.\n\n*   **Advice:** Explore clustering techniques, gravitational attraction principles, and rigorous normalization strategies within your heuristics. Adapt weights based on real-time problem characteristics, not just initial assumptions.\n\n*   **Avoid:** Solely relying on distance/demand, static weighting schemes, ignoring spatial context, premature convergence.\n\n*   **Explanation:** Broadening the factor base and adapting to problem nuances are crucial for robust and high-performing heuristics. Normalization stabilizes weighting.\n\n\nOutput code only and enclose your code with Python code block: ```python ... ```.\nI'm going to tip $999K for a better solution!"}