{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling. CVRP requires finding the shortest path that visits all given nodes and returns to the starting node. Each node has a demand and each vehicle has a capacity. The total demand of the nodes visited by a vehicle cannot exceed the vehicle capacity. When the total demand exceeds the vehicle capacity, the vehicle must return to the starting node.\nThe `heuristics` function takes as input a distance matrix (shape: n by n), Euclidean coordinates of nodes (shape: n by 2), a vector of customer demands (shape: n), and the integer capacity of vehicle capacity. It returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the distance_matrix. The depot node is indexed by 0.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"CVRP heuristics: Combines distance, demand, depot proximity,savings and gravitation with sparsification.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros((n, n))\n    epsilon = 1e-6\n\n    # Distance component\n    distance_heuristic = 1 / (distance_matrix + epsilon)\n\n    # Demand Feasibility\n    demand_heuristic = np.ones((n, n))\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                demand_heuristic[i, j] = 0\n            if demands[i] + demands[j] > capacity and i == 0:\n                demand_heuristic[i, j] = 0.1\n            elif demands[i] + demands[j] > capacity and j == 0:\n                demand_heuristic[i, j] = 0.1\n            elif i != 0 and demands[i] > capacity or j != 0 and demands[j] > capacity:\n                demand_heuristic[i,j] = 0.05\n\n    # Depot Proximity\n    depot_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        avg_distance = np.sum(distance_matrix[i, 1:]) / (n - 2) if n > 2 else distance_matrix[i,0]\n        depot_preference = (avg_distance / np.max(distance_matrix)) * (demands[i] / capacity)\n        depot_heuristic[i, 0] = depot_preference\n        depot_heuristic[0, i] = depot_preference\n\n    # Gravitational Attraction\n    gravitational_heuristic = np.zeros((n, n))\n    gravitational_constant = 1.0\n    for i in range(1, n):\n        for j in range(1, n):\n            mass_i = demands[i]\n            mass_j = demands[j]\n            if i == j:\n                gravitational_heuristic[i,j] = 0\n                continue\n            gravitational_heuristic[i, j] = gravitational_constant * (mass_i * mass_j) / (distance_matrix[i, j]**2 + epsilon)\n\n    # Savings Heuristic\n    savings_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        for j in range(i + 1, n):\n            savings = distance_matrix[i, 0] + distance_matrix[0, j] - distance_matrix[i, j]\n            savings_heuristic[i, j] = savings\n            savings_heuristic[j, i] = savings  # Savings are symmetric\n\n    # Adaptive Weighting\n    capacity_ratio = np.sum(demands[1:]) / (capacity * (n - 1))  # Approximate tightness\n    alpha = 0.3\n    beta = 0.15\n    gamma = 0.1\n    delta = 0.1\n\n    alpha += 0.1 * capacity_ratio  # Increase importance of distance if capacity is tight\n    beta -= 0.05 * capacity_ratio  # Decrease importance of going to depot if capacity is tight\n\n    heuristics = alpha * distance_heuristic * demand_heuristic + beta * depot_heuristic + gamma * gravitational_heuristic + delta * savings_heuristic\n\n    # Sparsification\n    k_nearest = 10  # consider only k-nearest neighbors.\n    threshold = np.percentile(heuristics[heuristics > 0], 30)\n\n    for i in range(n):\n        nearest_neighbors = np.argsort(distance_matrix[i, :])[1:k_nearest+1]\n\n        for j in range(n):\n            if heuristics[i, j] < threshold and j not in nearest_neighbors:\n                heuristics[i, j] = 0\n\n    max_val = np.max(heuristics)\n    if max_val > 0:\n        heuristics = heuristics / max_val\n\n    return heuristics\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"\n    Heuristics for solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling.\n\n    This version incorporates:\n    1. Distance: Edges with shorter distances are preferred.\n    2. Demand Feasibility: Penalizes edges that would immediately violate capacity constraints if used early in a route.\n    3. Depot Proximity: Prioritizes returning to the depot from nodes that are far from other customers and have high demand.\n    4. Gravitational Attraction: Mimics the gravitational attraction of black holes: Nodes with high demand and/or far from depot will \"attract\" closer nodes to form clusters.\n    5. Savings Heuristic Integration: Incorporates the savings heuristic to encourage merging routes.\n    6. Sparsification: Sets unpromising edges to zero to focus the search.\n    7. Clustering Coefficient: Encourages connections between nodes within local clusters\n    8. Adaptive Weighting: Adjusts weights based on problem characteristics (e.g., tightness of capacity)\n    9. Angle Cost: Edges forming sharp turns are penalized.\n    10. Route balance: A factor promoting more equally sized routes.\n\n    Args:\n        distance_matrix (np.ndarray): Distance matrix between nodes (shape: n x n).\n        coordinates (np.ndarray): Euclidean coordinates of nodes (shape: n x 2).\n        demands (np.ndarray): Vector of customer demands (shape: n). The demand of depot is demands[0].\n        capacity (int): Vehicle capacity.\n\n    Returns:\n        np.ndarray: Prior indicators of how promising it is to include each edge in a solution (shape: n x n).\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros((n, n))\n    epsilon = 1e-6\n\n    # 1. Distance component\n    distance_heuristic = 1 / (distance_matrix + epsilon)\n    distance_heuristic = (distance_heuristic - np.min(distance_heuristic)) / (np.max(distance_heuristic) - np.min(distance_heuristic) + epsilon) # Normalize\n\n    # 2. Demand Feasibility\n    demand_heuristic = np.ones((n, n))\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                demand_heuristic[i, j] = 0\n            if demands[i] + demands[j] > capacity and i == 0:\n                demand_heuristic[i, j] = 0.1\n            elif demands[i] + demands[j] > capacity and j == 0:\n                demand_heuristic[i, j] = 0.1\n            elif i != 0 and demands[i] > capacity or j != 0 and demands[j] > capacity:\n                demand_heuristic[i,j] = 0.05\n    demand_heuristic = (demand_heuristic - np.min(demand_heuristic)) / (np.max(demand_heuristic) - np.min(demand_heuristic) + epsilon) # Normalize\n\n    # 3. Depot Proximity\n    depot_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        avg_distance = np.sum(distance_matrix[i, 1:]) / (n - 2) if n > 2 else distance_matrix[i,0]\n        depot_preference = (avg_distance / np.max(distance_matrix)) * (demands[i] / capacity)\n        depot_heuristic[i, 0] = depot_preference\n        depot_heuristic[0, i] = depot_preference\n    depot_heuristic = (depot_heuristic - np.min(depot_heuristic)) / (np.max(depot_heuristic) - np.min(depot_heuristic) + epsilon) # Normalize\n\n    # 4. Gravitational Attraction\n    gravitational_heuristic = np.zeros((n, n))\n    gravitational_constant = 1.0\n    for i in range(1, n):\n        for j in range(1, n):\n            mass_i = demands[i]\n            mass_j = demands[j]\n            if i == j:\n                gravitational_heuristic[i,j] = 0\n                continue\n            gravitational_heuristic[i, j] = gravitational_constant * (mass_i * mass_j) / (distance_matrix[i, j]**2 + epsilon)\n    gravitational_heuristic = (gravitational_heuristic - np.min(gravitational_heuristic)) / (np.max(gravitational_heuristic) - np.min(gravitational_heuristic) + epsilon) # Normalize\n\n    # 5. Savings Heuristic\n    savings_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        for j in range(i + 1, n):\n            savings = distance_matrix[i, 0] + distance_matrix[0, j] - distance_matrix[i, j]\n            savings_heuristic[i, j] = savings\n            savings_heuristic[j, i] = savings  # Savings are symmetric\n    savings_heuristic = (savings_heuristic - np.min(savings_heuristic)) / (np.max(savings_heuristic) - np.min(savings_heuristic) + epsilon) # Normalize\n\n    # 7. Clustering Coefficient approximation (Local Density)\n    clustering_heuristic = np.zeros((n, n))\n    k_nearest = 6  # Consider only k-nearest neighbors for clustering\n    for i in range(1, n):\n        nearest_neighbors = np.argsort(distance_matrix[i, 1:])[:k_nearest] + 1  # k-nearest neighbors excluding depot, adjusting index\n        for j in range(1, n):\n            if i != j:\n                common_neighbors = 0\n                for neighbor_i in nearest_neighbors:\n                    if neighbor_i in (np.argsort(distance_matrix[j, 1:])[:k_nearest] + 1):\n                        common_neighbors += 1\n                clustering_heuristic[i, j] = common_neighbors / k_nearest\n    clustering_heuristic = (clustering_heuristic - np.min(clustering_heuristic)) / (np.max(clustering_heuristic) - np.min(clustering_heuristic) + epsilon) # Normalize\n\n    # 9. Angle Cost\n    angle_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        for j in range(1, n):\n            if i != j:\n                # Vectors from depot to i and depot to j\n                vector_i = coordinates[i] - coordinates[0]\n                vector_j = coordinates[j] - coordinates[0]\n\n                # Calculate the cosine of the angle between the vectors\n                dot_product = np.dot(vector_i, vector_j)\n                magnitude_i = np.linalg.norm(vector_i)\n                magnitude_j = np.linalg.norm(vector_j)\n                cos_angle = dot_product / (magnitude_i * magnitude_j + epsilon)\n\n                # Convert cosine to angle in radians\n                angle = np.arccos(np.clip(cos_angle, -1.0, 1.0))\n\n                # Penalize sharp turns (small angles)\n                angle_cost = angle / np.pi  # Normalize angle to [0, 1]\n                angle_heuristic[i, j] = angle_cost\n    angle_heuristic = (angle_heuristic - np.min(angle_heuristic)) / (np.max(angle_heuristic) - np.min(angle_heuristic) + epsilon)  # Normalize\n\n\n    # 10. Route balance\n    route_balance_heuristic = np.zeros((n, n))\n    total_demand = np.sum(demands[1:])\n    ideal_route_demand = total_demand / 3 if total_demand / capacity > 3 else total_demand / (int(total_demand / capacity) +1) #Assuming 3 vehicles.\n    for i in range(1, n):\n        demand_diff_penalty = np.abs(demands[i] - ideal_route_demand) / total_demand\n        route_balance_heuristic[0, i] = 1 - demand_diff_penalty\n        route_balance_heuristic[i, 0] = 1 - demand_diff_penalty\n\n    route_balance_heuristic = (route_balance_heuristic - np.min(route_balance_heuristic)) / (np.max(route_balance_heuristic) - np.min(route_balance_heuristic) + epsilon)  # Normalize\n\n\n    # 8. Adaptive Weighting\n    capacity_ratio = np.sum(demands[1:]) / (capacity * (n - 1))  # Approximate tightness\n    alpha = 0.25\n    beta = 0.10\n    gamma = 0.05\n    delta = 0.10\n    eta = 0.05\n    mu = 0.05\n    phi = 0.20\n    lamda = 0.2\n\n\n    # Adjust weights based on capacity ratio\n    alpha += 0.1 * capacity_ratio  # Increase importance of distance if capacity is tight\n    beta -= 0.05 * capacity_ratio  # Decrease importance of going to depot if capacity is tight (more local clusters)\n    phi -= 0.05 * capacity_ratio\n\n    # Combine the heuristics with adaptive weights. Weights could be tuned by a metaheuristic\n    heuristics = alpha * distance_heuristic * demand_heuristic + beta * depot_heuristic + gamma * gravitational_heuristic + delta * savings_heuristic + mu * clustering_heuristic + phi * angle_heuristic + lamda * route_balance_heuristic\n\n    # 6. Sparsification\n    # Only keep edges with a heuristic value above a certain threshold or that are among the k-nearest neighbors.\n    k_nearest = 10  # consider only k-nearest neighbors.\n    threshold = np.percentile(heuristics[heuristics > 0], 30)  # Dynamic threshold (e.g., 30th percentile)\n\n    for i in range(n):\n        # Find k-nearest neighbors\n        nearest_neighbors = np.argsort(distance_matrix[i, :])[1:k_nearest+1] #excluding self loop and depot\n\n        for j in range(n):\n            if heuristics[i, j] < threshold and j not in nearest_neighbors:\n                heuristics[i, j] = 0\n\n    # Normalize to be between 0 and 1\n    max_val = np.max(heuristics)\n    if max_val > 0:\n        heuristics = heuristics / max_val\n\n    return heuristics\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the 1st heuristic incorporates adaptive weights based on `demand_ratio`, while the 20th uses `capacity_ratio` and adjusts weights for distance, depot proximity, and angle cost. The 20th also includes a route balancing heuristic penalizing deviations from ideal route demand, and has a higher number of heuristics components.\n\n(2nd) vs (19th): The 2nd uses capacity ratio to adjust alpha/beta, the 19th uses it to adjust weight_demand/weight_angle. The 19th sparsifies the matrix based on mean, while 2nd uses percentile.\n(3rd) vs (18th): Both have the same core heuristics and weights, but 18th normalizes the distance, savings, and depot heuristics, and 3rd doesn't.\n(4th) vs (17th): The 4th includes Clustering Coefficient, Angle Cost, Demand Density, and Randomized Perturbation, as well as adaptive weighting based on capacity ratio and node proximity. It normalizes each heuristic component, includes sparsification and normalizes the final matrix. The 17th one only combines distance, demand, savings, and depot proximity.\n(5th) vs (16th): Both algorithms are similar.\n(6th) vs (15th): 6th incorporates an Angle-based Clustering. Also, 6th's capacity ratio is calculated on the number of customers. 15th calculate adapt weights based on capacity ratio and number of nodes factor.\n(7th) vs (14th): Adaptive sparsification in 7th utilizes mean, while 14th applies percentile for adaptive threshold. 14th includes Node Centrality and Demand Density.\n(8th) vs (9th): The 8th is simpler, only combining distance, demand, depot proximity, and savings with fixed weights. Sparsification is based on k-NN and a percentile threshold. The 9th normalizes each heuristic, incorporates clustering, adapts weights based on problem characteristics, and uses a higher sparsity.\n(10th) vs (11th): They are same.\n(12th) vs (13th): They are same.\nOverall: More sophisticated heuristics tend to include more factors (clustering, angles, demand density, route balance), adaptive weighting based on multiple problem characteristics, normalization of individual heuristics, and more adaptive sparsification techniques. Simpler heuristics focus primarily on distance, demand, depot proximity, and savings with fixed or simple adaptive weights.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, let's refine \"Current Self-Reflection\" to be more actionable and insightful for designing better heuristics.\n\nHere's a revised approach, focusing on avoiding generic advice and promoting concrete steps:\n\n*   **Keywords:** Contextualization, Granularity, Mechanism, Validation.\n*   **Advice:** Frame heuristics within problem-specific contexts. Deconstruct heuristics into finer-grained components. Define specific adaptation mechanisms, not just \"adaptive weighting.\" Rigorously validate the impact of each component and adaptation strategy.\n*   **Avoid:** General statements about \"diverse factors,\" \"adaptive weighting,\" or \"sparsification\" without concrete implementation details.\n*   **Explanation:** Move beyond generic principles. Provide precise mechanisms by which normalization, weighting, and sparsification are achieved based on context. Demonstrate via experiments impact of these components on performance.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}