```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:
    """
    Heuristics for CVRP using distance, demand, and node proximity.

    This heuristic combines several factors to estimate the desirability of including an edge:
    1. Inverse distance: Shorter distances are preferred.
    2. Demand consideration: Edges connecting nodes with higher demands are penalized, especially if
       the combined demand would likely exceed capacity. This helps avoid overloading vehicles.
    3. Depot proximity: Edges closer to the depot (node 0) are favored, as they are likely to be
       involved in return trips to the depot for refueling/unloading.

    Args:
        distance_matrix (np.ndarray): Distance between all pairs of nodes (n x n).
        coordinates (np.ndarray): Euclidean coordinates of nodes (n x 2).
        demands (np.ndarray): Demand of each node (n).  depot (node 0) is assumed to have demand 0.
        capacity (int): Vehicle capacity.

    Returns:
        np.ndarray: Edge desirability matrix (n x n).  Higher values indicate more desirable edges.
    """
    n = distance_matrix.shape[0]
    heuristics = np.zeros((n, n))

    # Inverse distance component
    inverse_distance = 1 / (distance_matrix + 1e-6)  # Add a small constant to avoid division by zero
    heuristics += inverse_distance

    # Demand consideration - penalize edges connecting high-demand nodes
    demand_penalty = np.zeros((n, n))
    for i in range(n):
        for j in range(n):
            if i == j:
                demand_penalty[i, j] = 0  # Avoid self-loops
            else:
                # Heuristic:  penalty increases exponentially with demand
                demand_penalty[i, j] = np.exp((demands[i] + demands[j]) / capacity)
                # Alternatively: a more direct proportional penalty
                # demand_penalty[i, j] = (demands[i] + demands[j]) / (2 * capacity)

    heuristics -= demand_penalty

    # Depot proximity bonus - reward connections closer to the depot (node 0)
    depot_bonus = np.zeros((n, n))
    for i in range(n):
        for j in range(n):
            if i == j:
                depot_bonus[i,j] = 0 # avoid self loops.
            else:
                depot_bonus[i, j] = np.exp(-0.5 * (distance_matrix[0, i] + distance_matrix[0, j]) / np.mean(distance_matrix))  # Exponential decay with distance from depot

    heuristics += depot_bonus

    # Ensure no self-loops (optional, but good practice)
    for i in range(n):
        heuristics[i, i] = 0

    # Ensure non-negativity and normalize the results
    heuristics = np.maximum(heuristics, 0)
    heuristics = heuristics / np.max(heuristics) if np.max(heuristics) > 0 else heuristics # Ensure no division by zero

    return heuristics
```
