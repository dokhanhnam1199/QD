{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling. CVRP requires finding the shortest path that visits all given nodes and returns to the starting node. Each node has a demand and each vehicle has a capacity. The total demand of the nodes visited by a vehicle cannot exceed the vehicle capacity. When the total demand exceeds the vehicle capacity, the vehicle must return to the starting node.\nThe `heuristics` function takes as input a distance matrix (shape: n by n), Euclidean coordinates of nodes (shape: n by 2), a vector of customer demands (shape: n), and the integer capacity of vehicle capacity. It returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the distance_matrix. The depot node is indexed by 0.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"\n    Heuristics for solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling.\n\n    This version incorporates:\n    1.  Distance: Edges with shorter distances are preferred.\n    2.  Demand Feasibility:  Penalizes edges that would immediately violate capacity constraints if used early in a route.\n    3.  Depot Proximity: Prioritizes returning to the depot from nodes that are far from other customers and have high demand.\n    4.  Gravitational Attraction: Mimics the gravitational attraction of black holes: Nodes with high demand and/or far from depot will \"attract\" closer nodes to form clusters.\n    5.  Savings Heuristic Component:  Estimates cost savings by merging routes.\n    6.  Sparsification: Setting unpromising edges to zero to reduce the search space and computational cost.\n    7.  Adaptive Weighting: Dynamically adjusts the weights of different heuristic components based on problem characteristics.\n\n    Args:\n        distance_matrix (np.ndarray): Distance matrix between nodes (shape: n x n).\n        coordinates (np.ndarray): Euclidean coordinates of nodes (shape: n x 2).\n        demands (np.ndarray): Vector of customer demands (shape: n). The demand of depot is demands[0].\n        capacity (int): Vehicle capacity.\n\n    Returns:\n        np.ndarray: Prior indicators of how promising it is to include each edge in a solution (shape: n x n).\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros((n, n))\n\n    # Add a small value to avoid division by zero\n    epsilon = 1e-6\n\n    # 1. Distance component (inverse relationship)\n    distance_heuristic = 1 / (distance_matrix + epsilon)\n\n    # 2. Demand Feasibility component\n    demand_heuristic = np.ones((n, n))\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                demand_heuristic[i, j] = 0  # No self-loops\n\n            # If using this edge would exceed vehicle capacity (assuming starting from depot), penalize\n            if demands[i] + demands[j] > capacity and i == 0: # starting node\n                demand_heuristic[i, j] = 0.1  # A small value but not zero so it is not totally ignored\n            elif demands[i] + demands[j] > capacity and j == 0:\n                demand_heuristic[i, j] = 0.1\n            elif i != 0 and demands[i] > capacity or j != 0 and demands[j] > capacity:\n                 demand_heuristic[i,j] = 0.05\n\n\n    # 3. Depot Proximity (encourage returning to depot if far and demand is high)\n    depot_heuristic = np.zeros((n, n))\n    for i in range(1, n):  # Exclude depot itself\n        # Calculate average distance from node i to all other nodes (excluding the depot)\n        avg_distance = np.sum(distance_matrix[i, 1:]) / (n - 2) if n > 2 else distance_matrix[i,0] # If only one other point exist use the distance to depot.\n\n        # Encourage going back to the depot from this node IF it is far and demands are relatively high.\n        # Depot preference is weighted based on avg_distance and demand compared to capacity\n        depot_preference = (avg_distance / np.max(distance_matrix)) * (demands[i] / capacity)\n        depot_heuristic[i, 0] = depot_preference\n        depot_heuristic[0, i] = depot_preference #symmetry\n\n    # 4. Gravitational Attraction: Node `i` attracts closeby node `j`\n    gravitational_heuristic = np.zeros((n, n))\n    gravitational_constant = 1.0  # Adjust to control attraction strength.\n    for i in range(1, n):  # Start from 1 to exclude the depot itself as a gravity center. Depot is served by the previous depot_heuristic.\n        for j in range(1, n): # Start from 1 to exclude the depot itself being attracted by the gravitational heuristic.\n\n            mass_i = demands[i]\n            mass_j = demands[j]\n            if i == j:\n                gravitational_heuristic[i,j] = 0\n                continue\n            gravitational_heuristic[i, j] = gravitational_constant * (mass_i * mass_j) / (distance_matrix[i, j]**2 + epsilon) # F = G*m1*m2/r^2\n\n    # 5. Savings Heuristic Component\n    savings_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        for j in range(i + 1, n):\n            savings_heuristic[i, j] = distance_matrix[i, 0] + distance_matrix[0, j] - distance_matrix[i, j]\n            savings_heuristic[j, i] = savings_heuristic[i, j]  # Symmetry\n\n    # Adaptive Weighting (Example: Adjust based on average demand relative to capacity)\n    avg_demand = np.mean(demands[1:])\n    demand_ratio = avg_demand / capacity\n\n    # Adjust weights based on demand ratio (example)\n    weight_distance = 0.4  # Base weight\n    weight_demand = 0.3\n    weight_depot = 0.1 + demand_ratio * 0.2  # Increase depot weight if demand is high\n    weight_gravitational = 0.1\n    weight_savings = 0.1 - demand_ratio * 0.05 #Decrease saving if demand is high\n\n    # Combine the heuristics with adaptive weights\n    heuristics = (weight_distance * distance_heuristic * demand_heuristic +\n                  weight_depot * depot_heuristic +\n                  weight_gravitational * gravitational_heuristic +\n                  weight_savings * savings_heuristic)\n\n    # 6. Sparsification (set unpromising edges to zero)\n    threshold = np.mean(heuristics) * 0.2  # Dynamic threshold based on mean\n    heuristics[heuristics < threshold] = 0\n\n    # Normalize to be between 0 and 1, can help stability of stochastic sampling methods\n    max_val = np.max(heuristics)\n    if max_val > 0:\n        heuristics = heuristics / max_val\n\n    return heuristics\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"\n    Heuristics for CVRP combining distance, demand, and angle; adds depot proximity.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros((n, n))\n    normalized_demands = demands / np.max(demands)  # Scale to 0-1\n\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                distance_factor = 1 / distance_matrix[i, j]\n                demand_factor = 1 - normalized_demands[j]\n                if i == 0:\n                    demand_factor = 1.0\n\n                # Angle heuristic relative to the depot\n                depot_x, depot_y = coordinates[0]\n                i_x, i_y = coordinates[i]\n                j_x, j_y = coordinates[j]\n\n                vector_ij = np.array([j_x - i_x, j_y - i_y])\n                vector_di = np.array([i_x - depot_x, i_y - depot_y])\n\n                vector_ij = vector_ij / (np.linalg.norm(vector_ij) + 1e-9)\n                vector_di = vector_di / (np.linalg.norm(vector_di) + 1e-9)\n\n                dot_product = np.clip(np.dot(vector_ij, vector_di), -1.0, 1.0)\n                angle = np.arccos(dot_product)\n                angle_factor = 1 - (angle / np.pi)\n\n                # Depot proximity: encourage nodes close to depot\n                depot_distance_i = distance_matrix[0, i]\n                depot_distance_j = distance_matrix[0, j]\n                depot_proximity_factor = 1 / (depot_distance_i + depot_distance_j + 1e-9)\n\n                heuristic_matrix[i, j] = distance_factor * demand_factor * angle_factor * depot_proximity_factor\n            else:\n                heuristic_matrix[i, j] = 0\n\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n    else:\n        heuristic_matrix = np.ones_like(heuristic_matrix) / n\n\n    return heuristic_matrix\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), there's no difference.\nComparing (3rd) vs (4th), there's no difference.\nComparing (1st) vs (5th), the former utilizes multiple heuristics (distance, demand feasibility, depot proximity, gravitational attraction, savings, sparsification) with adaptive weights, while the latter combines distance, demand, angle to depot, and angle between nodes with fixed weights and capacity penalty.\nComparing (5th) vs (6th), there's no difference.\nComparing (5th) vs (7th), there's no difference.\nComparing (1st) vs (8th), (1st) uses sparsification based on k-nearest neighbors and a dynamic threshold, (8th) uses simpler sparsification based on a mean threshold. (1st) combines with fixed weights while (8th) uses adaptive weighting.\nComparing (1st) vs (9th), (1st) is more complex, (9th) appears simpler.\nComparing (9th) vs (10th), there's no difference.\nComparing (9th) vs (11th), there's no difference.\nComparing (1st) vs (12th), (1st) uses more diverse heuristics like gravitational attraction and savings, along with k-NN sparsification, while (12th) focuses on distance, demand, spatial clustering and depot attraction. Adaptive scaling is present in both.\nComparing (12th) vs (13th), there's no difference.\nComparing (12th) vs (14th), there's no difference.\nComparing (1st) vs (15th), (1st) uses more heuristics and better sparsification.\nComparing (15th) vs (16th), there's no difference.\nComparing (1st) vs (17th), (1st) has more diverse heuristics and better sparsification. (17th) uses unusual demand scaling with distance.\nComparing (1st) vs (18th), (1st) has more diverse heuristics and better sparsification.\nComparing (1st) vs (19th), (1st) is more complex and includes sparsification while (19th) lacks it.\nComparing (19th) vs (20th), there's no difference.\nComparing (second worst) vs (worst), (19th) and (20th) are identical.\n\nOverall: The better heuristics combine multiple factors (distance, demand, depot proximity, angles, savings) using adaptive weights. Sparsification using k-NN or dynamic thresholds is preferred. Simpler heuristics focusing on fewer factors or fixed weights tend to perform worse.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, here's a refined perspective on self-reflection to guide heuristic design, focusing on actionable insights:\n\n*   **Keywords:** Factor diversity, adaptive weighting, normalization, spatial relationships, sparsification, problem characteristics.\n\n*   **Advice:** Explore clustering techniques, gravitational attraction principles, and rigorous normalization strategies within your heuristics. Adapt weights based on real-time problem characteristics, not just initial assumptions.\n\n*   **Avoid:** Solely relying on distance/demand, static weighting schemes, ignoring spatial context, premature convergence.\n\n*   **Explanation:** Broadening the factor base and adapting to problem nuances are crucial for robust and high-performing heuristics. Normalization stabilizes weighting.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}