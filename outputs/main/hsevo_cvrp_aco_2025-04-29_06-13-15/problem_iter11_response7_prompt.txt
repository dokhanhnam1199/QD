{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling. CVRP requires finding the shortest path that visits all given nodes and returns to the starting node. Each node has a demand and each vehicle has a capacity. The total demand of the nodes visited by a vehicle cannot exceed the vehicle capacity. When the total demand exceeds the vehicle capacity, the vehicle must return to the starting node.\nThe `heuristics` function takes as input a distance matrix (shape: n by n), Euclidean coordinates of nodes (shape: n by 2), a vector of customer demands (shape: n), and the integer capacity of vehicle capacity. It returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the distance_matrix. The depot node is indexed by 0.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"CVRP heuristics combining distance, demand, savings, angles, and adaptive weighting.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros((n, n))\n    epsilon = 1e-6\n\n    # 1. Distance component (normalized)\n    distance_heuristic = 1 / (distance_matrix + epsilon)\n    distance_heuristic = (distance_heuristic - np.min(distance_heuristic)) / (np.max(distance_heuristic) - np.min(distance_heuristic) + epsilon)\n\n    # 2. Demand Feasibility\n    demand_heuristic = np.ones((n, n))\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                demand_heuristic[i, j] = 0\n            if demands[i] + demands[j] > capacity and (i == 0 or j == 0):\n                demand_heuristic[i, j] = 0.1  # Reduced penalty\n            elif i != 0 and demands[i] > capacity or j != 0 and demands[j] > capacity:\n                demand_heuristic[i,j] = 0.05 #reduced penalty\n\n    # 3. Depot Proximity (normalized)\n    depot_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        avg_distance = np.sum(distance_matrix[i, 1:]) / (n - 2) if n > 2 else distance_matrix[i, 0]\n        depot_preference = (avg_distance / (np.max(distance_matrix) + epsilon)) * (demands[i] / capacity)\n        depot_heuristic[i, 0] = depot_preference\n        depot_heuristic[0, i] = depot_preference\n    depot_heuristic = (depot_heuristic - np.min(depot_heuristic)) / (np.max(depot_heuristic) - np.min(depot_heuristic) + epsilon)\n\n    # 4. Savings Heuristic (normalized)\n    savings_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        for j in range(i + 1, n):\n            savings = distance_matrix[i, 0] + distance_matrix[0, j] - distance_matrix[i, j]\n            savings_heuristic[i, j] = savings\n            savings_heuristic[j, i] = savings  # Savings are symmetric\n    savings_heuristic = (savings_heuristic - np.min(savings_heuristic)) / (np.max(savings_heuristic) - np.min(savings_heuristic) + epsilon)\n\n    # 5. Angle-based Clustering\n    angle_heuristic = np.zeros((n, n))\n    depot_x, depot_y = coordinates[0]\n    for i in range(1, n):\n        angle_i = np.arctan2(coordinates[i, 1] - depot_y, coordinates[i, 0] - depot_x)\n        for j in range(i + 1, n):\n            angle_j = np.arctan2(coordinates[j, 1] - depot_y, coordinates[j, 0] - depot_x)\n            angle_diff = min(abs(angle_i - angle_j), 2 * np.pi - abs(angle_i - angle_j))\n            angle_preference = np.exp(-angle_diff)  # Higher value for smaller angle differences\n            angle_heuristic[i, j] = angle_preference\n            angle_heuristic[j, i] = angle_preference\n\n    angle_heuristic = (angle_heuristic - np.min(angle_heuristic)) / (np.max(angle_heuristic) - np.min(angle_heuristic) + epsilon)\n\n    # 6. Adaptive Weighting\n    capacity_ratio = np.sum(demands[1:]) / (capacity * (n-1))\n    alpha = 0.35 #distance\n    beta = 0.1 #depot\n    gamma = 0.25 #savings\n    delta = 0.3 # Angle\n    if capacity < np.mean(demands) * 5: # Tighter capacity constraints, increase savings\n        gamma += 0.05\n        alpha -= 0.05\n\n    # Combine the heuristics with adaptive weights\n    heuristics = alpha * distance_heuristic * demand_heuristic + beta * depot_heuristic + gamma * savings_heuristic * demand_heuristic + delta * angle_heuristic * demand_heuristic\n\n    # 7. Sparsification\n    k_nearest = 10\n    threshold = np.percentile(heuristics[heuristics > 0], 40)\n\n    for i in range(n):\n        nearest_neighbors = np.argsort(distance_matrix[i, :])[1:k_nearest+1]\n\n        for j in range(n):\n            if heuristics[i, j] < threshold and j not in nearest_neighbors:\n                heuristics[i, j] = 0\n\n    # Normalize to be between 0 and 1\n    max_val = np.max(heuristics)\n    if max_val > 0:\n        heuristics = heuristics / max_val\n\n    return heuristics\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"Heuristic: Combines distance, demand, angle, depot proximity with adaptive weighting.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros((n, n))\n    epsilon = 1e-6\n\n    # Calculate tightness of capacity constraint\n    capacity_ratio = np.sum(demands) / (capacity * (n - 1)) #excluding depot\n\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                continue\n\n            dist_h = 1 / (distance_matrix[i, j] + epsilon)\n            demand_h = 1 - np.clip((demands[i] + demands[j]) / (2 * capacity + epsilon), 0, 1)\n            if i == 0 or j == 0:\n                demand_h = 1.0\n\n            angle_h = 1.0\n            if i != 0 and j != 0:\n                angle_h = 0.0\n\n                # Calculate angle to depot\n                depot_x, depot_y = coordinates[0]\n                i_x, i_y = coordinates[i]\n                j_x, j_y = coordinates[j]\n\n                vector_ij = np.array([j_x - i_x, j_y - i_y])\n                vector_di = np.array([i_x - depot_x, i_y - depot_y])\n\n                vector_ij = vector_ij / (np.linalg.norm(vector_ij) + epsilon)\n                vector_di = vector_di / (np.linalg.norm(vector_di) + epsilon)\n\n                dot_product = np.clip(np.dot(vector_ij, vector_di), -1.0, 1.0)\n                angle = np.arccos(dot_product)\n                angle_h = 1 - (angle / np.pi)\n\n\n            depot_prox_h = 1 - np.clip((distance_matrix[0, i] + distance_matrix[0, j]) / (2 * np.max(distance_matrix) + epsilon), 0, 1)\n\n            # Adaptive weights based on capacity tightness\n            weight_dist = 0.5\n            weight_demand = 0.15 + 0.2 * capacity_ratio  # Increase weight if capacity is tight\n            weight_angle = 0.25 - 0.1 * capacity_ratio   # Decrease weight if capacity is tight\n            weight_depot = 0.1\n\n            heuristic_matrix[i, j] = (\n                weight_dist * dist_h +\n                weight_demand * demand_h +\n                weight_angle * angle_h +\n                weight_depot * depot_prox_h\n            )\n\n    # Normalize heuristic values\n    max_heuristic = np.max(heuristic_matrix)\n    if max_heuristic > 0:\n        heuristic_matrix /= max_heuristic\n    else:\n        heuristic_matrix = np.ones_like(heuristic_matrix) / n\n\n\n    # Sparsify the matrix based on mean heuristic value\n    threshold = np.mean(heuristic_matrix) * 0.5\n    heuristic_matrix[heuristic_matrix < threshold] = 0\n\n    return heuristic_matrix\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see the 1st heuristic incorporates adaptive weights based on `demand_ratio`, while the 20th uses `capacity_ratio` and adjusts weights for distance, depot proximity, and angle cost. The 20th also includes a route balancing heuristic penalizing deviations from ideal route demand, and has a higher number of heuristics components.\n\n(2nd) vs (19th): The 2nd uses capacity ratio to adjust alpha/beta, the 19th uses it to adjust weight_demand/weight_angle. The 19th sparsifies the matrix based on mean, while 2nd uses percentile.\n(3rd) vs (18th): Both have the same core heuristics and weights, but 18th normalizes the distance, savings, and depot heuristics, and 3rd doesn't.\n(4th) vs (17th): The 4th includes Clustering Coefficient, Angle Cost, Demand Density, and Randomized Perturbation, as well as adaptive weighting based on capacity ratio and node proximity. It normalizes each heuristic component, includes sparsification and normalizes the final matrix. The 17th one only combines distance, demand, savings, and depot proximity.\n(5th) vs (16th): Both algorithms are similar.\n(6th) vs (15th): 6th incorporates an Angle-based Clustering. Also, 6th's capacity ratio is calculated on the number of customers. 15th calculate adapt weights based on capacity ratio and number of nodes factor.\n(7th) vs (14th): Adaptive sparsification in 7th utilizes mean, while 14th applies percentile for adaptive threshold. 14th includes Node Centrality and Demand Density.\n(8th) vs (9th): The 8th is simpler, only combining distance, demand, depot proximity, and savings with fixed weights. Sparsification is based on k-NN and a percentile threshold. The 9th normalizes each heuristic, incorporates clustering, adapts weights based on problem characteristics, and uses a higher sparsity.\n(10th) vs (11th): They are same.\n(12th) vs (13th): They are same.\nOverall: More sophisticated heuristics tend to include more factors (clustering, angles, demand density, route balance), adaptive weighting based on multiple problem characteristics, normalization of individual heuristics, and more adaptive sparsification techniques. Simpler heuristics focus primarily on distance, demand, depot proximity, and savings with fixed or simple adaptive weights.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, let's refine \"Current Self-Reflection\" to be more actionable and insightful for designing better heuristics.\n\nHere's a revised approach, focusing on avoiding generic advice and promoting concrete steps:\n\n*   **Keywords:** Contextualization, Granularity, Mechanism, Validation.\n*   **Advice:** Frame heuristics within problem-specific contexts. Deconstruct heuristics into finer-grained components. Define specific adaptation mechanisms, not just \"adaptive weighting.\" Rigorously validate the impact of each component and adaptation strategy.\n*   **Avoid:** General statements about \"diverse factors,\" \"adaptive weighting,\" or \"sparsification\" without concrete implementation details.\n*   **Explanation:** Move beyond generic principles. Provide precise mechanisms by which normalization, weighting, and sparsification are achieved based on context. Demonstrate via experiments impact of these components on performance.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}