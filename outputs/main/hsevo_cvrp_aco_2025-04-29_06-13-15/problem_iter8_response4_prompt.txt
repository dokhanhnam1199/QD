{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling. CVRP requires finding the shortest path that visits all given nodes and returns to the starting node. Each node has a demand and each vehicle has a capacity. The total demand of the nodes visited by a vehicle cannot exceed the vehicle capacity. When the total demand exceeds the vehicle capacity, the vehicle must return to the starting node.\nThe `heuristics` function takes as input a distance matrix (shape: n by n), Euclidean coordinates of nodes (shape: n by 2), a vector of customer demands (shape: n), and the integer capacity of vehicle capacity. It returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the distance_matrix. The depot node is indexed by 0.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"\n    Heuristics for solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling.\n\n    This version incorporates:\n    1. Distance: Edges with shorter distances are preferred.\n    2. Demand Feasibility: Penalizes edges that would immediately violate capacity constraints.\n    3. Depot Proximity: Prioritizes returning to the depot from nodes that are far from other customers and have high demand.\n    4. Savings Heuristic Integration: Incorporates the savings heuristic to encourage merging routes.\n    5. Clustering Encouragement: Encourages connections within spatial clusters.\n    6. Sparsification: Sets unpromising edges to zero to focus the search, adaptively.\n    7. Adaptive Weighting: Dynamically adjusts weights based on problem characteristics.\n    8. Demand Density: Considers demand density around each node.\n    9. Angle to Depot: Prioritizes connections that reduce the angle formed by (node i - depot - node j) to encourage direct routes\n\n    Args:\n        distance_matrix (np.ndarray): Distance matrix between nodes (shape: n x n).\n        coordinates (np.ndarray): Euclidean coordinates of nodes (shape: n x 2).\n        demands (np.ndarray): Vector of customer demands (shape: n). The demand of depot is demands[0].\n        capacity (int): Vehicle capacity.\n\n    Returns:\n        np.ndarray: Prior indicators of how promising it is to include each edge in a solution (shape: n x n).\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros((n, n))\n    epsilon = 1e-6\n\n    # 1. Distance component (normalized)\n    distance_heuristic = 1 / (distance_matrix + epsilon)\n    distance_heuristic = (distance_heuristic - np.min(distance_heuristic)) / (np.max(distance_heuristic) - np.min(distance_heuristic) + epsilon)\n\n    # 2. Demand Feasibility\n    demand_heuristic = np.ones((n, n))\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                demand_heuristic[i, j] = 0\n            if demands[i] + demands[j] > capacity and i == 0:\n                demand_heuristic[i, j] = 0.1\n            elif demands[i] + demands[j] > capacity and j == 0:\n                demand_heuristic[i, j] = 0.1\n            elif i != 0 and demands[i] > capacity or j != 0 and demands[j] > capacity:\n                demand_heuristic[i,j] = 0.05\n\n    # 3. Depot Proximity (normalized and enhanced)\n    depot_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        avg_distance = np.sum(distance_matrix[i, 1:]) / (n - 2) if n > 2 else distance_matrix[i, 0]\n        depot_preference = (avg_distance / np.max(distance_matrix)) * (demands[i] / capacity)\n        depot_heuristic[i, 0] = depot_preference\n        depot_heuristic[0, i] = depot_preference\n    depot_heuristic = (depot_heuristic - np.min(depot_heuristic)) / (np.max(depot_heuristic) - np.min(depot_heuristic) + epsilon)\n\n\n    # 4. Savings Heuristic (normalized)\n    savings_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        for j in range(i + 1, n):\n            savings = distance_matrix[i, 0] + distance_matrix[0, j] - distance_matrix[i, j]\n            savings_heuristic[i, j] = savings\n            savings_heuristic[j, i] = savings  # Savings are symmetric\n    savings_heuristic = (savings_heuristic - np.min(savings_heuristic)) / (np.max(savings_heuristic) - np.min(savings_heuristic) + epsilon)\n\n    # 5. Clustering Encouragement (based on spatial proximity)\n    clustering_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        for j in range(i + 1, n):\n            dist_ij = distance_matrix[i, j]\n            # Encourage connections between nodes that are close relative to their distance to the depot\n            clustering_heuristic[i, j] = clustering_heuristic[j, i] = np.exp(-dist_ij / (distance_matrix[i, 0] + distance_matrix[j, 0] + epsilon))\n\n    # 6. Demand Density\n    demand_density_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        for j in range(1, n):\n            if i == j:\n                continue\n            # Measure demand density around each node\n            neighborhood_size = 5 #number of neighbors to consider\n            i_neighbors = np.argsort(distance_matrix[i, 1:])[:neighborhood_size] + 1\n            j_neighbors = np.argsort(distance_matrix[j, 1:])[:neighborhood_size] + 1\n\n            i_density = np.sum(demands[i_neighbors]) / np.sum(distance_matrix[i, i_neighbors]) if np.sum(distance_matrix[i, i_neighbors]) > 0 else 0\n            j_density = np.sum(demands[j_neighbors]) / np.sum(distance_matrix[j, j_neighbors]) if np.sum(distance_matrix[j, j_neighbors]) > 0 else 0\n            demand_density_heuristic[i,j] = demand_density_heuristic[j, i] = i_density + j_density\n\n    demand_density_heuristic = (demand_density_heuristic - np.min(demand_density_heuristic)) / (np.max(demand_density_heuristic) - np.min(demand_density_heuristic) + epsilon)\n\n    #7. Angle to Depot\n    angle_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        for j in range(1, n):\n            if i == j:\n                continue\n            vector_i = coordinates[i] - coordinates[0]\n            vector_j = coordinates[j] - coordinates[0]\n\n            # Calculate the cosine of the angle\n            cosine_angle = np.dot(vector_i, vector_j) / (np.linalg.norm(vector_i) * np.linalg.norm(vector_j) + epsilon)\n\n            # Convert cosine to angle in radians\n            angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n\n            angle_heuristic[i, j] = angle_heuristic[j, i] =  1- (angle / np.pi) # Normalize to [0, 1] (higher is better, smaller angle)\n\n    # Adaptive Weighting (adjust based on problem size/characteristics)\n    n_customers = n - 1\n    alpha = 0.3 #distance\n    beta = 0.15 #depot proximity\n    gamma = 0.20 #savings\n    delta = 0.15 #clustering\n    eta = 0.1 #demand density\n    phi = 0.1 #angle heuristic\n    # Adjust weights (example: emphasize depot proximity more for larger problems)\n    if n_customers > 50:\n        beta += 0.05\n        alpha -= 0.05 #reduce alpha a bit\n    if capacity < np.mean(demands) * 5: # Tighter capacity constraints, increase savings\n        gamma += 0.05\n\n    # Combine the heuristics\n    heuristics = (alpha * distance_heuristic * demand_heuristic +\n                  beta * depot_heuristic +\n                  gamma * savings_heuristic +\n                  delta * clustering_heuristic +\n                  eta * demand_density_heuristic +\n                  phi * angle_heuristic)\n\n    # 8. Sparsification (adaptive threshold based on heuristic values)\n    threshold = np.percentile(heuristics[heuristics > 0], 40) # Increased sparsity\n\n    k_nearest = 12 #consider k-nearest neighbors, increase it a bit\n\n    for i in range(n):\n        nearest_neighbors = np.argsort(distance_matrix[i, :])[1:k_nearest+1]\n        for j in range(n):\n            if heuristics[i, j] < threshold and j not in nearest_neighbors:\n                heuristics[i, j] = 0\n\n    # Normalize to be between 0 and 1\n    max_val = np.max(heuristics)\n    if max_val > 0:\n        heuristics = heuristics / max_val\n\n    return heuristics\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"Combines distance, demand, angle, and depot proximity with adaptive weighting.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros((n, n))\n    normalized_demands = demands / np.max(demands)\n    depot_x, depot_y = coordinates[0]\n\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                heuristic_matrix[i, j] = 0\n                continue\n\n            distance_factor = 1 / distance_matrix[i, j] if distance_matrix[i,j] > 0 else 0\n            demand_factor = 1 - normalized_demands[j]\n            if i == 0:\n                demand_factor = 1.0\n\n            i_x, i_y = coordinates[i]\n            j_x, j_y = coordinates[j]\n\n            vector_ij = np.array([j_x - i_x, j_y - i_y])\n            vector_di = np.array([i_x - depot_x, i_y - depot_y])\n\n            vector_ij = vector_ij / (np.linalg.norm(vector_ij) + 1e-9)\n            vector_di = vector_di / (np.linalg.norm(vector_di) + 1e-9)\n\n            dot_product = np.clip(np.dot(vector_ij, vector_di), -1.0, 1.0)\n            angle = np.arccos(dot_product)\n            angle_factor = 1 - (angle / np.pi)\n\n            depot_distance_i = distance_matrix[0, i]\n            depot_distance_j = distance_matrix[0, j]\n            depot_proximity_factor = 1 / (depot_distance_i + depot_distance_j + 1e-9)\n\n            #Adaptive weighting based on demand\n            demand_weight = 0.5 + 0.5 * normalized_demands[j] #increase weight for high demand nodes\n            heuristic_matrix[i, j] = distance_factor * (demand_weight * demand_factor + (1-demand_weight) * (angle_factor * depot_proximity_factor))\n\n    #Sparsification: zero out less promising edges\n    mean_heuristic = np.mean(heuristic_matrix)\n    heuristic_matrix[heuristic_matrix < 0.5 * mean_heuristic] = 0\n\n    return heuristic_matrix\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the best heuristic incorporates more diverse factors, including distance, demand feasibility, depot proximity, gravitational attraction, savings heuristic, clustering coefficient, and adaptive weighting, while the worst only considers distance, demand, angle, and depot proximity. (2nd best) vs (second worst) shows similar trend. Comparing (1st) vs (2nd), we see that the best heuristic uses adaptive weighting that adjusts based on problem characteristics, such as capacity tightness, while the second best uses fixed weights based on demand ratio. (3rd) vs (4th) shows a trend where later heuristics incorporate angle-based clustering and normalize heuristic components, features absent in the earlier ones. Comparing (second worst) vs (worst), they share same logic. Overall: The best heuristics incorporate a wider range of problem-specific information, use adaptive weighting schemes, and normalize their heuristic components. Sparsification is a common feature, but its implementation and thresholding vary.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, I will help you redefine \"Current self-reflection\" to design better heuristics, focusing on actionable advice and avoiding common pitfalls.\n\nHere's a refined reflection framework:\n\n*   **Keywords:** Multifactorial, Adaptive Weighting, Normalization, Sparsification, Problem Characteristics, Spatial Relationships.\n*   **Advice:** Design heuristics incorporating diverse factors beyond basic features, especially spatial relationships. Implement adaptive weighting schemes dynamically adjusted by problem characteristics. Normalize heuristic outputs.\n*   **Avoid:** Static weights, neglecting problem-specific features, unnormalized components, and fixed sparsification thresholds.\n*   **Explanation:** Combine diverse, normalized factors using problem-aware adaptive weights. Use sparsification judiciously.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}