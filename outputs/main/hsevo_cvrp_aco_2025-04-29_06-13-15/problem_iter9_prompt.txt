{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling. CVRP requires finding the shortest path that visits all given nodes and returns to the starting node. Each node has a demand and each vehicle has a capacity. The total demand of the nodes visited by a vehicle cannot exceed the vehicle capacity. When the total demand exceeds the vehicle capacity, the vehicle must return to the starting node.\nThe `heuristics` function takes as input a distance matrix (shape: n by n), Euclidean coordinates of nodes (shape: n by 2), a vector of customer demands (shape: n), and the integer capacity of vehicle capacity. It returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the distance_matrix. The depot node is indexed by 0.\n\n\nCurrent heuristics:\ndef heuristics_v1(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"\n    Heuristics for solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling.\n\n    This version incorporates:\n    1.  Distance: Edges with shorter distances are preferred.\n    2.  Demand Feasibility: Penalizes edges that would immediately violate capacity constraints if used early in a route.\n    3.  Depot Proximity: Prioritizes returning to the depot from nodes that are far from other customers and have high demand.\n    4.  Gravitational Attraction: Mimics the gravitational attraction of black holes: Nodes with high demand and/or far from depot will \"attract\" closer nodes to form clusters.\n    5.  Savings Heuristic Integration: Incorporates the savings heuristic to encourage merging routes.\n    6.  Sparsification: Sets unpromising edges to zero to focus the search.\n    7.  Clustering Coefficient: Encourages connections between nodes within local clusters\n    8.  Adaptive Weighting: Adjusts weights based on problem characteristics (e.g., tightness of capacity)\n\n    Args:\n        distance_matrix (np.ndarray): Distance matrix between nodes (shape: n x n).\n        coordinates (np.ndarray): Euclidean coordinates of nodes (shape: n x 2).\n        demands (np.ndarray): Vector of customer demands (shape: n). The demand of depot is demands[0].\n        capacity (int): Vehicle capacity.\n\n    Returns:\n        np.ndarray: Prior indicators of how promising it is to include each edge in a solution (shape: n x n).\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros((n, n))\n    epsilon = 1e-6\n\n    # 1. Distance component\n    distance_heuristic = 1 / (distance_matrix + epsilon)\n\n    # 2. Demand Feasibility\n    demand_heuristic = np.ones((n, n))\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                demand_heuristic[i, j] = 0\n            if demands[i] + demands[j] > capacity and i == 0:\n                demand_heuristic[i, j] = 0.1\n            elif demands[i] + demands[j] > capacity and j == 0:\n                demand_heuristic[i, j] = 0.1\n            elif i != 0 and demands[i] > capacity or j != 0 and demands[j] > capacity:\n                demand_heuristic[i,j] = 0.05\n\n    # 3. Depot Proximity\n    depot_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        avg_distance = np.sum(distance_matrix[i, 1:]) / (n - 2) if n > 2 else distance_matrix[i,0]\n        depot_preference = (avg_distance / np.max(distance_matrix)) * (demands[i] / capacity)\n        depot_heuristic[i, 0] = depot_preference\n        depot_heuristic[0, i] = depot_preference\n\n    # 4. Gravitational Attraction\n    gravitational_heuristic = np.zeros((n, n))\n    gravitational_constant = 1.0\n    for i in range(1, n):\n        for j in range(1, n):\n            mass_i = demands[i]\n            mass_j = demands[j]\n            if i == j:\n                gravitational_heuristic[i,j] = 0\n                continue\n            gravitational_heuristic[i, j] = gravitational_constant * (mass_i * mass_j) / (distance_matrix[i, j]**2 + epsilon)\n\n    # 5. Savings Heuristic\n    savings_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        for j in range(i + 1, n):\n            savings = distance_matrix[i, 0] + distance_matrix[0, j] - distance_matrix[i, j]\n            savings_heuristic[i, j] = savings\n            savings_heuristic[j, i] = savings  # Savings are symmetric\n\n    # 7. Clustering Coefficient approximation (Local Density)\n    clustering_heuristic = np.zeros((n, n))\n    k_nearest = 6  # Consider only k-nearest neighbors for clustering\n    for i in range(1, n):\n        nearest_neighbors = np.argsort(distance_matrix[i, 1:])[:k_nearest] + 1  # k-nearest neighbors excluding depot, adjusting index\n        for j in range(1, n):\n            if i != j:\n                common_neighbors = 0\n                for neighbor_i in nearest_neighbors:\n                    if neighbor_i in (np.argsort(distance_matrix[j, 1:])[:k_nearest] + 1):\n                        common_neighbors += 1\n                clustering_heuristic[i, j] = common_neighbors / k_nearest\n\n    # 8. Adaptive Weighting\n    # Adjust weights based on problem characteristics (e.g., capacity tightness)\n    capacity_ratio = np.sum(demands[1:]) / (capacity * (n - 1))  # Approximate tightness\n    alpha = 0.3\n    beta = 0.15\n    gamma = 0.1\n    delta = 0.15\n    eta = 0.1\n    mu = 0.2\n\n    # Adjust alpha (distance) and beta (depot) based on capacity ratio\n    alpha += 0.1 * capacity_ratio  # Increase importance of distance if capacity is tight\n    beta -= 0.05 * capacity_ratio  # Decrease importance of going to depot if capacity is tight (more local clusters)\n\n    # Combine the heuristics with adaptive weights. Weights could be tuned by a metaheuristic\n    heuristics = alpha * distance_heuristic * demand_heuristic + beta * depot_heuristic + gamma * gravitational_heuristic + delta * savings_heuristic + mu * clustering_heuristic\n\n    # 6. Sparsification\n    # Only keep edges with a heuristic value above a certain threshold or that are among the k-nearest neighbors.\n    k_nearest = 10  # consider only k-nearest neighbors.\n    threshold = np.percentile(heuristics[heuristics > 0], 30)  # Dynamic threshold (e.g., 30th percentile)\n\n    for i in range(n):\n        # Find k-nearest neighbors\n        nearest_neighbors = np.argsort(distance_matrix[i, :])[1:k_nearest+1] #excluding self loop and depot\n\n        for j in range(n):\n            if heuristics[i, j] < threshold and j not in nearest_neighbors:\n                heuristics[i, j] = 0\n\n    # Normalize to be between 0 and 1\n    max_val = np.max(heuristics)\n    if max_val > 0:\n        heuristics = heuristics / max_val\n\n    return heuristics\n\nNow, think outside the box write a mutated function `heuristics_v2` better than current version.\nYou can use some hints below:\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, I will help you redefine \"Current self-reflection\" to design better heuristics, focusing on actionable advice and avoiding common pitfalls.\n\nHere's a refined reflection framework:\n\n*   **Keywords:** Multifactorial, Adaptive Weighting, Normalization, Sparsification, Problem Characteristics, Spatial Relationships.\n*   **Advice:** Design heuristics incorporating diverse factors beyond basic features, especially spatial relationships. Implement adaptive weighting schemes dynamically adjusted by problem characteristics. Normalize heuristic outputs.\n*   **Avoid:** Static weights, neglecting problem-specific features, unnormalized components, and fixed sparsification thresholds.\n*   **Explanation:** Combine diverse, normalized factors using problem-aware adaptive weights. Use sparsification judiciously.\n\n\nOutput code only and enclose your code with Python code block: ```python ... ```.\nI'm going to tip $999K for a better solution!"}