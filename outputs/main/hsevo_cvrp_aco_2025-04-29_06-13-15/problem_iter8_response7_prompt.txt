{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling. CVRP requires finding the shortest path that visits all given nodes and returns to the starting node. Each node has a demand and each vehicle has a capacity. The total demand of the nodes visited by a vehicle cannot exceed the vehicle capacity. When the total demand exceeds the vehicle capacity, the vehicle must return to the starting node.\nThe `heuristics` function takes as input a distance matrix (shape: n by n), Euclidean coordinates of nodes (shape: n by 2), a vector of customer demands (shape: n), and the integer capacity of vehicle capacity. It returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the distance_matrix. The depot node is indexed by 0.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"\n    Combines distance, demand, depot proximity, and sparsification.\n    Uses adaptive weights and k-NN sparsification.\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros((n, n))\n    epsilon = 1e-6\n\n    # 1. Distance component\n    distance_heuristic = 1 / (distance_matrix + epsilon)\n\n    # 2. Demand Feasibility\n    demand_heuristic = np.ones((n, n))\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                demand_heuristic[i, j] = 0\n            if demands[i] + demands[j] > capacity and i == 0:\n                demand_heuristic[i, j] = 0.1\n            elif demands[i] + demands[j] > capacity and j == 0:\n                demand_heuristic[i, j] = 0.1\n            elif i != 0 and demands[i] > capacity or j != 0 and demands[j] > capacity:\n                demand_heuristic[i,j] = 0.05\n\n    # 3. Depot Proximity\n    depot_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        avg_distance = np.sum(distance_matrix[i, 1:]) / (n - 2) if n > 2 else distance_matrix[i,0]\n        depot_preference = (avg_distance / np.max(distance_matrix)) * (demands[i] / capacity)\n        depot_heuristic[i, 0] = depot_preference\n        depot_heuristic[0, i] = depot_preference\n\n    # Combine the heuristics with adaptive weights.\n    alpha = 0.5\n    beta = 0.5\n    heuristics = alpha * distance_heuristic * demand_heuristic + beta * depot_heuristic\n\n    # Sparsification\n    k_nearest = 10 #consider only k-nearest neighbors.\n    threshold = np.percentile(heuristics[heuristics > 0], 30)\n\n    for i in range(n):\n        # Find k-nearest neighbors\n        nearest_neighbors = np.argsort(distance_matrix[i, :])[1:k_nearest+1]\n\n        for j in range(n):\n            if heuristics[i, j] < threshold and j not in nearest_neighbors:\n                heuristics[i, j] = 0\n\n    # Normalize to be between 0 and 1\n    max_val = np.max(heuristics)\n    if max_val > 0:\n        heuristics = heuristics / max_val\n\n    return heuristics\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"Combines distance, demand, angle, and depot proximity with adaptive weighting.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros((n, n))\n    normalized_demands = demands / np.max(demands)\n    depot_x, depot_y = coordinates[0]\n\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                heuristic_matrix[i, j] = 0\n                continue\n\n            distance_factor = 1 / distance_matrix[i, j] if distance_matrix[i,j] > 0 else 0\n            demand_factor = 1 - normalized_demands[j]\n            if i == 0:\n                demand_factor = 1.0\n\n            i_x, i_y = coordinates[i]\n            j_x, j_y = coordinates[j]\n\n            vector_ij = np.array([j_x - i_x, j_y - i_y])\n            vector_di = np.array([i_x - depot_x, i_y - depot_y])\n\n            vector_ij = vector_ij / (np.linalg.norm(vector_ij) + 1e-9)\n            vector_di = vector_di / (np.linalg.norm(vector_di) + 1e-9)\n\n            dot_product = np.clip(np.dot(vector_ij, vector_di), -1.0, 1.0)\n            angle = np.arccos(dot_product)\n            angle_factor = 1 - (angle / np.pi)\n\n            depot_distance_i = distance_matrix[0, i]\n            depot_distance_j = distance_matrix[0, j]\n            depot_proximity_factor = 1 / (depot_distance_i + depot_distance_j + 1e-9)\n\n            #Adaptive weighting based on demand\n            demand_weight = 0.5 + 0.5 * normalized_demands[j] #increase weight for high demand nodes\n            heuristic_matrix[i, j] = distance_factor * (demand_weight * demand_factor + (1-demand_weight) * (angle_factor * depot_proximity_factor))\n\n    #Sparsification: zero out less promising edges\n    mean_heuristic = np.mean(heuristic_matrix)\n    heuristic_matrix[heuristic_matrix < 0.5 * mean_heuristic] = 0\n\n    return heuristic_matrix\n\n### Analyze & experience\n- Comparing (1st) vs (20th), we see that the best heuristic incorporates more diverse factors, including distance, demand feasibility, depot proximity, gravitational attraction, savings heuristic, clustering coefficient, and adaptive weighting, while the worst only considers distance, demand, angle, and depot proximity. (2nd best) vs (second worst) shows similar trend. Comparing (1st) vs (2nd), we see that the best heuristic uses adaptive weighting that adjusts based on problem characteristics, such as capacity tightness, while the second best uses fixed weights based on demand ratio. (3rd) vs (4th) shows a trend where later heuristics incorporate angle-based clustering and normalize heuristic components, features absent in the earlier ones. Comparing (second worst) vs (worst), they share same logic. Overall: The best heuristics incorporate a wider range of problem-specific information, use adaptive weighting schemes, and normalize their heuristic components. Sparsification is a common feature, but its implementation and thresholding vary.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, I will help you redefine \"Current self-reflection\" to design better heuristics, focusing on actionable advice and avoiding common pitfalls.\n\nHere's a refined reflection framework:\n\n*   **Keywords:** Multifactorial, Adaptive Weighting, Normalization, Sparsification, Problem Characteristics, Spatial Relationships.\n*   **Advice:** Design heuristics incorporating diverse factors beyond basic features, especially spatial relationships. Implement adaptive weighting schemes dynamically adjusted by problem characteristics. Normalize heuristic outputs.\n*   **Avoid:** Static weights, neglecting problem-specific features, unnormalized components, and fixed sparsification thresholds.\n*   **Explanation:** Combine diverse, normalized factors using problem-aware adaptive weights. Use sparsification judiciously.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}