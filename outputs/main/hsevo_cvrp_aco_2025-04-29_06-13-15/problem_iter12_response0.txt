```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:
    """
    Heuristics for solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling.

    This version focuses on a refined combination of factors, dynamic parameter adaptation,
    and more aggressive sparsification.

    Args:
        distance_matrix (np.ndarray): Distance matrix between nodes (shape: n x n).
        coordinates (np.ndarray): Euclidean coordinates of nodes (shape: n x 2).
        demands (np.ndarray): Vector of customer demands (shape: n).
        capacity (int): Vehicle capacity.

    Returns:
        np.ndarray: Prior indicators of how promising it is to include each edge in a solution (shape: n x n).
    """
    n = distance_matrix.shape[0]
    heuristics = np.zeros((n, n))
    epsilon = 1e-6

    # 1. Distance Component (Enhanced)
    #   - Inverse square distance emphasizes shorter edges more strongly.
    distance_heuristic = 1 / (distance_matrix**2 + epsilon)

    # 2. Demand Feasibility (Refined)
    #   - Stricter penalty for immediate capacity violations.
    #   - Considers the remaining capacity of the current route (simulated).
    demand_heuristic = np.ones((n, n))
    for i in range(n):
        for j in range(n):
            if i == j:
                demand_heuristic[i, j] = 0
            if demands[i] + demands[j] > capacity and i == 0:
                demand_heuristic[i, j] = 0.01  # Stronger penalty for depot-initiated violation
            elif demands[i] + demands[j] > capacity and j == 0:
                demand_heuristic[i, j] = 0.01  # Stronger penalty for depot-initiated violation
            elif i != 0 and demands[i] > capacity or j != 0 and demands[j] > capacity:
                demand_heuristic[i,j] = 0.005

            # Simulate a simple route: depot -> i -> j
            remaining_capacity = capacity - demands[i] if i != 0 else capacity
            if i != 0 and j!= 0 and remaining_capacity < demands[j]:
                 demand_heuristic[i,j] = 0.001 #Very strong penalty


    # 3. Depot Proximity (Contextualized)
    #   - Only apply depot preference to nodes that are "isolated" (far from most others).
    #   - Adjust preference strength based on demand.
    depot_heuristic = np.zeros((n, n))
    isolation_threshold = np.mean(distance_matrix)  # Node is "isolated" if its avg dist is above this
    for i in range(1, n):
        avg_distance = np.sum(distance_matrix[i, 1:]) / (n - 2) if n > 2 else distance_matrix[i,0]
        if avg_distance > isolation_threshold:
            depot_preference = (avg_distance / np.max(distance_matrix)) * (demands[i] / capacity)**0.5 # sqrt makes demands less impact
            depot_heuristic[i, 0] = depot_preference
            depot_heuristic[0, i] = depot_preference


    # 4. Savings Heuristic (Aggressive)
    #   - Prioritize high-saving merges very aggressively.
    savings_heuristic = np.zeros((n, n))
    for i in range(1, n):
        for j in range(i + 1, n):
            savings = distance_matrix[i, 0] + distance_matrix[0, j] - distance_matrix[i, j]
            savings_heuristic[i, j] = savings**2  # Emphasize high savings
            savings_heuristic[j, i] = savings**2

    # 5. Node Similarity (Demand-Distance Tradeoff)
    # Encourage edges between nodes with similar demand/distance profiles
    similarity_heuristic = np.zeros((n, n))
    demand_normalized = demands / np.max(demands)
    distance_to_depot_normalized = distance_matrix[:, 0] / np.max(distance_matrix[:, 0])

    for i in range(1, n):
        for j in range(i + 1, n):
            demand_diff = abs(demand_normalized[i] - demand_normalized[j])
            distance_diff = abs(distance_to_depot_normalized[i] - distance_to_depot_normalized[j])
            similarity_heuristic[i, j] = 1 - (demand_diff + distance_diff) / 2 #High score when demand diff and distance_to_depot_diff are small
            similarity_heuristic[j, i] = similarity_heuristic[i, j]

    # 6. Adaptive Weighting (Mechanism-Driven)
    #   - Dynamically adjust weights based on network connectivity.
    #   - High connectivity -> emphasize savings. Low connectivity -> emphasize distance.
    connectivity = np.sum(distance_matrix < np.mean(distance_matrix)) / (n * n)  # Ratio of "close" edges
    alpha = 0.4 * (1 - connectivity)  # Distance importance (inversely proportional to connectivity)
    beta = 0.1 * (1-connectivity) # Depot proximity
    gamma = 0.4 * connectivity  # Savings importance (proportional to connectivity)
    eta = 0.1 * connectivity #Similarity heuristic

    heuristics = alpha * distance_heuristic * demand_heuristic + beta * depot_heuristic + gamma * savings_heuristic + eta * similarity_heuristic

    # 7. Sparsification (Aggressive and Dynamic)
    #   - Remove edges below a percentile threshold AND those that violate "triangle inequality".
    #   - Only keep k-nearest neighbors.
    k_nearest = 8
    threshold = np.percentile(heuristics[heuristics > 0], 50)  # Aggressive sparsification

    for i in range(n):
        nearest_neighbors = np.argsort(distance_matrix[i, :])[1:k_nearest+1]

        for j in range(n):
            if heuristics[i, j] < threshold and j not in nearest_neighbors:
                heuristics[i, j] = 0
            #Triangle inequality check
            for k in range(n):
              if distance_matrix[i,j] > distance_matrix[i,k] + distance_matrix[k,j]:
                heuristics[i,j] = 0
                break



    # Normalize
    max_val = np.max(heuristics)
    if max_val > 0:
        heuristics = heuristics / max_val

    return heuristics
```
