{"system": "You are an expert in the domain of optimization heuristics. Your task is to design heuristics that can effectively solve optimization problems.\nYour response outputs Python code and nothing else. Format your code as a Python code string: \"```python ... ```\".\n", "user": "You are an expert in the domain of optimization heuristics. Your task is to write a heuristics function for Solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling. CVRP requires finding the shortest path that visits all given nodes and returns to the starting node. Each node has a demand and each vehicle has a capacity. The total demand of the nodes visited by a vehicle cannot exceed the vehicle capacity. When the total demand exceeds the vehicle capacity, the vehicle must return to the starting node.\nThe `heuristics` function takes as input a distance matrix (shape: n by n), Euclidean coordinates of nodes (shape: n by 2), a vector of customer demands (shape: n), and the integer capacity of vehicle capacity. It returns prior indicators of how promising it is to include each edge in a solution. The return is of the same shape as the distance_matrix. The depot node is indexed by 0.\n\n\n### Better code\ndef heuristics_v0(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"\n    Heuristics for solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling.\n\n    This version incorporates:\n    1. Distance: Edges with shorter distances are preferred.\n    2. Demand Feasibility: Penalizes edges that would immediately violate capacity constraints.\n    3. Depot Proximity: Prioritizes returning to the depot from nodes that are far from other customers and have high demand.\n    4. Gravitational Attraction: Mimics the gravitational attraction of black holes.\n    5. Angle Prioritization:  Prioritizes edges that create smaller angles at intersections, promoting smoother routes.\n    6. Sparsification: Sets unpromising edges to zero to reduce search space.\n    7. Adaptive Scaling: Adaptively scales the influence of different heuristic components based on problem characteristics.\n\n    Args:\n        distance_matrix (np.ndarray): Distance matrix between nodes (shape: n x n).\n        coordinates (np.ndarray): Euclidean coordinates of nodes (shape: n x 2).\n        demands (np.ndarray): Vector of customer demands (shape: n). The demand of depot is demands[0].\n        capacity (int): Vehicle capacity.\n\n    Returns:\n        np.ndarray: Prior indicators of how promising it is to include each edge in a solution (shape: n x n).\n    \"\"\"\n    n = distance_matrix.shape[0]\n    heuristics = np.zeros((n, n))\n\n    # Add a small value to avoid division by zero\n    epsilon = 1e-6\n\n    # 1. Distance component (inverse relationship)\n    distance_heuristic = 1 / (distance_matrix + epsilon)\n\n    # 2. Demand Feasibility component\n    demand_heuristic = np.ones((n, n))\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                demand_heuristic[i, j] = 0  # No self-loops\n            if demands[i] + demands[j] > capacity and i == 0:\n                demand_heuristic[i, j] = 0.1\n            elif demands[i] + demands[j] > capacity and j == 0:\n                demand_heuristic[i, j] = 0.1\n            elif i != 0 and demands[i] > capacity or j != 0 and demands[j] > capacity:\n                 demand_heuristic[i,j] = 0.05\n\n\n    # 3. Depot Proximity\n    depot_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        avg_distance = np.sum(distance_matrix[i, 1:]) / (n - 2) if n > 2 else distance_matrix[i,0]\n        depot_preference = (avg_distance / np.max(distance_matrix)) * (demands[i] / capacity)\n        depot_heuristic[i, 0] = depot_preference\n        depot_heuristic[0, i] = depot_preference\n\n    # 4. Gravitational Attraction\n    gravitational_heuristic = np.zeros((n, n))\n    gravitational_constant = 1.0\n    for i in range(1, n):\n        for j in range(1, n):\n            mass_i = demands[i]\n            mass_j = demands[j]\n            if i == j:\n                gravitational_heuristic[i,j] = 0\n                continue\n            gravitational_heuristic[i, j] = gravitational_constant * (mass_i * mass_j) / (distance_matrix[i, j]**2 + epsilon)\n\n\n    # 5. Angle Prioritization: Smaller angles are preferred (smoother routes).  Only calculate for non-depot nodes.\n    angle_heuristic = np.zeros((n, n))\n    for i in range(1, n):\n        for j in range(1, n):\n            if i != j:\n                #Find a k such that k is close to both i and j.\n                best_k = -1\n                min_dist = float('inf')\n                for k in range(1, n):\n                    if k != i and k != j:\n                        dist = distance_matrix[i, k] + distance_matrix[j, k]\n                        if dist < min_dist:\n                            min_dist = dist\n                            best_k = k\n                if best_k != -1:\n                    # cosine rule\n                    a = distance_matrix[i,j]\n                    b = distance_matrix[i, best_k]\n                    c = distance_matrix[j, best_k]\n                    angle = np.arccos((b**2 + c**2 - a**2) / (2 * b * c + epsilon))\n                    angle_heuristic[i,j] = 1 - (angle / np.pi) #Smaller angle, bigger value\n\n    # 6. Sparsification: Remove edges that are too long relative to average distance. Adaptively determined.\n    avg_distance = np.sum(distance_matrix) / (n * (n - 1))\n    sparsification_threshold = 2.5 * avg_distance  # Tune this parameter.\n    sparsification_mask = distance_matrix <= sparsification_threshold\n\n    # Combine the heuristics with adaptive scaling.  Weights can be tuned.\n    alpha = 0.4  # Distance weight\n    beta = 0.2  # Demand weight\n    gamma = 0.15 # Depot weight\n    delta = 0.15 # Gravitational weight\n    theta = 0.1 # Angle weight\n    heuristics = alpha * distance_heuristic * demand_heuristic + beta * demand_heuristic + gamma * depot_heuristic + delta * gravitational_heuristic + theta * angle_heuristic\n\n    # Apply sparsification\n    heuristics = heuristics * sparsification_mask\n\n    # Normalize to be between 0 and 1\n    max_val = np.max(heuristics)\n    if max_val > 0:\n        heuristics = heuristics / max_val\n\n    return heuristics\n\n### Worse code\ndef heuristics_v1(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:\n\n    \"\"\"Combines distance, demand, angle to depot, and angle between nodes to create a heuristic.\"\"\"\n    n = distance_matrix.shape[0]\n    heuristic_matrix = np.zeros((n, n))\n\n    distance_weight = 1.0\n    demand_weight = 0.5\n    angle_weight = 0.3\n    capacity_penalty = 2.0\n\n    depot_x, depot_y = coordinates[0]\n    angles = np.zeros(n)\n\n    for i in range(1, n):\n        x, y = coordinates[i]\n        dx = x - depot_x\n        dy = y - depot_y\n        angles[i] = np.arctan2(dy, dx)\n\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                heuristic_matrix[i, j] = 0\n                continue\n\n            distance_term = distance_weight / distance_matrix[i, j] if distance_matrix[i,j] > 0 else 0\n            demand_term = (1 - demand_weight * demands[j] / capacity)\n\n            if i == 0:\n              angle_term = 0\n            else:\n              vector_ij = coordinates[j] - coordinates[i]\n              vector_j0 = coordinates[0] - coordinates[j]\n              norm_ij = np.linalg.norm(vector_ij)\n              norm_j0 = np.linalg.norm(vector_j0)\n              if norm_ij > 0 and norm_j0 > 0:\n                dot_product = np.dot(vector_ij, vector_j0)\n                cosine_angle = dot_product / (norm_ij * norm_j0)\n                angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n                angle_term = (1 - angle_weight * angle / np.pi)\n              else:\n                angle_term = 0\n\n            if demands[j] > (capacity/2):\n               demand_term = demand_term / capacity_penalty\n\n            angle_diff = abs(angles[i]-angles[j])\n            angle_depot_term =  angle_diff/np.pi\n\n            heuristic_matrix[i, j] = distance_term * demand_term * angle_term + 0.1 * angle_depot_term # Combine factors, depot angle has lower weight\n\n    return heuristic_matrix\n\n### Analyze & experience\n- Comparing (1st) vs (2nd), there's no difference.\nComparing (3rd) vs (4th), there's no difference.\nComparing (1st) vs (5th), the former utilizes multiple heuristics (distance, demand feasibility, depot proximity, gravitational attraction, savings, sparsification) with adaptive weights, while the latter combines distance, demand, angle to depot, and angle between nodes with fixed weights and capacity penalty.\nComparing (5th) vs (6th), there's no difference.\nComparing (5th) vs (7th), there's no difference.\nComparing (1st) vs (8th), (1st) uses sparsification based on k-nearest neighbors and a dynamic threshold, (8th) uses simpler sparsification based on a mean threshold. (1st) combines with fixed weights while (8th) uses adaptive weighting.\nComparing (1st) vs (9th), (1st) is more complex, (9th) appears simpler.\nComparing (9th) vs (10th), there's no difference.\nComparing (9th) vs (11th), there's no difference.\nComparing (1st) vs (12th), (1st) uses more diverse heuristics like gravitational attraction and savings, along with k-NN sparsification, while (12th) focuses on distance, demand, spatial clustering and depot attraction. Adaptive scaling is present in both.\nComparing (12th) vs (13th), there's no difference.\nComparing (12th) vs (14th), there's no difference.\nComparing (1st) vs (15th), (1st) uses more heuristics and better sparsification.\nComparing (15th) vs (16th), there's no difference.\nComparing (1st) vs (17th), (1st) has more diverse heuristics and better sparsification. (17th) uses unusual demand scaling with distance.\nComparing (1st) vs (18th), (1st) has more diverse heuristics and better sparsification.\nComparing (1st) vs (19th), (1st) is more complex and includes sparsification while (19th) lacks it.\nComparing (19th) vs (20th), there's no difference.\nComparing (second worst) vs (worst), (19th) and (20th) are identical.\n\nOverall: The better heuristics combine multiple factors (distance, demand, depot proximity, angles, savings) using adaptive weights. Sparsification using k-NN or dynamic thresholds is preferred. Simpler heuristics focusing on fewer factors or fixed weights tend to perform worse.\n- - Try combining various factors to determine how promising it is to select an edge.\n- Try sparsifying the matrix by setting unpromising elements to zero.\nOkay, here's a refined perspective on self-reflection to guide heuristic design, focusing on actionable insights:\n\n*   **Keywords:** Factor diversity, adaptive weighting, normalization, spatial relationships, sparsification, problem characteristics.\n\n*   **Advice:** Explore clustering techniques, gravitational attraction principles, and rigorous normalization strategies within your heuristics. Adapt weights based on real-time problem characteristics, not just initial assumptions.\n\n*   **Avoid:** Solely relying on distance/demand, static weighting schemes, ignoring spatial context, premature convergence.\n\n*   **Explanation:** Broadening the factor base and adapting to problem nuances are crucial for robust and high-performing heuristics. Normalization stabilizes weighting.\n\n\nYour task is to write an improved function `heuristics_v2` by COMBINING elements of two above heuristics base Analyze & experience.\nOutput the code within a Python code block: ```python ... ```, has comment and docstring (<50 words) to description key idea of heuristics design.\n\nI'm going to tip $999K for a better heuristics! Let's think step by step."}