```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray, coordinates: np.ndarray, demands: np.ndarray, capacity: int) -> np.ndarray:
    """
    Heuristics for solving Capacitated Vehicle Routing Problem (CVRP) via stochastic solution sampling.

    This version incorporates advanced strategies over v1, focusing on adaptive learning and
    problem-specific characteristics.

    Key improvements include:

    1.  Adaptive Sparsification: Dynamically adjusts sparsification based on problem tightness.
    2.  Enhanced Node Similarity: Considers both demand and spatial proximity for node clustering.
    3.  Contextual Depot Prioritization: Uses demand context to prioritize depot returns.
    4.  Refined Gravitational Model: Modifies gravitational forces based on a normalized demand scale.
    5.  Dynamic Weight Adjustment: Integrates a neural network-inspired approach to adaptively adjust
        heuristic weights based on problem characteristics.
    6.  Comprehensive Capacity Slack Handling: Leverages capacity slack for better route optimization.
    7.  Probabilistic Edge Selection Bias: Biases towards edges that lead to more balanced routes.

    Args:
        distance_matrix (np.ndarray): Distance matrix between nodes (shape: n x n).
        coordinates (np.ndarray): Euclidean coordinates of nodes (shape: n x 2).
        demands (np.ndarray): Vector of customer demands (shape: n). The demand of depot is demands[0].
        capacity (int): Vehicle capacity.

    Returns:
        np.ndarray: Prior indicators of how promising it is to include each edge in a solution (shape: n x n).
    """
    n = distance_matrix.shape[0]
    heuristics = np.zeros((n, n))
    epsilon = 1e-6

    # 1. Adaptive Distance Scaling
    total_demand = np.sum(demands[1:])
    capacity_ratio = total_demand / (capacity * (n - 1))
    distance_scale = 1.0 + 0.5 * capacity_ratio
    distance_heuristic = 1 / (distance_matrix * distance_scale + epsilon)
    distance_heuristic = (distance_heuristic - np.min(distance_heuristic)) / (np.max(distance_heuristic) - np.min(distance_heuristic) + epsilon)  # Normalize

    # 2. Refined Demand Feasibility
    demand_heuristic = np.ones((n, n))
    for i in range(n):
        for j in range(n):
            if i == j:
                demand_heuristic[i, j] = 0
            if demands[i] + demands[j] > capacity and i == 0:
                demand_heuristic[i, j] = 0.1
            elif demands[i] + demands[j] > capacity and j == 0:
                demand_heuristic[i, j] = 0.1
            elif i != 0 and demands[i] > capacity or j != 0 and demands[j] > capacity:
                demand_heuristic[i,j] = 0.05
    demand_heuristic = (demand_heuristic - np.min(demand_heuristic)) / (np.max(demand_heuristic) - np.min(demand_heuristic) + epsilon)  # Normalize

    # 3. Contextual Depot Prioritization
    depot_heuristic = np.zeros((n, n))
    urgency_factor = 5.0
    for i in range(1, n):
        avg_distance = np.sum(distance_matrix[i, 1:]) / (n - 2) if n > 2 else distance_matrix[i,0]
        urgency = np.exp(urgency_factor * (avg_distance / np.max(distance_matrix)) * (demands[i] / capacity))
        depot_heuristic[i, 0] = urgency
        depot_heuristic[0, i] = urgency
    depot_heuristic = (depot_heuristic - np.min(depot_heuristic)) / (np.max(depot_heuristic) - np.min(depot_heuristic) + epsilon)  # Normalize


    # 4. Refined Gravitational Attraction
    gravitational_heuristic = np.zeros((n, n))
    avg_demand = np.mean(demands[1:])
    adaptive_gravitational_constant = 1.0 + 0.2 * (avg_demand / capacity)
    normalized_demands = demands / np.max(demands)
    for i in range(1, n):
        for j in range(1, n):
            if i == j:
                gravitational_heuristic[i,j] = 0
                continue
            mass_i = normalized_demands[i]
            mass_j = normalized_demands[j]
            gravitational_heuristic[i, j] = adaptive_gravitational_constant * (mass_i * mass_j) / (distance_matrix[i, j]**2 + epsilon)
    gravitational_heuristic = (gravitational_heuristic - np.min(gravitational_heuristic)) / (np.max(gravitational_heuristic) - np.min(gravitational_heuristic) + epsilon)  # Normalize


    # 5. Savings Heuristic with Lookahead
    savings_heuristic = np.zeros((n, n))
    lookahead_neighbors = 5
    for i in range(1, n):
        for j in range(i + 1, n):
            savings = distance_matrix[i, 0] + distance_matrix[0, j] - distance_matrix[i, j]
            neighbor_i = np.argsort(distance_matrix[i, 1:])[:lookahead_neighbors] + 1
            neighbor_j = np.argsort(distance_matrix[j, 1:])[:lookahead_neighbors] + 1
            future_savings = 0
            for ni in neighbor_i:
                for nj in neighbor_j:
                    future_savings += distance_matrix[ni, 0] + distance_matrix[0, nj] - distance_matrix[ni, nj]
            savings += 0.1 * future_savings / (lookahead_neighbors**2 + epsilon)
            savings_heuristic[i, j] = savings
            savings_heuristic[j, i] = savings
    savings_heuristic = (savings_heuristic - np.min(savings_heuristic)) / (np.max(savings_heuristic) - np.min(savings_heuristic) + epsilon)  # Normalize


    # 6. Enhanced Node Similarity (Demand + Spatial)
    similarity_heuristic = np.zeros((n, n))
    for i in range(1, n):
        for j in range(i + 1, n):
            demand_similarity = 1 - abs(demands[i] - demands[j]) / (capacity + epsilon)
            spatial_similarity = np.exp(-distance_matrix[i, j] / np.mean(distance_matrix))
            similarity_heuristic[i, j] = demand_similarity * spatial_similarity
            similarity_heuristic[j, i] = similarity_heuristic[i, j]
    similarity_heuristic = (similarity_heuristic - np.min(similarity_heuristic)) / (np.max(similarity_heuristic) - np.min(similarity_heuristic) + epsilon)  # Normalize

    # 7. Capacity Slack Aware Weight Adjustments
    capacity_slack = 1 - (total_demand / (capacity * (n - 1)))

    # 8. Dynamic Weight Adjustment
    # Simplified "Neural Network" - adjusts weights based on capacity slack and capacity ratio
    w_distance = 0.3 + 0.2 * capacity_slack - 0.1 * capacity_ratio
    w_depot = 0.15 - 0.1 * capacity_slack + 0.05 * capacity_ratio
    w_gravitational = 0.2 + 0.1 * capacity_slack
    w_savings = 0.15 + 0.05 * capacity_slack
    w_similarity = 0.2 - 0.05 * capacity_ratio

    w_distance = max(0, min(w_distance, 1))
    w_depot = max(0, min(w_depot, 1))
    w_gravitational = max(0, min(w_gravitational, 1))
    w_savings = max(0, min(w_savings, 1))
    w_similarity = max(0, min(w_similarity, 1))

    # Renormalize weights to sum to 1
    total_weight = w_distance + w_depot + w_gravitational + w_savings + w_similarity
    w_distance /= total_weight
    w_depot /= total_weight
    w_gravitational /= total_weight
    w_savings /= total_weight
    w_similarity /= total_weight


    heuristics = (w_distance * distance_heuristic +
                  w_depot * depot_heuristic +
                  w_gravitational * gravitational_heuristic +
                  w_savings * savings_heuristic +
                  w_similarity * similarity_heuristic)

    # 9. Adaptive Sparsification
    sparsification_threshold = 35 - 10 * capacity_slack
    sparsification_threshold = max(5, min(sparsification_threshold, 45))  # Clamp between 5 and 45
    threshold = np.percentile(heuristics[heuristics > 0], sparsification_threshold)
    k_nearest = 10

    for i in range(n):
        nearest_neighbors = np.argsort(distance_matrix[i, :])[1:k_nearest + 1]
        for j in range(n):
            if heuristics[i, j] < threshold and j not in nearest_neighbors:
                heuristics[i, j] = 0

    # 10. Probabilistic Edge Selection Bias
    # Bias towards edges that, when included, tend to balance route lengths/demands
    route_balance_bias = np.zeros((n, n))
    for i in range(1, n):
        for j in range(1, n):
            if i != j:
                # Estimate the impact of including edge (i, j) on the balance of demands
                # A very crude estimate - needs significant refinement
                demand_diff = abs(demands[i] - demands[j])
                route_balance_bias[i, j] = np.exp(-demand_diff / (avg_demand + epsilon)) # Prefer edges that connect nodes with similar demand.
                route_balance_bias[j, i] = route_balance_bias[i, j]

    route_balance_bias = (route_balance_bias - np.min(route_balance_bias)) / (np.max(route_balance_bias) - np.min(route_balance_bias) + epsilon)  # Normalize
    heuristics = 0.9 * heuristics + 0.1 * route_balance_bias

    # Normalize
    max_val = np.max(heuristics)
    if max_val > 0:
        heuristics = heuristics / max_val

    return heuristics
```
