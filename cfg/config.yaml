defaults:
  - _self_
  - problem: tsp_aco
  - override hydra/output: local

hydra:
  job:
    chdir: True

# The chosen algorithm
algorithm: hsevo

# LLM parameters
model: 'nvidia_nim/meta/llama-4-maverick-17b-128e-instruct' # LLM model
temperature: 1 # temperature for chat completion

# Main GA loop parameters
max_token: 250000
max_fe: 100 # maximum number of function evaluations
max_request: 200
pop_size: 10 # population size for GA
init_pop_size: 30 # initial population size for GA
mutation_rate: 0.5 # mutation rate for GA
timeout: 50 # timeout for evaluation of a single heuristic
warm_up: 2

# Harmony search
hm_size: 5
hmcr: 0.7
par: 0.5
bandwidth: 0.2
max_iter: 5

# behavior descriptor
bd_list: ["SLOC", "cyclomatic_complexity", "halstead", "mi", "token_count"]
bd_step: [3, 1, 50, 5, 30]